{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcH-jWf5-xmA"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW5SHpUdgEXP",
        "outputId": "933c9bf1-f6f1-4039-abd1-08250d6baf76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "download = False\n",
        "\n",
        "if not download:\n",
        "  drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNBpiyfVat3Y",
        "outputId": "1ffb0973-0f1d-4a03-b8ca-e1c6e989cd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtdEBKATg1FL",
        "outputId": "06602031-6cab-4eca-e9b5-502dc63a83af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/davej23/image-segmentation-keras.git\n",
            "  Cloning https://github.com/davej23/image-segmentation-keras.git to /tmp/pip-req-build-zq8x9jjv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/davej23/image-segmentation-keras.git /tmp/pip-req-build-zq8x9jjv\n",
            "  Resolved https://github.com/davej23/image-segmentation-keras.git to commit e01b0a8d5859854cd9d259a618829889166439f5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.14.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.10/dist-packages (1.9.4.post1)\n",
            "Collecting pyshp\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_unet_collection\n",
            "  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easyprocess (from pyunpack)\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting entrypoint2 (from pyunpack)\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation-models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting image-classifiers==1.0.0 (from segmentation-models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation-models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.19.3)\n",
            "Collecting h5py<=2.10.0 (from keras-segmentation==0.3.0)\n",
            "  Downloading h5py-2.10.0.tar.gz (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from keras-segmentation==0.3.0) (2.12.0)\n",
            "Collecting imageio==2.5.0 (from keras-segmentation==0.3.0)\n",
            "  Downloading imageio-2.5.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from keras-segmentation==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from keras-segmentation==0.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-segmentation==0.3.0) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.5.0->keras-segmentation==0.3.0) (9.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from rioxarray) (23.1)\n",
            "Collecting rasterio>=1.2 (from rioxarray)\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray>=0.17 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (2022.12.0)\n",
            "Requirement already satisfied: pyproj>=2.2 in /usr/local/lib/python3.10/dist-packages (from rioxarray) (3.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (8.1.6)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->keras-segmentation==0.3.0) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n",
            "Collecting affine (from rasterio>=1.2->rioxarray)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting snuggs>=1.4.1 (from rasterio>=1.2->rioxarray)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->rioxarray) (67.7.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2023.7.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio>=1.2->rioxarray) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->keras-segmentation==0.3.0) (1.4.4)\n",
            "Building wheels for collected packages: keras-segmentation, h5py\n",
            "  Building wheel for keras-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-py3-none-any.whl size=34365 sha256=ae8739f3045af0cc73ce49c676569b998f456ffa49101dd0a6ca27dbbf6fa6c4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q9zg0vms/wheels/5c/59/c2/c09ffefb9394a1ee78b237aeaf84b269daf168d8dcf8e4ab0c\n",
            "  Building wheel for h5py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h5py: filename=h5py-2.10.0-cp310-cp310-linux_x86_64.whl size=4717493 sha256=009622d3c9e3301a5ee2a4d8ce7903d03d9a6fdc2655fdf65a8f3ca01ba0097a\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/bc/58/0d0c6056e1339f40188d136cd838c6554d9c17545196dd9110\n",
            "Successfully built keras-segmentation h5py\n",
            "Installing collected packages: rarfile, patool, entrypoint2, easyprocess, snuggs, pyunpack, pyshp, keras_unet_collection, imageio, h5py, affine, rasterio, keras-applications, image-classifiers, efficientnet, segmentation-models, rioxarray, keras-segmentation\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.1\n",
            "    Uninstalling imageio-2.25.1:\n",
            "      Successfully uninstalled imageio-2.25.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "Successfully installed affine-2.4.0 easyprocess-1.1 efficientnet-1.0.0 entrypoint2-1.1 h5py-2.10.0 image-classifiers-1.0.0 imageio-2.5.0 keras-applications-1.0.8 keras-segmentation-0.3.0 keras_unet_collection-0.1.13 patool-1.12 pyshp-2.3.1 pyunpack-0.3 rarfile-4.0 rasterio-1.3.8 rioxarray-0.14.1 segmentation-models-1.0.1 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "import os, os.path\n",
        "!pip install pyunpack patool rarfile segmentation-models git+https://github.com/davej23/image-segmentation-keras.git rioxarray geopandas fiona pyshp keras_unet_collection\n",
        "from matplotlib import pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.windows import get_data_window\n",
        "from rasterio.windows import Window\n",
        "import rasterio.mask\n",
        "import numpy as np\n",
        "import rioxarray as rxr\n",
        "from skimage.io import imread\n",
        "import tensorflow as tf\n",
        "from osgeo import gdal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwFe_GbATgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a80f2f6-47f0-431f-9301-31183c7233fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'drive/Mydrive/Output': No such file or directory\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!cp -r drive/Mydrive/Output drive/MyDrive/paramo_ml/Output ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usgwoZ-xObox",
        "outputId": "d6f45900-941a-4897-f689-7d5d244f5aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot open 'drive/MyDrive/paramo_ml/Output/metrics_im_only_trainedmore.gsheet' for reading: Operation not supported\n",
            "cp: cannot open 'drive/MyDrive/paramo_ml/Output/metrics_im_only_512x512_trainedmorept2.gsheet' for reading: Operation not supported\n",
            "cp: cannot open 'drive/MyDrive/paramo_ml/Output/metrics_im_only_512x512_short_new.gsheet' for reading: Operation not supported\n",
            "cp: cannot open 'drive/MyDrive/paramo_ml/Output/results.gdoc' for reading: Operation not supported\n",
            "cp: cannot open 'drive/MyDrive/paramo_ml/Output/metrics_im_only_512x512_avgs.gsheet' for reading: Operation not supported\n"
          ]
        }
      ],
      "source": [
        "!cp -r drive/MyDrive/paramo_ml/Output ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2TNeATnQzun"
      },
      "outputs": [],
      "source": [
        "def save_to_drive():\n",
        "  !cp -r Output/ sv_para/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkqtexD50bf"
      },
      "source": [
        "# **Data preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j25At9Ag87wb"
      },
      "source": [
        "### Loading entire image into memory\n",
        "\n",
        "\n",
        "*   Reads entire image into memory\n",
        "*   Splits into HxW tiles\n",
        "*   Finds good short masks (tiles with short plants inside)\n",
        "*   Finds good tall masks\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWCeZ4BrLN9d"
      },
      "outputs": [],
      "source": [
        "def load_and_split_image(path, tileSize, offset=(0, 0), channels=3):\n",
        "    full_img_og = np.array(rxr.open_rasterio(path))\n",
        "    full_img_og = full_img_og.T\n",
        "\n",
        "    if offset[0] == 0 and offset[1] == 0:\n",
        "        full_img = full_img_og[:, :, :]\n",
        "    else:\n",
        "        full_img = full_img_og[offset[0]:offset[1], offset[0]:offset[1], :]\n",
        "\n",
        "    all_ims = []\n",
        "    for i in range(full_img.shape[0] // tileSize):\n",
        "        for j in range(full_img.shape[1] // tileSize):\n",
        "            all_ims.append(full_img[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,channels))\n",
        "\n",
        "    return all_ims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSB28uDucLkZ",
        "outputId": "7ea3cf6c-6872-4c39-aa55-db329c553928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "\n",
        "# 修改工作路径\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "path = \"/content/drive/MyDrive\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfcg8f7Xcjzo",
        "outputId": "aafde890-d689-428b-cb47-03905784881a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZCsHPVMgQGY",
        "outputId": "50984ad4-32ed-4535-c822-c3c219a9543d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16789 32.791015625\n",
            "206\n",
            "206\n",
            "147\n",
            "147\n"
          ]
        }
      ],
      "source": [
        "tileSize = 512\n",
        "#tileSize = 128  #(some models need)\n",
        "# Ingest tall plant mask\n",
        "full_mask_og = np.array(rxr.open_rasterio('labels/paramo_label_final/tall_mask_new.tif'))\n",
        "full_mask_og = full_mask_og.T\n",
        "# full_mask = full_mask_og[5000:13192, 5000:13192, :] # This is a region which contains tall and short plants\n",
        "full_mask = full_mask_og[:, :, :]\n",
        "\n",
        "# Ingest short plant mask\n",
        "full_mask_og_short = np.array(rxr.open_rasterio('labels/paramo_label_final/short_mask_new.tif'))\n",
        "full_mask_og_short = full_mask_og_short.T\n",
        "# full_mask_short = full_mask_og_short[5000:13192, 5000:13192, :]\n",
        "full_mask_short = full_mask_og_short[:, :, :]\n",
        "\n",
        "# Split into tileSize x tileSize images and masks\n",
        "all_masks = []\n",
        "for i in range(full_mask.shape[0] // tileSize):\n",
        "  for j in range(full_mask.shape[1] // tileSize):\n",
        "    all_masks.append(full_mask[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,1))\n",
        "\n",
        "# Find indices of masks and images which have at least one plant in\n",
        "# masks = []\n",
        "# ind = []\n",
        "# tot = []\n",
        "# for i in range(len(all_masks)):\n",
        "#   if np.sum(all_masks[i]) > 0: # If sum of mask pixels is > 0, some plants in\n",
        "#     masks.append(all_masks[i])\n",
        "#     tot.append([i, np.sum(all_masks[i])])\n",
        "#     ind.append(i)\n",
        "\n",
        "## Uncomment the next three lines if wanting to use masks with top n_top plants in\n",
        "#n_top = 100\n",
        "#tot = sorted(tot, key=lambda x: x[1], reverse=True)\n",
        "#tot = tot[0:n_top]\n",
        "#ind = [n[0] for n in tot]\n",
        "\n",
        "# Read image data\n",
        "full_img_og = np.array(rxr.open_rasterio('images/drone_paramo/DUI-01-1_ortho.tif'))\n",
        "full_img_og = full_img_og.T\n",
        "# full_img = full_img_og[5000:13192, 5000:13192, :]\n",
        "full_img = full_img_og[:, :, :]\n",
        "\n",
        "print(len(full_img), len(full_img)/tileSize)\n",
        "\n",
        "# Break into smaller subimages\n",
        "all_images = []\n",
        "for i in range(full_img.shape[0] // tileSize):\n",
        "  for j in range(full_img.shape[1] // tileSize):\n",
        "    all_images.append(full_img[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,3))\n",
        "\n",
        "# Removing edge tiles (background 0s)\n",
        "good = []\n",
        "for i,im in enumerate(all_images):\n",
        "    if 0 not in im:\n",
        "        good.append(i)\n",
        "\n",
        "all_images = [all_images[n] for n in good]\n",
        "all_masks = [all_masks[n] for n in good]\n",
        "\n",
        "\n",
        "# Extract the HxW images which have plants in\n",
        "tall_images = []\n",
        "masks2 = []\n",
        "for i,im in enumerate(all_masks):\n",
        "    if 1 in im:\n",
        "        tall_images.append(all_images[i])\n",
        "        masks2.append(im)\n",
        "print(len(tall_images))\n",
        "print(len(masks2))\n",
        "\n",
        "tall_images = [n/255 for n in tall_images] # Normalise images\n",
        "\n",
        "# Split short mask into HxW submasks\n",
        "all_short_masks = []\n",
        "for i in range(full_mask_short.shape[0] // tileSize):\n",
        "  for j in range(full_mask_short.shape[1] // tileSize):\n",
        "    all_short_masks.append(full_mask_short[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,1))\n",
        "\n",
        "all_short_masks = [all_short_masks[n] for n in good]\n",
        "\n",
        "short_images = []\n",
        "masks_short = []\n",
        "for i,im in enumerate(all_short_masks):\n",
        "    if 1 in im:\n",
        "        short_images.append(all_images[i])\n",
        "        masks_short.append(im)\n",
        "\n",
        "short_images = [n/255 for n in short_images]\n",
        "print(len(short_images))\n",
        "print(len(masks_short))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISedywnlSVUn"
      },
      "source": [
        "\n",
        "*   images => contains 512x512 RGB images with plants in\n",
        "*   masks2 => contains 512x512 mask of tall plants\n",
        "*   masks_short => contains 512x512 mask of short plants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_QOaB7FDxK9"
      },
      "source": [
        "## **Splitting apart**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNS-AYvTD0I2"
      },
      "outputs": [],
      "source": [
        "def split_sep(images, masks, split=0.3):\n",
        "    #  Splitting\n",
        "    splitRange = math.ceil(len(images)*(1-split))\n",
        "\n",
        "    z = list(zip(images, masks))\n",
        "    random.shuffle(z)\n",
        "\n",
        "    shuff_images, shuff_masks = zip(*z)\n",
        "\n",
        "    to_train = [i for i in range(splitRange)]\n",
        "    to_test = [i for i in range(splitRange, len(masks))]\n",
        "\n",
        "    xTrain = []\n",
        "    xTest = []\n",
        "\n",
        "    yTrain = []\n",
        "    yTest = []\n",
        "\n",
        "    for i in to_train:\n",
        "        xTrain.append(shuff_images[i])\n",
        "        yTrain.append(shuff_masks[i])\n",
        "\n",
        "    for i in to_test:\n",
        "        xTest.append(shuff_images[i])\n",
        "        yTest.append(shuff_masks[i])\n",
        "\n",
        "    return (xTrain, yTrain), (xTest, yTest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gZdZpfoXqV-"
      },
      "source": [
        "## **Data generator to provide NN with batches from arrays defined above**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsP9D0PtoPqh",
        "outputId": "306b1dba-082e-46aa-c25f-d618e6ce2adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n",
            "145 145\n",
            "103 103\n",
            "Testing\n",
            "61 61\n",
            "44 44\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend\n",
        "import math\n",
        "import gc\n",
        "\n",
        "def adjustData(img, mask, num_class):\n",
        "\n",
        "    mask[mask > 0.5] = 1 # FOREST\n",
        "    mask[mask <= 0.5] = 0 # NON-FOREST\n",
        "\n",
        "    return (img,mask)\n",
        "\n",
        "def TrainGenerator(batch_size,\n",
        "                   image_array,\n",
        "                   mask_array,\n",
        "                   aug_dict,\n",
        "                   image_save_prefix  = \"image\",\n",
        "                   mask_save_prefix  = \"mask\",\n",
        "                   num_class = 2,\n",
        "                   save_to_dir = None,\n",
        "                   target_size = (tileSize,tileSize),\n",
        "                   seed = 1):\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "    image_generator = image_datagen.flow(image_array,\n",
        "    batch_size = batch_size,\n",
        "    save_to_dir = save_to_dir,\n",
        "    save_prefix = image_save_prefix,\n",
        "    seed = seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow(mask_array,\n",
        "    batch_size = batch_size,\n",
        "    save_to_dir = save_to_dir,\n",
        "    save_prefix = mask_save_prefix,\n",
        "    seed = seed)\n",
        "\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "    for (img,mask) in train_generator:\n",
        "        img, mask = img, mask\n",
        "        yield (img, mask)\n",
        "\n",
        "data_gen_args = dict(rotation_range=180,\n",
        "                    width_shift_range=0.5,\n",
        "                    height_shift_range=0.5,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.25,\n",
        "                    horizontal_flip=True,\n",
        "                    vertical_flip = True,\n",
        "                    fill_mode='reflect',\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# Looping through image, removing masks and tiles if 0 is present in tile\n",
        "# Makes it possible to pass all input data\n",
        "(xTrain, yTrainTall), (xTest, yTestTall) = split_sep(tall_images, masks2)\n",
        "(xTrainShort, yTrainShort), (xTestShort, yTestShort) = split_sep(short_images, masks_short)\n",
        "\n",
        "print(\"Training\")\n",
        "print(len(xTrain), len(yTrainTall))\n",
        "print(len(xTrainShort), len(yTrainShort))\n",
        "\n",
        "print(\"Testing\")\n",
        "print(len(xTest), len(yTestTall))\n",
        "print(len(xTestShort), len(yTestShort))\n",
        "\n",
        "images_rgb = np.stack([n[:,:,0:3] for n in xTrain])\n",
        "images_rgb_short = np.stack([n[:,:,0:3] for n in xTrainShort])\n",
        "\n",
        "tall_masks = np.stack(yTrainTall)\n",
        "short_masks = np.stack(yTrainShort)\n",
        "\n",
        "# # Splitting\n",
        "# splitRange = math.ceil(len(tall_images)*0.7)\n",
        "\n",
        "# print(len(tall_images), len(tall_images))\n",
        "\n",
        "# z = list(zip(tall_images, masks2))\n",
        "# random.shuffle(z)\n",
        "\n",
        "# shuff_images, shuff_masks2 = zip(*z)\n",
        "\n",
        "# to_train = [i for i in range(splitRange)]\n",
        "# to_test = [i for i in range(splitRange, len(tall_images))]\n",
        "\n",
        "# len(tall_images)\n",
        "# len(to_train)\n",
        "# len(to_test)\n",
        "\n",
        "# xTrain = []\n",
        "# xTest = []\n",
        "\n",
        "# yTrainShort = []\n",
        "# yTestShort = []\n",
        "\n",
        "# yTrainTall = []\n",
        "# yTestTall = []\n",
        "\n",
        "# for i in to_train:\n",
        "#   xTrain.append(shuff_images[i])\n",
        "#   yTrainTall.append(shuff_masks2[i])\n",
        "#   yTrainShort.append(masks_short[i])\n",
        "\n",
        "# for i in to_test:\n",
        "#   xTest.append(shuff_images[i])\n",
        "#   yTestTall.append(shuff_masks2[i])\n",
        "#   yTestShort.append(masks_short[i])\n",
        "\n",
        "\n",
        "\n",
        "# Validation for tall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r17hhGKE5kTM"
      },
      "source": [
        "# **NN Implementations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84pQFCMkwyEi"
      },
      "source": [
        "## **UNet implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axeWmy7ToSgT",
        "outputId": "2a2bcf84-5d2b-4e20-9ad0-1b4447ffe0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 64  0           ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 12  0           ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 12  0           ['conv2d_3[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 25  0           ['conv2d_4[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 25  0           ['conv2d_5[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 512)  0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 1024  0           ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 1024  0           ['conv2d_9[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['activation_7[0][0]',           \n",
            "                                )                                 'conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64, 64, 512)  0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 64, 512)  0           ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['activation_5[0][0]',           \n",
            "                                2)                                'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 25  0           ['conv2d_12[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 25  0           ['conv2d_13[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['activation_3[0][0]',           \n",
            "                                6)                                'conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 256, 256, 12  0           ['conv2d_14[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256, 256, 12  0           ['conv2d_15[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['activation_1[0][0]',           \n",
            "                                8)                                'conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 512, 512, 64  0           ['conv2d_16[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 512, 512, 64  0           ['conv2d_17[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 512, 512, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 512, 512, 1)  0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,745\n",
            "Trainable params: 31,031,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Dropout, Lambda, Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.nn import leaky_relu, relu\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    coef = (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "    return coef\n",
        "\n",
        "def convBlock(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "  else:\n",
        "    #conv = ZeroPadding2D((1,1))(input)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "\n",
        "  conv = Activation(act)(conv)\n",
        "  return conv\n",
        "\n",
        "def UNet(trained_weights = None, batch_size=1, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Hidden layers\n",
        "    ## Contraction phase\n",
        "    conv1 = convBlock(inputs, 64, 3)\n",
        "    conv1 = convBlock(conv1, 64, 3)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = convBlock(pool1, 128, 3)\n",
        "    conv2 = convBlock(conv2, 128, 3)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    #drop2 = Dropout(drop_rate)(pool2)\n",
        "\n",
        "    conv3 = convBlock(pool2, 256, 3)\n",
        "    conv3 = convBlock(conv3, 256, 3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    #drop3 = Dropout(drop_rate)(pool3)\n",
        "\n",
        "    conv4 = convBlock(pool3, 512, 3)\n",
        "    conv4 = convBlock(conv4, 512, 3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "    #drop4 = Dropout(drop_rate)(pool4)\n",
        "\n",
        "    conv5 = convBlock(pool4, 1024, 3)\n",
        "    conv5 = convBlock(conv5, 1024, 3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up6 = (Conv2DTranspose(512, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = concatenate([conv4,up6])\n",
        "    conv6 = convBlock(merge6, 512, 3)\n",
        "    conv6 = convBlock(conv6, 512, 3)\n",
        "    #conv6 = Dropout(drop_rate)(conv6)\n",
        "\n",
        "    up7 = (Conv2DTranspose(256, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = concatenate([conv3,up7])\n",
        "    conv7 = convBlock(merge7, 256, 3)\n",
        "    conv7 = convBlock(conv7, 256, 3)\n",
        "    #conv7 = Dropout(drop_rate)(conv7)\n",
        "\n",
        "    up8 = (Conv2DTranspose(128, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv7))\n",
        "    merge8 = concatenate([conv2,up8])\n",
        "    conv8 = convBlock(merge8, 128, 3)\n",
        "    conv8 = convBlock(conv8, 128, 3)\n",
        "    #conv8 = Dropout(drop_rate)(conv8)\n",
        "\n",
        "    up9 = (Conv2DTranspose(64, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv8))\n",
        "    merge9 = concatenate([conv1,up9])\n",
        "    conv9 = convBlock(merge9, 64, 3)\n",
        "    conv9 = convBlock(conv9, 64, 3)\n",
        "\n",
        "    # Output layer\n",
        "    conv10 = convBlock(conv9, num_out, 1, act=out_layer)\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "UNet().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bMTSXO5xTTb"
      },
      "source": [
        "## **Attention UNet implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knKGC9RI0A4p",
        "outputId": "789969d5-cd25-466a-f710-bfd2340f6808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(1, 512, 512, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (1, 512, 512, 16)    448         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (1, 512, 512, 16)    0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (1, 512, 512, 16)    2320        ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (1, 512, 512, 16)    0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (1, 256, 256, 16)   0           ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (1, 256, 256, 32)    4640        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (1, 256, 256, 32)    0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (1, 256, 256, 32)    9248        ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (1, 256, 256, 32)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (1, 128, 128, 32)   0           ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (1, 128, 128, 64)    18496       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (1, 128, 128, 64)    0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (1, 128, 128, 64)    36928       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (1, 128, 128, 64)    0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (1, 64, 64, 64)     0           ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (1, 64, 64, 128)     73856       ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (1, 64, 64, 128)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (1, 64, 64, 128)     147584      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (1, 64, 64, 128)     0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (1, 32, 32, 128)    0           ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (1, 32, 32, 256)     295168      ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (1, 32, 32, 256)     0           ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (1, 32, 32, 256)     590080      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (1, 32, 32, 256)     0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (1, 64, 64, 128)     16512       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (1, 32, 32, 128)     32896       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (1, 32, 32, 128)    0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " add (Add)                      (1, 32, 32, 128)     0           ['conv2d_30[0][0]',              \n",
            "                                                                  'max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (1, 32, 32, 128)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (1, 32, 32, 1)       129         ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (1, 32, 32, 1)       0           ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (1, 64, 64, 1)       0           ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " tf.broadcast_to (TFOpLambda)   (1, 64, 64, 128)     0           ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (1, 64, 64, 128)    131200      ['activation_28[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (1, 64, 64, 128)     0           ['tf.broadcast_to[0][0]',        \n",
            "                                                                  'activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (1, 64, 64, 256)     0           ['conv2d_transpose_4[0][0]',     \n",
            "                                                                  'multiply[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (1, 64, 64, 128)     295040      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (1, 64, 64, 128)     0           ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (1, 64, 64, 128)     147584      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (1, 64, 64, 128)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (1, 128, 128, 64)    4160        ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (1, 64, 64, 64)      8256        ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (1, 64, 64, 64)     0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (1, 64, 64, 64)      0           ['conv2d_35[0][0]',              \n",
            "                                                                  'max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (1, 64, 64, 64)      0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (1, 64, 64, 1)       65          ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (1, 64, 64, 1)       0           ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (1, 128, 128, 1)    0           ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " tf.broadcast_to_1 (TFOpLambda)  (1, 128, 128, 64)   0           ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (1, 128, 128, 64)   32832       ['activation_32[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (1, 128, 128, 64)    0           ['tf.broadcast_to_1[0][0]',      \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (1, 128, 128, 128)   0           ['conv2d_transpose_5[0][0]',     \n",
            "                                                                  'multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (1, 128, 128, 64)    73792       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (1, 128, 128, 64)    0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (1, 128, 128, 64)    36928       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (1, 128, 128, 64)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (1, 256, 256, 32)    1056        ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (1, 128, 128, 32)    2080        ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (1, 128, 128, 32)   0           ['conv2d_39[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (1, 128, 128, 32)    0           ['conv2d_40[0][0]',              \n",
            "                                                                  'max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (1, 128, 128, 32)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (1, 128, 128, 1)     33          ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (1, 128, 128, 1)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (1, 256, 256, 1)    0           ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " tf.broadcast_to_2 (TFOpLambda)  (1, 256, 256, 32)   0           ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (1, 256, 256, 32)   8224        ['activation_36[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (1, 256, 256, 32)    0           ['tf.broadcast_to_2[0][0]',      \n",
            "                                                                  'activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (1, 256, 256, 64)    0           ['conv2d_transpose_6[0][0]',     \n",
            "                                                                  'multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (1, 256, 256, 32)    18464       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (1, 256, 256, 32)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (1, 256, 256, 32)    9248        ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (1, 256, 256, 32)    0           ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (1, 512, 512, 16)    272         ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (1, 256, 256, 16)    528         ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (1, 256, 256, 16)   0           ['conv2d_44[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (1, 256, 256, 16)    0           ['conv2d_45[0][0]',              \n",
            "                                                                  'max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (1, 256, 256, 16)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (1, 256, 256, 1)     17          ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (1, 256, 256, 1)     0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (1, 512, 512, 1)    0           ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " tf.broadcast_to_3 (TFOpLambda)  (1, 512, 512, 16)   0           ['up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (1, 512, 512, 16)   2064        ['activation_40[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (1, 512, 512, 16)    0           ['tf.broadcast_to_3[0][0]',      \n",
            "                                                                  'activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (1, 512, 512, 32)    0           ['conv2d_transpose_7[0][0]',     \n",
            "                                                                  'multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (1, 512, 512, 16)    4624        ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (1, 512, 512, 16)    0           ['conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (1, 512, 512, 16)    2320        ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (1, 512, 512, 16)    0           ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (1, 512, 512, 1)     17          ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (1, 512, 512, 1)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,007,109\n",
            "Trainable params: 2,007,109\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "from sklearn.metrics import *\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.losses import *\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    coef = (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "    return coef\n",
        "\n",
        "def convBlock2(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
        "  if transpose == False:\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "  else:\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
        "    conv = Activation(act)(conv)\n",
        "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
        "    conv = Activation(act)(conv)\n",
        "\n",
        "  return conv\n",
        "\n",
        "def attention_block(x, gating, inter_shape, drop_rate=0.25):\n",
        "\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "    # Initial gate\n",
        "    theta_x = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(x)\n",
        "    theta_x = MaxPooling2D((2,2))(theta_x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(gating)\n",
        "    shape_phi_g = K.int_shape(phi_g)\n",
        "\n",
        "    # Add components\n",
        "    concat_xg = add([phi_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "\n",
        "    # Apply convolution\n",
        "    psi = Conv2D(1, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(act_xg)\n",
        "\n",
        "    # Apply sigmoid activation\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "\n",
        "    # UpSample and resample to correct size\n",
        "    upsample_psi = UpSampling2D(interpolation='bilinear', size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = tf.broadcast_to(upsample_psi, shape=shape_x)\n",
        "    y = multiply([upsample_psi, x])\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def UNetAM(trained_weights = None, input_size = (512,512,3), batch_size = 1, drop_rate = 0.25, lr=0.0001, out_layer = 'sigmoid', lossfunc = 'binary_crossentropy', filter_base=16, num_out=1):\n",
        "\n",
        "    ## Can add pretrained weights by specifying 'trained_weights'\n",
        "\n",
        "    # Input layer\n",
        "    inputs = Input(input_size, batch_size=batch_size)\n",
        "\n",
        "    # Hidden layers\n",
        "    ## Contraction phase\n",
        "    conv = convBlock2(inputs, filter_base, 3)\n",
        "    #conv0 = Dropout(drop_rate)(conv0)\n",
        "\n",
        "    conv0 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "    conv0 = convBlock2(conv0, 2 * filter_base, 3)\n",
        "\n",
        "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n",
        "    conv1 = convBlock2(pool0, 4 * filter_base, 3)\n",
        "    #conv1 = Dropout(drop_rate)(conv1)\n",
        "\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = convBlock2(pool1, 8 * filter_base, 3)\n",
        "    #conv2 = Dropout(drop_rate)(conv2)\n",
        "\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = convBlock2(pool2, 16 * filter_base, 3)\n",
        "    #conv3 = Dropout(drop_rate)(conv3)\n",
        "\n",
        "    ## Expansion phase\n",
        "    up4 = (Conv2DTranspose(8 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv3))\n",
        "    merge4 = attention_block(conv2, conv3, 8 * filter_base, drop_rate) # Attention gate\n",
        "    conv4 = concatenate([up4, merge4])\n",
        "    conv4 = convBlock2(conv4, 8 * filter_base, 3)\n",
        "\n",
        "    up5 = (Conv2DTranspose(4 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv4))\n",
        "    merge5 = attention_block(conv1, conv4, 4 * filter_base, drop_rate) # Attention gate\n",
        "    conv5 = concatenate([up5, merge5])\n",
        "    conv5 = convBlock2(conv5, 4 * filter_base, 3)\n",
        "\n",
        "    up6 = (Conv2DTranspose(2 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
        "    merge6 = attention_block(conv0, conv5, 2 * filter_base, drop_rate) # Attention gate\n",
        "    conv6 = concatenate([up6, merge6])\n",
        "    conv6 = convBlock2(conv6, 2 * filter_base, 3)\n",
        "\n",
        "    up7 = (Conv2DTranspose(1 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
        "    merge7 = attention_block(conv, conv6, 1 * filter_base, drop_rate) # Attention gate\n",
        "    conv7 = concatenate([up7, merge7])\n",
        "    conv7 = convBlock2(conv7, 1 * filter_base, 3)\n",
        "\n",
        "    # Output layer\n",
        "    out = convBlock(conv7, num_out, 1, act=out_layer)\n",
        "\n",
        "    model = Model(inputs, out)\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    if trained_weights != None:\n",
        "    \tmodel.load_weights(trained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "UNetAM().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCBtnut5Ftjn"
      },
      "source": [
        "## **ResNet50-SegNet**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXW-IU8kF6vS",
        "outputId": "8f5618e1-442c-45d5-cd41-36be04852a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 514, 514, 3)  0          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 512, 512, 64  1792        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 512, 512, 64  0           ['conv2d_50[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 514, 514, 64  0          ['activation_46[0][0]']          \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 512, 512, 64  36928       ['zero_padding2d_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 512, 512, 64  0           ['conv2d_51[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_2 (ZeroPadding2  (None, 514, 514, 64  0          ['activation_47[0][0]']          \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 512, 512, 64  36928       ['zero_padding2d_2[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 512, 512, 64  0           ['conv2d_52[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling_with_argmax2d (Max  [(None, 256, 256, 6  0          ['activation_48[0][0]']          \n",
            " PoolingWithArgmax2D)           4),                                                               \n",
            "                                 (None, 256, 256, 6                                               \n",
            "                                4)]                                                               \n",
            "                                                                                                  \n",
            " zero_padding2d_3 (ZeroPadding2  (None, 258, 258, 64  0          ['max_pooling_with_argmax2d[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 256, 256, 12  73856       ['zero_padding2d_3[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 256, 256, 12  0           ['conv2d_53[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadding2  (None, 258, 258, 12  0          ['activation_49[0][0]']          \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 256, 256, 12  147584      ['zero_padding2d_4[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 256, 256, 12  0           ['conv2d_54[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_5 (ZeroPadding2  (None, 258, 258, 12  0          ['activation_50[0][0]']          \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 256, 256, 12  147584      ['zero_padding2d_5[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 256, 256, 12  0           ['conv2d_55[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling_with_argmax2d_1 (M  [(None, 128, 128, 1  0          ['activation_51[0][0]']          \n",
            " axPoolingWithArgmax2D)         28),                                                              \n",
            "                                 (None, 128, 128, 1                                               \n",
            "                                28)]                                                              \n",
            "                                                                                                  \n",
            " zero_padding2d_6 (ZeroPadding2  (None, 130, 130, 12  0          ['max_pooling_with_argmax2d_1[0][\n",
            " D)                             8)                               0]']                             \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 128, 128, 25  295168      ['zero_padding2d_6[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 128, 128, 25  0           ['conv2d_56[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_7 (ZeroPadding2  (None, 130, 130, 25  0          ['activation_52[0][0]']          \n",
            " D)                             6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 128, 128, 25  590080      ['zero_padding2d_7[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 128, 128, 25  0           ['conv2d_57[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_8 (ZeroPadding2  (None, 130, 130, 25  0          ['activation_53[0][0]']          \n",
            " D)                             6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 128, 128, 25  590080      ['zero_padding2d_8[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 128, 128, 25  0           ['conv2d_58[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling_with_argmax2d_2 (M  [(None, 64, 64, 256  0          ['activation_54[0][0]']          \n",
            " axPoolingWithArgmax2D)         ),                                                                \n",
            "                                 (None, 64, 64, 256                                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_9 (ZeroPadding2  (None, 66, 66, 256)  0          ['max_pooling_with_argmax2d_2[0][\n",
            " D)                                                              0]']                             \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 64, 64, 512)  1180160     ['zero_padding2d_9[0][0]']       \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 64, 64, 512)  0           ['conv2d_59[0][0]']              \n",
            "                                                                                                  \n",
            " zero_padding2d_10 (ZeroPadding  (None, 66, 66, 512)  0          ['activation_55[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 64, 64, 512)  2359808     ['zero_padding2d_10[0][0]']      \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 64, 64, 512)  0           ['conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " zero_padding2d_11 (ZeroPadding  (None, 66, 66, 512)  0          ['activation_56[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 64, 64, 512)  2359808     ['zero_padding2d_11[0][0]']      \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 64, 64, 512)  0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling_with_argmax2d_3 (M  [(None, 32, 32, 512  0          ['activation_57[0][0]']          \n",
            " axPoolingWithArgmax2D)         ),                                                                \n",
            "                                 (None, 32, 32, 512                                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_12 (ZeroPadding  (None, 34, 34, 512)  0          ['max_pooling_with_argmax2d_3[0][\n",
            " 2D)                                                             0]']                             \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 32, 32, 1024  4719616     ['zero_padding2d_12[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 32, 32, 1024  0           ['conv2d_62[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_13 (ZeroPadding  (None, 34, 34, 1024  0          ['activation_58[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 32, 32, 1024  9438208     ['zero_padding2d_13[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 32, 32, 1024  0           ['conv2d_63[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_14 (ZeroPadding  (None, 34, 34, 1024  0          ['activation_59[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 32, 32, 1024  9438208     ['zero_padding2d_14[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 32, 32, 1024  0           ['conv2d_64[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling_with_argmax2d_4 (M  [(None, 16, 16, 102  0          ['activation_60[0][0]']          \n",
            " axPoolingWithArgmax2D)         4),                                                               \n",
            "                                 (None, 16, 16, 102                                               \n",
            "                                4)]                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024  0          ['max_pooling_with_argmax2d_4[0][\n",
            "                                )                                0]']                             \n",
            "                                                                                                  \n",
            " zero_padding2d_15 (ZeroPadding  (None, 34, 34, 1024  0          ['up_sampling2d_4[0][0]']        \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 32, 32, 1024  9438208     ['zero_padding2d_15[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 32, 32, 1024  0           ['conv2d_65[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_16 (ZeroPadding  (None, 34, 34, 1024  0          ['activation_61[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 32, 32, 1024  9438208     ['zero_padding2d_16[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 32, 32, 1024  0           ['conv2d_66[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_17 (ZeroPadding  (None, 34, 34, 1024  0          ['activation_62[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 32, 32, 1024  9438208     ['zero_padding2d_17[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 32, 32, 1024  0           ['conv2d_67[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 1024  0          ['activation_63[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_18 (ZeroPadding  (None, 66, 66, 1024  0          ['up_sampling2d_5[0][0]']        \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 64, 64, 512)  4719104     ['zero_padding2d_18[0][0]']      \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 64, 64, 512)  0           ['conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " zero_padding2d_19 (ZeroPadding  (None, 66, 66, 512)  0          ['activation_64[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 64, 64, 512)  2359808     ['zero_padding2d_19[0][0]']      \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 64, 64, 512)  0           ['conv2d_69[0][0]']              \n",
            "                                                                                                  \n",
            " zero_padding2d_20 (ZeroPadding  (None, 66, 66, 512)  0          ['activation_65[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 64, 64, 512)  2359808     ['zero_padding2d_20[0][0]']      \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 64, 64, 512)  0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " max_unpooling2d (MaxUnpooling2  (None, 64, 64, 512)  0          ['max_pooling_with_argmax2d_3[0][\n",
            " D)                                                              0]',                             \n",
            "                                                                  'max_pooling_with_argmax2d_3[0][\n",
            "                                                                 1]']                             \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 64, 512)  0           ['activation_66[0][0]',          \n",
            "                                                                  'max_unpooling2d[0][0]']        \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 51  0          ['add_4[0][0]']                  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_21 (ZeroPadding  (None, 130, 130, 51  0          ['up_sampling2d_6[0][0]']        \n",
            " 2D)                            2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 128, 128, 25  1179904     ['zero_padding2d_21[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 128, 128, 25  0           ['conv2d_71[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_22 (ZeroPadding  (None, 130, 130, 25  0          ['activation_67[0][0]']          \n",
            " 2D)                            6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 128, 128, 25  590080      ['zero_padding2d_22[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 128, 128, 25  0           ['conv2d_72[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_23 (ZeroPadding  (None, 130, 130, 25  0          ['activation_68[0][0]']          \n",
            " 2D)                            6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 128, 128, 25  590080      ['zero_padding2d_23[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 128, 128, 25  0           ['conv2d_73[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_unpooling2d_1 (MaxUnpoolin  (None, 128, 128, 25  0          ['max_pooling_with_argmax2d_2[0][\n",
            " g2D)                           6)                               0]',                             \n",
            "                                                                  'max_pooling_with_argmax2d_2[0][\n",
            "                                                                 1]']                             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 128, 128, 25  0           ['activation_69[0][0]',          \n",
            "                                6)                                'max_unpooling2d_1[0][0]']      \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 25  0          ['add_5[0][0]']                  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_24 (ZeroPadding  (None, 258, 258, 25  0          ['up_sampling2d_7[0][0]']        \n",
            " 2D)                            6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 256, 256, 12  295040      ['zero_padding2d_24[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 256, 256, 12  0           ['conv2d_74[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_25 (ZeroPadding  (None, 258, 258, 12  0          ['activation_70[0][0]']          \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 256, 256, 12  147584      ['zero_padding2d_25[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 256, 256, 12  0           ['conv2d_75[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_26 (ZeroPadding  (None, 258, 258, 12  0          ['activation_71[0][0]']          \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 256, 256, 12  147584      ['zero_padding2d_26[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 256, 256, 12  0           ['conv2d_76[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_unpooling2d_2 (MaxUnpoolin  (None, 256, 256, 12  0          ['max_pooling_with_argmax2d_1[0][\n",
            " g2D)                           8)                               0]',                             \n",
            "                                                                  'max_pooling_with_argmax2d_1[0][\n",
            "                                                                 1]']                             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 256, 256, 12  0           ['activation_72[0][0]',          \n",
            "                                8)                                'max_unpooling2d_2[0][0]']      \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, 512, 512, 12  0          ['add_6[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_27 (ZeroPadding  (None, 514, 514, 12  0          ['up_sampling2d_8[0][0]']        \n",
            " 2D)                            8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 512, 512, 64  73792       ['zero_padding2d_27[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 512, 512, 64  0           ['conv2d_77[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_28 (ZeroPadding  (None, 514, 514, 64  0          ['activation_73[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 512, 512, 64  36928       ['zero_padding2d_28[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 512, 512, 64  0           ['conv2d_78[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_29 (ZeroPadding  (None, 514, 514, 64  0          ['activation_74[0][0]']          \n",
            " 2D)                            )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 512, 512, 64  36928       ['zero_padding2d_29[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 512, 512, 64  0           ['conv2d_79[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_unpooling2d_3 (MaxUnpoolin  (None, 512, 512, 64  0          ['max_pooling_with_argmax2d[0][0]\n",
            " g2D)                           )                                ',                               \n",
            "                                                                  'max_pooling_with_argmax2d[0][1]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 512, 512, 64  0           ['activation_75[0][0]',          \n",
            "                                )                                 'max_unpooling2d_3[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 512, 512, 1)  65          ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 512, 512, 1)  0           ['conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 72,267,137\n",
            "Trainable params: 72,267,137\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Forked code from: https://github.com/ykamikawa/tf-keras-SegNet\n",
        "\n",
        "from keras.layers import Layer\n",
        "\n",
        "# Max Pooling which keeps record of indices of max-pooled points\n",
        "class MaxPoolingWithArgmax2D(Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n",
        "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        padding = 'same'#self.padding\n",
        "        pool_size = (2,2)#self.pool_size\n",
        "        strides = (2,2)#self.strides\n",
        "        if K.backend() == \"tensorflow\":\n",
        "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
        "            padding = padding.upper()\n",
        "            strides = [1, strides[0], strides[1], 1]\n",
        "            output, argmax = K.tf.nn.max_pool_with_argmax(\n",
        "                inputs, ksize=ksize, strides=strides, padding=padding\n",
        "            )\n",
        "        else:\n",
        "            errmsg = \"{} backend is not supported for layer {}\".format(\n",
        "                K.backend(), type(self).__name__\n",
        "            )\n",
        "            raise NotImplementedError(errmsg)\n",
        "        argmax = K.cast(argmax, K.floatx())\n",
        "        return [output, argmax]\n",
        "\n",
        "# Unpooling using indices\n",
        "class MaxUnpooling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), **kwargs):\n",
        "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
        "        self.size = size\n",
        "\n",
        "    def call(self, inputs, output_shape=None):\n",
        "        updates, mask = inputs[0], inputs[1]\n",
        "        with tf.compat.v1.variable_scope(self.name):\n",
        "            mask = K.cast(mask, \"int32\")\n",
        "            input_shape = K.tf.shape(updates, out_type=\"int32\")\n",
        "            #  calculation new shape\n",
        "            if output_shape is None:\n",
        "                output_shape = (\n",
        "                    input_shape[0],\n",
        "                    input_shape[1] * self.size[0],\n",
        "                    input_shape[2] * self.size[1],\n",
        "                    input_shape[3],\n",
        "                )\n",
        "            self.output_shape1 = output_shape\n",
        "\n",
        "            # calculation indices for batch, height, width and feature maps\n",
        "            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n",
        "            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n",
        "            batch_range = K.reshape(\n",
        "                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n",
        "            )\n",
        "            b = one_like_mask * batch_range\n",
        "            y = mask // (output_shape[2] * output_shape[3])\n",
        "            x = (mask // output_shape[3]) % output_shape[2]\n",
        "            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n",
        "            f = one_like_mask * feature_range\n",
        "\n",
        "            # transpose indices & reshape update values to one dimension\n",
        "            updates_size = K.tf.size(updates)\n",
        "            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n",
        "            values = K.reshape(updates, [updates_size])\n",
        "            ret = K.tf.scatter_nd(indices, values, output_shape)\n",
        "            return ret\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        mask_shape = input_shape[1]\n",
        "        return (\n",
        "            mask_shape[0],\n",
        "            mask_shape[1] * self.size[0],\n",
        "            mask_shape[2] * self.size[1],\n",
        "            mask_shape[3],\n",
        "        )\n",
        "\n",
        "# Custom version of MaxUnpooling2D\n",
        "# Takes raw layer values and outputs values\n",
        "# Takes tf.nn.max_pool_with_argmax output as input\n",
        "def unpool_with_indices(pool, indices, out_size=2):\n",
        "  print(pool)\n",
        "  print(indices)\n",
        "  # Create empty array of appropriate size\n",
        "  shape = np.array(np.shape(pool))\n",
        "  shape = np.array((shape[0], out_size * shape[1], out_size * shape[2], shape[3]))\n",
        "  out = np.zeros(shape)\n",
        "\n",
        "  # Make upsample\n",
        "  inds = np.array(indices).flatten()\n",
        "  outs = np.array(pool).flatten()\n",
        "  for i in range(len(inds)):\n",
        "    blk = inds[i] // (shape[2] * shape[3]) # Find which block to place numbers in\n",
        "    ln  = inds[i] - (blk * shape[3] * shape[2]) # Find which line\n",
        "    ln2 = ln // (shape[3]) # Find line\n",
        "    pos = ln % (shape[3]) # Find position\n",
        "    #print(blk, ln2, pos)\n",
        "    out[0][blk][ln2][pos] = outs[i]\n",
        "\n",
        "\n",
        "  #print(out.shape)\n",
        "  return (out)\n",
        "\n",
        "def resnetConvDownBlock(x, filter, kernel, act='relu'):\n",
        "  # Convolutional Block for encoding phase\n",
        "  for i in range(3):\n",
        "    x = ZeroPadding2D((1,1))(x)\n",
        "    x = Conv2D(filters = filter, kernel_size = kernel, kernel_initializer = 'he_normal')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def resnetConvUpBlock(x, skip_connection = None, filter = None, kernel = None, act='relu'):\n",
        "  # Convolutional block for decoding phase\n",
        "\n",
        "  out = x\n",
        "\n",
        "  # Unpooling\n",
        "  out = UpSampling2D((2,2))(out)\n",
        "  #out = Conv2DTranspose(filters = filter, kernel_size = kernel, kernel_initializer = 'he_normal')(out)\n",
        "\n",
        "  # Conv Block\n",
        "  for i in range(3):\n",
        "    out = ZeroPadding2D((1,1))(out)\n",
        "    out = Conv2D(filters = filter, kernel_size = kernel, kernel_initializer = 'he_normal')(out)\n",
        "    out = Activation('relu')(out)\n",
        "\n",
        "  # Implement skip connection\n",
        "  if skip_connection != None:\n",
        "    out = Add()([out, skip_connection])\n",
        "\n",
        "  return out\n",
        "\n",
        "def ResNet50SegNet(input_size=(512,512,3), lr = 0.0001, filters = 64, kernel_sz = 3, num_out=1, out_layer = 'sigmoid', lossfunc='binary_crossentropy'):\n",
        "\n",
        "  inputs = Input(input_size)\n",
        "\n",
        "  # Encoder\n",
        "  # Conv, Conv, Conv, MaxPool #1\n",
        "  block1 = resnetConvDownBlock(inputs, filter = filters, kernel = kernel_sz)\n",
        "  pool1, mask1 = MaxPoolingWithArgmax2D((2,2))(block1)#MaxPooling2D((2,2))(block1)\n",
        "  # Conv, Conv, Conv, MaxPool #2\n",
        "  block2 = resnetConvDownBlock(pool1, filter = 2 * filters, kernel = kernel_sz)\n",
        "  pool2, mask2 = MaxPoolingWithArgmax2D((2,2))(block2)#K.tf.nn.max_pool_with_argmax(block2, 2, 2, 'SAME')#MaxPooling2D((2,2))(block2)\n",
        "  # Conv, Conv, Conv, MaxPool #3\n",
        "  block3 = resnetConvDownBlock(pool2, filter = 4 * filters, kernel = kernel_sz)\n",
        "  pool3, mask3 = MaxPoolingWithArgmax2D((2,2))(block3)#MaxPooling2D((2,2))(block3)\n",
        "  # Conv, Conv, Conv, MaxPool #4\n",
        "  block4 = resnetConvDownBlock(pool3, filter = 8 * filters, kernel = kernel_sz)\n",
        "  pool4, mask4 = MaxPoolingWithArgmax2D((2,2))(block4)#MaxPooling2D((2,2))(block4)\n",
        "  # Conv, Conv, Conv, MaxPool #5\n",
        "  block5 = resnetConvDownBlock(pool4, filter = 16 * filters, kernel = kernel_sz)\n",
        "  pool5, mask5 = MaxPoolingWithArgmax2D((2,2))(block5)#MaxPooling2D((2,2))(block5)\n",
        "\n",
        "  # Decoder\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #1\n",
        "  block5_ = resnetConvUpBlock(pool5, filter = 16 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #2\n",
        "  block4_ = resnetConvUpBlock(block5_, skip_connection = MaxUnpooling2D((2,2))([pool4, mask4]), filter = 8 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #3\n",
        "  block3_ = resnetConvUpBlock(block4_, skip_connection = MaxUnpooling2D((2,2))([pool3, mask3]), filter = 4 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #4\n",
        "  block2_ = resnetConvUpBlock(block3_, skip_connection = MaxUnpooling2D((2,2))([pool2, mask2]), filter = 2 * filters, kernel = kernel_sz)\n",
        "  # ConvTranspose + Concat, Conv, Conv, Conv #5\n",
        "  block1_ = resnetConvUpBlock(block2_, skip_connection = MaxUnpooling2D((2,2))([pool1, mask1]), filter = filters, kernel = kernel_sz)\n",
        "  # Output\n",
        "  outputs = Conv2D(num_out, kernel_size = 1, strides = 1, kernel_initializer = 'he_normal')(block1_)\n",
        "  outputs = Activation(out_layer)(outputs)\n",
        "\n",
        "  model = Model(inputs, outputs)\n",
        "  model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "  return model\n",
        "\n",
        "ResNet50SegNet().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKKP20ENHZ2S"
      },
      "source": [
        "## **FCN32-VGG16**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8xpq7huHzX_",
        "outputId": "2a800758-6018-431a-f475-29c21fafa1f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
            "                                                                 \n",
            " activation_77 (Activation)  (None, 512, 512, 64)      0         \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
            "                                                                 \n",
            " activation_78 (Activation)  (None, 512, 512, 64)      0         \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 256, 256, 128)     73856     \n",
            "                                                                 \n",
            " activation_79 (Activation)  (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 256, 256, 128)     147584    \n",
            "                                                                 \n",
            " activation_80 (Activation)  (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 128, 128, 256)     295168    \n",
            "                                                                 \n",
            " activation_81 (Activation)  (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 128, 128, 256)     590080    \n",
            "                                                                 \n",
            " activation_82 (Activation)  (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 128, 128, 256)     590080    \n",
            "                                                                 \n",
            " activation_83 (Activation)  (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 64, 64, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 64, 64, 512)       1180160   \n",
            "                                                                 \n",
            " activation_84 (Activation)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " activation_85 (Activation)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " activation_86 (Activation)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " activation_87 (Activation)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " activation_88 (Activation)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " activation_89 (Activation)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " conv6 (Conv2D)              (None, 16, 16, 4096)      102764544 \n",
            "                                                                 \n",
            " activation_90 (Activation)  (None, 16, 16, 4096)      0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 4096)      0         \n",
            "                                                                 \n",
            " conv7 (Conv2D)              (None, 16, 16, 4096)      16781312  \n",
            "                                                                 \n",
            " activation_91 (Activation)  (None, 16, 16, 4096)      0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 4096)      0         \n",
            "                                                                 \n",
            " scorer1 (Conv2D)            (None, 16, 16, 1)         4097      \n",
            "                                                                 \n",
            " Upsample32 (Conv2DTranspose  (None, 512, 512, 1)      4097      \n",
            " )                                                               \n",
            "                                                                 \n",
            " activation_92 (Activation)  (None, 512, 512, 1)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 134,268,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def fcn_32(input_size = (512,512,3), lr = 0.0001, drop_rate = 0, num_out=1, out_layer = 'sigmoid', lossfunc='binary_crossentropy'):\n",
        "\n",
        "    kernel = 3\n",
        "    filter_size = 64\n",
        "    pad = 1\n",
        "    pool_size = 2\n",
        "\n",
        "    IMAGE_ORDERING = 'channels_last'\n",
        "    inputs = Input(shape=input_size)\n",
        "\n",
        "    x = inputs\n",
        "    levels = []\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same',\n",
        "               name='block1_conv1', data_format=IMAGE_ORDERING)(inputs)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same',\n",
        "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same',\n",
        "               name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same',\n",
        "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same',\n",
        "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    levels.append(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same',\n",
        "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "\n",
        "    levels.append(x)\n",
        "\n",
        "    [f1, f2, f3, f4, f5] = levels\n",
        "\n",
        "    o = f5\n",
        "\n",
        "    o = (Conv2D(4096, (7 , 7 ), padding = 'same', kernel_initializer = 'he_normal', name = \"conv6\"))(o)\n",
        "    o = Activation('relu')(o)\n",
        "    o = Dropout(drop_rate)(o)\n",
        "    o = (Conv2D(4096, (1 , 1 ), padding = 'same', kernel_initializer = 'he_normal', name = \"conv7\"))(o)\n",
        "    o = Activation('relu')(o)\n",
        "    o = Dropout(drop_rate)(o)\n",
        "\n",
        "    o = (Conv2D(1, 1, padding='same', kernel_initializer='he_normal', name=\"scorer1\"))(o)\n",
        "    o = Conv2DTranspose(num_out, kernel_size=(64,64), padding='same', strides=(32,32), name=\"Upsample32\")(o)\n",
        "\n",
        "\n",
        "    #o = Conv2D(1,1,1)(o)\n",
        "    o = Activation(out_layer)(o)\n",
        "\n",
        "    model = Model(inputs, o)\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "    model.model_name = \"fcn_32\"\n",
        "    return model\n",
        "\n",
        "fcn_32().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmaqrSN05VgT"
      },
      "source": [
        "## **RES UNet implementation**\n",
        "Forked from: https://github.com/dmolony3/ResUNet/blob/master/res_unet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a63G0V-f5Ta8",
        "outputId": "f5a5a5e3-afbf-4460-df01-72a163425a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " layer1_1 (Conv2D)              (None, 512, 512, 32  896         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 32  128        ['layer1_1[0][0]']               \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " layer1_shortcut (Conv2D)       (None, 512, 512, 32  128         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 512, 512, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 32  128        ['layer1_shortcut[0][0]']        \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " layer1_2 (Conv2D)              (None, 512, 512, 32  9248        ['activation_93[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 512, 512, 32  0           ['batch_normalization_1[0][0]',  \n",
            "                                )                                 'layer1_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 512, 512, 32  128        ['add_8[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " encoder_layer1_1 (Conv2D)      (None, 256, 256, 64  18496       ['activation_94[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 64  256        ['encoder_layer1_1[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " encoder_layer1_shortcut (Conv2  (None, 256, 256, 64  2112       ['add_8[0][0]']                  \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 256, 256, 64  256        ['encoder_layer1_shortcut[0][0]']\n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " encoder_layer1_2 (Conv2D)      (None, 256, 256, 64  36928       ['activation_95[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 256, 256, 64  0           ['batch_normalization_4[0][0]',  \n",
            "                                )                                 'encoder_layer1_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 256, 256, 64  256        ['add_9[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " encoder_layer2_1 (Conv2D)      (None, 128, 128, 12  73856       ['activation_96[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 12  512        ['encoder_layer2_1[0][0]']       \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer2_shortcut (Conv2  (None, 128, 128, 12  8320       ['add_9[0][0]']                  \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_6[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 12  512        ['encoder_layer2_shortcut[0][0]']\n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer2_2 (Conv2D)      (None, 128, 128, 12  147584      ['activation_97[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 128, 128, 12  0           ['batch_normalization_7[0][0]',  \n",
            "                                8)                                'encoder_layer2_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 12  512        ['add_10[0][0]']                 \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_8[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer3_1 (Conv2D)      (None, 64, 64, 256)  295168      ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 64, 64, 256)  1024       ['encoder_layer3_1[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " encoder_layer3_shortcut (Conv2  (None, 64, 64, 256)  33024      ['add_10[0][0]']                 \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 256)  1024       ['encoder_layer3_shortcut[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " encoder_layer3_2 (Conv2D)      (None, 64, 64, 256)  590080      ['activation_99[0][0]']          \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 64, 64, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'encoder_layer3_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 256)  1024       ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " bridge_1 (Conv2D)              (None, 32, 32, 512)  1180160     ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 512)  2048       ['bridge_1[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " bridge_shortcut (Conv2D)       (None, 32, 32, 512)  131584      ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 512)  2048       ['bridge_shortcut[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " bridge_2 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_101[0][0]']         \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 32, 32, 512)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'bridge_2[0][0]']               \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 64, 64, 512)  0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 64, 64, 768)  0           ['lambda[0][0]',                 \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 64, 64, 768)  3072       ['concatenate_8[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 64, 64, 768)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " decoder_layer1_1 (Conv2D)      (None, 64, 64, 256)  1769728     ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 64, 64, 256)  1024       ['decoder_layer1_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " decoder_layer1_shortcut (Conv2  (None, 64, 64, 256)  196864     ['concatenate_8[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 256)  1024       ['decoder_layer1_shortcut[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " decoder_layer1_2 (Conv2D)      (None, 64, 64, 256)  590080      ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 64, 64, 256)  0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'decoder_layer1_2[0][0]']       \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 128, 128, 25  0           ['add_13[0][0]']                 \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 128, 128, 38  0           ['lambda_1[0][0]',               \n",
            "                                4)                                'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 128, 128, 38  1536       ['concatenate_9[0][0]']          \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 128, 128, 38  0           ['batch_normalization_17[0][0]'] \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_1 (Conv2D)      (None, 128, 128, 12  442496      ['activation_104[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 128, 128, 12  512        ['decoder_layer2_1[0][0]']       \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_shortcut (Conv2  (None, 128, 128, 12  49280      ['concatenate_9[0][0]']          \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_18[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128, 128, 12  512        ['decoder_layer2_shortcut[0][0]']\n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_2 (Conv2D)      (None, 128, 128, 12  147584      ['activation_105[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 128, 128, 12  0           ['batch_normalization_19[0][0]', \n",
            "                                8)                                'decoder_layer2_2[0][0]']       \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 256, 256, 12  0           ['add_14[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 256, 256, 19  0           ['lambda_2[0][0]',               \n",
            "                                2)                                'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 256, 256, 19  768        ['concatenate_10[0][0]']         \n",
            " ormalization)                  2)                                                                \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 256, 256, 19  0           ['batch_normalization_20[0][0]'] \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer3_1 (Conv2D)      (None, 256, 256, 64  110656      ['activation_106[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 256, 256, 64  256        ['decoder_layer3_1[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer3_shortcut (Conv2  (None, 256, 256, 64  12352      ['concatenate_10[0][0]']         \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 256, 256, 64  256        ['decoder_layer3_shortcut[0][0]']\n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer3_2 (Conv2D)      (None, 256, 256, 64  36928       ['activation_107[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 256, 256, 64  0           ['batch_normalization_22[0][0]', \n",
            "                                )                                 'decoder_layer3_2[0][0]']       \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 512, 512, 64  0           ['add_15[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 512, 512, 96  0           ['lambda_3[0][0]',               \n",
            "                                )                                 'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 512, 512, 96  384        ['concatenate_11[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 512, 512, 96  0           ['batch_normalization_23[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer4_1 (Conv2D)      (None, 512, 512, 32  27680       ['activation_108[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 512, 512, 32  128        ['decoder_layer4_1[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer4_shortcut (Conv2  (None, 512, 512, 32  3104       ['concatenate_11[0][0]']         \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 512, 512, 32  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 512, 512, 32  128        ['decoder_layer4_shortcut[0][0]']\n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer4_2 (Conv2D)      (None, 512, 512, 32  9248        ['activation_109[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 512, 512, 32  0           ['batch_normalization_25[0][0]', \n",
            "                                )                                 'decoder_layer4_2[0][0]']       \n",
            "                                                                                                  \n",
            " output (Conv2D)                (None, 512, 512, 1)  289         ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 512, 512, 1)  0           ['output[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,303,137\n",
            "Trainable params: 8,293,409\n",
            "Non-trainable params: 9,728\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def res_block_initial(x, num_filters, kernel_size, strides, name):\n",
        "    \"\"\"Residual Unet block layer for first layer\n",
        "    In the residual unet the first residual block does not contain an\n",
        "    initial batch normalization and activation so we create this separate\n",
        "    block for it.\n",
        "    Args:\n",
        "        x: tensor, image or image activation\n",
        "        num_filters: list, contains the number of filters for each subblock\n",
        "        kernel_size: int, size of the convolutional kernel\n",
        "        strides: list, contains the stride for each subblock convolution\n",
        "        name: name of the layer\n",
        "    Returns:\n",
        "        x1: tensor, output from residual connection of x and x1\n",
        "    \"\"\"\n",
        "\n",
        "    if len(num_filters) == 1:\n",
        "        num_filters = [num_filters[0], num_filters[0]]\n",
        "\n",
        "    x1 = tf.keras.layers.Conv2D(filters=num_filters[0],\n",
        "                                kernel_size=kernel_size,\n",
        "                                strides=strides[0],\n",
        "                                padding='same',\n",
        "                                kernel_initializer = 'he_normal',\n",
        "                                name=name+'_1')(x)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
        "    x1 = tf.keras.layers.Conv2D(filters=num_filters[1],\n",
        "                                kernel_size=kernel_size,\n",
        "                                strides=strides[1],\n",
        "                                padding='same',\n",
        "                                kernel_initializer = 'he_normal',\n",
        "                                name=name+'_2')(x1)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=num_filters[-1],\n",
        "                                kernel_size=1,\n",
        "                                strides=1,\n",
        "                                padding='same',\n",
        "                                kernel_initializer = 'he_normal',\n",
        "                                name=name+'_shortcut')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x1 = tf.keras.layers.Add()([x, x1])\n",
        "\n",
        "    return x1\n",
        "\n",
        "def res_block(x, num_filters, kernel_size, strides, name):\n",
        "    \"\"\"Residual Unet block layer\n",
        "    Consists of batch norm and relu, folowed by conv, batch norm and relu and\n",
        "    final convolution. The input is then put through\n",
        "    Args:\n",
        "        x: tensor, image or image activation\n",
        "        num_filters: list, contains the number of filters for each subblock\n",
        "        kernel_size: int, size of the convolutional kernel\n",
        "        strides: list, contains the stride for each subblock convolution\n",
        "        name: name of the layer\n",
        "    Returns:\n",
        "        x1: tensor, output from residual connection of x and x1\n",
        "    \"\"\"\n",
        "\n",
        "    if len(num_filters) == 1:\n",
        "        num_filters = [num_filters[0], num_filters[0]]\n",
        "\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x)\n",
        "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
        "    x1 = tf.keras.layers.Conv2D(filters=num_filters[0],\n",
        "                                kernel_size=kernel_size,\n",
        "                                strides=strides[0],\n",
        "                                padding='same',\n",
        "                                kernel_initializer = 'he_normal',\n",
        "                                name=name+'_1')(x1)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "    x1 = tf.keras.layers.Activation('relu')(x1)\n",
        "    x1 = tf.keras.layers.Conv2D(filters=num_filters[1],\n",
        "                                kernel_size=kernel_size,\n",
        "                                strides=strides[1],\n",
        "                                padding='same',\n",
        "                                kernel_initializer = 'he_normal',\n",
        "                                name=name+'_2')(x1)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=num_filters[-1],\n",
        "                                    kernel_size=1,\n",
        "                                    strides=strides[0],\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer = 'he_normal',\n",
        "                                    name=name+'_shortcut')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x1 = tf.keras.layers.Add()([x, x1])\n",
        "\n",
        "    return x1\n",
        "\n",
        "\n",
        "def upsample(x, target_size):\n",
        "    \"\"\"\"Upsampling function, upsamples the feature map\n",
        "    Deep Residual Unet paper does not describe the upsampling function\n",
        "    in detail. Original Unet uses a transpose convolution that downsamples\n",
        "    the number of feature maps. In order to restrict the number of\n",
        "    parameters here we use a bilinear resampling layer. This results in\n",
        "    the concatentation layer concatenting feature maps with n and n/2\n",
        "    features as opposed to n/2  and n/2 in the original unet.\n",
        "    Args:\n",
        "        x: tensor, feature map\n",
        "        target_size: size to resize feature map to\n",
        "    Returns:\n",
        "        x_resized: tensor, upsampled feature map\n",
        "    \"\"\"\n",
        "\n",
        "    x_resized = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, target_size))(x)\n",
        "\n",
        "    return x_resized\n",
        "\n",
        "def encoder(x, num_filters, kernel_size):\n",
        "    \"\"\"Unet encoder\n",
        "    Args:\n",
        "        x: tensor, output from previous layer\n",
        "        num_filters: list, number of filters for each decoder layer\n",
        "        kernel_size: int, size of the convolutional kernel\n",
        "    Returns:\n",
        "        encoder_output: list, output from all encoder layers\n",
        "    \"\"\"\n",
        "\n",
        "    x = res_block_initial(x, [num_filters[0]], kernel_size, strides=[1,1], name='layer1')\n",
        "\n",
        "    encoder_output = [x]\n",
        "    for i in range(1, len(num_filters)):\n",
        "        layer = 'encoder_layer' + str(i)\n",
        "        x = res_block(x, [num_filters[i]], kernel_size, strides=[2,1], name=layer)\n",
        "        encoder_output.append(x)\n",
        "\n",
        "    return encoder_output\n",
        "\n",
        "def decoder(x, encoder_output, num_filters, kernel_size):\n",
        "    \"\"\"Unet decoder\n",
        "    Args:\n",
        "        x: tensor, output from previous layer\n",
        "        encoder_output: list, output from all previous encoder layers\n",
        "        num_filters: list, number of filters for each decoder layer\n",
        "        kernel_size: int, size of the convolutional kernel\n",
        "    Returns:\n",
        "        x: tensor, output from last layer of decoder\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(1, len(num_filters) + 1):\n",
        "        layer = 'decoder_layer' + str(i)\n",
        "        target_size = encoder_output[-i].shape[1:3]\n",
        "        x = upsample(x, target_size)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, encoder_output[-i]])\n",
        "        x = res_block(x, [num_filters[-i]], kernel_size, strides=[1,1], name=layer)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def res_unet(input_size, num_filters, kernel_size, num_channels, num_classes, lr = 0.0001, out_layer = 'sigmoid', lossfunc='binary_crossentropy', num_out=1):\n",
        "    \"\"\"Residual Unet\n",
        "    Function that generates a residual unet\n",
        "    Args:\n",
        "        input_size: int, dimension of the input image\n",
        "        num_layers: int, number of layers in the encoder half, excludes bridge\n",
        "        num_filters: list, number of filters for each encoder layer\n",
        "        kernel_size: size of the kernel, applied to all convolutions\n",
        "        num_channels: int, number of channels for the input image\n",
        "        num_classes: int, number of output classes for the output\n",
        "    Returns:\n",
        "        model: tensorflow keras model for residual unet architecture\n",
        "    \"\"\"\n",
        "\n",
        "    x = tf.keras.Input(shape=[input_size, input_size, num_channels])\n",
        "\n",
        "    encoder_output = encoder(x, num_filters, kernel_size)\n",
        "\n",
        "    # bridge layer, number of filters is double that of the last encoder layer\n",
        "    bridge = res_block(encoder_output[-1], [num_filters[-1]*2], kernel_size,\n",
        "                        strides=[2,1], name='bridge')\n",
        "\n",
        "    decoder_output = decoder(bridge, encoder_output, num_filters, kernel_size)\n",
        "\n",
        "    output = tf.keras.layers.Conv2D(num_classes,\n",
        "                                    kernel_size,\n",
        "                                    strides=1,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer = 'he_normal',\n",
        "                                    name='output')(decoder_output)\n",
        "\n",
        "    output = Activation(out_layer)(output)\n",
        "\n",
        "    model = tf.keras.Model(x, output)\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics=[dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "res_unet(tileSize, [32, 64, 128, 256], 3, 3, 1).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzrN0bSOH9Y4"
      },
      "source": [
        "## **Attention ResUNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF_o52WbIAUJ",
        "outputId": "aa2a8d44-346b-46a2-8627-9b797ef5d19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " layer1_1 (Conv2D)              (None, 512, 512, 64  1792        ['input_6[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 512, 512, 64  256        ['layer1_1[0][0]']               \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " layer1_shortcut (Conv2D)       (None, 512, 512, 64  256         ['input_6[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 512, 512, 64  256        ['layer1_shortcut[0][0]']        \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " layer1_2 (Conv2D)              (None, 512, 512, 64  36928       ['activation_111[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 512, 512, 64  0           ['batch_normalization_27[0][0]', \n",
            "                                )                                 'layer1_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 512, 512, 64  256        ['add_17[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " encoder_layer1_1 (Conv2D)      (None, 256, 256, 12  73856       ['activation_112[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 256, 256, 12  512        ['encoder_layer1_1[0][0]']       \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer1_shortcut (Conv2  (None, 256, 256, 12  8320       ['add_17[0][0]']                 \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_29[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 256, 256, 12  512        ['encoder_layer1_shortcut[0][0]']\n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer1_2 (Conv2D)      (None, 256, 256, 12  147584      ['activation_113[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 256, 256, 12  0           ['batch_normalization_30[0][0]', \n",
            "                                8)                                'encoder_layer1_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 256, 256, 12  512        ['add_18[0][0]']                 \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_31[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer2_1 (Conv2D)      (None, 128, 128, 25  295168      ['activation_114[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 128, 25  1024       ['encoder_layer2_1[0][0]']       \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer2_shortcut (Conv2  (None, 128, 128, 25  33024      ['add_18[0][0]']                 \n",
            " D)                             6)                                                                \n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_32[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 128, 25  1024       ['encoder_layer2_shortcut[0][0]']\n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer2_2 (Conv2D)      (None, 128, 128, 25  590080      ['activation_115[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 128, 128, 25  0           ['batch_normalization_33[0][0]', \n",
            "                                6)                                'encoder_layer2_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 128, 25  1024       ['add_19[0][0]']                 \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_34[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " encoder_layer3_1 (Conv2D)      (None, 64, 64, 512)  1180160     ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 64, 64, 512)  2048       ['encoder_layer3_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " encoder_layer3_shortcut (Conv2  (None, 64, 64, 512)  131584     ['add_19[0][0]']                 \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 64, 64, 512)  2048       ['encoder_layer3_shortcut[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " encoder_layer3_2 (Conv2D)      (None, 64, 64, 512)  2359808     ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 64, 64, 512)  0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'encoder_layer3_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 64, 64, 512)  2048       ['add_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " bridge_1 (Conv2D)              (None, 32, 32, 1024  4719616     ['activation_118[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 32, 32, 1024  4096       ['bridge_1[0][0]']               \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " bridge_shortcut (Conv2D)       (None, 32, 32, 1024  525312      ['add_20[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 32, 32, 1024  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 32, 32, 1024  4096       ['bridge_shortcut[0][0]']        \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " bridge_2 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_119[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 32, 32, 1024  0           ['batch_normalization_39[0][0]', \n",
            "                                )                                 'bridge_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 64, 64, 512)  262656      ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 32, 32, 512)  524800      ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 32, 32, 512)  0          ['conv2d_81[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 32, 32, 512)  0           ['conv2d_82[0][0]',              \n",
            "                                                                  'max_pooling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 32, 32, 512)  0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 32, 32, 1)    513         ['activation_120[0][0]']         \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 32, 32, 1)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 64, 64, 1)   0           ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 64, 64, 512)  1024        ['up_sampling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 64, 64, 1024  0           ['add_21[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 64, 64, 512)  0           ['conv2d_84[0][0]',              \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 64, 64, 1536  0           ['lambda_4[0][0]',               \n",
            "                                )                                 'multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 64, 64, 1536  6144       ['concatenate_12[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 64, 64, 1536  0           ['batch_normalization_40[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer1_1 (Conv2D)      (None, 64, 64, 512)  7078400     ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 64, 64, 512)  2048       ['decoder_layer1_1[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " decoder_layer1_shortcut (Conv2  (None, 64, 64, 512)  786944     ['concatenate_12[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 64, 64, 512)  2048       ['decoder_layer1_shortcut[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " decoder_layer1_2 (Conv2D)      (None, 64, 64, 512)  2359808     ['activation_123[0][0]']         \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 64, 64, 512)  0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'decoder_layer1_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 128, 128, 25  65792       ['add_19[0][0]']                 \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 64, 64, 256)  131328      ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 64, 64, 256)  0          ['conv2d_85[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 64, 64, 256)  0           ['conv2d_86[0][0]',              \n",
            "                                                                  'max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 64, 64, 256)  0           ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 64, 64, 1)    257         ['activation_124[0][0]']         \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 64, 64, 1)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampling2D  (None, 128, 128, 1)  0          ['activation_125[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 128, 128, 25  512         ['up_sampling2d_10[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 128, 128, 51  0           ['add_23[0][0]']                 \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 128, 128, 25  0           ['conv2d_88[0][0]',              \n",
            "                                6)                                'add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 128, 128, 76  0           ['lambda_5[0][0]',               \n",
            "                                8)                                'multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 128, 128, 76  3072       ['concatenate_13[0][0]']         \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 128, 128, 76  0           ['batch_normalization_43[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_1 (Conv2D)      (None, 128, 128, 25  1769728     ['activation_126[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 128, 128, 25  1024       ['decoder_layer2_1[0][0]']       \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_shortcut (Conv2  (None, 128, 128, 25  196864     ['concatenate_13[0][0]']         \n",
            " D)                             6)                                                                \n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_44[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 128, 128, 25  1024       ['decoder_layer2_shortcut[0][0]']\n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer2_2 (Conv2D)      (None, 128, 128, 25  590080      ['activation_127[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 128, 128, 25  0           ['batch_normalization_45[0][0]', \n",
            "                                6)                                'decoder_layer2_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 256, 256, 12  16512       ['add_18[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 128, 128, 12  32896       ['add_25[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 128, 128, 12  0          ['conv2d_89[0][0]']              \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 128, 128, 12  0           ['conv2d_90[0][0]',              \n",
            "                                8)                                'max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 128, 128, 12  0           ['add_26[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 128, 128, 1)  129         ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 128, 128, 1)  0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampling2D  (None, 256, 256, 1)  0          ['activation_129[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 256, 256, 12  256         ['up_sampling2d_11[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 256, 256, 25  0           ['add_25[0][0]']                 \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 256, 256, 12  0           ['conv2d_92[0][0]',              \n",
            "                                8)                                'add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 256, 256, 38  0           ['lambda_6[0][0]',               \n",
            "                                4)                                'multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 256, 256, 38  1536       ['concatenate_14[0][0]']         \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 256, 256, 38  0           ['batch_normalization_46[0][0]'] \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer3_1 (Conv2D)      (None, 256, 256, 12  442496      ['activation_130[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 256, 256, 12  512        ['decoder_layer3_1[0][0]']       \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer3_shortcut (Conv2  (None, 256, 256, 12  49280      ['concatenate_14[0][0]']         \n",
            " D)                             8)                                                                \n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_47[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 256, 256, 12  512        ['decoder_layer3_shortcut[0][0]']\n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer3_2 (Conv2D)      (None, 256, 256, 12  147584      ['activation_131[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 256, 256, 12  0           ['batch_normalization_48[0][0]', \n",
            "                                8)                                'decoder_layer3_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 512, 512, 64  4160        ['add_17[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 256, 256, 64  8256        ['add_27[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 256, 256, 64  0          ['conv2d_93[0][0]']              \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 256, 256, 64  0           ['conv2d_94[0][0]',              \n",
            "                                )                                 'max_pooling2d_15[0][0]']       \n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 256, 256, 64  0           ['add_28[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 256, 256, 1)  65          ['activation_132[0][0]']         \n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 256, 256, 1)  0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_12 (UpSampling2D  (None, 512, 512, 1)  0          ['activation_133[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 512, 512, 64  128         ['up_sampling2d_12[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 512, 512, 12  0           ['add_27[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 512, 512, 64  0           ['conv2d_96[0][0]',              \n",
            "                                )                                 'add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 512, 512, 19  0           ['lambda_7[0][0]',               \n",
            "                                2)                                'multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 512, 512, 19  768        ['concatenate_15[0][0]']         \n",
            " ormalization)                  2)                                                                \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 512, 512, 19  0           ['batch_normalization_49[0][0]'] \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " decoder_layer4_1 (Conv2D)      (None, 512, 512, 64  110656      ['activation_134[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 512, 512, 64  256        ['decoder_layer4_1[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer4_shortcut (Conv2  (None, 512, 512, 64  12352      ['concatenate_15[0][0]']         \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_50[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 512, 512, 64  256        ['decoder_layer4_shortcut[0][0]']\n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " decoder_layer4_2 (Conv2D)      (None, 512, 512, 64  36928       ['activation_135[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 512, 512, 64  0           ['batch_normalization_51[0][0]', \n",
            "                                )                                 'decoder_layer4_2[0][0]']       \n",
            "                                                                                                  \n",
            " output (Conv2D)                (None, 512, 512, 1)  577         ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 512, 512, 1)  0           ['output[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,211,589\n",
            "Trainable params: 34,192,133\n",
            "Non-trainable params: 19,456\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def attention_block2(x, gating, inter_shape, drop_rate=0.25):\n",
        "\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "    # Initial gate\n",
        "    theta_x = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(x)\n",
        "    theta_x = MaxPooling2D((2,2))(theta_x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "    phi_g = Conv2D(inter_shape, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(gating)\n",
        "    shape_phi_g = K.int_shape(phi_g)\n",
        "\n",
        "    # Add components\n",
        "    concat_xg = add([phi_g, theta_x])\n",
        "    act_xg = Activation('relu')(concat_xg)\n",
        "\n",
        "    # Apply convolution\n",
        "    psi = Conv2D(1, kernel_size = 1, strides = 1, padding='same', kernel_initializer='he_normal', activation=None)(act_xg)\n",
        "\n",
        "    # Apply sigmoid activation\n",
        "    sigmoid_xg = Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "\n",
        "    # UpSample and resample to correct size\n",
        "    upsample_psi = UpSampling2D(interpolation='bilinear', size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = Conv2D(shape_x[3], 1, 1, kernel_initializer='he_normal')(upsample_psi)\n",
        "    #upsample_psi = tf.broadcast_to(upsample_psi, shape=shape_x)\n",
        "    y = multiply([upsample_psi, x])\n",
        "\n",
        "    return y\n",
        "\n",
        "def decoder2(x, encoder_output, num_filters, kernel_size):\n",
        "    for i in range(1, len(num_filters) + 1):\n",
        "        layer = 'decoder_layer' + str(i)\n",
        "        target_size = encoder_output[-i].shape[1:3]\n",
        "        # Attention Block/Mechanism\n",
        "        att = attention_block2(encoder_output[-i], x, num_filters[-i], drop_rate=0.0)\n",
        "        x = upsample(x, target_size)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, att])\n",
        "        x = res_block(x, [num_filters[-i]], kernel_size, strides=[1,1], name=layer)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def att_res_unet(input_size, num_filters, kernel_size, num_channels, num_classes, lr = 0.0001, out_layer = 'sigmoid', lossfunc='binary_crossentropy', num_out=1):\n",
        "\n",
        "    x = tf.keras.Input(shape=[input_size, input_size, num_channels])\n",
        "    # Encoding\n",
        "    encoder_output = encoder(x, num_filters, kernel_size)\n",
        "    # Bottleneck\n",
        "    bridge = res_block(encoder_output[-1], [num_filters[-1]*2], kernel_size,\n",
        "                        strides=[2,1], name='bridge')\n",
        "    # Decoding\n",
        "    decoder_output = decoder2(bridge, encoder_output, num_filters, kernel_size)\n",
        "    # Output\n",
        "    output = tf.keras.layers.Conv2D(num_classes,\n",
        "                                    kernel_size,\n",
        "                                    strides=1,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer = 'he_normal',\n",
        "                                    name='output')(decoder_output)\n",
        "\n",
        "    output = Activation(out_layer)(output)\n",
        "\n",
        "    model = tf.keras.Model(x, output)\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics=[dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "resaunet_tall_ = att_res_unet(tileSize, [64, 128, 256, 512], 3, 3, 1, lr = 0.0005).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OuWrCJvtv70"
      },
      "source": [
        "## **UNet++**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTUyO7LkrzUU",
        "outputId": "6c838a7b-dfca-48ff-97fa-2d21b5a706c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"xnet_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " xnet_down0_0 (Conv2D)       (None, 512, 512, 64)      1792      \n",
            "                                                                 \n",
            " xnet_down0_0_activation (Re  (None, 512, 512, 64)     0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " xnet_down0_1 (Conv2D)       (None, 512, 512, 64)      36928     \n",
            "                                                                 \n",
            " xnet_down0_1_activation (Re  (None, 512, 512, 64)     0         \n",
            " LU)                                                             \n",
            "                                                                 \n",
            " xnet_down1_encode_maxpool (  (None, 256, 256, 64)     0         \n",
            " MaxPooling2D)                                                   \n",
            "                                                                 \n",
            " xnet_down1_conv_0 (Conv2D)  (None, 256, 256, 128)     73856     \n",
            "                                                                 \n",
            " xnet_down1_conv_0_activatio  (None, 256, 256, 128)    0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_down1_conv_1 (Conv2D)  (None, 256, 256, 128)     147584    \n",
            "                                                                 \n",
            " xnet_down1_conv_1_activatio  (None, 256, 256, 128)    0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_down2_encode_maxpool (  (None, 128, 128, 128)    0         \n",
            " MaxPooling2D)                                                   \n",
            "                                                                 \n",
            " xnet_down2_conv_0 (Conv2D)  (None, 128, 128, 256)     295168    \n",
            "                                                                 \n",
            " xnet_down2_conv_0_activatio  (None, 128, 128, 256)    0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_down2_conv_1 (Conv2D)  (None, 128, 128, 256)     590080    \n",
            "                                                                 \n",
            " xnet_down2_conv_1_activatio  (None, 128, 128, 256)    0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_down3_encode_maxpool (  (None, 64, 64, 256)      0         \n",
            " MaxPooling2D)                                                   \n",
            "                                                                 \n",
            " xnet_down3_conv_0 (Conv2D)  (None, 64, 64, 512)       1180160   \n",
            "                                                                 \n",
            " xnet_down3_conv_0_activatio  (None, 64, 64, 512)      0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_down3_conv_1 (Conv2D)  (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " xnet_down3_conv_1_activatio  (None, 64, 64, 512)      0         \n",
            " n (ReLU)                                                        \n",
            "                                                                 \n",
            " xnet_up0_from2_decode_unpoo  (None, 128, 128, 512)    0         \n",
            " l (UpSampling2D)                                                \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_before_  (None, 128, 128, 256)    1179904   \n",
            " concat_0 (Conv2D)                                               \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_before_  (None, 128, 128, 256)    0         \n",
            " concat_0_activation (ReLU)                                      \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_after_c  (None, 128, 128, 256)    590080    \n",
            " oncat_0 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_after_c  (None, 128, 128, 256)    0         \n",
            " oncat_0_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_after_c  (None, 128, 128, 256)    590080    \n",
            " oncat_1 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up0_from2_conv_after_c  (None, 128, 128, 256)    0         \n",
            " oncat_1_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_up1_from1_decode_unpoo  (None, 256, 256, 256)    0         \n",
            " l (UpSampling2D)                                                \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_before_  (None, 256, 256, 128)    295040    \n",
            " concat_0 (Conv2D)                                               \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_before_  (None, 256, 256, 128)    0         \n",
            " concat_0_activation (ReLU)                                      \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_after_c  (None, 256, 256, 128)    147584    \n",
            " oncat_0 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_after_c  (None, 256, 256, 128)    0         \n",
            " oncat_0_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_after_c  (None, 256, 256, 128)    147584    \n",
            " oncat_1 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up1_from1_conv_after_c  (None, 256, 256, 128)    0         \n",
            " oncat_1_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_up2_from0_decode_unpoo  (None, 512, 512, 128)    0         \n",
            " l (UpSampling2D)                                                \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_before_  (None, 512, 512, 64)     73792     \n",
            " concat_0 (Conv2D)                                               \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_before_  (None, 512, 512, 64)     0         \n",
            " concat_0_activation (ReLU)                                      \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_after_c  (None, 512, 512, 64)     36928     \n",
            " oncat_0 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_after_c  (None, 512, 512, 64)     0         \n",
            " oncat_0_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_after_c  (None, 512, 512, 64)     36928     \n",
            " oncat_1 (Conv2D)                                                \n",
            "                                                                 \n",
            " xnet_up2_from0_conv_after_c  (None, 512, 512, 64)     0         \n",
            " oncat_1_activation (ReLU)                                       \n",
            "                                                                 \n",
            " xnet_output (Conv2D)        (None, 512, 512, 1)       65        \n",
            "                                                                 \n",
            " xnet_output_activation (Act  (None, 512, 512, 1)      0         \n",
            " ivation)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,783,361\n",
            "Trainable params: 7,783,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras_unet_collection import models, base, utils\n",
        "from keras_unet_collection.losses import dice\n",
        "\n",
        "def unet_plus(filter_num, n_labels, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "    model = models.unet_plus_2d(input_size, filter_num, n_labels, activation='ReLU', output_activation=out_layer)\n",
        "    # print(model.summary())\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "uNetplus_tall = unet_plus([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3)).summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy5OcOL8048_"
      },
      "source": [
        "## **R2U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PDjJ7EQ08rE",
        "outputId": "e50a51ba-18ac-4026-cf49-a7dd9343a27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"r2_unet_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " r2_unet_input (InputLayer)     [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv (Conv2D)    (None, 512, 512, 64  256         ['r2_unet_input[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv0 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_down0_conv[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation0 (ReL  (None, 512, 512, 64  0          ['r2_unet_down0_conv0[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_add0_0 (Add)     (None, 512, 512, 64  0           ['r2_unet_down0_activation0[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'r2_unet_down0_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv0_0 (Conv2D)  (None, 512, 512, 64  36928      ['r2_unet_down0_add0_0[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation0_0 (R  (None, 512, 512, 64  0          ['r2_unet_down0_conv0_0[0][0]']  \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_add0_1 (Add)     (None, 512, 512, 64  0           ['r2_unet_down0_activation0_0[0][\n",
            "                                )                                0]',                             \n",
            "                                                                  'r2_unet_down0_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv0_1 (Conv2D)  (None, 512, 512, 64  36928      ['r2_unet_down0_add0_1[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation0_1 (R  (None, 512, 512, 64  0          ['r2_unet_down0_conv0_1[0][0]']  \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv1 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_down0_activation0_1[0][\n",
            "                                )                                0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation1 (ReL  (None, 512, 512, 64  0          ['r2_unet_down0_conv1[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_add1_0 (Add)     (None, 512, 512, 64  0           ['r2_unet_down0_activation1[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'r2_unet_down0_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv1_0 (Conv2D)  (None, 512, 512, 64  36928      ['r2_unet_down0_add1_0[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation1_0 (R  (None, 512, 512, 64  0          ['r2_unet_down0_conv1_0[0][0]']  \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_add1_1 (Add)     (None, 512, 512, 64  0           ['r2_unet_down0_activation1_0[0][\n",
            "                                )                                0]',                             \n",
            "                                                                  'r2_unet_down0_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down0_conv1_1 (Conv2D)  (None, 512, 512, 64  36928      ['r2_unet_down0_add1_1[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_activation1_1 (R  (None, 512, 512, 64  0          ['r2_unet_down0_conv1_1[0][0]']  \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down0_add1 (Add)       (None, 512, 512, 64  0           ['r2_unet_down0_activation1_1[0][\n",
            "                                )                                0]',                             \n",
            "                                                                  'r2_unet_down0_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down1_encode_maxpool (  (None, 256, 256, 64  0          ['r2_unet_down0_add1[0][0]']     \n",
            " MaxPooling2D)                  )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv (Conv2D)    (None, 256, 256, 12  8320        ['r2_unet_down1_encode_maxpool[0]\n",
            "                                8)                               [0]']                            \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv0 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_down1_conv[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation0 (ReL  (None, 256, 256, 12  0          ['r2_unet_down1_conv0[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_add0_0 (Add)     (None, 256, 256, 12  0           ['r2_unet_down1_activation0[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'r2_unet_down1_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv0_0 (Conv2D)  (None, 256, 256, 12  147584     ['r2_unet_down1_add0_0[0][0]']   \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation0_0 (R  (None, 256, 256, 12  0          ['r2_unet_down1_conv0_0[0][0]']  \n",
            " eLU)                           8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_add0_1 (Add)     (None, 256, 256, 12  0           ['r2_unet_down1_activation0_0[0][\n",
            "                                8)                               0]',                             \n",
            "                                                                  'r2_unet_down1_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv0_1 (Conv2D)  (None, 256, 256, 12  147584     ['r2_unet_down1_add0_1[0][0]']   \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation0_1 (R  (None, 256, 256, 12  0          ['r2_unet_down1_conv0_1[0][0]']  \n",
            " eLU)                           8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv1 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_down1_activation0_1[0][\n",
            "                                8)                               0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation1 (ReL  (None, 256, 256, 12  0          ['r2_unet_down1_conv1[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_add1_0 (Add)     (None, 256, 256, 12  0           ['r2_unet_down1_activation1[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'r2_unet_down1_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv1_0 (Conv2D)  (None, 256, 256, 12  147584     ['r2_unet_down1_add1_0[0][0]']   \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation1_0 (R  (None, 256, 256, 12  0          ['r2_unet_down1_conv1_0[0][0]']  \n",
            " eLU)                           8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_add1_1 (Add)     (None, 256, 256, 12  0           ['r2_unet_down1_activation1_0[0][\n",
            "                                8)                               0]',                             \n",
            "                                                                  'r2_unet_down1_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down1_conv1_1 (Conv2D)  (None, 256, 256, 12  147584     ['r2_unet_down1_add1_1[0][0]']   \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_activation1_1 (R  (None, 256, 256, 12  0          ['r2_unet_down1_conv1_1[0][0]']  \n",
            " eLU)                           8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down1_add1 (Add)       (None, 256, 256, 12  0           ['r2_unet_down1_activation1_1[0][\n",
            "                                8)                               0]',                             \n",
            "                                                                  'r2_unet_down1_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down2_encode_maxpool (  (None, 128, 128, 12  0          ['r2_unet_down1_add1[0][0]']     \n",
            " MaxPooling2D)                  8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv (Conv2D)    (None, 128, 128, 25  33024       ['r2_unet_down2_encode_maxpool[0]\n",
            "                                6)                               [0]']                            \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv0 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_down2_conv[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation0 (ReL  (None, 128, 128, 25  0          ['r2_unet_down2_conv0[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_add0_0 (Add)     (None, 128, 128, 25  0           ['r2_unet_down2_activation0[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'r2_unet_down2_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv0_0 (Conv2D)  (None, 128, 128, 25  590080     ['r2_unet_down2_add0_0[0][0]']   \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation0_0 (R  (None, 128, 128, 25  0          ['r2_unet_down2_conv0_0[0][0]']  \n",
            " eLU)                           6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_add0_1 (Add)     (None, 128, 128, 25  0           ['r2_unet_down2_activation0_0[0][\n",
            "                                6)                               0]',                             \n",
            "                                                                  'r2_unet_down2_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv0_1 (Conv2D)  (None, 128, 128, 25  590080     ['r2_unet_down2_add0_1[0][0]']   \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation0_1 (R  (None, 128, 128, 25  0          ['r2_unet_down2_conv0_1[0][0]']  \n",
            " eLU)                           6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv1 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_down2_activation0_1[0][\n",
            "                                6)                               0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation1 (ReL  (None, 128, 128, 25  0          ['r2_unet_down2_conv1[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_add1_0 (Add)     (None, 128, 128, 25  0           ['r2_unet_down2_activation1[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'r2_unet_down2_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv1_0 (Conv2D)  (None, 128, 128, 25  590080     ['r2_unet_down2_add1_0[0][0]']   \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation1_0 (R  (None, 128, 128, 25  0          ['r2_unet_down2_conv1_0[0][0]']  \n",
            " eLU)                           6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_add1_1 (Add)     (None, 128, 128, 25  0           ['r2_unet_down2_activation1_0[0][\n",
            "                                6)                               0]',                             \n",
            "                                                                  'r2_unet_down2_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down2_conv1_1 (Conv2D)  (None, 128, 128, 25  590080     ['r2_unet_down2_add1_1[0][0]']   \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_activation1_1 (R  (None, 128, 128, 25  0          ['r2_unet_down2_conv1_1[0][0]']  \n",
            " eLU)                           6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_down2_add1 (Add)       (None, 128, 128, 25  0           ['r2_unet_down2_activation1_1[0][\n",
            "                                6)                               0]',                             \n",
            "                                                                  'r2_unet_down2_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down3_encode_maxpool (  (None, 64, 64, 256)  0          ['r2_unet_down2_add1[0][0]']     \n",
            " MaxPooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv (Conv2D)    (None, 64, 64, 512)  131584      ['r2_unet_down3_encode_maxpool[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv0 (Conv2D)   (None, 64, 64, 512)  2359808     ['r2_unet_down3_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation0 (ReL  (None, 64, 64, 512)  0          ['r2_unet_down3_conv0[0][0]']    \n",
            " U)                                                                                               \n",
            "                                                                                                  \n",
            " r2_unet_down3_add0_0 (Add)     (None, 64, 64, 512)  0           ['r2_unet_down3_activation0[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'r2_unet_down3_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv0_0 (Conv2D)  (None, 64, 64, 512)  2359808    ['r2_unet_down3_add0_0[0][0]']   \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation0_0 (R  (None, 64, 64, 512)  0          ['r2_unet_down3_conv0_0[0][0]']  \n",
            " eLU)                                                                                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_add0_1 (Add)     (None, 64, 64, 512)  0           ['r2_unet_down3_activation0_0[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'r2_unet_down3_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv0_1 (Conv2D)  (None, 64, 64, 512)  2359808    ['r2_unet_down3_add0_1[0][0]']   \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation0_1 (R  (None, 64, 64, 512)  0          ['r2_unet_down3_conv0_1[0][0]']  \n",
            " eLU)                                                                                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv1 (Conv2D)   (None, 64, 64, 512)  2359808     ['r2_unet_down3_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation1 (ReL  (None, 64, 64, 512)  0          ['r2_unet_down3_conv1[0][0]']    \n",
            " U)                                                                                               \n",
            "                                                                                                  \n",
            " r2_unet_down3_add1_0 (Add)     (None, 64, 64, 512)  0           ['r2_unet_down3_activation1[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'r2_unet_down3_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv1_0 (Conv2D)  (None, 64, 64, 512)  2359808    ['r2_unet_down3_add1_0[0][0]']   \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation1_0 (R  (None, 64, 64, 512)  0          ['r2_unet_down3_conv1_0[0][0]']  \n",
            " eLU)                                                                                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_add1_1 (Add)     (None, 64, 64, 512)  0           ['r2_unet_down3_activation1_0[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'r2_unet_down3_activation0_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_conv1_1 (Conv2D)  (None, 64, 64, 512)  2359808    ['r2_unet_down3_add1_1[0][0]']   \n",
            "                                                                                                  \n",
            " r2_unet_down3_activation1_1 (R  (None, 64, 64, 512)  0          ['r2_unet_down3_conv1_1[0][0]']  \n",
            " eLU)                                                                                             \n",
            "                                                                                                  \n",
            " r2_unet_down3_add1 (Add)       (None, 64, 64, 512)  0           ['r2_unet_down3_activation1_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'r2_unet_down3_conv[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_up1_decode_unpool (UpS  (None, 128, 128, 51  0          ['r2_unet_down3_add1[0][0]']     \n",
            " ampling2D)                     2)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv_before_concat  (None, 128, 128, 25  1179904    ['r2_unet_up1_decode_unpool[0][0]\n",
            " _0 (Conv2D)                    6)                               ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv_before_concat  (None, 128, 128, 25  0          ['r2_unet_up1_conv_before_concat_\n",
            " _0_activation (ReLU)           6)                               0[0][0]']                        \n",
            "                                                                                                  \n",
            " r2_unet_up1_concat (Concatenat  (None, 128, 128, 51  0          ['r2_unet_up1_conv_before_concat_\n",
            " e)                             2)                               0_activation[0][0]',             \n",
            "                                                                  'r2_unet_down2_add1[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv (Conv2D)      (None, 128, 128, 25  131328      ['r2_unet_up1_concat[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv0 (Conv2D)     (None, 128, 128, 25  590080      ['r2_unet_up1_conv[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation0 (ReLU)  (None, 128, 128, 25  0          ['r2_unet_up1_conv0[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_add0_0 (Add)       (None, 128, 128, 25  0           ['r2_unet_up1_activation0[0][0]',\n",
            "                                6)                                'r2_unet_up1_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv0_0 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_up1_add0_0[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation0_0 (ReL  (None, 128, 128, 25  0          ['r2_unet_up1_conv0_0[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_add0_1 (Add)       (None, 128, 128, 25  0           ['r2_unet_up1_activation0_0[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'r2_unet_up1_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv0_1 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_up1_add0_1[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation0_1 (ReL  (None, 128, 128, 25  0          ['r2_unet_up1_conv0_1[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv1 (Conv2D)     (None, 128, 128, 25  590080      ['r2_unet_up1_activation0_1[0][0]\n",
            "                                6)                               ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation1 (ReLU)  (None, 128, 128, 25  0          ['r2_unet_up1_conv1[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_add1_0 (Add)       (None, 128, 128, 25  0           ['r2_unet_up1_activation1[0][0]',\n",
            "                                6)                                'r2_unet_up1_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv1_0 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_up1_add1_0[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation1_0 (ReL  (None, 128, 128, 25  0          ['r2_unet_up1_conv1_0[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_add1_1 (Add)       (None, 128, 128, 25  0           ['r2_unet_up1_activation1_0[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'r2_unet_up1_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up1_conv1_1 (Conv2D)   (None, 128, 128, 25  590080      ['r2_unet_up1_add1_1[0][0]']     \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_activation1_1 (ReL  (None, 128, 128, 25  0          ['r2_unet_up1_conv1_1[0][0]']    \n",
            " U)                             6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up1_add1 (Add)         (None, 128, 128, 25  0           ['r2_unet_up1_activation1_1[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'r2_unet_up1_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up2_decode_unpool (UpS  (None, 256, 256, 25  0          ['r2_unet_up1_add1[0][0]']       \n",
            " ampling2D)                     6)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv_before_concat  (None, 256, 256, 12  295040     ['r2_unet_up2_decode_unpool[0][0]\n",
            " _0 (Conv2D)                    8)                               ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv_before_concat  (None, 256, 256, 12  0          ['r2_unet_up2_conv_before_concat_\n",
            " _0_activation (ReLU)           8)                               0[0][0]']                        \n",
            "                                                                                                  \n",
            " r2_unet_up2_concat (Concatenat  (None, 256, 256, 25  0          ['r2_unet_up2_conv_before_concat_\n",
            " e)                             6)                               0_activation[0][0]',             \n",
            "                                                                  'r2_unet_down1_add1[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv (Conv2D)      (None, 256, 256, 12  32896       ['r2_unet_up2_concat[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv0 (Conv2D)     (None, 256, 256, 12  147584      ['r2_unet_up2_conv[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation0 (ReLU)  (None, 256, 256, 12  0          ['r2_unet_up2_conv0[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_add0_0 (Add)       (None, 256, 256, 12  0           ['r2_unet_up2_activation0[0][0]',\n",
            "                                8)                                'r2_unet_up2_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv0_0 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_up2_add0_0[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation0_0 (ReL  (None, 256, 256, 12  0          ['r2_unet_up2_conv0_0[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_add0_1 (Add)       (None, 256, 256, 12  0           ['r2_unet_up2_activation0_0[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'r2_unet_up2_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv0_1 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_up2_add0_1[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation0_1 (ReL  (None, 256, 256, 12  0          ['r2_unet_up2_conv0_1[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv1 (Conv2D)     (None, 256, 256, 12  147584      ['r2_unet_up2_activation0_1[0][0]\n",
            "                                8)                               ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation1 (ReLU)  (None, 256, 256, 12  0          ['r2_unet_up2_conv1[0][0]']      \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_add1_0 (Add)       (None, 256, 256, 12  0           ['r2_unet_up2_activation1[0][0]',\n",
            "                                8)                                'r2_unet_up2_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv1_0 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_up2_add1_0[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation1_0 (ReL  (None, 256, 256, 12  0          ['r2_unet_up2_conv1_0[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_add1_1 (Add)       (None, 256, 256, 12  0           ['r2_unet_up2_activation1_0[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'r2_unet_up2_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up2_conv1_1 (Conv2D)   (None, 256, 256, 12  147584      ['r2_unet_up2_add1_1[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_activation1_1 (ReL  (None, 256, 256, 12  0          ['r2_unet_up2_conv1_1[0][0]']    \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up2_add1 (Add)         (None, 256, 256, 12  0           ['r2_unet_up2_activation1_1[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'r2_unet_up2_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up3_decode_unpool (UpS  (None, 512, 512, 12  0          ['r2_unet_up2_add1[0][0]']       \n",
            " ampling2D)                     8)                                                                \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv_before_concat  (None, 512, 512, 64  73792      ['r2_unet_up3_decode_unpool[0][0]\n",
            " _0 (Conv2D)                    )                                ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv_before_concat  (None, 512, 512, 64  0          ['r2_unet_up3_conv_before_concat_\n",
            " _0_activation (ReLU)           )                                0[0][0]']                        \n",
            "                                                                                                  \n",
            " r2_unet_up3_concat (Concatenat  (None, 512, 512, 12  0          ['r2_unet_up3_conv_before_concat_\n",
            " e)                             8)                               0_activation[0][0]',             \n",
            "                                                                  'r2_unet_down0_add1[0][0]']     \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv (Conv2D)      (None, 512, 512, 64  8256        ['r2_unet_up3_concat[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv0 (Conv2D)     (None, 512, 512, 64  36928       ['r2_unet_up3_conv[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation0 (ReLU)  (None, 512, 512, 64  0          ['r2_unet_up3_conv0[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_add0_0 (Add)       (None, 512, 512, 64  0           ['r2_unet_up3_activation0[0][0]',\n",
            "                                )                                 'r2_unet_up3_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv0_0 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_up3_add0_0[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation0_0 (ReL  (None, 512, 512, 64  0          ['r2_unet_up3_conv0_0[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_add0_1 (Add)       (None, 512, 512, 64  0           ['r2_unet_up3_activation0_0[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'r2_unet_up3_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv0_1 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_up3_add0_1[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation0_1 (ReL  (None, 512, 512, 64  0          ['r2_unet_up3_conv0_1[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv1 (Conv2D)     (None, 512, 512, 64  36928       ['r2_unet_up3_activation0_1[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation1 (ReLU)  (None, 512, 512, 64  0          ['r2_unet_up3_conv1[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_add1_0 (Add)       (None, 512, 512, 64  0           ['r2_unet_up3_activation1[0][0]',\n",
            "                                )                                 'r2_unet_up3_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv1_0 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_up3_add1_0[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation1_0 (ReL  (None, 512, 512, 64  0          ['r2_unet_up3_conv1_0[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_add1_1 (Add)       (None, 512, 512, 64  0           ['r2_unet_up3_activation1_0[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'r2_unet_up3_activation0_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " r2_unet_up3_conv1_1 (Conv2D)   (None, 512, 512, 64  36928       ['r2_unet_up3_add1_1[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_activation1_1 (ReL  (None, 512, 512, 64  0          ['r2_unet_up3_conv1_1[0][0]']    \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " r2_unet_up3_add1 (Add)         (None, 512, 512, 64  0           ['r2_unet_up3_activation1_1[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'r2_unet_up3_conv[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_output (Conv2D)        (None, 512, 512, 1)  65          ['r2_unet_up3_add1[0][0]']       \n",
            "                                                                                                  \n",
            " r2_unet_output_activation (Act  (None, 512, 512, 1)  0          ['r2_unet_output[0][0]']         \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,348,417\n",
            "Trainable params: 25,348,417\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def r2_unet(filter_num, n_labels, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "    model = models.r2_unet_2d(input_size, [64, 128, 256, 512], 1, activation='ReLU', output_activation=out_layer)\n",
        "    # print(model.summary())\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "r2_unet([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3)).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r17kF2p111Hl"
      },
      "source": [
        "## **U^2 Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ58Mkp316zE",
        "outputId": "370f8cd9-882c-411c-a1d7-16adc74e571d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "The depth of u2net_2d = len(filter_num_down) + len(filter_4f_num) = 6\n",
            "----------\n",
            "deep_supervision = True\n",
            "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
            "\"final\" is the final output layer):\n",
            "\n",
            "\tu2net_output_sup0_activation\n",
            "\tu2net_output_sup1_activation\n",
            "\tu2net_output_sup2_activation\n",
            "\tu2net_output_sup3_activation\n",
            "\tu2net_output_sup4_activation\n",
            "\tu2net_output_sup5_activation\n",
            "\tu2net_output_final_activation\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " u2net_in_in_0 (Conv2D)         (None, 512, 512, 32  864         ['input_8[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_in_0_bn (BatchNormali  (None, 512, 512, 32  128        ['u2net_in_in_0[0][0]']          \n",
            " zation)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_in_0_activation (ReLU  (None, 512, 512, 32  0          ['u2net_in_in_0_bn[0][0]']       \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_0_0 (Conv2D)     (None, 512, 512, 32  9216        ['u2net_in_in_0_activation[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_in_down_0_0_bn (BatchNor  (None, 512, 512, 32  128        ['u2net_in_down_0_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_0_0_activation (  (None, 512, 512, 32  0          ['u2net_in_down_0_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_encode_0_stride_conv   (None, 256, 256, 32  4096       ['u2net_in_down_0_0_activation[0]\n",
            " (Conv2D)                       )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_0_bn (BatchNor  (None, 256, 256, 32  128        ['u2net_in_encode_0_stride_conv[0\n",
            " malization)                    )                                ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_in_encode_0_activation (  (None, 256, 256, 32  0          ['u2net_in_encode_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_1_0 (Conv2D)     (None, 256, 256, 32  9216        ['u2net_in_encode_0_activation[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_down_1_0_bn (BatchNor  (None, 256, 256, 32  128        ['u2net_in_down_1_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_1_0_activation (  (None, 256, 256, 32  0          ['u2net_in_down_1_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_encode_1_stride_conv   (None, 128, 128, 32  4096       ['u2net_in_down_1_0_activation[0]\n",
            " (Conv2D)                       )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_1_bn (BatchNor  (None, 128, 128, 32  128        ['u2net_in_encode_1_stride_conv[0\n",
            " malization)                    )                                ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_in_encode_1_activation (  (None, 128, 128, 32  0          ['u2net_in_encode_1_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_2_0 (Conv2D)     (None, 128, 128, 32  9216        ['u2net_in_encode_1_activation[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_down_2_0_bn (BatchNor  (None, 128, 128, 32  128        ['u2net_in_down_2_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_down_2_0_activation (  (None, 128, 128, 32  0          ['u2net_in_down_2_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_encode_2_stride_conv   (None, 64, 64, 32)  4096        ['u2net_in_down_2_0_activation[0]\n",
            " (Conv2D)                                                        [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_2_bn (BatchNor  (None, 64, 64, 32)  128         ['u2net_in_encode_2_stride_conv[0\n",
            " malization)                                                     ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_in_encode_2_activation (  (None, 64, 64, 32)  0           ['u2net_in_encode_2_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_down_3_0 (Conv2D)     (None, 64, 64, 32)   9216        ['u2net_in_encode_2_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_down_3_0_bn (BatchNor  (None, 64, 64, 32)  128         ['u2net_in_down_3_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_in_down_3_0_activation (  (None, 64, 64, 32)  0           ['u2net_in_down_3_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_3_stride_conv   (None, 32, 32, 32)  4096        ['u2net_in_down_3_0_activation[0]\n",
            " (Conv2D)                                                        [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_3_bn (BatchNor  (None, 32, 32, 32)  128         ['u2net_in_encode_3_stride_conv[0\n",
            " malization)                                                     ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_in_encode_3_activation (  (None, 32, 32, 32)  0           ['u2net_in_encode_3_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_down_4_0 (Conv2D)     (None, 32, 32, 32)   9216        ['u2net_in_encode_3_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_down_4_0_bn (BatchNor  (None, 32, 32, 32)  128         ['u2net_in_down_4_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_in_down_4_0_activation (  (None, 32, 32, 32)  0           ['u2net_in_down_4_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_4_stride_conv   (None, 16, 16, 32)  4096        ['u2net_in_down_4_0_activation[0]\n",
            " (Conv2D)                                                        [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_encode_4_bn (BatchNor  (None, 16, 16, 32)  128         ['u2net_in_encode_4_stride_conv[0\n",
            " malization)                                                     ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_in_encode_4_activation (  (None, 16, 16, 32)  0           ['u2net_in_encode_4_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_down_5_0 (Conv2D)     (None, 16, 16, 32)   9216        ['u2net_in_encode_4_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_down_5_0_bn (BatchNor  (None, 16, 16, 32)  128         ['u2net_in_down_5_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_in_down_5_0_activation (  (None, 16, 16, 32)  0           ['u2net_in_down_5_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_up_0_0 (Conv2D)       (None, 16, 16, 32)   9216        ['u2net_in_down_5_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_0_0_bn (BatchNorma  (None, 16, 16, 32)  128         ['u2net_in_up_0_0[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_in_up_0_0_activation (Re  (None, 16, 16, 32)  0           ['u2net_in_up_0_0_bn[0][0]']     \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " u2net_in_concat_0 (Concatenate  (None, 16, 16, 64)  0           ['u2net_in_up_0_0_activation[0][0\n",
            " )                                                               ]',                              \n",
            "                                                                  'u2net_in_down_5_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_1_0 (Conv2D)       (None, 16, 16, 32)   18432       ['u2net_in_concat_0[0][0]']      \n",
            "                                                                                                  \n",
            " u2net_in_up_1_0_bn (BatchNorma  (None, 16, 16, 32)  128         ['u2net_in_up_1_0[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_in_up_1_0_activation (Re  (None, 16, 16, 32)  0           ['u2net_in_up_1_0_bn[0][0]']     \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_0_trans_conv (  (None, 32, 32, 32)  9248        ['u2net_in_up_1_0_activation[0][0\n",
            " Conv2DTranspose)                                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_0_bn (BatchNor  (None, 32, 32, 32)  128         ['u2net_in_decode_0_trans_conv[0]\n",
            " malization)                                                     [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_decode_0_activation (  (None, 32, 32, 32)  0           ['u2net_in_decode_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_concat_1 (Concatenate  (None, 32, 32, 64)  0           ['u2net_in_decode_0_activation[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'u2net_in_down_4_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_2_0 (Conv2D)       (None, 32, 32, 32)   18432       ['u2net_in_concat_1[0][0]']      \n",
            "                                                                                                  \n",
            " u2net_in_up_2_0_bn (BatchNorma  (None, 32, 32, 32)  128         ['u2net_in_up_2_0[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_in_up_2_0_activation (Re  (None, 32, 32, 32)  0           ['u2net_in_up_2_0_bn[0][0]']     \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_1_trans_conv (  (None, 64, 64, 32)  9248        ['u2net_in_up_2_0_activation[0][0\n",
            " Conv2DTranspose)                                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_1_bn (BatchNor  (None, 64, 64, 32)  128         ['u2net_in_decode_1_trans_conv[0]\n",
            " malization)                                                     [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_decode_1_activation (  (None, 64, 64, 32)  0           ['u2net_in_decode_1_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_in_concat_2 (Concatenate  (None, 64, 64, 64)  0           ['u2net_in_decode_1_activation[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'u2net_in_down_3_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_3_0 (Conv2D)       (None, 64, 64, 32)   18432       ['u2net_in_concat_2[0][0]']      \n",
            "                                                                                                  \n",
            " u2net_in_up_3_0_bn (BatchNorma  (None, 64, 64, 32)  128         ['u2net_in_up_3_0[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_in_up_3_0_activation (Re  (None, 64, 64, 32)  0           ['u2net_in_up_3_0_bn[0][0]']     \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_2_trans_conv (  (None, 128, 128, 32  9248       ['u2net_in_up_3_0_activation[0][0\n",
            " Conv2DTranspose)               )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_2_bn (BatchNor  (None, 128, 128, 32  128        ['u2net_in_decode_2_trans_conv[0]\n",
            " malization)                    )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_decode_2_activation (  (None, 128, 128, 32  0          ['u2net_in_decode_2_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_concat_3 (Concatenate  (None, 128, 128, 64  0          ['u2net_in_decode_2_activation[0]\n",
            " )                              )                                [0]',                            \n",
            "                                                                  'u2net_in_down_2_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_4_0 (Conv2D)       (None, 128, 128, 32  18432       ['u2net_in_concat_3[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_up_4_0_bn (BatchNorma  (None, 128, 128, 32  128        ['u2net_in_up_4_0[0][0]']        \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_up_4_0_activation (Re  (None, 128, 128, 32  0          ['u2net_in_up_4_0_bn[0][0]']     \n",
            " LU)                            )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_decode_3_trans_conv (  (None, 256, 256, 32  9248       ['u2net_in_up_4_0_activation[0][0\n",
            " Conv2DTranspose)               )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_3_bn (BatchNor  (None, 256, 256, 32  128        ['u2net_in_decode_3_trans_conv[0]\n",
            " malization)                    )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_decode_3_activation (  (None, 256, 256, 32  0          ['u2net_in_decode_3_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_concat_4 (Concatenate  (None, 256, 256, 64  0          ['u2net_in_decode_3_activation[0]\n",
            " )                              )                                [0]',                            \n",
            "                                                                  'u2net_in_down_1_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_up_5_0 (Conv2D)       (None, 256, 256, 32  18432       ['u2net_in_concat_4[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_up_5_0_bn (BatchNorma  (None, 256, 256, 32  128        ['u2net_in_up_5_0[0][0]']        \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_up_5_0_activation (Re  (None, 256, 256, 32  0          ['u2net_in_up_5_0_bn[0][0]']     \n",
            " LU)                            )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_decode_4_trans_conv (  (None, 512, 512, 32  9248       ['u2net_in_up_5_0_activation[0][0\n",
            " Conv2DTranspose)               )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_in_decode_4_bn (BatchNor  (None, 512, 512, 32  128        ['u2net_in_decode_4_trans_conv[0]\n",
            " malization)                    )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_decode_4_activation (  (None, 512, 512, 32  0          ['u2net_in_decode_4_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_concat_out (Concatena  (None, 512, 512, 64  0          ['u2net_in_decode_4_activation[0]\n",
            " te)                            )                                [0]',                            \n",
            "                                                                  'u2net_in_down_0_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_in_out_0 (Conv2D)        (None, 512, 512, 32  18432       ['u2net_in_concat_out[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_out_0_bn (BatchNormal  (None, 512, 512, 32  128        ['u2net_in_out_0[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_out_0_activation (ReL  (None, 512, 512, 32  0          ['u2net_in_out_0_bn[0][0]']      \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " u2net_in_out_add (Add)         (None, 512, 512, 32  0           ['u2net_in_out_0_activation[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'u2net_in_in_0_activation[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " u2net_encode_0_stride_conv (Co  (None, 256, 256, 64  8192       ['u2net_in_out_add[0][0]']       \n",
            " nv2D)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_encode_0_bn (BatchNormal  (None, 256, 256, 64  256        ['u2net_encode_0_stride_conv[0][0\n",
            " ization)                       )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_encode_0_activation (ReL  (None, 256, 256, 64  0          ['u2net_encode_0_bn[0][0]']      \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_in_0 (Conv2D)     (None, 256, 256, 64  36864       ['u2net_encode_0_activation[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " u2net_down_0_in_0_bn (BatchNor  (None, 256, 256, 64  256        ['u2net_down_0_in_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_in_0_activation (  (None, 256, 256, 64  0          ['u2net_down_0_in_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_down_0_0 (Conv2D)  (None, 256, 256, 64  36864      ['u2net_down_0_in_0_activation[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_down_0_down_0_0_bn (Batc  (None, 256, 256, 64  256        ['u2net_down_0_down_0_0[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_down_0_0_activati  (None, 256, 256, 64  0          ['u2net_down_0_down_0_0_bn[0][0]'\n",
            " on (ReLU)                      )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_0_stride_c  (None, 128, 128, 64  16384      ['u2net_down_0_down_0_0_activatio\n",
            " onv (Conv2D)                   )                                n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_0_bn (Batc  (None, 128, 128, 64  256        ['u2net_down_0_encode_0_stride_co\n",
            " hNormalization)                )                                nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_0_activati  (None, 128, 128, 64  0          ['u2net_down_0_encode_0_bn[0][0]'\n",
            " on (ReLU)                      )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_down_1_0 (Conv2D)  (None, 128, 128, 64  36864      ['u2net_down_0_encode_0_activatio\n",
            "                                )                                n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_down_1_0_bn (Batc  (None, 128, 128, 64  256        ['u2net_down_0_down_1_0[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_down_1_0_activati  (None, 128, 128, 64  0          ['u2net_down_0_down_1_0_bn[0][0]'\n",
            " on (ReLU)                      )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_1_stride_c  (None, 64, 64, 64)  16384       ['u2net_down_0_down_1_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_1_bn (Batc  (None, 64, 64, 64)  256         ['u2net_down_0_encode_1_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_1_activati  (None, 64, 64, 64)  0           ['u2net_down_0_encode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_down_2_0 (Conv2D)  (None, 64, 64, 64)  36864       ['u2net_down_0_encode_1_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_down_2_0_bn (Batc  (None, 64, 64, 64)  256         ['u2net_down_0_down_2_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_0_down_2_0_activati  (None, 64, 64, 64)  0           ['u2net_down_0_down_2_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_2_stride_c  (None, 32, 32, 64)  16384       ['u2net_down_0_down_2_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_2_bn (Batc  (None, 32, 32, 64)  256         ['u2net_down_0_encode_2_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_2_activati  (None, 32, 32, 64)  0           ['u2net_down_0_encode_2_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_down_3_0 (Conv2D)  (None, 32, 32, 64)  36864       ['u2net_down_0_encode_2_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_down_3_0_bn (Batc  (None, 32, 32, 64)  256         ['u2net_down_0_down_3_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_0_down_3_0_activati  (None, 32, 32, 64)  0           ['u2net_down_0_down_3_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_3_stride_c  (None, 16, 16, 64)  16384       ['u2net_down_0_down_3_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_3_bn (Batc  (None, 16, 16, 64)  256         ['u2net_down_0_encode_3_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_0_encode_3_activati  (None, 16, 16, 64)  0           ['u2net_down_0_encode_3_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_down_4_0 (Conv2D)  (None, 16, 16, 64)  36864       ['u2net_down_0_encode_3_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_down_4_0_bn (Batc  (None, 16, 16, 64)  256         ['u2net_down_0_down_4_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_0_down_4_0_activati  (None, 16, 16, 64)  0           ['u2net_down_0_down_4_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_up_0_0 (Conv2D)   (None, 16, 16, 64)   36864       ['u2net_down_0_down_4_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_up_0_0_bn (BatchN  (None, 16, 16, 64)  256         ['u2net_down_0_up_0_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_0_up_0_0_activation  (None, 16, 16, 64)  0           ['u2net_down_0_up_0_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_0_concat_0 (Concate  (None, 16, 16, 128)  0          ['u2net_down_0_up_0_0_activation[\n",
            " nate)                                                           0][0]',                          \n",
            "                                                                  'u2net_down_0_down_4_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_up_1_0 (Conv2D)   (None, 16, 16, 64)   73728       ['u2net_down_0_concat_0[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_0_up_1_0_bn (BatchN  (None, 16, 16, 64)  256         ['u2net_down_0_up_1_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_0_up_1_0_activation  (None, 16, 16, 64)  0           ['u2net_down_0_up_1_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_0_trans_co  (None, 32, 32, 64)  36928       ['u2net_down_0_up_1_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_0_bn (Batc  (None, 32, 32, 64)  256         ['u2net_down_0_decode_0_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_0_activati  (None, 32, 32, 64)  0           ['u2net_down_0_decode_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_concat_1 (Concate  (None, 32, 32, 128)  0          ['u2net_down_0_decode_0_activatio\n",
            " nate)                                                           n[0][0]',                        \n",
            "                                                                  'u2net_down_0_down_3_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_up_2_0 (Conv2D)   (None, 32, 32, 64)   73728       ['u2net_down_0_concat_1[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_0_up_2_0_bn (BatchN  (None, 32, 32, 64)  256         ['u2net_down_0_up_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_0_up_2_0_activation  (None, 32, 32, 64)  0           ['u2net_down_0_up_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_1_trans_co  (None, 64, 64, 64)  36928       ['u2net_down_0_up_2_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_1_bn (Batc  (None, 64, 64, 64)  256         ['u2net_down_0_decode_1_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_1_activati  (None, 64, 64, 64)  0           ['u2net_down_0_decode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_concat_2 (Concate  (None, 64, 64, 128)  0          ['u2net_down_0_decode_1_activatio\n",
            " nate)                                                           n[0][0]',                        \n",
            "                                                                  'u2net_down_0_down_2_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_up_3_0 (Conv2D)   (None, 64, 64, 64)   73728       ['u2net_down_0_concat_2[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_0_up_3_0_bn (BatchN  (None, 64, 64, 64)  256         ['u2net_down_0_up_3_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_0_up_3_0_activation  (None, 64, 64, 64)  0           ['u2net_down_0_up_3_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_2_trans_co  (None, 128, 128, 64  36928      ['u2net_down_0_up_3_0_activation[\n",
            " nv (Conv2DTranspose)           )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_2_bn (Batc  (None, 128, 128, 64  256        ['u2net_down_0_decode_2_trans_con\n",
            " hNormalization)                )                                v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_2_activati  (None, 128, 128, 64  0          ['u2net_down_0_decode_2_bn[0][0]'\n",
            " on (ReLU)                      )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_concat_3 (Concate  (None, 128, 128, 12  0          ['u2net_down_0_decode_2_activatio\n",
            " nate)                          8)                               n[0][0]',                        \n",
            "                                                                  'u2net_down_0_down_1_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_up_4_0 (Conv2D)   (None, 128, 128, 64  73728       ['u2net_down_0_concat_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_up_4_0_bn (BatchN  (None, 128, 128, 64  256        ['u2net_down_0_up_4_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_up_4_0_activation  (None, 128, 128, 64  0          ['u2net_down_0_up_4_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_3_trans_co  (None, 256, 256, 64  36928      ['u2net_down_0_up_4_0_activation[\n",
            " nv (Conv2DTranspose)           )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_3_bn (Batc  (None, 256, 256, 64  256        ['u2net_down_0_decode_3_trans_con\n",
            " hNormalization)                )                                v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_decode_3_activati  (None, 256, 256, 64  0          ['u2net_down_0_decode_3_bn[0][0]'\n",
            " on (ReLU)                      )                                ]                                \n",
            "                                                                                                  \n",
            " u2net_down_0_concat_out (Conca  (None, 256, 256, 12  0          ['u2net_down_0_decode_3_activatio\n",
            " tenate)                        8)                               n[0][0]',                        \n",
            "                                                                  'u2net_down_0_down_0_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_0_out_0 (Conv2D)    (None, 256, 256, 64  73728       ['u2net_down_0_concat_out[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_out_0_bn (BatchNo  (None, 256, 256, 64  256        ['u2net_down_0_out_0[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_out_0_activation   (None, 256, 256, 64  0          ['u2net_down_0_out_0_bn[0][0]']  \n",
            " (ReLU)                         )                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_0_out_add (Add)     (None, 256, 256, 64  0           ['u2net_down_0_out_0_activation[0\n",
            "                                )                                ][0]',                           \n",
            "                                                                  'u2net_down_0_in_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_encode_1_stride_conv (Co  (None, 128, 128, 12  32768      ['u2net_down_0_out_add[0][0]']   \n",
            " nv2D)                          8)                                                                \n",
            "                                                                                                  \n",
            " u2net_encode_1_bn (BatchNormal  (None, 128, 128, 12  512        ['u2net_encode_1_stride_conv[0][0\n",
            " ization)                       8)                               ]']                              \n",
            "                                                                                                  \n",
            " u2net_encode_1_activation (ReL  (None, 128, 128, 12  0          ['u2net_encode_1_bn[0][0]']      \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_in_0 (Conv2D)     (None, 128, 128, 12  147456      ['u2net_encode_1_activation[0][0]\n",
            "                                8)                               ']                               \n",
            "                                                                                                  \n",
            " u2net_down_1_in_0_bn (BatchNor  (None, 128, 128, 12  512        ['u2net_down_1_in_0[0][0]']      \n",
            " malization)                    8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_in_0_activation (  (None, 128, 128, 12  0          ['u2net_down_1_in_0_bn[0][0]']   \n",
            " ReLU)                          8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_down_0_0 (Conv2D)  (None, 128, 128, 12  147456     ['u2net_down_1_in_0_activation[0]\n",
            "                                8)                               [0]']                            \n",
            "                                                                                                  \n",
            " u2net_down_1_down_0_0_bn (Batc  (None, 128, 128, 12  512        ['u2net_down_1_down_0_0[0][0]']  \n",
            " hNormalization)                8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_down_0_0_activati  (None, 128, 128, 12  0          ['u2net_down_1_down_0_0_bn[0][0]'\n",
            " on (ReLU)                      8)                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_0_stride_c  (None, 64, 64, 128)  65536      ['u2net_down_1_down_0_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_0_bn (Batc  (None, 64, 64, 128)  512        ['u2net_down_1_encode_0_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_0_activati  (None, 64, 64, 128)  0          ['u2net_down_1_encode_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_down_1_0 (Conv2D)  (None, 64, 64, 128)  147456     ['u2net_down_1_encode_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_down_1_0_bn (Batc  (None, 64, 64, 128)  512        ['u2net_down_1_down_1_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_1_down_1_0_activati  (None, 64, 64, 128)  0          ['u2net_down_1_down_1_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_1_stride_c  (None, 32, 32, 128)  65536      ['u2net_down_1_down_1_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_1_bn (Batc  (None, 32, 32, 128)  512        ['u2net_down_1_encode_1_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_1_activati  (None, 32, 32, 128)  0          ['u2net_down_1_encode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_down_2_0 (Conv2D)  (None, 32, 32, 128)  147456     ['u2net_down_1_encode_1_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_down_2_0_bn (Batc  (None, 32, 32, 128)  512        ['u2net_down_1_down_2_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_1_down_2_0_activati  (None, 32, 32, 128)  0          ['u2net_down_1_down_2_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_2_stride_c  (None, 16, 16, 128)  65536      ['u2net_down_1_down_2_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_2_bn (Batc  (None, 16, 16, 128)  512        ['u2net_down_1_encode_2_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_1_encode_2_activati  (None, 16, 16, 128)  0          ['u2net_down_1_encode_2_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_down_3_0 (Conv2D)  (None, 16, 16, 128)  147456     ['u2net_down_1_encode_2_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_down_3_0_bn (Batc  (None, 16, 16, 128)  512        ['u2net_down_1_down_3_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_1_down_3_0_activati  (None, 16, 16, 128)  0          ['u2net_down_1_down_3_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_up_0_0 (Conv2D)   (None, 16, 16, 128)  147456      ['u2net_down_1_down_3_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_up_0_0_bn (BatchN  (None, 16, 16, 128)  512        ['u2net_down_1_up_0_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_1_up_0_0_activation  (None, 16, 16, 128)  0          ['u2net_down_1_up_0_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_1_concat_0 (Concate  (None, 16, 16, 256)  0          ['u2net_down_1_up_0_0_activation[\n",
            " nate)                                                           0][0]',                          \n",
            "                                                                  'u2net_down_1_down_3_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_up_1_0 (Conv2D)   (None, 16, 16, 128)  294912      ['u2net_down_1_concat_0[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_1_up_1_0_bn (BatchN  (None, 16, 16, 128)  512        ['u2net_down_1_up_1_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_1_up_1_0_activation  (None, 16, 16, 128)  0          ['u2net_down_1_up_1_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_0_trans_co  (None, 32, 32, 128)  147584     ['u2net_down_1_up_1_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_0_bn (Batc  (None, 32, 32, 128)  512        ['u2net_down_1_decode_0_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_0_activati  (None, 32, 32, 128)  0          ['u2net_down_1_decode_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_concat_1 (Concate  (None, 32, 32, 256)  0          ['u2net_down_1_decode_0_activatio\n",
            " nate)                                                           n[0][0]',                        \n",
            "                                                                  'u2net_down_1_down_2_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_up_2_0 (Conv2D)   (None, 32, 32, 128)  294912      ['u2net_down_1_concat_1[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_1_up_2_0_bn (BatchN  (None, 32, 32, 128)  512        ['u2net_down_1_up_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_1_up_2_0_activation  (None, 32, 32, 128)  0          ['u2net_down_1_up_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_1_trans_co  (None, 64, 64, 128)  147584     ['u2net_down_1_up_2_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_1_bn (Batc  (None, 64, 64, 128)  512        ['u2net_down_1_decode_1_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_1_activati  (None, 64, 64, 128)  0          ['u2net_down_1_decode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_concat_2 (Concate  (None, 64, 64, 256)  0          ['u2net_down_1_decode_1_activatio\n",
            " nate)                                                           n[0][0]',                        \n",
            "                                                                  'u2net_down_1_down_1_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_up_3_0 (Conv2D)   (None, 64, 64, 128)  294912      ['u2net_down_1_concat_2[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_1_up_3_0_bn (BatchN  (None, 64, 64, 128)  512        ['u2net_down_1_up_3_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_1_up_3_0_activation  (None, 64, 64, 128)  0          ['u2net_down_1_up_3_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_2_trans_co  (None, 128, 128, 12  147584     ['u2net_down_1_up_3_0_activation[\n",
            " nv (Conv2DTranspose)           8)                               0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_2_bn (Batc  (None, 128, 128, 12  512        ['u2net_down_1_decode_2_trans_con\n",
            " hNormalization)                8)                               v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_decode_2_activati  (None, 128, 128, 12  0          ['u2net_down_1_decode_2_bn[0][0]'\n",
            " on (ReLU)                      8)                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_1_concat_out (Conca  (None, 128, 128, 25  0          ['u2net_down_1_decode_2_activatio\n",
            " tenate)                        6)                               n[0][0]',                        \n",
            "                                                                  'u2net_down_1_down_0_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_1_out_0 (Conv2D)    (None, 128, 128, 12  294912      ['u2net_down_1_concat_out[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_out_0_bn (BatchNo  (None, 128, 128, 12  512        ['u2net_down_1_out_0[0][0]']     \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_out_0_activation   (None, 128, 128, 12  0          ['u2net_down_1_out_0_bn[0][0]']  \n",
            " (ReLU)                         8)                                                                \n",
            "                                                                                                  \n",
            " u2net_down_1_out_add (Add)     (None, 128, 128, 12  0           ['u2net_down_1_out_0_activation[0\n",
            "                                8)                               ][0]',                           \n",
            "                                                                  'u2net_down_1_in_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_encode_2_stride_conv (Co  (None, 64, 64, 256)  131072     ['u2net_down_1_out_add[0][0]']   \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_encode_2_bn (BatchNormal  (None, 64, 64, 256)  1024       ['u2net_encode_2_stride_conv[0][0\n",
            " ization)                                                        ]']                              \n",
            "                                                                                                  \n",
            " u2net_encode_2_activation (ReL  (None, 64, 64, 256)  0          ['u2net_encode_2_bn[0][0]']      \n",
            " U)                                                                                               \n",
            "                                                                                                  \n",
            " u2net_down_2_in_0 (Conv2D)     (None, 64, 64, 256)  589824      ['u2net_encode_2_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " u2net_down_2_in_0_bn (BatchNor  (None, 64, 64, 256)  1024       ['u2net_down_2_in_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_down_2_in_0_activation (  (None, 64, 64, 256)  0          ['u2net_down_2_in_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_down_2_down_0_0 (Conv2D)  (None, 64, 64, 256)  589824     ['u2net_down_2_in_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_down_2_down_0_0_bn (Batc  (None, 64, 64, 256)  1024       ['u2net_down_2_down_0_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_2_down_0_0_activati  (None, 64, 64, 256)  0          ['u2net_down_2_down_0_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_0_stride_c  (None, 32, 32, 256)  262144     ['u2net_down_2_down_0_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_0_bn (Batc  (None, 32, 32, 256)  1024       ['u2net_down_2_encode_0_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_0_activati  (None, 32, 32, 256)  0          ['u2net_down_2_encode_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_down_1_0 (Conv2D)  (None, 32, 32, 256)  589824     ['u2net_down_2_encode_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_down_1_0_bn (Batc  (None, 32, 32, 256)  1024       ['u2net_down_2_down_1_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_2_down_1_0_activati  (None, 32, 32, 256)  0          ['u2net_down_2_down_1_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_1_stride_c  (None, 16, 16, 256)  262144     ['u2net_down_2_down_1_0_activatio\n",
            " onv (Conv2D)                                                    n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_1_bn (Batc  (None, 16, 16, 256)  1024       ['u2net_down_2_encode_1_stride_co\n",
            " hNormalization)                                                 nv[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_down_2_encode_1_activati  (None, 16, 16, 256)  0          ['u2net_down_2_encode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_down_2_0 (Conv2D)  (None, 16, 16, 256)  589824     ['u2net_down_2_encode_1_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_down_2_0_bn (Batc  (None, 16, 16, 256)  1024       ['u2net_down_2_down_2_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_2_down_2_0_activati  (None, 16, 16, 256)  0          ['u2net_down_2_down_2_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_up_0_0 (Conv2D)   (None, 16, 16, 256)  589824      ['u2net_down_2_down_2_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_up_0_0_bn (BatchN  (None, 16, 16, 256)  1024       ['u2net_down_2_up_0_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_2_up_0_0_activation  (None, 16, 16, 256)  0          ['u2net_down_2_up_0_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_2_concat_0 (Concate  (None, 16, 16, 512)  0          ['u2net_down_2_up_0_0_activation[\n",
            " nate)                                                           0][0]',                          \n",
            "                                                                  'u2net_down_2_down_2_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_up_1_0 (Conv2D)   (None, 16, 16, 256)  1179648     ['u2net_down_2_concat_0[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_2_up_1_0_bn (BatchN  (None, 16, 16, 256)  1024       ['u2net_down_2_up_1_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_2_up_1_0_activation  (None, 16, 16, 256)  0          ['u2net_down_2_up_1_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_0_trans_co  (None, 32, 32, 256)  590080     ['u2net_down_2_up_1_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_0_bn (Batc  (None, 32, 32, 256)  1024       ['u2net_down_2_decode_0_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_0_activati  (None, 32, 32, 256)  0          ['u2net_down_2_decode_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_concat_1 (Concate  (None, 32, 32, 512)  0          ['u2net_down_2_decode_0_activatio\n",
            " nate)                                                           n[0][0]',                        \n",
            "                                                                  'u2net_down_2_down_1_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_up_2_0 (Conv2D)   (None, 32, 32, 256)  1179648     ['u2net_down_2_concat_1[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_down_2_up_2_0_bn (BatchN  (None, 32, 32, 256)  1024       ['u2net_down_2_up_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_down_2_up_2_0_activation  (None, 32, 32, 256)  0          ['u2net_down_2_up_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_1_trans_co  (None, 64, 64, 256)  590080     ['u2net_down_2_up_2_0_activation[\n",
            " nv (Conv2DTranspose)                                            0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_1_bn (Batc  (None, 64, 64, 256)  1024       ['u2net_down_2_decode_1_trans_con\n",
            " hNormalization)                                                 v[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_decode_1_activati  (None, 64, 64, 256)  0          ['u2net_down_2_decode_1_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_2_concat_out (Conca  (None, 64, 64, 512)  0          ['u2net_down_2_decode_1_activatio\n",
            " tenate)                                                         n[0][0]',                        \n",
            "                                                                  'u2net_down_2_down_0_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " u2net_down_2_out_0 (Conv2D)    (None, 64, 64, 256)  1179648     ['u2net_down_2_concat_out[0][0]']\n",
            "                                                                                                  \n",
            " u2net_down_2_out_0_bn (BatchNo  (None, 64, 64, 256)  1024       ['u2net_down_2_out_0[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " u2net_down_2_out_0_activation   (None, 64, 64, 256)  0          ['u2net_down_2_out_0_bn[0][0]']  \n",
            " (ReLU)                                                                                           \n",
            "                                                                                                  \n",
            " u2net_down_2_out_add (Add)     (None, 64, 64, 256)  0           ['u2net_down_2_out_0_activation[0\n",
            "                                                                 ][0]',                           \n",
            "                                                                  'u2net_down_2_in_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_encode_4f_0_stride_conv   (None, 32, 32, 256)  262144     ['u2net_down_2_out_add[0][0]']   \n",
            " (Conv2D)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_encode_4f_0_bn (BatchNor  (None, 32, 32, 256)  1024       ['u2net_encode_4f_0_stride_conv[0\n",
            " malization)                                                     ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_encode_4f_0_activation (  (None, 32, 32, 256)  0          ['u2net_encode_4f_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_in_0 (Conv2D)  (None, 32, 32, 256)  589824      ['u2net_encode_4f_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_in_0_bn (Batch  (None, 32, 32, 256)  1024       ['u2net_down_4f_0_in_0[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_in_0_activatio  (None, 32, 32, 256)  0          ['u2net_down_4f_0_in_0_bn[0][0]']\n",
            " n (ReLU)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_0_0 (Conv  (None, 32, 32, 128)  294912     ['u2net_down_4f_0_in_0_activation\n",
            " 2D)                                                             [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_0_0_bn (B  (None, 32, 32, 128)  512        ['u2net_down_4f_0_down_0_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_0_0_activ  (None, 32, 32, 128)  0          ['u2net_down_4f_0_down_0_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_1_0 (Conv  (None, 32, 32, 128)  147456     ['u2net_down_4f_0_down_0_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_1_0_bn (B  (None, 32, 32, 128)  512        ['u2net_down_4f_0_down_1_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_1_0_activ  (None, 32, 32, 128)  0          ['u2net_down_4f_0_down_1_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_2_0 (Conv  (None, 32, 32, 128)  147456     ['u2net_down_4f_0_down_1_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_2_0_bn (B  (None, 32, 32, 128)  512        ['u2net_down_4f_0_down_2_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_2_0_activ  (None, 32, 32, 128)  0          ['u2net_down_4f_0_down_2_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_3_0 (Conv  (None, 32, 32, 128)  147456     ['u2net_down_4f_0_down_2_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_3_0_bn (B  (None, 32, 32, 128)  512        ['u2net_down_4f_0_down_3_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_down_3_0_activ  (None, 32, 32, 128)  0          ['u2net_down_4f_0_down_3_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_concat_0 (Conc  (None, 32, 32, 256)  0          ['u2net_down_4f_0_down_3_0_activa\n",
            " atenate)                                                        tion[0][0]',                     \n",
            "                                                                  'u2net_down_4f_0_down_2_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_0_0 (Conv2D  (None, 32, 32, 128)  294912     ['u2net_down_4f_0_concat_0[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_0_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_down_4f_0_up_0_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_0_0_activat  (None, 32, 32, 128)  0          ['u2net_down_4f_0_up_0_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_concat_1 (Conc  (None, 32, 32, 256)  0          ['u2net_down_4f_0_up_0_0_activati\n",
            " atenate)                                                        on[0][0]',                       \n",
            "                                                                  'u2net_down_4f_0_down_1_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_1_0 (Conv2D  (None, 32, 32, 128)  294912     ['u2net_down_4f_0_concat_1[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_1_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_down_4f_0_up_1_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_up_1_0_activat  (None, 32, 32, 128)  0          ['u2net_down_4f_0_up_1_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_concat_out (Co  (None, 32, 32, 256)  0          ['u2net_down_4f_0_up_1_0_activati\n",
            " ncatenate)                                                      on[0][0]',                       \n",
            "                                                                  'u2net_down_4f_0_down_0_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_out_0 (Conv2D)  (None, 32, 32, 256)  589824     ['u2net_down_4f_0_concat_out[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_out_0_bn (Batc  (None, 32, 32, 256)  1024       ['u2net_down_4f_0_out_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_out_0_activati  (None, 32, 32, 256)  0          ['u2net_down_4f_0_out_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_0_out_add (Add)  (None, 32, 32, 256)  0           ['u2net_down_4f_0_out_0_activatio\n",
            "                                                                 n[0][0]',                        \n",
            "                                                                  'u2net_down_4f_0_in_0_activation\n",
            "                                                                 [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_encode_4f_1_stride_conv   (None, 16, 16, 256)  262144     ['u2net_down_4f_0_out_add[0][0]']\n",
            " (Conv2D)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_encode_4f_1_bn (BatchNor  (None, 16, 16, 256)  1024       ['u2net_encode_4f_1_stride_conv[0\n",
            " malization)                                                     ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_encode_4f_1_activation (  (None, 16, 16, 256)  0          ['u2net_encode_4f_1_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_in_0 (Conv2D)  (None, 16, 16, 256)  589824      ['u2net_encode_4f_1_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_in_0_bn (Batch  (None, 16, 16, 256)  1024       ['u2net_down_4f_1_in_0[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_in_0_activatio  (None, 16, 16, 256)  0          ['u2net_down_4f_1_in_0_bn[0][0]']\n",
            " n (ReLU)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_0_0 (Conv  (None, 16, 16, 128)  294912     ['u2net_down_4f_1_in_0_activation\n",
            " 2D)                                                             [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_0_0_bn (B  (None, 16, 16, 128)  512        ['u2net_down_4f_1_down_0_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_0_0_activ  (None, 16, 16, 128)  0          ['u2net_down_4f_1_down_0_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_1_0 (Conv  (None, 16, 16, 128)  147456     ['u2net_down_4f_1_down_0_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_1_0_bn (B  (None, 16, 16, 128)  512        ['u2net_down_4f_1_down_1_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_1_0_activ  (None, 16, 16, 128)  0          ['u2net_down_4f_1_down_1_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_2_0 (Conv  (None, 16, 16, 128)  147456     ['u2net_down_4f_1_down_1_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_2_0_bn (B  (None, 16, 16, 128)  512        ['u2net_down_4f_1_down_2_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_2_0_activ  (None, 16, 16, 128)  0          ['u2net_down_4f_1_down_2_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_3_0 (Conv  (None, 16, 16, 128)  147456     ['u2net_down_4f_1_down_2_0_activa\n",
            " 2D)                                                             tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_3_0_bn (B  (None, 16, 16, 128)  512        ['u2net_down_4f_1_down_3_0[0][0]'\n",
            " atchNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_down_3_0_activ  (None, 16, 16, 128)  0          ['u2net_down_4f_1_down_3_0_bn[0][\n",
            " ation (ReLU)                                                    0]']                             \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_concat_0 (Conc  (None, 16, 16, 256)  0          ['u2net_down_4f_1_down_3_0_activa\n",
            " atenate)                                                        tion[0][0]',                     \n",
            "                                                                  'u2net_down_4f_1_down_2_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_0_0 (Conv2D  (None, 16, 16, 128)  294912     ['u2net_down_4f_1_concat_0[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_0_0_bn (Bat  (None, 16, 16, 128)  512        ['u2net_down_4f_1_up_0_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_0_0_activat  (None, 16, 16, 128)  0          ['u2net_down_4f_1_up_0_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_concat_1 (Conc  (None, 16, 16, 256)  0          ['u2net_down_4f_1_up_0_0_activati\n",
            " atenate)                                                        on[0][0]',                       \n",
            "                                                                  'u2net_down_4f_1_down_1_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_1_0 (Conv2D  (None, 16, 16, 128)  294912     ['u2net_down_4f_1_concat_1[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_1_0_bn (Bat  (None, 16, 16, 128)  512        ['u2net_down_4f_1_up_1_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_up_1_0_activat  (None, 16, 16, 128)  0          ['u2net_down_4f_1_up_1_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_concat_out (Co  (None, 16, 16, 256)  0          ['u2net_down_4f_1_up_1_0_activati\n",
            " ncatenate)                                                      on[0][0]',                       \n",
            "                                                                  'u2net_down_4f_1_down_0_0_activa\n",
            "                                                                 tion[0][0]']                     \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_out_0 (Conv2D)  (None, 16, 16, 256)  589824     ['u2net_down_4f_1_concat_out[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_out_0_bn (Batc  (None, 16, 16, 256)  1024       ['u2net_down_4f_1_out_0[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_out_0_activati  (None, 16, 16, 256)  0          ['u2net_down_4f_1_out_0_bn[0][0]'\n",
            " on (ReLU)                                                       ]                                \n",
            "                                                                                                  \n",
            " u2net_down_4f_1_out_add (Add)  (None, 16, 16, 256)  0           ['u2net_down_4f_1_out_0_activatio\n",
            "                                                                 n[0][0]',                        \n",
            "                                                                  'u2net_down_4f_1_in_0_activation\n",
            "                                                                 [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_decode_4f_0_trans_conv (  (None, 32, 32, 256)  590080     ['u2net_down_4f_1_out_add[0][0]']\n",
            " Conv2DTranspose)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_decode_4f_0_bn (BatchNor  (None, 32, 32, 256)  1024       ['u2net_decode_4f_0_trans_conv[0]\n",
            " malization)                                                     [0]']                            \n",
            "                                                                                                  \n",
            " u2net_decode_4f_0_activation (  (None, 32, 32, 256)  0          ['u2net_decode_4f_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_concat_4f_0 (Concatenate  (None, 32, 32, 512)  0          ['u2net_decode_4f_0_activation[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'u2net_down_4f_0_out_add[0][0]']\n",
            "                                                                                                  \n",
            " u2net_up_4f_0_in_0 (Conv2D)    (None, 32, 32, 256)  1179648     ['u2net_concat_4f_0[0][0]']      \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_in_0_bn (BatchNo  (None, 32, 32, 256)  1024       ['u2net_up_4f_0_in_0[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_in_0_activation   (None, 32, 32, 256)  0          ['u2net_up_4f_0_in_0_bn[0][0]']  \n",
            " (ReLU)                                                                                           \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_0_0 (Conv2D  (None, 32, 32, 128)  294912     ['u2net_up_4f_0_in_0_activation[0\n",
            " )                                                               ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_0_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_up_4f_0_down_0_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_0_0_activat  (None, 32, 32, 128)  0          ['u2net_up_4f_0_down_0_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_1_0 (Conv2D  (None, 32, 32, 128)  147456     ['u2net_up_4f_0_down_0_0_activati\n",
            " )                                                               on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_1_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_up_4f_0_down_1_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_1_0_activat  (None, 32, 32, 128)  0          ['u2net_up_4f_0_down_1_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_2_0 (Conv2D  (None, 32, 32, 128)  147456     ['u2net_up_4f_0_down_1_0_activati\n",
            " )                                                               on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_2_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_up_4f_0_down_2_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_2_0_activat  (None, 32, 32, 128)  0          ['u2net_up_4f_0_down_2_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_3_0 (Conv2D  (None, 32, 32, 128)  147456     ['u2net_up_4f_0_down_2_0_activati\n",
            " )                                                               on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_3_0_bn (Bat  (None, 32, 32, 128)  512        ['u2net_up_4f_0_down_3_0[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_down_3_0_activat  (None, 32, 32, 128)  0          ['u2net_up_4f_0_down_3_0_bn[0][0]\n",
            " ion (ReLU)                                                      ']                               \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_concat_0 (Concat  (None, 32, 32, 256)  0          ['u2net_up_4f_0_down_3_0_activati\n",
            " enate)                                                          on[0][0]',                       \n",
            "                                                                  'u2net_up_4f_0_down_2_0_activati\n",
            "                                                                 on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_0_0 (Conv2D)  (None, 32, 32, 128)  294912      ['u2net_up_4f_0_concat_0[0][0]'] \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_0_0_bn (Batch  (None, 32, 32, 128)  512        ['u2net_up_4f_0_up_0_0[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_0_0_activatio  (None, 32, 32, 128)  0          ['u2net_up_4f_0_up_0_0_bn[0][0]']\n",
            " n (ReLU)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_concat_1 (Concat  (None, 32, 32, 256)  0          ['u2net_up_4f_0_up_0_0_activation\n",
            " enate)                                                          [0][0]',                         \n",
            "                                                                  'u2net_up_4f_0_down_1_0_activati\n",
            "                                                                 on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_1_0 (Conv2D)  (None, 32, 32, 128)  294912      ['u2net_up_4f_0_concat_1[0][0]'] \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_1_0_bn (Batch  (None, 32, 32, 128)  512        ['u2net_up_4f_0_up_1_0[0][0]']   \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_up_1_0_activatio  (None, 32, 32, 128)  0          ['u2net_up_4f_0_up_1_0_bn[0][0]']\n",
            " n (ReLU)                                                                                         \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_concat_out (Conc  (None, 32, 32, 256)  0          ['u2net_up_4f_0_up_1_0_activation\n",
            " atenate)                                                        [0][0]',                         \n",
            "                                                                  'u2net_up_4f_0_down_0_0_activati\n",
            "                                                                 on[0][0]']                       \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_out_0 (Conv2D)   (None, 32, 32, 256)  589824      ['u2net_up_4f_0_concat_out[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_out_0_bn (BatchN  (None, 32, 32, 256)  1024       ['u2net_up_4f_0_out_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_out_0_activation  (None, 32, 32, 256)  0          ['u2net_up_4f_0_out_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_4f_0_out_add (Add)    (None, 32, 32, 256)  0           ['u2net_up_4f_0_out_0_activation[\n",
            "                                                                 0][0]',                          \n",
            "                                                                  'u2net_up_4f_0_in_0_activation[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " u2net_decode_0_trans_conv (Con  (None, 64, 64, 256)  590080     ['u2net_up_4f_0_out_add[0][0]']  \n",
            " v2DTranspose)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_decode_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['u2net_decode_0_trans_conv[0][0]\n",
            " ization)                                                        ']                               \n",
            "                                                                                                  \n",
            " u2net_decode_0_activation (ReL  (None, 64, 64, 256)  0          ['u2net_decode_0_bn[0][0]']      \n",
            " U)                                                                                               \n",
            "                                                                                                  \n",
            " u2net_concat_0 (Concatenate)   (None, 64, 64, 512)  0           ['u2net_decode_0_activation[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'u2net_down_2_out_add[0][0]']   \n",
            "                                                                                                  \n",
            " u2net_up_0_in_0 (Conv2D)       (None, 64, 64, 256)  1179648     ['u2net_concat_0[0][0]']         \n",
            "                                                                                                  \n",
            " u2net_up_0_in_0_bn (BatchNorma  (None, 64, 64, 256)  1024       ['u2net_up_0_in_0[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_up_0_in_0_activation (Re  (None, 64, 64, 256)  0          ['u2net_up_0_in_0_bn[0][0]']     \n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " u2net_up_0_down_0_0 (Conv2D)   (None, 64, 64, 256)  589824      ['u2net_up_0_in_0_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_up_0_down_0_0_bn (BatchN  (None, 64, 64, 256)  1024       ['u2net_up_0_down_0_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_0_down_0_0_activation  (None, 64, 64, 256)  0          ['u2net_up_0_down_0_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_0_stride_con  (None, 32, 32, 256)  262144     ['u2net_up_0_down_0_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_0_bn (BatchN  (None, 32, 32, 256)  1024       ['u2net_up_0_encode_0_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_0_activation  (None, 32, 32, 256)  0          ['u2net_up_0_encode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_down_1_0 (Conv2D)   (None, 32, 32, 256)  589824      ['u2net_up_0_encode_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_down_1_0_bn (BatchN  (None, 32, 32, 256)  1024       ['u2net_up_0_down_1_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_0_down_1_0_activation  (None, 32, 32, 256)  0          ['u2net_up_0_down_1_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_1_stride_con  (None, 16, 16, 256)  262144     ['u2net_up_0_down_1_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_1_bn (BatchN  (None, 16, 16, 256)  1024       ['u2net_up_0_encode_1_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_0_encode_1_activation  (None, 16, 16, 256)  0          ['u2net_up_0_encode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_down_2_0 (Conv2D)   (None, 16, 16, 256)  589824      ['u2net_up_0_encode_1_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_down_2_0_bn (BatchN  (None, 16, 16, 256)  1024       ['u2net_up_0_down_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_0_down_2_0_activation  (None, 16, 16, 256)  0          ['u2net_up_0_down_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_up_0_0 (Conv2D)     (None, 16, 16, 256)  589824      ['u2net_up_0_down_2_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_up_0_0_bn (BatchNor  (None, 16, 16, 256)  1024       ['u2net_up_0_up_0_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_0_up_0_0_activation (  (None, 16, 16, 256)  0          ['u2net_up_0_up_0_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_0_concat_0 (Concatena  (None, 16, 16, 512)  0          ['u2net_up_0_up_0_0_activation[0]\n",
            " te)                                                             [0]',                            \n",
            "                                                                  'u2net_up_0_down_2_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_up_1_0 (Conv2D)     (None, 16, 16, 256)  1179648     ['u2net_up_0_concat_0[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_0_up_1_0_bn (BatchNor  (None, 16, 16, 256)  1024       ['u2net_up_0_up_1_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_0_up_1_0_activation (  (None, 16, 16, 256)  0          ['u2net_up_0_up_1_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_0_trans_conv  (None, 32, 32, 256)  590080     ['u2net_up_0_up_1_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_0_bn (BatchN  (None, 32, 32, 256)  1024       ['u2net_up_0_decode_0_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_0_activation  (None, 32, 32, 256)  0          ['u2net_up_0_decode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_concat_1 (Concatena  (None, 32, 32, 512)  0          ['u2net_up_0_decode_0_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_0_down_1_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_up_2_0 (Conv2D)     (None, 32, 32, 256)  1179648     ['u2net_up_0_concat_1[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_0_up_2_0_bn (BatchNor  (None, 32, 32, 256)  1024       ['u2net_up_0_up_2_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_0_up_2_0_activation (  (None, 32, 32, 256)  0          ['u2net_up_0_up_2_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_1_trans_conv  (None, 64, 64, 256)  590080     ['u2net_up_0_up_2_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_1_bn (BatchN  (None, 64, 64, 256)  1024       ['u2net_up_0_decode_1_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_decode_1_activation  (None, 64, 64, 256)  0          ['u2net_up_0_decode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_0_concat_out (Concate  (None, 64, 64, 512)  0          ['u2net_up_0_decode_1_activation[\n",
            " nate)                                                           0][0]',                          \n",
            "                                                                  'u2net_up_0_down_0_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_0_out_0 (Conv2D)      (None, 64, 64, 256)  1179648     ['u2net_up_0_concat_out[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_up_0_out_0_bn (BatchNorm  (None, 64, 64, 256)  1024       ['u2net_up_0_out_0[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " u2net_up_0_out_0_activation (R  (None, 64, 64, 256)  0          ['u2net_up_0_out_0_bn[0][0]']    \n",
            " eLU)                                                                                             \n",
            "                                                                                                  \n",
            " u2net_up_0_out_add (Add)       (None, 64, 64, 256)  0           ['u2net_up_0_out_0_activation[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'u2net_up_0_in_0_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_decode_1_trans_conv (Con  (None, 128, 128, 12  295040     ['u2net_up_0_out_add[0][0]']     \n",
            " v2DTranspose)                  8)                                                                \n",
            "                                                                                                  \n",
            " u2net_decode_1_bn (BatchNormal  (None, 128, 128, 12  512        ['u2net_decode_1_trans_conv[0][0]\n",
            " ization)                       8)                               ']                               \n",
            "                                                                                                  \n",
            " u2net_decode_1_activation (ReL  (None, 128, 128, 12  0          ['u2net_decode_1_bn[0][0]']      \n",
            " U)                             8)                                                                \n",
            "                                                                                                  \n",
            " u2net_concat_1 (Concatenate)   (None, 128, 128, 25  0           ['u2net_decode_1_activation[0][0]\n",
            "                                6)                               ',                               \n",
            "                                                                  'u2net_down_1_out_add[0][0]']   \n",
            "                                                                                                  \n",
            " u2net_up_1_in_0 (Conv2D)       (None, 128, 128, 12  294912      ['u2net_concat_1[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_in_0_bn (BatchNorma  (None, 128, 128, 12  512        ['u2net_up_1_in_0[0][0]']        \n",
            " lization)                      8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_in_0_activation (Re  (None, 128, 128, 12  0          ['u2net_up_1_in_0_bn[0][0]']     \n",
            " LU)                            8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_down_0_0 (Conv2D)   (None, 128, 128, 12  147456      ['u2net_up_1_in_0_activation[0][0\n",
            "                                8)                               ]']                              \n",
            "                                                                                                  \n",
            " u2net_up_1_down_0_0_bn (BatchN  (None, 128, 128, 12  512        ['u2net_up_1_down_0_0[0][0]']    \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_down_0_0_activation  (None, 128, 128, 12  0          ['u2net_up_1_down_0_0_bn[0][0]'] \n",
            "  (ReLU)                        8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_0_stride_con  (None, 64, 64, 128)  65536      ['u2net_up_1_down_0_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_0_bn (BatchN  (None, 64, 64, 128)  512        ['u2net_up_1_encode_0_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_0_activation  (None, 64, 64, 128)  0          ['u2net_up_1_encode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_1_0 (Conv2D)   (None, 64, 64, 128)  147456      ['u2net_up_1_encode_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_1_0_bn (BatchN  (None, 64, 64, 128)  512        ['u2net_up_1_down_1_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_1_down_1_0_activation  (None, 64, 64, 128)  0          ['u2net_up_1_down_1_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_1_stride_con  (None, 32, 32, 128)  65536      ['u2net_up_1_down_1_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_1_bn (BatchN  (None, 32, 32, 128)  512        ['u2net_up_1_encode_1_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_1_activation  (None, 32, 32, 128)  0          ['u2net_up_1_encode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_2_0 (Conv2D)   (None, 32, 32, 128)  147456      ['u2net_up_1_encode_1_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_2_0_bn (BatchN  (None, 32, 32, 128)  512        ['u2net_up_1_down_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_1_down_2_0_activation  (None, 32, 32, 128)  0          ['u2net_up_1_down_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_2_stride_con  (None, 16, 16, 128)  65536      ['u2net_up_1_down_2_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_2_bn (BatchN  (None, 16, 16, 128)  512        ['u2net_up_1_encode_2_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_1_encode_2_activation  (None, 16, 16, 128)  0          ['u2net_up_1_encode_2_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_3_0 (Conv2D)   (None, 16, 16, 128)  147456      ['u2net_up_1_encode_2_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_down_3_0_bn (BatchN  (None, 16, 16, 128)  512        ['u2net_up_1_down_3_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_1_down_3_0_activation  (None, 16, 16, 128)  0          ['u2net_up_1_down_3_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_up_0_0 (Conv2D)     (None, 16, 16, 128)  147456      ['u2net_up_1_down_3_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_up_0_0_bn (BatchNor  (None, 16, 16, 128)  512        ['u2net_up_1_up_0_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_1_up_0_0_activation (  (None, 16, 16, 128)  0          ['u2net_up_1_up_0_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_1_concat_0 (Concatena  (None, 16, 16, 256)  0          ['u2net_up_1_up_0_0_activation[0]\n",
            " te)                                                             [0]',                            \n",
            "                                                                  'u2net_up_1_down_3_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_up_1_0 (Conv2D)     (None, 16, 16, 128)  294912      ['u2net_up_1_concat_0[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_1_up_1_0_bn (BatchNor  (None, 16, 16, 128)  512        ['u2net_up_1_up_1_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_1_up_1_0_activation (  (None, 16, 16, 128)  0          ['u2net_up_1_up_1_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_0_trans_conv  (None, 32, 32, 128)  147584     ['u2net_up_1_up_1_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_0_bn (BatchN  (None, 32, 32, 128)  512        ['u2net_up_1_decode_0_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_0_activation  (None, 32, 32, 128)  0          ['u2net_up_1_decode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_concat_1 (Concatena  (None, 32, 32, 256)  0          ['u2net_up_1_decode_0_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_1_down_2_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_up_2_0 (Conv2D)     (None, 32, 32, 128)  294912      ['u2net_up_1_concat_1[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_1_up_2_0_bn (BatchNor  (None, 32, 32, 128)  512        ['u2net_up_1_up_2_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_1_up_2_0_activation (  (None, 32, 32, 128)  0          ['u2net_up_1_up_2_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_1_trans_conv  (None, 64, 64, 128)  147584     ['u2net_up_1_up_2_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_1_bn (BatchN  (None, 64, 64, 128)  512        ['u2net_up_1_decode_1_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_1_activation  (None, 64, 64, 128)  0          ['u2net_up_1_decode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_1_concat_2 (Concatena  (None, 64, 64, 256)  0          ['u2net_up_1_decode_1_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_1_down_1_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_up_3_0 (Conv2D)     (None, 64, 64, 128)  294912      ['u2net_up_1_concat_2[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_1_up_3_0_bn (BatchNor  (None, 64, 64, 128)  512        ['u2net_up_1_up_3_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_1_up_3_0_activation (  (None, 64, 64, 128)  0          ['u2net_up_1_up_3_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_2_trans_conv  (None, 128, 128, 12  147584     ['u2net_up_1_up_3_0_activation[0]\n",
            "  (Conv2DTranspose)             8)                               [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_2_bn (BatchN  (None, 128, 128, 12  512        ['u2net_up_1_decode_2_trans_conv[\n",
            " ormalization)                  8)                               0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_decode_2_activation  (None, 128, 128, 12  0          ['u2net_up_1_decode_2_bn[0][0]'] \n",
            "  (ReLU)                        8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_concat_out (Concate  (None, 128, 128, 25  0          ['u2net_up_1_decode_2_activation[\n",
            " nate)                          6)                               0][0]',                          \n",
            "                                                                  'u2net_up_1_down_0_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_1_out_0 (Conv2D)      (None, 128, 128, 12  294912      ['u2net_up_1_concat_out[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_out_0_bn (BatchNorm  (None, 128, 128, 12  512        ['u2net_up_1_out_0[0][0]']       \n",
            " alization)                     8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_out_0_activation (R  (None, 128, 128, 12  0          ['u2net_up_1_out_0_bn[0][0]']    \n",
            " eLU)                           8)                                                                \n",
            "                                                                                                  \n",
            " u2net_up_1_out_add (Add)       (None, 128, 128, 12  0           ['u2net_up_1_out_0_activation[0][\n",
            "                                8)                               0]',                             \n",
            "                                                                  'u2net_up_1_in_0_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_decode_2_trans_conv (Con  (None, 256, 256, 64  73792      ['u2net_up_1_out_add[0][0]']     \n",
            " v2DTranspose)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_decode_2_bn (BatchNormal  (None, 256, 256, 64  256        ['u2net_decode_2_trans_conv[0][0]\n",
            " ization)                       )                                ']                               \n",
            "                                                                                                  \n",
            " u2net_decode_2_activation (ReL  (None, 256, 256, 64  0          ['u2net_decode_2_bn[0][0]']      \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " u2net_concat_2 (Concatenate)   (None, 256, 256, 12  0           ['u2net_decode_2_activation[0][0]\n",
            "                                8)                               ',                               \n",
            "                                                                  'u2net_down_0_out_add[0][0]']   \n",
            "                                                                                                  \n",
            " u2net_up_2_in_0 (Conv2D)       (None, 256, 256, 64  73728       ['u2net_concat_2[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_in_0_bn (BatchNorma  (None, 256, 256, 64  256        ['u2net_up_2_in_0[0][0]']        \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_in_0_activation (Re  (None, 256, 256, 64  0          ['u2net_up_2_in_0_bn[0][0]']     \n",
            " LU)                            )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_down_0_0 (Conv2D)   (None, 256, 256, 64  36864       ['u2net_up_2_in_0_activation[0][0\n",
            "                                )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_up_2_down_0_0_bn (BatchN  (None, 256, 256, 64  256        ['u2net_up_2_down_0_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_down_0_0_activation  (None, 256, 256, 64  0          ['u2net_up_2_down_0_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_0_stride_con  (None, 128, 128, 64  16384      ['u2net_up_2_down_0_0_activation[\n",
            " v (Conv2D)                     )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_0_bn (BatchN  (None, 128, 128, 64  256        ['u2net_up_2_encode_0_stride_conv\n",
            " ormalization)                  )                                [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_0_activation  (None, 128, 128, 64  0          ['u2net_up_2_encode_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_down_1_0 (Conv2D)   (None, 128, 128, 64  36864       ['u2net_up_2_encode_0_activation[\n",
            "                                )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_1_0_bn (BatchN  (None, 128, 128, 64  256        ['u2net_up_2_down_1_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_down_1_0_activation  (None, 128, 128, 64  0          ['u2net_up_2_down_1_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_1_stride_con  (None, 64, 64, 64)  16384       ['u2net_up_2_down_1_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_1_bn (BatchN  (None, 64, 64, 64)  256         ['u2net_up_2_encode_1_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_1_activation  (None, 64, 64, 64)  0           ['u2net_up_2_encode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_2_0 (Conv2D)   (None, 64, 64, 64)   36864       ['u2net_up_2_encode_1_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_2_0_bn (BatchN  (None, 64, 64, 64)  256         ['u2net_up_2_down_2_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_2_down_2_0_activation  (None, 64, 64, 64)  0           ['u2net_up_2_down_2_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_2_stride_con  (None, 32, 32, 64)  16384       ['u2net_up_2_down_2_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_2_bn (BatchN  (None, 32, 32, 64)  256         ['u2net_up_2_encode_2_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_2_activation  (None, 32, 32, 64)  0           ['u2net_up_2_encode_2_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_3_0 (Conv2D)   (None, 32, 32, 64)   36864       ['u2net_up_2_encode_2_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_3_0_bn (BatchN  (None, 32, 32, 64)  256         ['u2net_up_2_down_3_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_2_down_3_0_activation  (None, 32, 32, 64)  0           ['u2net_up_2_down_3_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_3_stride_con  (None, 16, 16, 64)  16384       ['u2net_up_2_down_3_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_3_bn (BatchN  (None, 16, 16, 64)  256         ['u2net_up_2_encode_3_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_2_encode_3_activation  (None, 16, 16, 64)  0           ['u2net_up_2_encode_3_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_4_0 (Conv2D)   (None, 16, 16, 64)   36864       ['u2net_up_2_encode_3_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_down_4_0_bn (BatchN  (None, 16, 16, 64)  256         ['u2net_up_2_down_4_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_2_down_4_0_activation  (None, 16, 16, 64)  0           ['u2net_up_2_down_4_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_0_0 (Conv2D)     (None, 16, 16, 64)   36864       ['u2net_up_2_down_4_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_0_0_bn (BatchNor  (None, 16, 16, 64)  256         ['u2net_up_2_up_0_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_2_up_0_0_activation (  (None, 16, 16, 64)  0           ['u2net_up_2_up_0_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_2_concat_0 (Concatena  (None, 16, 16, 128)  0          ['u2net_up_2_up_0_0_activation[0]\n",
            " te)                                                             [0]',                            \n",
            "                                                                  'u2net_up_2_down_4_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_1_0 (Conv2D)     (None, 16, 16, 64)   73728       ['u2net_up_2_concat_0[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_2_up_1_0_bn (BatchNor  (None, 16, 16, 64)  256         ['u2net_up_2_up_1_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_2_up_1_0_activation (  (None, 16, 16, 64)  0           ['u2net_up_2_up_1_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_0_trans_conv  (None, 32, 32, 64)  36928       ['u2net_up_2_up_1_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_0_bn (BatchN  (None, 32, 32, 64)  256         ['u2net_up_2_decode_0_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_0_activation  (None, 32, 32, 64)  0           ['u2net_up_2_decode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_concat_1 (Concatena  (None, 32, 32, 128)  0          ['u2net_up_2_decode_0_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_2_down_3_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_2_0 (Conv2D)     (None, 32, 32, 64)   73728       ['u2net_up_2_concat_1[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_2_up_2_0_bn (BatchNor  (None, 32, 32, 64)  256         ['u2net_up_2_up_2_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_2_up_2_0_activation (  (None, 32, 32, 64)  0           ['u2net_up_2_up_2_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_1_trans_conv  (None, 64, 64, 64)  36928       ['u2net_up_2_up_2_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_1_bn (BatchN  (None, 64, 64, 64)  256         ['u2net_up_2_decode_1_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_1_activation  (None, 64, 64, 64)  0           ['u2net_up_2_decode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_2_concat_2 (Concatena  (None, 64, 64, 128)  0          ['u2net_up_2_decode_1_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_2_down_2_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_3_0 (Conv2D)     (None, 64, 64, 64)   73728       ['u2net_up_2_concat_2[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_2_up_3_0_bn (BatchNor  (None, 64, 64, 64)  256         ['u2net_up_2_up_3_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_2_up_3_0_activation (  (None, 64, 64, 64)  0           ['u2net_up_2_up_3_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_2_trans_conv  (None, 128, 128, 64  36928      ['u2net_up_2_up_3_0_activation[0]\n",
            "  (Conv2DTranspose)             )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_2_bn (BatchN  (None, 128, 128, 64  256        ['u2net_up_2_decode_2_trans_conv[\n",
            " ormalization)                  )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_2_activation  (None, 128, 128, 64  0          ['u2net_up_2_decode_2_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_concat_3 (Concatena  (None, 128, 128, 12  0          ['u2net_up_2_decode_2_activation[\n",
            " te)                            8)                               0][0]',                          \n",
            "                                                                  'u2net_up_2_down_1_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_up_4_0 (Conv2D)     (None, 128, 128, 64  73728       ['u2net_up_2_concat_3[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_up_4_0_bn (BatchNor  (None, 128, 128, 64  256        ['u2net_up_2_up_4_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_up_4_0_activation (  (None, 128, 128, 64  0          ['u2net_up_2_up_4_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_3_trans_conv  (None, 256, 256, 64  36928      ['u2net_up_2_up_4_0_activation[0]\n",
            "  (Conv2DTranspose)             )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_3_bn (BatchN  (None, 256, 256, 64  256        ['u2net_up_2_decode_3_trans_conv[\n",
            " ormalization)                  )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_decode_3_activation  (None, 256, 256, 64  0          ['u2net_up_2_decode_3_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_concat_out (Concate  (None, 256, 256, 12  0          ['u2net_up_2_decode_3_activation[\n",
            " nate)                          8)                               0][0]',                          \n",
            "                                                                  'u2net_up_2_down_0_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_2_out_0 (Conv2D)      (None, 256, 256, 64  73728       ['u2net_up_2_concat_out[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_out_0_bn (BatchNorm  (None, 256, 256, 64  256        ['u2net_up_2_out_0[0][0]']       \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_out_0_activation (R  (None, 256, 256, 64  0          ['u2net_up_2_out_0_bn[0][0]']    \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_2_out_add (Add)       (None, 256, 256, 64  0           ['u2net_up_2_out_0_activation[0][\n",
            "                                )                                0]',                             \n",
            "                                                                  'u2net_up_2_in_0_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_decode_3_trans_conv (Con  (None, 512, 512, 32  18464      ['u2net_up_2_out_add[0][0]']     \n",
            " v2DTranspose)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_decode_3_bn (BatchNormal  (None, 512, 512, 32  128        ['u2net_decode_3_trans_conv[0][0]\n",
            " ization)                       )                                ']                               \n",
            "                                                                                                  \n",
            " u2net_decode_3_activation (ReL  (None, 512, 512, 32  0          ['u2net_decode_3_bn[0][0]']      \n",
            " U)                             )                                                                 \n",
            "                                                                                                  \n",
            " u2net_concat_3 (Concatenate)   (None, 512, 512, 64  0           ['u2net_decode_3_activation[0][0]\n",
            "                                )                                ',                               \n",
            "                                                                  'u2net_in_out_add[0][0]']       \n",
            "                                                                                                  \n",
            " u2net_up_3_in_0 (Conv2D)       (None, 512, 512, 32  18432       ['u2net_concat_3[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_in_0_bn (BatchNorma  (None, 512, 512, 32  128        ['u2net_up_3_in_0[0][0]']        \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_in_0_activation (Re  (None, 512, 512, 32  0          ['u2net_up_3_in_0_bn[0][0]']     \n",
            " LU)                            )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_0_0 (Conv2D)   (None, 512, 512, 32  9216        ['u2net_up_3_in_0_activation[0][0\n",
            "                                )                                ]']                              \n",
            "                                                                                                  \n",
            " u2net_up_3_down_0_0_bn (BatchN  (None, 512, 512, 32  128        ['u2net_up_3_down_0_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_0_0_activation  (None, 512, 512, 32  0          ['u2net_up_3_down_0_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_0_stride_con  (None, 256, 256, 32  4096       ['u2net_up_3_down_0_0_activation[\n",
            " v (Conv2D)                     )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_0_bn (BatchN  (None, 256, 256, 32  128        ['u2net_up_3_encode_0_stride_conv\n",
            " ormalization)                  )                                [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_0_activation  (None, 256, 256, 32  0          ['u2net_up_3_encode_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_1_0 (Conv2D)   (None, 256, 256, 32  9216        ['u2net_up_3_encode_0_activation[\n",
            "                                )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_1_0_bn (BatchN  (None, 256, 256, 32  128        ['u2net_up_3_down_1_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_1_0_activation  (None, 256, 256, 32  0          ['u2net_up_3_down_1_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_1_stride_con  (None, 128, 128, 32  4096       ['u2net_up_3_down_1_0_activation[\n",
            " v (Conv2D)                     )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_1_bn (BatchN  (None, 128, 128, 32  128        ['u2net_up_3_encode_1_stride_conv\n",
            " ormalization)                  )                                [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_1_activation  (None, 128, 128, 32  0          ['u2net_up_3_encode_1_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_2_0 (Conv2D)   (None, 128, 128, 32  9216        ['u2net_up_3_encode_1_activation[\n",
            "                                )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_2_0_bn (BatchN  (None, 128, 128, 32  128        ['u2net_up_3_down_2_0[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_down_2_0_activation  (None, 128, 128, 32  0          ['u2net_up_3_down_2_0_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_2_stride_con  (None, 64, 64, 32)  4096        ['u2net_up_3_down_2_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_2_bn (BatchN  (None, 64, 64, 32)  128         ['u2net_up_3_encode_2_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_2_activation  (None, 64, 64, 32)  0           ['u2net_up_3_encode_2_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_3_0 (Conv2D)   (None, 64, 64, 32)   9216        ['u2net_up_3_encode_2_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_3_0_bn (BatchN  (None, 64, 64, 32)  128         ['u2net_up_3_down_3_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_3_down_3_0_activation  (None, 64, 64, 32)  0           ['u2net_up_3_down_3_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_3_stride_con  (None, 32, 32, 32)  4096        ['u2net_up_3_down_3_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_3_bn (BatchN  (None, 32, 32, 32)  128         ['u2net_up_3_encode_3_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_3_activation  (None, 32, 32, 32)  0           ['u2net_up_3_encode_3_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_4_0 (Conv2D)   (None, 32, 32, 32)   9216        ['u2net_up_3_encode_3_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_4_0_bn (BatchN  (None, 32, 32, 32)  128         ['u2net_up_3_down_4_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_3_down_4_0_activation  (None, 32, 32, 32)  0           ['u2net_up_3_down_4_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_4_stride_con  (None, 16, 16, 32)  4096        ['u2net_up_3_down_4_0_activation[\n",
            " v (Conv2D)                                                      0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_4_bn (BatchN  (None, 16, 16, 32)  128         ['u2net_up_3_encode_4_stride_conv\n",
            " ormalization)                                                   [0][0]']                         \n",
            "                                                                                                  \n",
            " u2net_up_3_encode_4_activation  (None, 16, 16, 32)  0           ['u2net_up_3_encode_4_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_5_0 (Conv2D)   (None, 16, 16, 32)   9216        ['u2net_up_3_encode_4_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_down_5_0_bn (BatchN  (None, 16, 16, 32)  128         ['u2net_up_3_down_5_0[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " u2net_up_3_down_5_0_activation  (None, 16, 16, 32)  0           ['u2net_up_3_down_5_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_0_0 (Conv2D)     (None, 16, 16, 32)   9216        ['u2net_up_3_down_5_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_0_0_bn (BatchNor  (None, 16, 16, 32)  128         ['u2net_up_3_up_0_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_3_up_0_0_activation (  (None, 16, 16, 32)  0           ['u2net_up_3_up_0_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_0 (Concatena  (None, 16, 16, 64)  0           ['u2net_up_3_up_0_0_activation[0]\n",
            " te)                                                             [0]',                            \n",
            "                                                                  'u2net_up_3_down_5_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_1_0 (Conv2D)     (None, 16, 16, 32)   18432       ['u2net_up_3_concat_0[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_3_up_1_0_bn (BatchNor  (None, 16, 16, 32)  128         ['u2net_up_3_up_1_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_3_up_1_0_activation (  (None, 16, 16, 32)  0           ['u2net_up_3_up_1_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_0_trans_conv  (None, 32, 32, 32)  9248        ['u2net_up_3_up_1_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_0_bn (BatchN  (None, 32, 32, 32)  128         ['u2net_up_3_decode_0_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_0_activation  (None, 32, 32, 32)  0           ['u2net_up_3_decode_0_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_1 (Concatena  (None, 32, 32, 64)  0           ['u2net_up_3_decode_0_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_3_down_4_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_2_0 (Conv2D)     (None, 32, 32, 32)   18432       ['u2net_up_3_concat_1[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_3_up_2_0_bn (BatchNor  (None, 32, 32, 32)  128         ['u2net_up_3_up_2_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_3_up_2_0_activation (  (None, 32, 32, 32)  0           ['u2net_up_3_up_2_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_1_trans_conv  (None, 64, 64, 32)  9248        ['u2net_up_3_up_2_0_activation[0]\n",
            "  (Conv2DTranspose)                                              [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_1_bn (BatchN  (None, 64, 64, 32)  128         ['u2net_up_3_decode_1_trans_conv[\n",
            " ormalization)                                                   0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_1_activation  (None, 64, 64, 32)  0           ['u2net_up_3_decode_1_bn[0][0]'] \n",
            "  (ReLU)                                                                                          \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_2 (Concatena  (None, 64, 64, 64)  0           ['u2net_up_3_decode_1_activation[\n",
            " te)                                                             0][0]',                          \n",
            "                                                                  'u2net_up_3_down_3_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_3_0 (Conv2D)     (None, 64, 64, 32)   18432       ['u2net_up_3_concat_2[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_up_3_up_3_0_bn (BatchNor  (None, 64, 64, 32)  128         ['u2net_up_3_up_3_0[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_up_3_up_3_0_activation (  (None, 64, 64, 32)  0           ['u2net_up_3_up_3_0_bn[0][0]']   \n",
            " ReLU)                                                                                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_2_trans_conv  (None, 128, 128, 32  9248       ['u2net_up_3_up_3_0_activation[0]\n",
            "  (Conv2DTranspose)             )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_2_bn (BatchN  (None, 128, 128, 32  128        ['u2net_up_3_decode_2_trans_conv[\n",
            " ormalization)                  )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_2_activation  (None, 128, 128, 32  0          ['u2net_up_3_decode_2_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_3 (Concatena  (None, 128, 128, 64  0          ['u2net_up_3_decode_2_activation[\n",
            " te)                            )                                0][0]',                          \n",
            "                                                                  'u2net_up_3_down_2_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_4_0 (Conv2D)     (None, 128, 128, 32  18432       ['u2net_up_3_concat_3[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_up_4_0_bn (BatchNor  (None, 128, 128, 32  128        ['u2net_up_3_up_4_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_up_4_0_activation (  (None, 128, 128, 32  0          ['u2net_up_3_up_4_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_3_trans_conv  (None, 256, 256, 32  9248       ['u2net_up_3_up_4_0_activation[0]\n",
            "  (Conv2DTranspose)             )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_3_bn (BatchN  (None, 256, 256, 32  128        ['u2net_up_3_decode_3_trans_conv[\n",
            " ormalization)                  )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_3_activation  (None, 256, 256, 32  0          ['u2net_up_3_decode_3_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_4 (Concatena  (None, 256, 256, 64  0          ['u2net_up_3_decode_3_activation[\n",
            " te)                            )                                0][0]',                          \n",
            "                                                                  'u2net_up_3_down_1_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_up_5_0 (Conv2D)     (None, 256, 256, 32  18432       ['u2net_up_3_concat_4[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_up_5_0_bn (BatchNor  (None, 256, 256, 32  128        ['u2net_up_3_up_5_0[0][0]']      \n",
            " malization)                    )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_up_5_0_activation (  (None, 256, 256, 32  0          ['u2net_up_3_up_5_0_bn[0][0]']   \n",
            " ReLU)                          )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_4_trans_conv  (None, 512, 512, 32  9248       ['u2net_up_3_up_5_0_activation[0]\n",
            "  (Conv2DTranspose)             )                                [0]']                            \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_4_bn (BatchN  (None, 512, 512, 32  128        ['u2net_up_3_decode_4_trans_conv[\n",
            " ormalization)                  )                                0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_decode_4_activation  (None, 512, 512, 32  0          ['u2net_up_3_decode_4_bn[0][0]'] \n",
            "  (ReLU)                        )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_concat_out (Concate  (None, 512, 512, 64  0          ['u2net_up_3_decode_4_activation[\n",
            " nate)                          )                                0][0]',                          \n",
            "                                                                  'u2net_up_3_down_0_0_activation[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " u2net_up_3_out_0 (Conv2D)      (None, 512, 512, 32  18432       ['u2net_up_3_concat_out[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_out_0_bn (BatchNorm  (None, 512, 512, 32  128        ['u2net_up_3_out_0[0][0]']       \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_out_0_activation (R  (None, 512, 512, 32  0          ['u2net_up_3_out_0_bn[0][0]']    \n",
            " eLU)                           )                                                                 \n",
            "                                                                                                  \n",
            " u2net_up_3_out_add (Add)       (None, 512, 512, 32  0           ['u2net_up_3_out_0_activation[0][\n",
            "                                )                                0]',                             \n",
            "                                                                  'u2net_up_3_in_0_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " u2net_output_conv_1 (Conv2D)   (None, 256, 256, 1)  577         ['u2net_up_2_out_add[0][0]']     \n",
            "                                                                                                  \n",
            " u2net_output_conv_2 (Conv2D)   (None, 128, 128, 1)  1153        ['u2net_up_1_out_add[0][0]']     \n",
            "                                                                                                  \n",
            " u2net_output_conv_3 (Conv2D)   (None, 64, 64, 1)    2305        ['u2net_up_0_out_add[0][0]']     \n",
            "                                                                                                  \n",
            " u2net_output_conv_4 (Conv2D)   (None, 32, 32, 1)    2305        ['u2net_up_4f_0_out_add[0][0]']  \n",
            "                                                                                                  \n",
            " u2net_output_conv_5 (Conv2D)   (None, 16, 16, 1)    2305        ['u2net_down_4f_1_out_add[0][0]']\n",
            "                                                                                                  \n",
            " u2net_output_sup0 (Conv2D)     (None, 512, 512, 1)  289         ['u2net_up_3_out_add[0][0]']     \n",
            "                                                                                                  \n",
            " u2net_sup1_trans_conv (Conv2DT  (None, 512, 512, 1)  10         ['u2net_output_conv_1[0][0]']    \n",
            " ranspose)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_sup2_trans_conv (Conv2DT  (None, 512, 512, 1)  10         ['u2net_output_conv_2[0][0]']    \n",
            " ranspose)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_sup3_trans_conv (Conv2DT  (None, 512, 512, 1)  10         ['u2net_output_conv_3[0][0]']    \n",
            " ranspose)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_sup4_trans_conv (Conv2DT  (None, 512, 512, 1)  10         ['u2net_output_conv_4[0][0]']    \n",
            " ranspose)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_sup5_trans_conv (Conv2DT  (None, 512, 512, 1)  10         ['u2net_output_conv_5[0][0]']    \n",
            " ranspose)                                                                                        \n",
            "                                                                                                  \n",
            " u2net_output_sup0_activation (  (None, 512, 512, 1)  0          ['u2net_output_sup0[0][0]']      \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_sup1_activation (  (None, 512, 512, 1)  0          ['u2net_sup1_trans_conv[0][0]']  \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_sup2_activation (  (None, 512, 512, 1)  0          ['u2net_sup2_trans_conv[0][0]']  \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_sup3_activation (  (None, 512, 512, 1)  0          ['u2net_sup3_trans_conv[0][0]']  \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_sup4_activation (  (None, 512, 512, 1)  0          ['u2net_sup4_trans_conv[0][0]']  \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_sup5_activation (  (None, 512, 512, 1)  0          ['u2net_sup5_trans_conv[0][0]']  \n",
            " Activation)                                                                                      \n",
            "                                                                                                  \n",
            " u2net_output_concat (Concatena  (None, 512, 512, 6)  0          ['u2net_output_sup0_activation[0]\n",
            " te)                                                             [0]',                            \n",
            "                                                                  'u2net_output_sup1_activation[0]\n",
            "                                                                 [0]',                            \n",
            "                                                                  'u2net_output_sup2_activation[0]\n",
            "                                                                 [0]',                            \n",
            "                                                                  'u2net_output_sup3_activation[0]\n",
            "                                                                 [0]',                            \n",
            "                                                                  'u2net_output_sup4_activation[0]\n",
            "                                                                 [0]',                            \n",
            "                                                                  'u2net_output_sup5_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " u2net_output_final (Conv2D)    (None, 512, 512, 1)  7           ['u2net_output_concat[0][0]']    \n",
            "                                                                                                  \n",
            " u2net_output_final_activation   (None, 512, 512, 1)  0          ['u2net_output_final[0][0]']     \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 35,211,807\n",
            "Trainable params: 35,172,063\n",
            "Non-trainable params: 39,744\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def u2net(n_labels, filter_num_down, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "   ## model = models.u2net_2d(input_size, n_labels, filter_num_down, activation='ReLU', output_activation=out_layer)\n",
        "\n",
        "    model = models.u2net_2d(input_size,n_labels=1,\n",
        "                        filter_num_down=filter_num_down, filter_num_up=filter_num_down,\n",
        "                        filter_mid_num_down=filter_num_down, filter_mid_num_up=filter_num_down,\n",
        "                        filter_4f_num=[256, 256], filter_4f_mid_num=[128, 128],\n",
        "                        activation='ReLU', output_activation=out_layer,\n",
        "                        batch_norm=True, pool=False, unpool=False, deep_supervision=True)\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "u2net(2, [32, 64, 128, 256], input_size=(tileSize, tileSize, 3)).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss57ZlJYp4dz"
      },
      "source": [
        "## **Swin U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wFT3aLLqKdU",
        "outputId": "8d460783-3272-4d4c-8923-8857cbf3a4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"swin_unet_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " patch_extract (patch_extract)  (None, 65536, 12)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " patch_embedding (patch_embeddi  (None, 65536, 64)   4195136     ['patch_extract[0][0]']          \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " swin_transformer_block (SwinTr  (None, 65536, 64)   83460       ['patch_embedding[0][0]']        \n",
            " ansformerBlock)                                                                                  \n",
            "                                                                                                  \n",
            " swin_transformer_block_1 (Swin  (None, 65536, 64)   1132036     ['swin_transformer_block[0][0]'] \n",
            " TransformerBlock)                                                                                \n",
            "                                                                                                  \n",
            " patch_merging (patch_merging)  (None, 16384, 128)   32768       ['swin_transformer_block_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_2 (Swin  (None, 16384, 128)  198360      ['patch_merging[0][0]']          \n",
            " TransformerBlock)                                                                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_3 (Swin  (None, 16384, 128)  263896      ['swin_transformer_block_2[0][0]'\n",
            " TransformerBlock)                                               ]                                \n",
            "                                                                                                  \n",
            " patch_merging_1 (patch_merging  (None, 4096, 256)   131072      ['swin_transformer_block_3[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_4 (Swin  (None, 4096, 256)   527192      ['patch_merging_1[0][0]']        \n",
            " TransformerBlock)                                                                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_5 (Swin  (None, 4096, 256)   543576      ['swin_transformer_block_4[0][0]'\n",
            " TransformerBlock)                                               ]                                \n",
            "                                                                                                  \n",
            " patch_merging_2 (patch_merging  (None, 1024, 512)   524288      ['swin_transformer_block_5[0][0]'\n",
            " )                                                               ]                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_6 (Swin  (None, 1024, 512)   1578072     ['patch_merging_2[0][0]']        \n",
            " TransformerBlock)                                                                                \n",
            "                                                                                                  \n",
            " swin_transformer_block_7 (Swin  (None, 1024, 512)   1582168     ['swin_transformer_block_6[0][0]'\n",
            " TransformerBlock)                                               ]                                \n",
            "                                                                                                  \n",
            " patch_expanding (patch_expandi  (None, 4096, 256)   524288      ['swin_transformer_block_7[0][0]'\n",
            " ng)                                                             ]                                \n",
            "                                                                                                  \n",
            " swin_unet_concat_0 (Concatenat  (None, 4096, 512)   0           ['patch_expanding[0][0]',        \n",
            " e)                                                               'swin_transformer_block_5[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " swin_unet_concat_linear_proj_0  (None, 4096, 256)   131072      ['swin_unet_concat_0[0][0]']     \n",
            "  (Dense)                                                                                         \n",
            "                                                                                                  \n",
            " swin_transformer_block_8 (Swin  (None, 4096, 256)   527192      ['swin_unet_concat_linear_proj_0[\n",
            " TransformerBlock)                                               0][0]']                          \n",
            "                                                                                                  \n",
            " swin_transformer_block_9 (Swin  (None, 4096, 256)   543576      ['swin_transformer_block_8[0][0]'\n",
            " TransformerBlock)                                               ]                                \n",
            "                                                                                                  \n",
            " patch_expanding_1 (patch_expan  (None, 16384, 128)  131072      ['swin_transformer_block_9[0][0]'\n",
            " ding)                                                           ]                                \n",
            "                                                                                                  \n",
            " swin_unet_concat_1 (Concatenat  (None, 16384, 256)  0           ['patch_expanding_1[0][0]',      \n",
            " e)                                                               'swin_transformer_block_3[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " swin_unet_concat_linear_proj_1  (None, 16384, 128)  32768       ['swin_unet_concat_1[0][0]']     \n",
            "  (Dense)                                                                                         \n",
            "                                                                                                  \n",
            " swin_transformer_block_10 (Swi  (None, 16384, 128)  198360      ['swin_unet_concat_linear_proj_1[\n",
            " nTransformerBlock)                                              0][0]']                          \n",
            "                                                                                                  \n",
            " swin_transformer_block_11 (Swi  (None, 16384, 128)  263896      ['swin_transformer_block_10[0][0]\n",
            " nTransformerBlock)                                              ']                               \n",
            "                                                                                                  \n",
            " patch_expanding_2 (patch_expan  (None, 65536, 64)   32768       ['swin_transformer_block_11[0][0]\n",
            " ding)                                                           ']                               \n",
            "                                                                                                  \n",
            " swin_unet_concat_2 (Concatenat  (None, 65536, 128)  0           ['patch_expanding_2[0][0]',      \n",
            " e)                                                               'swin_transformer_block_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " swin_unet_concat_linear_proj_2  (None, 65536, 64)   8192        ['swin_unet_concat_2[0][0]']     \n",
            "  (Dense)                                                                                         \n",
            "                                                                                                  \n",
            " swin_transformer_block_12 (Swi  (None, 65536, 64)   83096       ['swin_unet_concat_linear_proj_2[\n",
            " nTransformerBlock)                                              0][0]']                          \n",
            "                                                                                                  \n",
            " swin_transformer_block_13 (Swi  (None, 65536, 64)   345240      ['swin_transformer_block_12[0][0]\n",
            " nTransformerBlock)                                              ']                               \n",
            "                                                                                                  \n",
            " patch_expanding_3 (patch_expan  (None, 512, 512, 32  8192       ['swin_transformer_block_13[0][0]\n",
            " ding)                          )                                ']                               \n",
            "                                                                                                  \n",
            " swin_unet_output (Conv2D)      (None, 512, 512, 1)  33          ['patch_expanding_3[0][0]']      \n",
            "                                                                                                  \n",
            " swin_unet_output_activation (A  (None, 512, 512, 1)  0          ['swin_unet_output[0][0]']       \n",
            " ctivation)                                                                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,621,769\n",
            "Trainable params: 12,142,409\n",
            "Non-trainable params: 1,479,360\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def swin_unet(n_labels, filter_num_begin, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "    # model = models.swin_unet_2d(input_size, filter_num_begin=filter_num_begin, n_labels=n_labels, depth=4, stack_num_down=8, stack_num_up=8, patch_size=(2,2), num_heads=[2, 2, 4, 4], window_size=[4, 2, 2, 2], num_mlp=1)\n",
        "    model = models.swin_unet_2d(input_size, filter_num_begin=64, n_labels=1, depth=4, stack_num_down=2, stack_num_up=2,\n",
        "                                patch_size=(2, 2), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512,\n",
        "                                output_activation=out_layer, shift_window=True, name='swin_unet')\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = lr), loss = lossfunc, metrics = [dice_coef, 'accuracy', 'mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3)).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQLp4pYO5szb"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZd2MuAUADbN"
      },
      "source": [
        "## **Train and analyse model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSMDCW2d0dDw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "\n",
        "def train(model, callbacks, inGen, valGen, modelName, batch_size=1, epochs=20, steps_per_epoch=100):\n",
        "\n",
        "    fullOutPath = os.path.join(\"Output\", modelName);\n",
        "\n",
        "    if not os.path.exists(fullOutPath) : os.mkdir(fullOutPath)\n",
        "\n",
        "    startTime = time.time()\n",
        "    history = model.fit(inGen, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                      validation_data=valGen, batch_size=batch_size, callbacks=[callbacks])\n",
        "    trainTime = time.time() - startTime\n",
        "    print(\"Total time to train:\", trainTime)\n",
        "\n",
        "    save_to_drive()\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_dice_coef = history.history['val_dice_coef']\n",
        "    dice_coef = history.history['dice_coef']\n",
        "\n",
        "    np.savetxt(fullOutPath+\"/%s_Loss.csv\" % (modelName),\n",
        "               loss, delimiter=\", \")\n",
        "\n",
        "    np.savetxt(fullOutPath+\"/%s_ValLoss.csv\" % (modelName),\n",
        "               val_loss, delimiter=\", \")\n",
        "\n",
        "    np.savetxt(fullOutPath+\"/%s_ValDiceCoef.csv\" % (modelName),\n",
        "               val_dice_coef, delimiter=\", \")\n",
        "\n",
        "    np.savetxt(fullOutPath+\"/%s_DiceCoef.csv\" % (modelName),\n",
        "               dice_coef, delimiter=\", \")\n",
        "\n",
        "    epochs = range(1, len(loss)+1)\n",
        "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and Validaton loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(fullOutPath+\"/%s_Training_Validation_Loss.png\" % (modelName))\n",
        "\n",
        "    plt.cla()\n",
        "    plt.plot(epochs, dice_coef, 'g', label='Training dice coef')\n",
        "    plt.plot(epochs, val_dice_coef, 'b', label='Validation dice coef')\n",
        "    plt.title(\"Training and Validation dice coef\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(fullOutPath+\"/%s_Training_ValidationDiceCoef.png\" % (modelName))\n",
        "\n",
        "\n",
        "    # Saving to drive\n",
        "    save_to_drive()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GI7R6DehKkR"
      },
      "source": [
        "## **Training on tall plants**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgd0GLWyKta3"
      },
      "source": [
        "### **UNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xubBNedqAbCr",
        "outputId": "2ebfffb2-0ade-40d3-9ad3-5a08d5a916fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1390 - dice_coef: 0.0233 - accuracy: 0.9654 - mse: 0.0280\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.09553, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 232s 2s/step - loss: 0.1390 - dice_coef: 0.0233 - accuracy: 0.9654 - mse: 0.0280 - val_loss: 0.0731 - val_dice_coef: 0.0955 - val_accuracy: 0.9805 - val_mse: 0.0171\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0633 - dice_coef: 0.2600 - accuracy: 0.9765 - mse: 0.0156\n",
            "Epoch 2: val_dice_coef improved from 0.09553 to 0.33858, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 177s 2s/step - loss: 0.0633 - dice_coef: 0.2600 - accuracy: 0.9765 - mse: 0.0156 - val_loss: 0.0429 - val_dice_coef: 0.3386 - val_accuracy: 0.9846 - val_mse: 0.0118\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0460 - dice_coef: 0.4357 - accuracy: 0.9814 - mse: 0.0117\n",
            "Epoch 3: val_dice_coef did not improve from 0.33858\n",
            "100/100 [==============================] - 172s 2s/step - loss: 0.0460 - dice_coef: 0.4357 - accuracy: 0.9814 - mse: 0.0117 - val_loss: 0.0685 - val_dice_coef: 0.3134 - val_accuracy: 0.9759 - val_mse: 0.0183\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0499 - dice_coef: 0.4283 - accuracy: 0.9805 - mse: 0.0124\n",
            "Epoch 4: val_dice_coef improved from 0.33858 to 0.44983, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0499 - dice_coef: 0.4283 - accuracy: 0.9805 - mse: 0.0124 - val_loss: 0.0325 - val_dice_coef: 0.4498 - val_accuracy: 0.9875 - val_mse: 0.0093\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0396 - dice_coef: 0.5086 - accuracy: 0.9832 - mse: 0.0102\n",
            "Epoch 5: val_dice_coef improved from 0.44983 to 0.50373, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.0396 - dice_coef: 0.5086 - accuracy: 0.9832 - mse: 0.0102 - val_loss: 0.0301 - val_dice_coef: 0.5037 - val_accuracy: 0.9886 - val_mse: 0.0085\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0410 - dice_coef: 0.4756 - accuracy: 0.9828 - mse: 0.0105\n",
            "Epoch 6: val_dice_coef did not improve from 0.50373\n",
            "100/100 [==============================] - 163s 2s/step - loss: 0.0410 - dice_coef: 0.4756 - accuracy: 0.9828 - mse: 0.0105 - val_loss: 0.0320 - val_dice_coef: 0.4805 - val_accuracy: 0.9881 - val_mse: 0.0089\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0368 - dice_coef: 0.5266 - accuracy: 0.9839 - mse: 0.0096\n",
            "Epoch 7: val_dice_coef did not improve from 0.50373\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0368 - dice_coef: 0.5266 - accuracy: 0.9839 - mse: 0.0096 - val_loss: 0.0328 - val_dice_coef: 0.4662 - val_accuracy: 0.9881 - val_mse: 0.0091\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0373 - dice_coef: 0.5248 - accuracy: 0.9839 - mse: 0.0097\n",
            "Epoch 8: val_dice_coef did not improve from 0.50373\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0373 - dice_coef: 0.5248 - accuracy: 0.9839 - mse: 0.0097 - val_loss: 0.0405 - val_dice_coef: 0.3913 - val_accuracy: 0.9881 - val_mse: 0.0099\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0357 - dice_coef: 0.5253 - accuracy: 0.9844 - mse: 0.0093\n",
            "Epoch 9: val_dice_coef improved from 0.50373 to 0.51750, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 191s 2s/step - loss: 0.0357 - dice_coef: 0.5253 - accuracy: 0.9844 - mse: 0.0093 - val_loss: 0.0294 - val_dice_coef: 0.5175 - val_accuracy: 0.9887 - val_mse: 0.0083\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0356 - dice_coef: 0.5507 - accuracy: 0.9840 - mse: 0.0093\n",
            "Epoch 10: val_dice_coef did not improve from 0.51750\n",
            "100/100 [==============================] - 163s 2s/step - loss: 0.0356 - dice_coef: 0.5507 - accuracy: 0.9840 - mse: 0.0093 - val_loss: 0.0329 - val_dice_coef: 0.5043 - val_accuracy: 0.9872 - val_mse: 0.0095\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0333 - dice_coef: 0.5599 - accuracy: 0.9849 - mse: 0.0087\n",
            "Epoch 11: val_dice_coef did not improve from 0.51750\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0333 - dice_coef: 0.5599 - accuracy: 0.9849 - mse: 0.0087 - val_loss: 0.0315 - val_dice_coef: 0.5043 - val_accuracy: 0.9881 - val_mse: 0.0089\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0340 - dice_coef: 0.5671 - accuracy: 0.9844 - mse: 0.0090\n",
            "Epoch 12: val_dice_coef improved from 0.51750 to 0.53742, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 204s 2s/step - loss: 0.0340 - dice_coef: 0.5671 - accuracy: 0.9844 - mse: 0.0090 - val_loss: 0.0269 - val_dice_coef: 0.5374 - val_accuracy: 0.9895 - val_mse: 0.0078\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0327 - dice_coef: 0.5716 - accuracy: 0.9852 - mse: 0.0085\n",
            "Epoch 13: val_dice_coef did not improve from 0.53742\n",
            "100/100 [==============================] - 161s 2s/step - loss: 0.0327 - dice_coef: 0.5716 - accuracy: 0.9852 - mse: 0.0085 - val_loss: 0.0298 - val_dice_coef: 0.4717 - val_accuracy: 0.9894 - val_mse: 0.0082\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0319 - dice_coef: 0.5881 - accuracy: 0.9852 - mse: 0.0085\n",
            "Epoch 14: val_dice_coef improved from 0.53742 to 0.55959, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 232s 2s/step - loss: 0.0319 - dice_coef: 0.5881 - accuracy: 0.9852 - mse: 0.0085 - val_loss: 0.0256 - val_dice_coef: 0.5596 - val_accuracy: 0.9899 - val_mse: 0.0074\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0290 - dice_coef: 0.6115 - accuracy: 0.9863 - mse: 0.0077\n",
            "Epoch 15: val_dice_coef improved from 0.55959 to 0.57302, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 239s 2s/step - loss: 0.0290 - dice_coef: 0.6115 - accuracy: 0.9863 - mse: 0.0077 - val_loss: 0.0254 - val_dice_coef: 0.5730 - val_accuracy: 0.9900 - val_mse: 0.0074\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0304 - dice_coef: 0.5947 - accuracy: 0.9858 - mse: 0.0080\n",
            "Epoch 16: val_dice_coef improved from 0.57302 to 0.57671, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 230s 2s/step - loss: 0.0304 - dice_coef: 0.5947 - accuracy: 0.9858 - mse: 0.0080 - val_loss: 0.0262 - val_dice_coef: 0.5767 - val_accuracy: 0.9895 - val_mse: 0.0077\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0324 - dice_coef: 0.5720 - accuracy: 0.9854 - mse: 0.0084\n",
            "Epoch 17: val_dice_coef did not improve from 0.57671\n",
            "100/100 [==============================] - 159s 2s/step - loss: 0.0324 - dice_coef: 0.5720 - accuracy: 0.9854 - mse: 0.0084 - val_loss: 0.0294 - val_dice_coef: 0.5294 - val_accuracy: 0.9889 - val_mse: 0.0083\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0310 - dice_coef: 0.6033 - accuracy: 0.9857 - mse: 0.0081\n",
            "Epoch 18: val_dice_coef improved from 0.57671 to 0.59685, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 251s 3s/step - loss: 0.0310 - dice_coef: 0.6033 - accuracy: 0.9857 - mse: 0.0081 - val_loss: 0.0235 - val_dice_coef: 0.5969 - val_accuracy: 0.9906 - val_mse: 0.0069\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0353 - dice_coef: 0.5567 - accuracy: 0.9844 - mse: 0.0091\n",
            "Epoch 19: val_dice_coef did not improve from 0.59685\n",
            "100/100 [==============================] - 161s 2s/step - loss: 0.0353 - dice_coef: 0.5567 - accuracy: 0.9844 - mse: 0.0091 - val_loss: 0.0314 - val_dice_coef: 0.5168 - val_accuracy: 0.9879 - val_mse: 0.0090\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0299 - dice_coef: 0.6034 - accuracy: 0.9861 - mse: 0.0078\n",
            "Epoch 20: val_dice_coef did not improve from 0.59685\n",
            "100/100 [==============================] - 170s 2s/step - loss: 0.0299 - dice_coef: 0.6034 - accuracy: 0.9861 - mse: 0.0078 - val_loss: 0.0241 - val_dice_coef: 0.5898 - val_accuracy: 0.9903 - val_mse: 0.0071\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - dice_coef: 0.6186 - accuracy: 0.9863 - mse: 0.0077\n",
            "Epoch 21: val_dice_coef improved from 0.59685 to 0.60446, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 260s 3s/step - loss: 0.0291 - dice_coef: 0.6186 - accuracy: 0.9863 - mse: 0.0077 - val_loss: 0.0239 - val_dice_coef: 0.6045 - val_accuracy: 0.9905 - val_mse: 0.0070\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0315 - dice_coef: 0.5880 - accuracy: 0.9853 - mse: 0.0083\n",
            "Epoch 22: val_dice_coef did not improve from 0.60446\n",
            "100/100 [==============================] - 171s 2s/step - loss: 0.0315 - dice_coef: 0.5880 - accuracy: 0.9853 - mse: 0.0083 - val_loss: 0.0243 - val_dice_coef: 0.5743 - val_accuracy: 0.9903 - val_mse: 0.0071\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0286 - dice_coef: 0.6163 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 23: val_dice_coef did not improve from 0.60446\n",
            "100/100 [==============================] - 169s 2s/step - loss: 0.0286 - dice_coef: 0.6163 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0309 - val_dice_coef: 0.5343 - val_accuracy: 0.9876 - val_mse: 0.0091\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0285 - dice_coef: 0.6156 - accuracy: 0.9863 - mse: 0.0075\n",
            "Epoch 24: val_dice_coef did not improve from 0.60446\n",
            "100/100 [==============================] - 166s 2s/step - loss: 0.0285 - dice_coef: 0.6156 - accuracy: 0.9863 - mse: 0.0075 - val_loss: 0.0233 - val_dice_coef: 0.5982 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0270 - dice_coef: 0.6407 - accuracy: 0.9870 - mse: 0.0071\n",
            "Epoch 25: val_dice_coef did not improve from 0.60446\n",
            "100/100 [==============================] - 165s 2s/step - loss: 0.0270 - dice_coef: 0.6407 - accuracy: 0.9870 - mse: 0.0071 - val_loss: 0.0225 - val_dice_coef: 0.5979 - val_accuracy: 0.9911 - val_mse: 0.0065\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0273 - dice_coef: 0.6303 - accuracy: 0.9867 - mse: 0.0073\n",
            "Epoch 26: val_dice_coef improved from 0.60446 to 0.61679, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 265s 3s/step - loss: 0.0273 - dice_coef: 0.6303 - accuracy: 0.9867 - mse: 0.0073 - val_loss: 0.0223 - val_dice_coef: 0.6168 - val_accuracy: 0.9909 - val_mse: 0.0066\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0265 - dice_coef: 0.6449 - accuracy: 0.9871 - mse: 0.0070\n",
            "Epoch 27: val_dice_coef did not improve from 0.61679\n",
            "100/100 [==============================] - 156s 2s/step - loss: 0.0265 - dice_coef: 0.6449 - accuracy: 0.9871 - mse: 0.0070 - val_loss: 0.0376 - val_dice_coef: 0.4869 - val_accuracy: 0.9853 - val_mse: 0.0108\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0277 - dice_coef: 0.6459 - accuracy: 0.9865 - mse: 0.0073\n",
            "Epoch 28: val_dice_coef did not improve from 0.61679\n",
            "100/100 [==============================] - 162s 2s/step - loss: 0.0277 - dice_coef: 0.6459 - accuracy: 0.9865 - mse: 0.0073 - val_loss: 0.0231 - val_dice_coef: 0.5835 - val_accuracy: 0.9909 - val_mse: 0.0066\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0254 - dice_coef: 0.6656 - accuracy: 0.9872 - mse: 0.0068\n",
            "Epoch 29: val_dice_coef improved from 0.61679 to 0.63842, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 256s 3s/step - loss: 0.0254 - dice_coef: 0.6656 - accuracy: 0.9872 - mse: 0.0068 - val_loss: 0.0209 - val_dice_coef: 0.6384 - val_accuracy: 0.9913 - val_mse: 0.0062\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0256 - dice_coef: 0.6570 - accuracy: 0.9871 - mse: 0.0068\n",
            "Epoch 30: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 159s 2s/step - loss: 0.0256 - dice_coef: 0.6570 - accuracy: 0.9871 - mse: 0.0068 - val_loss: 0.0212 - val_dice_coef: 0.6320 - val_accuracy: 0.9912 - val_mse: 0.0063\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - dice_coef: 0.6510 - accuracy: 0.9875 - mse: 0.0067\n",
            "Epoch 31: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 161s 2s/step - loss: 0.0251 - dice_coef: 0.6510 - accuracy: 0.9875 - mse: 0.0067 - val_loss: 0.0253 - val_dice_coef: 0.5926 - val_accuracy: 0.9896 - val_mse: 0.0075\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0248 - dice_coef: 0.6667 - accuracy: 0.9875 - mse: 0.0066\n",
            "Epoch 32: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 163s 2s/step - loss: 0.0248 - dice_coef: 0.6667 - accuracy: 0.9875 - mse: 0.0066 - val_loss: 0.0253 - val_dice_coef: 0.5771 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - dice_coef: 0.6655 - accuracy: 0.9876 - mse: 0.0065\n",
            "Epoch 33: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 165s 2s/step - loss: 0.0245 - dice_coef: 0.6655 - accuracy: 0.9876 - mse: 0.0065 - val_loss: 0.0213 - val_dice_coef: 0.6331 - val_accuracy: 0.9912 - val_mse: 0.0064\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0250 - dice_coef: 0.6636 - accuracy: 0.9875 - mse: 0.0066\n",
            "Epoch 34: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 165s 2s/step - loss: 0.0250 - dice_coef: 0.6636 - accuracy: 0.9875 - mse: 0.0066 - val_loss: 0.0263 - val_dice_coef: 0.5780 - val_accuracy: 0.9894 - val_mse: 0.0077\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - dice_coef: 0.6688 - accuracy: 0.9876 - mse: 0.0065\n",
            "Epoch 35: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0245 - dice_coef: 0.6688 - accuracy: 0.9876 - mse: 0.0065 - val_loss: 0.0214 - val_dice_coef: 0.6213 - val_accuracy: 0.9911 - val_mse: 0.0063\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.6476 - accuracy: 0.9872 - mse: 0.0069\n",
            "Epoch 36: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0261 - dice_coef: 0.6476 - accuracy: 0.9872 - mse: 0.0069 - val_loss: 0.0235 - val_dice_coef: 0.6032 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0273 - dice_coef: 0.6325 - accuracy: 0.9869 - mse: 0.0072\n",
            "Epoch 37: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0273 - dice_coef: 0.6325 - accuracy: 0.9869 - mse: 0.0072 - val_loss: 0.0211 - val_dice_coef: 0.6285 - val_accuracy: 0.9913 - val_mse: 0.0063\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0242 - dice_coef: 0.6757 - accuracy: 0.9878 - mse: 0.0064\n",
            "Epoch 38: val_dice_coef did not improve from 0.63842\n",
            "100/100 [==============================] - 164s 2s/step - loss: 0.0242 - dice_coef: 0.6757 - accuracy: 0.9878 - mse: 0.0064 - val_loss: 0.0272 - val_dice_coef: 0.5677 - val_accuracy: 0.9896 - val_mse: 0.0077\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0246 - dice_coef: 0.6743 - accuracy: 0.9875 - mse: 0.0065\n",
            "Epoch 39: val_dice_coef improved from 0.63842 to 0.64146, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 259s 3s/step - loss: 0.0246 - dice_coef: 0.6743 - accuracy: 0.9875 - mse: 0.0065 - val_loss: 0.0201 - val_dice_coef: 0.6415 - val_accuracy: 0.9917 - val_mse: 0.0060\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0226 - dice_coef: 0.6780 - accuracy: 0.9885 - mse: 0.0060\n",
            "Epoch 40: val_dice_coef improved from 0.64146 to 0.64150, saving model to Output/unet_tall/unet_tall.hdf5\n",
            "100/100 [==============================] - 244s 2s/step - loss: 0.0226 - dice_coef: 0.6780 - accuracy: 0.9885 - mse: 0.0060 - val_loss: 0.0208 - val_dice_coef: 0.6415 - val_accuracy: 0.9914 - val_mse: 0.0062\n",
            "Total time to train: 7524.994291067123\n",
            "cp: cannot create directory 'drive/MyDrive/paramo_ml/': No such file or directory\n",
            "cp: cannot create directory 'drive/MyDrive/paramo_ml/': No such file or directory\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uNet_tall = UNet(input_size=(tileSize,tileSize,3))\n",
        "\n",
        "callbacks = [ EarlyStopping(patience=200, monitor=\"val_dice_coef\"),\n",
        "                 ModelCheckpoint(os.path.join(\"Output/unet_tall\", \"unet_tall.hdf5\"),\n",
        "                 monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max') ]\n",
        "\n",
        "train_rgb_tall = TrainGenerator(8, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "uNet_tall = train(uNet_tall, callbacks, train_rgb_tall, validation_df, \"unet_tall\", epochs=40, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhgkiCgG63Mo",
        "outputId": "91b84f1e-aa42-4954-f223-df473d811832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot create directory 'MyDrive/sv_para/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-o5c_auKvyF"
      },
      "source": [
        "### **Attention UNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X_yGpvoMhccn",
        "outputId": "bc77d327-471b-43fe-b4df-579f7178bff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1645 - dice_coef: 0.0184 - accuracy: 0.9712 - mse: 0.0315\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.02212, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 24s 161ms/step - loss: 0.1645 - dice_coef: 0.0184 - accuracy: 0.9712 - mse: 0.0315 - val_loss: 0.1183 - val_dice_coef: 0.0221 - val_accuracy: 0.9805 - val_mse: 0.0217\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1158 - dice_coef: 0.0169 - accuracy: 0.9757 - mse: 0.0217\n",
            "Epoch 2: val_dice_coef did not improve from 0.02212\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.1158 - dice_coef: 0.0169 - accuracy: 0.9757 - mse: 0.0217 - val_loss: 0.1029 - val_dice_coef: 0.0116 - val_accuracy: 0.9805 - val_mse: 0.0193\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1175 - dice_coef: 0.0257 - accuracy: 0.9740 - mse: 0.0227\n",
            "Epoch 3: val_dice_coef improved from 0.02212 to 0.03811, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.1175 - dice_coef: 0.0257 - accuracy: 0.9740 - mse: 0.0227 - val_loss: 0.0837 - val_dice_coef: 0.0381 - val_accuracy: 0.9805 - val_mse: 0.0184\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1020 - dice_coef: 0.0746 - accuracy: 0.9728 - mse: 0.0219\n",
            "Epoch 4: val_dice_coef improved from 0.03811 to 0.14640, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1020 - dice_coef: 0.0746 - accuracy: 0.9728 - mse: 0.0219 - val_loss: 0.0603 - val_dice_coef: 0.1464 - val_accuracy: 0.9805 - val_mse: 0.0154\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0622 - dice_coef: 0.1519 - accuracy: 0.9794 - mse: 0.0146\n",
            "Epoch 5: val_dice_coef improved from 0.14640 to 0.16553, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0622 - dice_coef: 0.1519 - accuracy: 0.9794 - mse: 0.0146 - val_loss: 0.0655 - val_dice_coef: 0.1655 - val_accuracy: 0.9805 - val_mse: 0.0159\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0702 - dice_coef: 0.1774 - accuracy: 0.9750 - mse: 0.0166\n",
            "Epoch 6: val_dice_coef improved from 0.16553 to 0.23040, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.0702 - dice_coef: 0.1774 - accuracy: 0.9750 - mse: 0.0166 - val_loss: 0.0513 - val_dice_coef: 0.2304 - val_accuracy: 0.9805 - val_mse: 0.0138\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0656 - dice_coef: 0.2066 - accuracy: 0.9758 - mse: 0.0160\n",
            "Epoch 7: val_dice_coef did not improve from 0.23040\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0656 - dice_coef: 0.2066 - accuracy: 0.9758 - mse: 0.0160 - val_loss: 0.0552 - val_dice_coef: 0.2262 - val_accuracy: 0.9811 - val_mse: 0.0142\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0605 - dice_coef: 0.2617 - accuracy: 0.9757 - mse: 0.0152\n",
            "Epoch 8: val_dice_coef improved from 0.23040 to 0.31414, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0605 - dice_coef: 0.2617 - accuracy: 0.9757 - mse: 0.0152 - val_loss: 0.0455 - val_dice_coef: 0.3141 - val_accuracy: 0.9842 - val_mse: 0.0124\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0613 - dice_coef: 0.2459 - accuracy: 0.9789 - mse: 0.0147\n",
            "Epoch 9: val_dice_coef did not improve from 0.31414\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.0613 - dice_coef: 0.2459 - accuracy: 0.9789 - mse: 0.0147 - val_loss: 0.0483 - val_dice_coef: 0.2938 - val_accuracy: 0.9833 - val_mse: 0.0129\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0573 - dice_coef: 0.2855 - accuracy: 0.9788 - mse: 0.0142\n",
            "Epoch 10: val_dice_coef improved from 0.31414 to 0.35651, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0573 - dice_coef: 0.2855 - accuracy: 0.9788 - mse: 0.0142 - val_loss: 0.0407 - val_dice_coef: 0.3565 - val_accuracy: 0.9855 - val_mse: 0.0113\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0571 - dice_coef: 0.3037 - accuracy: 0.9780 - mse: 0.0146\n",
            "Epoch 11: val_dice_coef did not improve from 0.35651\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0571 - dice_coef: 0.3037 - accuracy: 0.9780 - mse: 0.0146 - val_loss: 0.0572 - val_dice_coef: 0.2978 - val_accuracy: 0.9791 - val_mse: 0.0153\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0553 - dice_coef: 0.3075 - accuracy: 0.9798 - mse: 0.0137\n",
            "Epoch 12: val_dice_coef did not improve from 0.35651\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0553 - dice_coef: 0.3075 - accuracy: 0.9798 - mse: 0.0137 - val_loss: 0.0408 - val_dice_coef: 0.3554 - val_accuracy: 0.9857 - val_mse: 0.0112\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0426 - dice_coef: 0.3546 - accuracy: 0.9829 - mse: 0.0108\n",
            "Epoch 13: val_dice_coef did not improve from 0.35651\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0426 - dice_coef: 0.3546 - accuracy: 0.9829 - mse: 0.0108 - val_loss: 0.0638 - val_dice_coef: 0.2831 - val_accuracy: 0.9818 - val_mse: 0.0151\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0451 - dice_coef: 0.3590 - accuracy: 0.9817 - mse: 0.0116\n",
            "Epoch 14: val_dice_coef improved from 0.35651 to 0.41639, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0451 - dice_coef: 0.3590 - accuracy: 0.9817 - mse: 0.0116 - val_loss: 0.0380 - val_dice_coef: 0.4164 - val_accuracy: 0.9861 - val_mse: 0.0105\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0560 - dice_coef: 0.3742 - accuracy: 0.9769 - mse: 0.0145\n",
            "Epoch 15: val_dice_coef did not improve from 0.41639\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0560 - dice_coef: 0.3742 - accuracy: 0.9769 - mse: 0.0145 - val_loss: 0.0399 - val_dice_coef: 0.3827 - val_accuracy: 0.9868 - val_mse: 0.0104\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0471 - dice_coef: 0.3854 - accuracy: 0.9807 - mse: 0.0121\n",
            "Epoch 16: val_dice_coef improved from 0.41639 to 0.43923, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.0471 - dice_coef: 0.3854 - accuracy: 0.9807 - mse: 0.0121 - val_loss: 0.0344 - val_dice_coef: 0.4392 - val_accuracy: 0.9873 - val_mse: 0.0096\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0415 - dice_coef: 0.3929 - accuracy: 0.9828 - mse: 0.0107\n",
            "Epoch 17: val_dice_coef did not improve from 0.43923\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0415 - dice_coef: 0.3929 - accuracy: 0.9828 - mse: 0.0107 - val_loss: 0.0433 - val_dice_coef: 0.4142 - val_accuracy: 0.9836 - val_mse: 0.0120\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0470 - dice_coef: 0.3921 - accuracy: 0.9807 - mse: 0.0121\n",
            "Epoch 18: val_dice_coef did not improve from 0.43923\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0470 - dice_coef: 0.3921 - accuracy: 0.9807 - mse: 0.0121 - val_loss: 0.0361 - val_dice_coef: 0.4344 - val_accuracy: 0.9870 - val_mse: 0.0100\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0451 - dice_coef: 0.3989 - accuracy: 0.9832 - mse: 0.0108\n",
            "Epoch 19: val_dice_coef did not improve from 0.43923\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0451 - dice_coef: 0.3989 - accuracy: 0.9832 - mse: 0.0108 - val_loss: 0.0393 - val_dice_coef: 0.4310 - val_accuracy: 0.9854 - val_mse: 0.0108\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0434 - dice_coef: 0.4137 - accuracy: 0.9814 - mse: 0.0113\n",
            "Epoch 20: val_dice_coef improved from 0.43923 to 0.50041, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0434 - dice_coef: 0.4137 - accuracy: 0.9814 - mse: 0.0113 - val_loss: 0.0315 - val_dice_coef: 0.5004 - val_accuracy: 0.9879 - val_mse: 0.0090\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0342 - dice_coef: 0.4106 - accuracy: 0.9855 - mse: 0.0089\n",
            "Epoch 21: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0342 - dice_coef: 0.4106 - accuracy: 0.9855 - mse: 0.0089 - val_loss: 0.0329 - val_dice_coef: 0.4659 - val_accuracy: 0.9876 - val_mse: 0.0092\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0412 - dice_coef: 0.4381 - accuracy: 0.9822 - mse: 0.0107\n",
            "Epoch 22: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0412 - dice_coef: 0.4381 - accuracy: 0.9822 - mse: 0.0107 - val_loss: 0.0321 - val_dice_coef: 0.4964 - val_accuracy: 0.9878 - val_mse: 0.0091\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0376 - dice_coef: 0.3876 - accuracy: 0.9852 - mse: 0.0093\n",
            "Epoch 23: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.0376 - dice_coef: 0.3876 - accuracy: 0.9852 - mse: 0.0093 - val_loss: 0.0315 - val_dice_coef: 0.4794 - val_accuracy: 0.9883 - val_mse: 0.0088\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0375 - dice_coef: 0.4320 - accuracy: 0.9842 - mse: 0.0096\n",
            "Epoch 24: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0375 - dice_coef: 0.4320 - accuracy: 0.9842 - mse: 0.0096 - val_loss: 0.0364 - val_dice_coef: 0.4711 - val_accuracy: 0.9860 - val_mse: 0.0103\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0432 - dice_coef: 0.4384 - accuracy: 0.9816 - mse: 0.0112\n",
            "Epoch 25: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0432 - dice_coef: 0.4384 - accuracy: 0.9816 - mse: 0.0112 - val_loss: 0.0356 - val_dice_coef: 0.4505 - val_accuracy: 0.9869 - val_mse: 0.0098\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0484 - dice_coef: 0.3992 - accuracy: 0.9812 - mse: 0.0119\n",
            "Epoch 26: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0484 - dice_coef: 0.3992 - accuracy: 0.9812 - mse: 0.0119 - val_loss: 0.0316 - val_dice_coef: 0.4627 - val_accuracy: 0.9881 - val_mse: 0.0090\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0422 - dice_coef: 0.4510 - accuracy: 0.9827 - mse: 0.0107\n",
            "Epoch 27: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0422 - dice_coef: 0.4510 - accuracy: 0.9827 - mse: 0.0107 - val_loss: 0.0312 - val_dice_coef: 0.4877 - val_accuracy: 0.9881 - val_mse: 0.0088\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0414 - dice_coef: 0.4076 - accuracy: 0.9824 - mse: 0.0107\n",
            "Epoch 28: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0414 - dice_coef: 0.4076 - accuracy: 0.9824 - mse: 0.0107 - val_loss: 0.0366 - val_dice_coef: 0.4548 - val_accuracy: 0.9861 - val_mse: 0.0103\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0357 - dice_coef: 0.4645 - accuracy: 0.9843 - mse: 0.0093\n",
            "Epoch 29: val_dice_coef did not improve from 0.50041\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0357 - dice_coef: 0.4645 - accuracy: 0.9843 - mse: 0.0093 - val_loss: 0.0306 - val_dice_coef: 0.4900 - val_accuracy: 0.9883 - val_mse: 0.0087\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0332 - dice_coef: 0.4017 - accuracy: 0.9860 - mse: 0.0086\n",
            "Epoch 30: val_dice_coef improved from 0.50041 to 0.53760, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.0332 - dice_coef: 0.4017 - accuracy: 0.9860 - mse: 0.0086 - val_loss: 0.0292 - val_dice_coef: 0.5376 - val_accuracy: 0.9883 - val_mse: 0.0085\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0390 - dice_coef: 0.4545 - accuracy: 0.9829 - mse: 0.0100\n",
            "Epoch 31: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0390 - dice_coef: 0.4545 - accuracy: 0.9829 - mse: 0.0100 - val_loss: 0.0333 - val_dice_coef: 0.4956 - val_accuracy: 0.9874 - val_mse: 0.0093\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0343 - dice_coef: 0.4291 - accuracy: 0.9848 - mse: 0.0090\n",
            "Epoch 32: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0343 - dice_coef: 0.4291 - accuracy: 0.9848 - mse: 0.0090 - val_loss: 0.0298 - val_dice_coef: 0.5165 - val_accuracy: 0.9887 - val_mse: 0.0084\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0361 - dice_coef: 0.4340 - accuracy: 0.9852 - mse: 0.0090\n",
            "Epoch 33: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.0361 - dice_coef: 0.4340 - accuracy: 0.9852 - mse: 0.0090 - val_loss: 0.0346 - val_dice_coef: 0.4742 - val_accuracy: 0.9871 - val_mse: 0.0096\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0451 - dice_coef: 0.4489 - accuracy: 0.9811 - mse: 0.0116\n",
            "Epoch 34: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0451 - dice_coef: 0.4489 - accuracy: 0.9811 - mse: 0.0116 - val_loss: 0.0299 - val_dice_coef: 0.5222 - val_accuracy: 0.9882 - val_mse: 0.0086\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0390 - dice_coef: 0.4588 - accuracy: 0.9822 - mse: 0.0104\n",
            "Epoch 35: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0390 - dice_coef: 0.4588 - accuracy: 0.9822 - mse: 0.0104 - val_loss: 0.0381 - val_dice_coef: 0.4458 - val_accuracy: 0.9863 - val_mse: 0.0104\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0355 - dice_coef: 0.4324 - accuracy: 0.9849 - mse: 0.0091\n",
            "Epoch 36: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0355 - dice_coef: 0.4324 - accuracy: 0.9849 - mse: 0.0091 - val_loss: 0.0309 - val_dice_coef: 0.4878 - val_accuracy: 0.9884 - val_mse: 0.0087\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0358 - dice_coef: 0.4344 - accuracy: 0.9846 - mse: 0.0093\n",
            "Epoch 37: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.0358 - dice_coef: 0.4344 - accuracy: 0.9846 - mse: 0.0093 - val_loss: 0.0417 - val_dice_coef: 0.4618 - val_accuracy: 0.9843 - val_mse: 0.0119\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0375 - dice_coef: 0.4681 - accuracy: 0.9835 - mse: 0.0097\n",
            "Epoch 38: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0375 - dice_coef: 0.4681 - accuracy: 0.9835 - mse: 0.0097 - val_loss: 0.0410 - val_dice_coef: 0.4460 - val_accuracy: 0.9859 - val_mse: 0.0109\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0387 - dice_coef: 0.4370 - accuracy: 0.9834 - mse: 0.0099\n",
            "Epoch 39: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0387 - dice_coef: 0.4370 - accuracy: 0.9834 - mse: 0.0099 - val_loss: 0.0297 - val_dice_coef: 0.5262 - val_accuracy: 0.9885 - val_mse: 0.0085\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0412 - dice_coef: 0.4562 - accuracy: 0.9821 - mse: 0.0108\n",
            "Epoch 40: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0412 - dice_coef: 0.4562 - accuracy: 0.9821 - mse: 0.0108 - val_loss: 0.0280 - val_dice_coef: 0.5210 - val_accuracy: 0.9892 - val_mse: 0.0080\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0390 - dice_coef: 0.4507 - accuracy: 0.9828 - mse: 0.0102\n",
            "Epoch 41: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.0390 - dice_coef: 0.4507 - accuracy: 0.9828 - mse: 0.0102 - val_loss: 0.0433 - val_dice_coef: 0.4232 - val_accuracy: 0.9850 - val_mse: 0.0115\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0325 - dice_coef: 0.4681 - accuracy: 0.9858 - mse: 0.0084\n",
            "Epoch 42: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0325 - dice_coef: 0.4681 - accuracy: 0.9858 - mse: 0.0084 - val_loss: 0.0312 - val_dice_coef: 0.5185 - val_accuracy: 0.9878 - val_mse: 0.0090\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0375 - dice_coef: 0.4359 - accuracy: 0.9839 - mse: 0.0097\n",
            "Epoch 43: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0375 - dice_coef: 0.4359 - accuracy: 0.9839 - mse: 0.0097 - val_loss: 0.0350 - val_dice_coef: 0.4225 - val_accuracy: 0.9883 - val_mse: 0.0092\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0317 - dice_coef: 0.4847 - accuracy: 0.9857 - mse: 0.0083\n",
            "Epoch 44: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0317 - dice_coef: 0.4847 - accuracy: 0.9857 - mse: 0.0083 - val_loss: 0.0304 - val_dice_coef: 0.4982 - val_accuracy: 0.9886 - val_mse: 0.0085\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0400 - dice_coef: 0.4287 - accuracy: 0.9834 - mse: 0.0101\n",
            "Epoch 45: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.0400 - dice_coef: 0.4287 - accuracy: 0.9834 - mse: 0.0101 - val_loss: 0.0278 - val_dice_coef: 0.5263 - val_accuracy: 0.9892 - val_mse: 0.0080\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0381 - dice_coef: 0.4636 - accuracy: 0.9831 - mse: 0.0099\n",
            "Epoch 46: val_dice_coef did not improve from 0.53760\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.0381 - dice_coef: 0.4636 - accuracy: 0.9831 - mse: 0.0099 - val_loss: 0.0386 - val_dice_coef: 0.4406 - val_accuracy: 0.9865 - val_mse: 0.0103\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0402 - dice_coef: 0.4985 - accuracy: 0.9818 - mse: 0.0106\n",
            "Epoch 47: val_dice_coef improved from 0.53760 to 0.54540, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 116ms/step - loss: 0.0402 - dice_coef: 0.4985 - accuracy: 0.9818 - mse: 0.0106 - val_loss: 0.0283 - val_dice_coef: 0.5454 - val_accuracy: 0.9888 - val_mse: 0.0082\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.4806 - accuracy: 0.9860 - mse: 0.0083\n",
            "Epoch 48: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0322 - dice_coef: 0.4806 - accuracy: 0.9860 - mse: 0.0083 - val_loss: 0.0292 - val_dice_coef: 0.5285 - val_accuracy: 0.9889 - val_mse: 0.0083\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0403 - dice_coef: 0.4168 - accuracy: 0.9832 - mse: 0.0102\n",
            "Epoch 49: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0403 - dice_coef: 0.4168 - accuracy: 0.9832 - mse: 0.0102 - val_loss: 0.0337 - val_dice_coef: 0.4743 - val_accuracy: 0.9870 - val_mse: 0.0095\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0385 - dice_coef: 0.4858 - accuracy: 0.9828 - mse: 0.0100\n",
            "Epoch 50: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.0385 - dice_coef: 0.4858 - accuracy: 0.9828 - mse: 0.0100 - val_loss: 0.0304 - val_dice_coef: 0.4897 - val_accuracy: 0.9890 - val_mse: 0.0083\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - dice_coef: 0.4490 - accuracy: 0.9846 - mse: 0.0090\n",
            "Epoch 51: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0336 - dice_coef: 0.4490 - accuracy: 0.9846 - mse: 0.0090 - val_loss: 0.0273 - val_dice_coef: 0.5322 - val_accuracy: 0.9892 - val_mse: 0.0079\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0390 - dice_coef: 0.4863 - accuracy: 0.9826 - mse: 0.0101\n",
            "Epoch 52: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0390 - dice_coef: 0.4863 - accuracy: 0.9826 - mse: 0.0101 - val_loss: 0.0293 - val_dice_coef: 0.5280 - val_accuracy: 0.9888 - val_mse: 0.0083\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0345 - dice_coef: 0.4803 - accuracy: 0.9845 - mse: 0.0090\n",
            "Epoch 53: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0345 - dice_coef: 0.4803 - accuracy: 0.9845 - mse: 0.0090 - val_loss: 0.0320 - val_dice_coef: 0.5103 - val_accuracy: 0.9872 - val_mse: 0.0092\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0344 - dice_coef: 0.4437 - accuracy: 0.9847 - mse: 0.0090\n",
            "Epoch 54: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0344 - dice_coef: 0.4437 - accuracy: 0.9847 - mse: 0.0090 - val_loss: 0.0316 - val_dice_coef: 0.4669 - val_accuracy: 0.9883 - val_mse: 0.0088\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0342 - dice_coef: 0.5006 - accuracy: 0.9842 - mse: 0.0091\n",
            "Epoch 55: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.0342 - dice_coef: 0.5006 - accuracy: 0.9842 - mse: 0.0091 - val_loss: 0.0308 - val_dice_coef: 0.5347 - val_accuracy: 0.9872 - val_mse: 0.0091\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0340 - dice_coef: 0.4546 - accuracy: 0.9851 - mse: 0.0088\n",
            "Epoch 56: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0340 - dice_coef: 0.4546 - accuracy: 0.9851 - mse: 0.0088 - val_loss: 0.0462 - val_dice_coef: 0.3957 - val_accuracy: 0.9880 - val_mse: 0.0108\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0381 - dice_coef: 0.4555 - accuracy: 0.9836 - mse: 0.0097\n",
            "Epoch 57: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0381 - dice_coef: 0.4555 - accuracy: 0.9836 - mse: 0.0097 - val_loss: 0.0274 - val_dice_coef: 0.5238 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0319 - dice_coef: 0.4825 - accuracy: 0.9851 - mse: 0.0085\n",
            "Epoch 58: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0319 - dice_coef: 0.4825 - accuracy: 0.9851 - mse: 0.0085 - val_loss: 0.0350 - val_dice_coef: 0.5003 - val_accuracy: 0.9861 - val_mse: 0.0101\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0279 - dice_coef: 0.4420 - accuracy: 0.9877 - mse: 0.0072\n",
            "Epoch 59: val_dice_coef did not improve from 0.54540\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0279 - dice_coef: 0.4420 - accuracy: 0.9877 - mse: 0.0072 - val_loss: 0.0272 - val_dice_coef: 0.5406 - val_accuracy: 0.9896 - val_mse: 0.0077\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0302 - dice_coef: 0.4647 - accuracy: 0.9864 - mse: 0.0079\n",
            "Epoch 60: val_dice_coef improved from 0.54540 to 0.56106, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0302 - dice_coef: 0.4647 - accuracy: 0.9864 - mse: 0.0079 - val_loss: 0.0272 - val_dice_coef: 0.5611 - val_accuracy: 0.9888 - val_mse: 0.0081\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.4926 - accuracy: 0.9854 - mse: 0.0085\n",
            "Epoch 61: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0322 - dice_coef: 0.4926 - accuracy: 0.9854 - mse: 0.0085 - val_loss: 0.0288 - val_dice_coef: 0.5191 - val_accuracy: 0.9891 - val_mse: 0.0081\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0305 - dice_coef: 0.4568 - accuracy: 0.9857 - mse: 0.0081\n",
            "Epoch 62: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0305 - dice_coef: 0.4568 - accuracy: 0.9857 - mse: 0.0081 - val_loss: 0.0262 - val_dice_coef: 0.5420 - val_accuracy: 0.9896 - val_mse: 0.0076\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0311 - dice_coef: 0.4937 - accuracy: 0.9853 - mse: 0.0084\n",
            "Epoch 63: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0311 - dice_coef: 0.4937 - accuracy: 0.9853 - mse: 0.0084 - val_loss: 0.0302 - val_dice_coef: 0.5167 - val_accuracy: 0.9881 - val_mse: 0.0087\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.5073 - accuracy: 0.9850 - mse: 0.0086\n",
            "Epoch 64: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0322 - dice_coef: 0.5073 - accuracy: 0.9850 - mse: 0.0086 - val_loss: 0.0264 - val_dice_coef: 0.5535 - val_accuracy: 0.9895 - val_mse: 0.0077\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0340 - dice_coef: 0.4621 - accuracy: 0.9843 - mse: 0.0090\n",
            "Epoch 65: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0340 - dice_coef: 0.4621 - accuracy: 0.9843 - mse: 0.0090 - val_loss: 0.0314 - val_dice_coef: 0.4866 - val_accuracy: 0.9876 - val_mse: 0.0090\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0353 - dice_coef: 0.5105 - accuracy: 0.9838 - mse: 0.0094\n",
            "Epoch 66: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0353 - dice_coef: 0.5105 - accuracy: 0.9838 - mse: 0.0094 - val_loss: 0.0276 - val_dice_coef: 0.5540 - val_accuracy: 0.9887 - val_mse: 0.0082\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0384 - dice_coef: 0.4827 - accuracy: 0.9835 - mse: 0.0098\n",
            "Epoch 67: val_dice_coef did not improve from 0.56106\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0384 - dice_coef: 0.4827 - accuracy: 0.9835 - mse: 0.0098 - val_loss: 0.0279 - val_dice_coef: 0.5070 - val_accuracy: 0.9894 - val_mse: 0.0079\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0289 - dice_coef: 0.5038 - accuracy: 0.9865 - mse: 0.0076\n",
            "Epoch 68: val_dice_coef improved from 0.56106 to 0.56753, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.0289 - dice_coef: 0.5038 - accuracy: 0.9865 - mse: 0.0076 - val_loss: 0.0251 - val_dice_coef: 0.5675 - val_accuracy: 0.9900 - val_mse: 0.0074\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0328 - dice_coef: 0.4728 - accuracy: 0.9847 - mse: 0.0086\n",
            "Epoch 69: val_dice_coef did not improve from 0.56753\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0328 - dice_coef: 0.4728 - accuracy: 0.9847 - mse: 0.0086 - val_loss: 0.0371 - val_dice_coef: 0.4379 - val_accuracy: 0.9867 - val_mse: 0.0100\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0305 - dice_coef: 0.4543 - accuracy: 0.9865 - mse: 0.0078\n",
            "Epoch 70: val_dice_coef did not improve from 0.56753\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0305 - dice_coef: 0.4543 - accuracy: 0.9865 - mse: 0.0078 - val_loss: 0.0255 - val_dice_coef: 0.5576 - val_accuracy: 0.9900 - val_mse: 0.0074\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0375 - dice_coef: 0.5048 - accuracy: 0.9830 - mse: 0.0099\n",
            "Epoch 71: val_dice_coef did not improve from 0.56753\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0375 - dice_coef: 0.5048 - accuracy: 0.9830 - mse: 0.0099 - val_loss: 0.0255 - val_dice_coef: 0.5584 - val_accuracy: 0.9897 - val_mse: 0.0075\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0315 - dice_coef: 0.4937 - accuracy: 0.9857 - mse: 0.0082\n",
            "Epoch 72: val_dice_coef did not improve from 0.56753\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.0315 - dice_coef: 0.4937 - accuracy: 0.9857 - mse: 0.0082 - val_loss: 0.0330 - val_dice_coef: 0.5239 - val_accuracy: 0.9870 - val_mse: 0.0095\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0332 - dice_coef: 0.5032 - accuracy: 0.9849 - mse: 0.0086\n",
            "Epoch 73: val_dice_coef did not improve from 0.56753\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0332 - dice_coef: 0.5032 - accuracy: 0.9849 - mse: 0.0086 - val_loss: 0.0282 - val_dice_coef: 0.5186 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - dice_coef: 0.4886 - accuracy: 0.9877 - mse: 0.0068\n",
            "Epoch 74: val_dice_coef improved from 0.56753 to 0.58443, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.0252 - dice_coef: 0.4886 - accuracy: 0.9877 - mse: 0.0068 - val_loss: 0.0256 - val_dice_coef: 0.5844 - val_accuracy: 0.9897 - val_mse: 0.0075\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0329 - dice_coef: 0.4983 - accuracy: 0.9846 - mse: 0.0087\n",
            "Epoch 75: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0329 - dice_coef: 0.4983 - accuracy: 0.9846 - mse: 0.0087 - val_loss: 0.0266 - val_dice_coef: 0.5541 - val_accuracy: 0.9892 - val_mse: 0.0078\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0308 - dice_coef: 0.4592 - accuracy: 0.9862 - mse: 0.0080\n",
            "Epoch 76: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0308 - dice_coef: 0.4592 - accuracy: 0.9862 - mse: 0.0080 - val_loss: 0.0288 - val_dice_coef: 0.5213 - val_accuracy: 0.9889 - val_mse: 0.0082\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0314 - dice_coef: 0.4928 - accuracy: 0.9849 - mse: 0.0084\n",
            "Epoch 77: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0314 - dice_coef: 0.4928 - accuracy: 0.9849 - mse: 0.0084 - val_loss: 0.0260 - val_dice_coef: 0.5475 - val_accuracy: 0.9897 - val_mse: 0.0076\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0359 - dice_coef: 0.4743 - accuracy: 0.9838 - mse: 0.0096\n",
            "Epoch 78: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.0359 - dice_coef: 0.4743 - accuracy: 0.9838 - mse: 0.0096 - val_loss: 0.0279 - val_dice_coef: 0.5340 - val_accuracy: 0.9891 - val_mse: 0.0081\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0298 - dice_coef: 0.4836 - accuracy: 0.9862 - mse: 0.0077\n",
            "Epoch 79: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0298 - dice_coef: 0.4836 - accuracy: 0.9862 - mse: 0.0077 - val_loss: 0.0282 - val_dice_coef: 0.5225 - val_accuracy: 0.9897 - val_mse: 0.0078\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0292 - dice_coef: 0.4858 - accuracy: 0.9865 - mse: 0.0076\n",
            "Epoch 80: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0292 - dice_coef: 0.4858 - accuracy: 0.9865 - mse: 0.0076 - val_loss: 0.0263 - val_dice_coef: 0.5741 - val_accuracy: 0.9894 - val_mse: 0.0077\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0289 - dice_coef: 0.4692 - accuracy: 0.9865 - mse: 0.0077\n",
            "Epoch 81: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.0289 - dice_coef: 0.4692 - accuracy: 0.9865 - mse: 0.0077 - val_loss: 0.0264 - val_dice_coef: 0.5315 - val_accuracy: 0.9899 - val_mse: 0.0075\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0353 - dice_coef: 0.4589 - accuracy: 0.9845 - mse: 0.0091\n",
            "Epoch 82: val_dice_coef improved from 0.58443 to 0.58649, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.0353 - dice_coef: 0.4589 - accuracy: 0.9845 - mse: 0.0091 - val_loss: 0.0244 - val_dice_coef: 0.5865 - val_accuracy: 0.9901 - val_mse: 0.0072\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0349 - dice_coef: 0.4889 - accuracy: 0.9832 - mse: 0.0094\n",
            "Epoch 83: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0349 - dice_coef: 0.4889 - accuracy: 0.9832 - mse: 0.0094 - val_loss: 0.0349 - val_dice_coef: 0.4989 - val_accuracy: 0.9869 - val_mse: 0.0098\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0294 - dice_coef: 0.4555 - accuracy: 0.9870 - mse: 0.0077\n",
            "Epoch 84: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0294 - dice_coef: 0.4555 - accuracy: 0.9870 - mse: 0.0077 - val_loss: 0.0275 - val_dice_coef: 0.5098 - val_accuracy: 0.9892 - val_mse: 0.0079\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0333 - dice_coef: 0.4695 - accuracy: 0.9852 - mse: 0.0085\n",
            "Epoch 85: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0333 - dice_coef: 0.4695 - accuracy: 0.9852 - mse: 0.0085 - val_loss: 0.0317 - val_dice_coef: 0.5193 - val_accuracy: 0.9881 - val_mse: 0.0089\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0306 - dice_coef: 0.4980 - accuracy: 0.9858 - mse: 0.0081\n",
            "Epoch 86: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0306 - dice_coef: 0.4980 - accuracy: 0.9858 - mse: 0.0081 - val_loss: 0.0272 - val_dice_coef: 0.5546 - val_accuracy: 0.9891 - val_mse: 0.0079\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0306 - dice_coef: 0.5038 - accuracy: 0.9857 - mse: 0.0080\n",
            "Epoch 87: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0306 - dice_coef: 0.5038 - accuracy: 0.9857 - mse: 0.0080 - val_loss: 0.0279 - val_dice_coef: 0.5426 - val_accuracy: 0.9892 - val_mse: 0.0079\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0378 - dice_coef: 0.4942 - accuracy: 0.9831 - mse: 0.0098\n",
            "Epoch 88: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0378 - dice_coef: 0.4942 - accuracy: 0.9831 - mse: 0.0098 - val_loss: 0.0352 - val_dice_coef: 0.4691 - val_accuracy: 0.9873 - val_mse: 0.0096\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0321 - dice_coef: 0.4359 - accuracy: 0.9856 - mse: 0.0084\n",
            "Epoch 89: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0321 - dice_coef: 0.4359 - accuracy: 0.9856 - mse: 0.0084 - val_loss: 0.0282 - val_dice_coef: 0.5257 - val_accuracy: 0.9893 - val_mse: 0.0080\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0342 - dice_coef: 0.5137 - accuracy: 0.9842 - mse: 0.0089\n",
            "Epoch 90: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.0342 - dice_coef: 0.5137 - accuracy: 0.9842 - mse: 0.0089 - val_loss: 0.0263 - val_dice_coef: 0.5747 - val_accuracy: 0.9894 - val_mse: 0.0077\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0333 - dice_coef: 0.4565 - accuracy: 0.9859 - mse: 0.0084\n",
            "Epoch 91: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0333 - dice_coef: 0.4565 - accuracy: 0.9859 - mse: 0.0084 - val_loss: 0.0298 - val_dice_coef: 0.5220 - val_accuracy: 0.9891 - val_mse: 0.0082\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0274 - dice_coef: 0.4829 - accuracy: 0.9872 - mse: 0.0072\n",
            "Epoch 92: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0274 - dice_coef: 0.4829 - accuracy: 0.9872 - mse: 0.0072 - val_loss: 0.0261 - val_dice_coef: 0.5447 - val_accuracy: 0.9895 - val_mse: 0.0076\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0297 - dice_coef: 0.5101 - accuracy: 0.9857 - mse: 0.0079\n",
            "Epoch 93: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0297 - dice_coef: 0.5101 - accuracy: 0.9857 - mse: 0.0079 - val_loss: 0.0272 - val_dice_coef: 0.5664 - val_accuracy: 0.9890 - val_mse: 0.0080\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - dice_coef: 0.4908 - accuracy: 0.9869 - mse: 0.0074\n",
            "Epoch 94: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0287 - dice_coef: 0.4908 - accuracy: 0.9869 - mse: 0.0074 - val_loss: 0.0246 - val_dice_coef: 0.5864 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0298 - dice_coef: 0.4945 - accuracy: 0.9863 - mse: 0.0079\n",
            "Epoch 95: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.0298 - dice_coef: 0.4945 - accuracy: 0.9863 - mse: 0.0079 - val_loss: 0.0317 - val_dice_coef: 0.4883 - val_accuracy: 0.9883 - val_mse: 0.0087\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0316 - dice_coef: 0.5028 - accuracy: 0.9850 - mse: 0.0084\n",
            "Epoch 96: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0316 - dice_coef: 0.5028 - accuracy: 0.9850 - mse: 0.0084 - val_loss: 0.0261 - val_dice_coef: 0.5534 - val_accuracy: 0.9901 - val_mse: 0.0074\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0318 - dice_coef: 0.5029 - accuracy: 0.9850 - mse: 0.0084\n",
            "Epoch 97: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0318 - dice_coef: 0.5029 - accuracy: 0.9850 - mse: 0.0084 - val_loss: 0.0322 - val_dice_coef: 0.5208 - val_accuracy: 0.9874 - val_mse: 0.0092\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0308 - dice_coef: 0.5282 - accuracy: 0.9851 - mse: 0.0084\n",
            "Epoch 98: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0308 - dice_coef: 0.5282 - accuracy: 0.9851 - mse: 0.0084 - val_loss: 0.0278 - val_dice_coef: 0.5551 - val_accuracy: 0.9889 - val_mse: 0.0082\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0289 - dice_coef: 0.5042 - accuracy: 0.9862 - mse: 0.0076\n",
            "Epoch 99: val_dice_coef did not improve from 0.58649\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0289 - dice_coef: 0.5042 - accuracy: 0.9862 - mse: 0.0076 - val_loss: 0.0232 - val_dice_coef: 0.5852 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0313 - dice_coef: 0.4803 - accuracy: 0.9856 - mse: 0.0082\n",
            "Epoch 100: val_dice_coef improved from 0.58649 to 0.58765, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.0313 - dice_coef: 0.4803 - accuracy: 0.9856 - mse: 0.0082 - val_loss: 0.0230 - val_dice_coef: 0.5877 - val_accuracy: 0.9906 - val_mse: 0.0068\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0307 - dice_coef: 0.5126 - accuracy: 0.9853 - mse: 0.0082\n",
            "Epoch 101: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0307 - dice_coef: 0.5126 - accuracy: 0.9853 - mse: 0.0082 - val_loss: 0.0245 - val_dice_coef: 0.5589 - val_accuracy: 0.9903 - val_mse: 0.0071\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0337 - dice_coef: 0.4719 - accuracy: 0.9851 - mse: 0.0088\n",
            "Epoch 102: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0337 - dice_coef: 0.4719 - accuracy: 0.9851 - mse: 0.0088 - val_loss: 0.0363 - val_dice_coef: 0.4223 - val_accuracy: 0.9873 - val_mse: 0.0096\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0341 - dice_coef: 0.5083 - accuracy: 0.9843 - mse: 0.0089\n",
            "Epoch 103: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0341 - dice_coef: 0.5083 - accuracy: 0.9843 - mse: 0.0089 - val_loss: 0.0256 - val_dice_coef: 0.5629 - val_accuracy: 0.9897 - val_mse: 0.0075\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0272 - dice_coef: 0.4966 - accuracy: 0.9873 - mse: 0.0071\n",
            "Epoch 104: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0272 - dice_coef: 0.4966 - accuracy: 0.9873 - mse: 0.0071 - val_loss: 0.0247 - val_dice_coef: 0.5774 - val_accuracy: 0.9901 - val_mse: 0.0072\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0321 - dice_coef: 0.4737 - accuracy: 0.9854 - mse: 0.0085\n",
            "Epoch 105: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.0321 - dice_coef: 0.4737 - accuracy: 0.9854 - mse: 0.0085 - val_loss: 0.0272 - val_dice_coef: 0.5244 - val_accuracy: 0.9896 - val_mse: 0.0078\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0347 - dice_coef: 0.5177 - accuracy: 0.9839 - mse: 0.0091\n",
            "Epoch 106: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0347 - dice_coef: 0.5177 - accuracy: 0.9839 - mse: 0.0091 - val_loss: 0.0288 - val_dice_coef: 0.5247 - val_accuracy: 0.9889 - val_mse: 0.0081\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0270 - dice_coef: 0.4681 - accuracy: 0.9875 - mse: 0.0071\n",
            "Epoch 107: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0270 - dice_coef: 0.4681 - accuracy: 0.9875 - mse: 0.0071 - val_loss: 0.0255 - val_dice_coef: 0.5752 - val_accuracy: 0.9894 - val_mse: 0.0076\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0303 - dice_coef: 0.5364 - accuracy: 0.9854 - mse: 0.0080\n",
            "Epoch 108: val_dice_coef did not improve from 0.58765\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0303 - dice_coef: 0.5364 - accuracy: 0.9854 - mse: 0.0080 - val_loss: 0.0235 - val_dice_coef: 0.5774 - val_accuracy: 0.9904 - val_mse: 0.0069\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0266 - dice_coef: 0.5248 - accuracy: 0.9869 - mse: 0.0071\n",
            "Epoch 109: val_dice_coef improved from 0.58765 to 0.59508, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0266 - dice_coef: 0.5248 - accuracy: 0.9869 - mse: 0.0071 - val_loss: 0.0239 - val_dice_coef: 0.5951 - val_accuracy: 0.9901 - val_mse: 0.0071\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0301 - dice_coef: 0.4970 - accuracy: 0.9855 - mse: 0.0081\n",
            "Epoch 110: val_dice_coef did not improve from 0.59508\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0301 - dice_coef: 0.4970 - accuracy: 0.9855 - mse: 0.0081 - val_loss: 0.0251 - val_dice_coef: 0.5696 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - dice_coef: 0.5418 - accuracy: 0.9874 - mse: 0.0068\n",
            "Epoch 111: val_dice_coef did not improve from 0.59508\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0251 - dice_coef: 0.5418 - accuracy: 0.9874 - mse: 0.0068 - val_loss: 0.0227 - val_dice_coef: 0.5944 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0354 - dice_coef: 0.4732 - accuracy: 0.9841 - mse: 0.0094\n",
            "Epoch 112: val_dice_coef did not improve from 0.59508\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0354 - dice_coef: 0.4732 - accuracy: 0.9841 - mse: 0.0094 - val_loss: 0.0273 - val_dice_coef: 0.5117 - val_accuracy: 0.9903 - val_mse: 0.0073\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0288 - dice_coef: 0.5207 - accuracy: 0.9860 - mse: 0.0076\n",
            "Epoch 113: val_dice_coef did not improve from 0.59508\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0288 - dice_coef: 0.5207 - accuracy: 0.9860 - mse: 0.0076 - val_loss: 0.0247 - val_dice_coef: 0.5631 - val_accuracy: 0.9901 - val_mse: 0.0072\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0325 - dice_coef: 0.5389 - accuracy: 0.9841 - mse: 0.0087\n",
            "Epoch 114: val_dice_coef did not improve from 0.59508\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.0325 - dice_coef: 0.5389 - accuracy: 0.9841 - mse: 0.0087 - val_loss: 0.0324 - val_dice_coef: 0.5303 - val_accuracy: 0.9869 - val_mse: 0.0095\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0268 - dice_coef: 0.5078 - accuracy: 0.9872 - mse: 0.0070\n",
            "Epoch 115: val_dice_coef improved from 0.59508 to 0.59571, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.0268 - dice_coef: 0.5078 - accuracy: 0.9872 - mse: 0.0070 - val_loss: 0.0235 - val_dice_coef: 0.5957 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0281 - dice_coef: 0.5005 - accuracy: 0.9863 - mse: 0.0075\n",
            "Epoch 116: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0281 - dice_coef: 0.5005 - accuracy: 0.9863 - mse: 0.0075 - val_loss: 0.0246 - val_dice_coef: 0.5610 - val_accuracy: 0.9902 - val_mse: 0.0072\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - dice_coef: 0.4593 - accuracy: 0.9878 - mse: 0.0069\n",
            "Epoch 117: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0262 - dice_coef: 0.4593 - accuracy: 0.9878 - mse: 0.0069 - val_loss: 0.0268 - val_dice_coef: 0.5580 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0303 - dice_coef: 0.5084 - accuracy: 0.9855 - mse: 0.0080\n",
            "Epoch 118: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0303 - dice_coef: 0.5084 - accuracy: 0.9855 - mse: 0.0080 - val_loss: 0.0253 - val_dice_coef: 0.5802 - val_accuracy: 0.9900 - val_mse: 0.0074\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0285 - dice_coef: 0.5191 - accuracy: 0.9862 - mse: 0.0077\n",
            "Epoch 119: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0285 - dice_coef: 0.5191 - accuracy: 0.9862 - mse: 0.0077 - val_loss: 0.0228 - val_dice_coef: 0.5842 - val_accuracy: 0.9907 - val_mse: 0.0067\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0312 - dice_coef: 0.5265 - accuracy: 0.9854 - mse: 0.0082\n",
            "Epoch 120: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0312 - dice_coef: 0.5265 - accuracy: 0.9854 - mse: 0.0082 - val_loss: 0.0268 - val_dice_coef: 0.5241 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0305 - dice_coef: 0.4879 - accuracy: 0.9855 - mse: 0.0082\n",
            "Epoch 121: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0305 - dice_coef: 0.4879 - accuracy: 0.9855 - mse: 0.0082 - val_loss: 0.0255 - val_dice_coef: 0.5660 - val_accuracy: 0.9900 - val_mse: 0.0074\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0243 - dice_coef: 0.5100 - accuracy: 0.9882 - mse: 0.0064\n",
            "Epoch 122: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0243 - dice_coef: 0.5100 - accuracy: 0.9882 - mse: 0.0064 - val_loss: 0.0243 - val_dice_coef: 0.5800 - val_accuracy: 0.9903 - val_mse: 0.0071\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0272 - dice_coef: 0.5170 - accuracy: 0.9867 - mse: 0.0073\n",
            "Epoch 123: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0272 - dice_coef: 0.5170 - accuracy: 0.9867 - mse: 0.0073 - val_loss: 0.0274 - val_dice_coef: 0.5363 - val_accuracy: 0.9890 - val_mse: 0.0080\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0314 - dice_coef: 0.5260 - accuracy: 0.9853 - mse: 0.0083\n",
            "Epoch 124: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.0314 - dice_coef: 0.5260 - accuracy: 0.9853 - mse: 0.0083 - val_loss: 0.0254 - val_dice_coef: 0.5684 - val_accuracy: 0.9898 - val_mse: 0.0074\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0301 - dice_coef: 0.5129 - accuracy: 0.9860 - mse: 0.0080\n",
            "Epoch 125: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0301 - dice_coef: 0.5129 - accuracy: 0.9860 - mse: 0.0080 - val_loss: 0.0341 - val_dice_coef: 0.4838 - val_accuracy: 0.9872 - val_mse: 0.0096\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.5111 - accuracy: 0.9874 - mse: 0.0068\n",
            "Epoch 126: val_dice_coef did not improve from 0.59571\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0261 - dice_coef: 0.5111 - accuracy: 0.9874 - mse: 0.0068 - val_loss: 0.0231 - val_dice_coef: 0.5841 - val_accuracy: 0.9906 - val_mse: 0.0068\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0307 - dice_coef: 0.5678 - accuracy: 0.9849 - mse: 0.0082\n",
            "Epoch 127: val_dice_coef improved from 0.59571 to 0.60212, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0307 - dice_coef: 0.5678 - accuracy: 0.9849 - mse: 0.0082 - val_loss: 0.0221 - val_dice_coef: 0.6021 - val_accuracy: 0.9909 - val_mse: 0.0066\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0283 - dice_coef: 0.4862 - accuracy: 0.9868 - mse: 0.0075\n",
            "Epoch 128: val_dice_coef did not improve from 0.60212\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0283 - dice_coef: 0.4862 - accuracy: 0.9868 - mse: 0.0075 - val_loss: 0.0252 - val_dice_coef: 0.5615 - val_accuracy: 0.9903 - val_mse: 0.0072\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - dice_coef: 0.5286 - accuracy: 0.9878 - mse: 0.0066\n",
            "Epoch 129: val_dice_coef improved from 0.60212 to 0.60538, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0252 - dice_coef: 0.5286 - accuracy: 0.9878 - mse: 0.0066 - val_loss: 0.0231 - val_dice_coef: 0.6054 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0235 - dice_coef: 0.4949 - accuracy: 0.9886 - mse: 0.0063\n",
            "Epoch 130: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 0.0235 - dice_coef: 0.4949 - accuracy: 0.9886 - mse: 0.0063 - val_loss: 0.0241 - val_dice_coef: 0.5956 - val_accuracy: 0.9902 - val_mse: 0.0071\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0272 - dice_coef: 0.5470 - accuracy: 0.9866 - mse: 0.0072\n",
            "Epoch 131: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0272 - dice_coef: 0.5470 - accuracy: 0.9866 - mse: 0.0072 - val_loss: 0.0270 - val_dice_coef: 0.5643 - val_accuracy: 0.9893 - val_mse: 0.0079\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0309 - dice_coef: 0.5106 - accuracy: 0.9859 - mse: 0.0079\n",
            "Epoch 132: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0309 - dice_coef: 0.5106 - accuracy: 0.9859 - mse: 0.0079 - val_loss: 0.0251 - val_dice_coef: 0.5722 - val_accuracy: 0.9901 - val_mse: 0.0073\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0256 - dice_coef: 0.5540 - accuracy: 0.9873 - mse: 0.0068\n",
            "Epoch 133: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0256 - dice_coef: 0.5540 - accuracy: 0.9873 - mse: 0.0068 - val_loss: 0.0242 - val_dice_coef: 0.5758 - val_accuracy: 0.9906 - val_mse: 0.0069\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0297 - dice_coef: 0.5163 - accuracy: 0.9857 - mse: 0.0079\n",
            "Epoch 134: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0297 - dice_coef: 0.5163 - accuracy: 0.9857 - mse: 0.0079 - val_loss: 0.0252 - val_dice_coef: 0.5574 - val_accuracy: 0.9906 - val_mse: 0.0070\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0279 - dice_coef: 0.5727 - accuracy: 0.9864 - mse: 0.0074\n",
            "Epoch 135: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0279 - dice_coef: 0.5727 - accuracy: 0.9864 - mse: 0.0074 - val_loss: 0.0229 - val_dice_coef: 0.5934 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - dice_coef: 0.5394 - accuracy: 0.9844 - mse: 0.0088\n",
            "Epoch 136: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0336 - dice_coef: 0.5394 - accuracy: 0.9844 - mse: 0.0088 - val_loss: 0.0243 - val_dice_coef: 0.5520 - val_accuracy: 0.9902 - val_mse: 0.0072\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0335 - dice_coef: 0.5258 - accuracy: 0.9840 - mse: 0.0089\n",
            "Epoch 137: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0335 - dice_coef: 0.5258 - accuracy: 0.9840 - mse: 0.0089 - val_loss: 0.0272 - val_dice_coef: 0.5386 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0302 - dice_coef: 0.5143 - accuracy: 0.9855 - mse: 0.0081\n",
            "Epoch 138: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0302 - dice_coef: 0.5143 - accuracy: 0.9855 - mse: 0.0081 - val_loss: 0.0232 - val_dice_coef: 0.5819 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0289 - dice_coef: 0.5055 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 139: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0289 - dice_coef: 0.5055 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0362 - val_dice_coef: 0.4563 - val_accuracy: 0.9884 - val_mse: 0.0090\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0281 - dice_coef: 0.5126 - accuracy: 0.9864 - mse: 0.0074\n",
            "Epoch 140: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0281 - dice_coef: 0.5126 - accuracy: 0.9864 - mse: 0.0074 - val_loss: 0.0313 - val_dice_coef: 0.5169 - val_accuracy: 0.9885 - val_mse: 0.0086\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0276 - dice_coef: 0.5248 - accuracy: 0.9871 - mse: 0.0071\n",
            "Epoch 141: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0276 - dice_coef: 0.5248 - accuracy: 0.9871 - mse: 0.0071 - val_loss: 0.0260 - val_dice_coef: 0.5742 - val_accuracy: 0.9899 - val_mse: 0.0074\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0264 - dice_coef: 0.5020 - accuracy: 0.9873 - mse: 0.0070\n",
            "Epoch 142: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.0264 - dice_coef: 0.5020 - accuracy: 0.9873 - mse: 0.0070 - val_loss: 0.0288 - val_dice_coef: 0.5395 - val_accuracy: 0.9892 - val_mse: 0.0080\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.5664 - accuracy: 0.9873 - mse: 0.0068\n",
            "Epoch 143: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.0261 - dice_coef: 0.5664 - accuracy: 0.9873 - mse: 0.0068 - val_loss: 0.0230 - val_dice_coef: 0.6033 - val_accuracy: 0.9906 - val_mse: 0.0068\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0273 - dice_coef: 0.5350 - accuracy: 0.9867 - mse: 0.0073\n",
            "Epoch 144: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0273 - dice_coef: 0.5350 - accuracy: 0.9867 - mse: 0.0073 - val_loss: 0.0252 - val_dice_coef: 0.5736 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0257 - dice_coef: 0.4946 - accuracy: 0.9877 - mse: 0.0068\n",
            "Epoch 145: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 12s 126ms/step - loss: 0.0257 - dice_coef: 0.4946 - accuracy: 0.9877 - mse: 0.0068 - val_loss: 0.0236 - val_dice_coef: 0.5811 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0254 - dice_coef: 0.5365 - accuracy: 0.9875 - mse: 0.0068\n",
            "Epoch 146: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0254 - dice_coef: 0.5365 - accuracy: 0.9875 - mse: 0.0068 - val_loss: 0.0227 - val_dice_coef: 0.5921 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0303 - dice_coef: 0.5188 - accuracy: 0.9852 - mse: 0.0081\n",
            "Epoch 147: val_dice_coef did not improve from 0.60538\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0303 - dice_coef: 0.5188 - accuracy: 0.9852 - mse: 0.0081 - val_loss: 0.0254 - val_dice_coef: 0.5750 - val_accuracy: 0.9903 - val_mse: 0.0072\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0240 - dice_coef: 0.5254 - accuracy: 0.9881 - mse: 0.0064\n",
            "Epoch 148: val_dice_coef improved from 0.60538 to 0.60984, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0240 - dice_coef: 0.5254 - accuracy: 0.9881 - mse: 0.0064 - val_loss: 0.0226 - val_dice_coef: 0.6098 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0279 - dice_coef: 0.5631 - accuracy: 0.9859 - mse: 0.0075\n",
            "Epoch 149: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0279 - dice_coef: 0.5631 - accuracy: 0.9859 - mse: 0.0075 - val_loss: 0.0227 - val_dice_coef: 0.6044 - val_accuracy: 0.9906 - val_mse: 0.0068\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0249 - dice_coef: 0.5227 - accuracy: 0.9879 - mse: 0.0066\n",
            "Epoch 150: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0249 - dice_coef: 0.5227 - accuracy: 0.9879 - mse: 0.0066 - val_loss: 0.0224 - val_dice_coef: 0.5884 - val_accuracy: 0.9911 - val_mse: 0.0065\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0318 - dice_coef: 0.4870 - accuracy: 0.9861 - mse: 0.0081\n",
            "Epoch 151: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0318 - dice_coef: 0.4870 - accuracy: 0.9861 - mse: 0.0081 - val_loss: 0.0282 - val_dice_coef: 0.5563 - val_accuracy: 0.9884 - val_mse: 0.0083\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0270 - dice_coef: 0.4970 - accuracy: 0.9872 - mse: 0.0071\n",
            "Epoch 152: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0270 - dice_coef: 0.4970 - accuracy: 0.9872 - mse: 0.0071 - val_loss: 0.0237 - val_dice_coef: 0.5817 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0299 - dice_coef: 0.5267 - accuracy: 0.9856 - mse: 0.0080\n",
            "Epoch 153: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0299 - dice_coef: 0.5267 - accuracy: 0.9856 - mse: 0.0080 - val_loss: 0.0235 - val_dice_coef: 0.5923 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0246 - dice_coef: 0.5324 - accuracy: 0.9881 - mse: 0.0066\n",
            "Epoch 154: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0246 - dice_coef: 0.5324 - accuracy: 0.9881 - mse: 0.0066 - val_loss: 0.0229 - val_dice_coef: 0.5824 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0271 - dice_coef: 0.5380 - accuracy: 0.9870 - mse: 0.0071\n",
            "Epoch 155: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.0271 - dice_coef: 0.5380 - accuracy: 0.9870 - mse: 0.0071 - val_loss: 0.0231 - val_dice_coef: 0.5870 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0269 - dice_coef: 0.5612 - accuracy: 0.9870 - mse: 0.0071\n",
            "Epoch 156: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0269 - dice_coef: 0.5612 - accuracy: 0.9870 - mse: 0.0071 - val_loss: 0.0253 - val_dice_coef: 0.5634 - val_accuracy: 0.9901 - val_mse: 0.0073\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0299 - dice_coef: 0.5495 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 157: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.0299 - dice_coef: 0.5495 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0332 - val_dice_coef: 0.5126 - val_accuracy: 0.9883 - val_mse: 0.0089\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0246 - dice_coef: 0.4914 - accuracy: 0.9883 - mse: 0.0065\n",
            "Epoch 158: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0246 - dice_coef: 0.4914 - accuracy: 0.9883 - mse: 0.0065 - val_loss: 0.0237 - val_dice_coef: 0.5834 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0258 - dice_coef: 0.5392 - accuracy: 0.9874 - mse: 0.0068\n",
            "Epoch 159: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0258 - dice_coef: 0.5392 - accuracy: 0.9874 - mse: 0.0068 - val_loss: 0.0272 - val_dice_coef: 0.5788 - val_accuracy: 0.9891 - val_mse: 0.0079\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.5157 - accuracy: 0.9869 - mse: 0.0071\n",
            "Epoch 160: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0261 - dice_coef: 0.5157 - accuracy: 0.9869 - mse: 0.0071 - val_loss: 0.0285 - val_dice_coef: 0.5513 - val_accuracy: 0.9890 - val_mse: 0.0082\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0361 - dice_coef: 0.5072 - accuracy: 0.9833 - mse: 0.0094\n",
            "Epoch 161: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0361 - dice_coef: 0.5072 - accuracy: 0.9833 - mse: 0.0094 - val_loss: 0.0355 - val_dice_coef: 0.5159 - val_accuracy: 0.9860 - val_mse: 0.0102\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0281 - dice_coef: 0.5092 - accuracy: 0.9871 - mse: 0.0072\n",
            "Epoch 162: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0281 - dice_coef: 0.5092 - accuracy: 0.9871 - mse: 0.0072 - val_loss: 0.0266 - val_dice_coef: 0.5516 - val_accuracy: 0.9896 - val_mse: 0.0076\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0307 - dice_coef: 0.5422 - accuracy: 0.9851 - mse: 0.0083\n",
            "Epoch 163: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0307 - dice_coef: 0.5422 - accuracy: 0.9851 - mse: 0.0083 - val_loss: 0.0247 - val_dice_coef: 0.5901 - val_accuracy: 0.9904 - val_mse: 0.0071\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0223 - dice_coef: 0.5166 - accuracy: 0.9890 - mse: 0.0060\n",
            "Epoch 164: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0223 - dice_coef: 0.5166 - accuracy: 0.9890 - mse: 0.0060 - val_loss: 0.0283 - val_dice_coef: 0.5545 - val_accuracy: 0.9890 - val_mse: 0.0081\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.5242 - accuracy: 0.9873 - mse: 0.0069\n",
            "Epoch 165: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0261 - dice_coef: 0.5242 - accuracy: 0.9873 - mse: 0.0069 - val_loss: 0.0259 - val_dice_coef: 0.5623 - val_accuracy: 0.9903 - val_mse: 0.0072\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0230 - dice_coef: 0.5160 - accuracy: 0.9886 - mse: 0.0060\n",
            "Epoch 166: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.0230 - dice_coef: 0.5160 - accuracy: 0.9886 - mse: 0.0060 - val_loss: 0.0235 - val_dice_coef: 0.5818 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - dice_coef: 0.5439 - accuracy: 0.9876 - mse: 0.0066\n",
            "Epoch 167: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.0251 - dice_coef: 0.5439 - accuracy: 0.9876 - mse: 0.0066 - val_loss: 0.0264 - val_dice_coef: 0.5887 - val_accuracy: 0.9894 - val_mse: 0.0077\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0246 - dice_coef: 0.5487 - accuracy: 0.9877 - mse: 0.0066\n",
            "Epoch 168: val_dice_coef did not improve from 0.60984\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0246 - dice_coef: 0.5487 - accuracy: 0.9877 - mse: 0.0066 - val_loss: 0.0224 - val_dice_coef: 0.6003 - val_accuracy: 0.9909 - val_mse: 0.0066\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0236 - dice_coef: 0.5380 - accuracy: 0.9882 - mse: 0.0062\n",
            "Epoch 169: val_dice_coef improved from 0.60984 to 0.62458, saving model to Output/unetAM_tall/unetAM_tall.hdf5\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.0236 - dice_coef: 0.5380 - accuracy: 0.9882 - mse: 0.0062 - val_loss: 0.0213 - val_dice_coef: 0.6246 - val_accuracy: 0.9912 - val_mse: 0.0063\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.5002 - accuracy: 0.9850 - mse: 0.0084\n",
            "Epoch 170: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0322 - dice_coef: 0.5002 - accuracy: 0.9850 - mse: 0.0084 - val_loss: 0.0280 - val_dice_coef: 0.5321 - val_accuracy: 0.9889 - val_mse: 0.0081\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0274 - dice_coef: 0.4909 - accuracy: 0.9867 - mse: 0.0072\n",
            "Epoch 171: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0274 - dice_coef: 0.4909 - accuracy: 0.9867 - mse: 0.0072 - val_loss: 0.0259 - val_dice_coef: 0.5817 - val_accuracy: 0.9899 - val_mse: 0.0074\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0285 - dice_coef: 0.5269 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 172: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0285 - dice_coef: 0.5269 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0223 - val_dice_coef: 0.5957 - val_accuracy: 0.9910 - val_mse: 0.0066\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0239 - dice_coef: 0.5522 - accuracy: 0.9880 - mse: 0.0064\n",
            "Epoch 173: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0239 - dice_coef: 0.5522 - accuracy: 0.9880 - mse: 0.0064 - val_loss: 0.0272 - val_dice_coef: 0.5775 - val_accuracy: 0.9894 - val_mse: 0.0078\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0266 - dice_coef: 0.5226 - accuracy: 0.9872 - mse: 0.0070\n",
            "Epoch 174: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.0266 - dice_coef: 0.5226 - accuracy: 0.9872 - mse: 0.0070 - val_loss: 0.0243 - val_dice_coef: 0.5685 - val_accuracy: 0.9902 - val_mse: 0.0072\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0337 - dice_coef: 0.4781 - accuracy: 0.9852 - mse: 0.0087\n",
            "Epoch 175: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0337 - dice_coef: 0.4781 - accuracy: 0.9852 - mse: 0.0087 - val_loss: 0.0293 - val_dice_coef: 0.5268 - val_accuracy: 0.9891 - val_mse: 0.0083\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - dice_coef: 0.5198 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 176: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0291 - dice_coef: 0.5198 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0322 - val_dice_coef: 0.5527 - val_accuracy: 0.9876 - val_mse: 0.0092\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0324 - dice_coef: 0.5148 - accuracy: 0.9852 - mse: 0.0083\n",
            "Epoch 177: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0324 - dice_coef: 0.5148 - accuracy: 0.9852 - mse: 0.0083 - val_loss: 0.0243 - val_dice_coef: 0.5842 - val_accuracy: 0.9902 - val_mse: 0.0071\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0267 - dice_coef: 0.5438 - accuracy: 0.9866 - mse: 0.0072\n",
            "Epoch 178: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.0267 - dice_coef: 0.5438 - accuracy: 0.9866 - mse: 0.0072 - val_loss: 0.0240 - val_dice_coef: 0.5713 - val_accuracy: 0.9906 - val_mse: 0.0069\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0258 - dice_coef: 0.5017 - accuracy: 0.9878 - mse: 0.0067\n",
            "Epoch 179: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.0258 - dice_coef: 0.5017 - accuracy: 0.9878 - mse: 0.0067 - val_loss: 0.0303 - val_dice_coef: 0.4962 - val_accuracy: 0.9891 - val_mse: 0.0083\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0261 - dice_coef: 0.5167 - accuracy: 0.9871 - mse: 0.0070\n",
            "Epoch 180: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.0261 - dice_coef: 0.5167 - accuracy: 0.9871 - mse: 0.0070 - val_loss: 0.0240 - val_dice_coef: 0.5912 - val_accuracy: 0.9904 - val_mse: 0.0070\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0284 - dice_coef: 0.5283 - accuracy: 0.9862 - mse: 0.0075\n",
            "Epoch 181: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0284 - dice_coef: 0.5283 - accuracy: 0.9862 - mse: 0.0075 - val_loss: 0.0227 - val_dice_coef: 0.6017 - val_accuracy: 0.9909 - val_mse: 0.0067\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - dice_coef: 0.5230 - accuracy: 0.9854 - mse: 0.0078\n",
            "Epoch 182: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0287 - dice_coef: 0.5230 - accuracy: 0.9854 - mse: 0.0078 - val_loss: 0.0222 - val_dice_coef: 0.6135 - val_accuracy: 0.9909 - val_mse: 0.0066\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - dice_coef: 0.5465 - accuracy: 0.9879 - mse: 0.0066\n",
            "Epoch 183: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0245 - dice_coef: 0.5465 - accuracy: 0.9879 - mse: 0.0066 - val_loss: 0.0255 - val_dice_coef: 0.5684 - val_accuracy: 0.9899 - val_mse: 0.0074\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0228 - dice_coef: 0.5442 - accuracy: 0.9885 - mse: 0.0060\n",
            "Epoch 184: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0228 - dice_coef: 0.5442 - accuracy: 0.9885 - mse: 0.0060 - val_loss: 0.0231 - val_dice_coef: 0.6160 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0248 - dice_coef: 0.5370 - accuracy: 0.9875 - mse: 0.0066\n",
            "Epoch 185: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0248 - dice_coef: 0.5370 - accuracy: 0.9875 - mse: 0.0066 - val_loss: 0.0235 - val_dice_coef: 0.6074 - val_accuracy: 0.9904 - val_mse: 0.0069\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0219 - dice_coef: 0.5347 - accuracy: 0.9892 - mse: 0.0058\n",
            "Epoch 186: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0219 - dice_coef: 0.5347 - accuracy: 0.9892 - mse: 0.0058 - val_loss: 0.0236 - val_dice_coef: 0.5897 - val_accuracy: 0.9905 - val_mse: 0.0069\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0286 - dice_coef: 0.5729 - accuracy: 0.9858 - mse: 0.0077\n",
            "Epoch 187: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0286 - dice_coef: 0.5729 - accuracy: 0.9858 - mse: 0.0077 - val_loss: 0.0226 - val_dice_coef: 0.6192 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - dice_coef: 0.5558 - accuracy: 0.9880 - mse: 0.0064\n",
            "Epoch 188: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.0245 - dice_coef: 0.5558 - accuracy: 0.9880 - mse: 0.0064 - val_loss: 0.0252 - val_dice_coef: 0.5992 - val_accuracy: 0.9901 - val_mse: 0.0073\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0285 - dice_coef: 0.5331 - accuracy: 0.9861 - mse: 0.0076\n",
            "Epoch 189: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.0285 - dice_coef: 0.5331 - accuracy: 0.9861 - mse: 0.0076 - val_loss: 0.0246 - val_dice_coef: 0.5769 - val_accuracy: 0.9901 - val_mse: 0.0072\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0247 - dice_coef: 0.5081 - accuracy: 0.9881 - mse: 0.0065\n",
            "Epoch 190: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.0247 - dice_coef: 0.5081 - accuracy: 0.9881 - mse: 0.0065 - val_loss: 0.0231 - val_dice_coef: 0.5818 - val_accuracy: 0.9908 - val_mse: 0.0067\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0234 - dice_coef: 0.5045 - accuracy: 0.9884 - mse: 0.0063\n",
            "Epoch 191: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0234 - dice_coef: 0.5045 - accuracy: 0.9884 - mse: 0.0063 - val_loss: 0.0252 - val_dice_coef: 0.5872 - val_accuracy: 0.9899 - val_mse: 0.0074\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - dice_coef: 0.5040 - accuracy: 0.9846 - mse: 0.0086\n",
            "Epoch 192: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.0336 - dice_coef: 0.5040 - accuracy: 0.9846 - mse: 0.0086 - val_loss: 0.0257 - val_dice_coef: 0.5514 - val_accuracy: 0.9897 - val_mse: 0.0075\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - dice_coef: 0.5099 - accuracy: 0.9878 - mse: 0.0067\n",
            "Epoch 193: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0252 - dice_coef: 0.5099 - accuracy: 0.9878 - mse: 0.0067 - val_loss: 0.0235 - val_dice_coef: 0.5984 - val_accuracy: 0.9909 - val_mse: 0.0068\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0282 - dice_coef: 0.5368 - accuracy: 0.9862 - mse: 0.0075\n",
            "Epoch 194: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0282 - dice_coef: 0.5368 - accuracy: 0.9862 - mse: 0.0075 - val_loss: 0.0251 - val_dice_coef: 0.6044 - val_accuracy: 0.9901 - val_mse: 0.0073\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - dice_coef: 0.5540 - accuracy: 0.9873 - mse: 0.0068\n",
            "Epoch 195: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0252 - dice_coef: 0.5540 - accuracy: 0.9873 - mse: 0.0068 - val_loss: 0.0285 - val_dice_coef: 0.5687 - val_accuracy: 0.9887 - val_mse: 0.0083\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0227 - dice_coef: 0.5619 - accuracy: 0.9886 - mse: 0.0060\n",
            "Epoch 196: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0227 - dice_coef: 0.5619 - accuracy: 0.9886 - mse: 0.0060 - val_loss: 0.0219 - val_dice_coef: 0.6216 - val_accuracy: 0.9910 - val_mse: 0.0065\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0274 - dice_coef: 0.5347 - accuracy: 0.9865 - mse: 0.0073\n",
            "Epoch 197: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.0274 - dice_coef: 0.5347 - accuracy: 0.9865 - mse: 0.0073 - val_loss: 0.0268 - val_dice_coef: 0.5295 - val_accuracy: 0.9897 - val_mse: 0.0076\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0237 - dice_coef: 0.5177 - accuracy: 0.9885 - mse: 0.0062\n",
            "Epoch 198: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0237 - dice_coef: 0.5177 - accuracy: 0.9885 - mse: 0.0062 - val_loss: 0.0224 - val_dice_coef: 0.6022 - val_accuracy: 0.9910 - val_mse: 0.0066\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0246 - dice_coef: 0.5894 - accuracy: 0.9875 - mse: 0.0066\n",
            "Epoch 199: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0246 - dice_coef: 0.5894 - accuracy: 0.9875 - mse: 0.0066 - val_loss: 0.0221 - val_dice_coef: 0.6216 - val_accuracy: 0.9911 - val_mse: 0.0065\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0249 - dice_coef: 0.5029 - accuracy: 0.9882 - mse: 0.0065\n",
            "Epoch 200: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0249 - dice_coef: 0.5029 - accuracy: 0.9882 - mse: 0.0065 - val_loss: 0.0252 - val_dice_coef: 0.5888 - val_accuracy: 0.9904 - val_mse: 0.0071\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0268 - dice_coef: 0.5258 - accuracy: 0.9861 - mse: 0.0073\n",
            "Epoch 201: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.0268 - dice_coef: 0.5258 - accuracy: 0.9861 - mse: 0.0073 - val_loss: 0.0229 - val_dice_coef: 0.6104 - val_accuracy: 0.9907 - val_mse: 0.0068\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0241 - dice_coef: 0.5583 - accuracy: 0.9882 - mse: 0.0064\n",
            "Epoch 202: val_dice_coef did not improve from 0.62458\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0241 - dice_coef: 0.5583 - accuracy: 0.9882 - mse: 0.0064 - val_loss: 0.0228 - val_dice_coef: 0.6203 - val_accuracy: 0.9906 - val_mse: 0.0068\n",
            "Total time to train: 2228.6041197776794\n",
            "cp: cannot create directory 'MyDrive/sv_para/': No such file or directory\n",
            "cp: cannot create directory 'MyDrive/sv_para/': No such file or directory\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uNetAM_tall = UNetAM(input_size=(tileSize,tileSize,3), batch_size=1)\n",
        "# model_amu_tall = load_model('Output/unetAM_tall/unetAM_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "\n",
        "callbacks = [ EarlyStopping(patience=200, monitor=\"val_dice_coef\"),\n",
        "                 ModelCheckpoint(os.path.join(\"Output/unetAM_tall\", \"unetAM_tall\"+\".hdf5\"),\n",
        "                 monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max') ]\n",
        "\n",
        "train_rgb_tall = TrainGenerator(1, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "uNetAM_tall = train(uNetAM_tall, callbacks, train_rgb_tall, validation_df, \"unetAM_tall\", batch_size=1, epochs=500, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gGjJcklKztE"
      },
      "source": [
        "### **ResNet50SegNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOgoRUU1E-qU",
        "outputId": "b2a39db4-be0b-4fa8-915a-023d45e7674f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1465 - dice_coef: 0.0185 - accuracy: 0.9731 - mse: 0.0254\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.01829, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 220s 2s/step - loss: 0.1465 - dice_coef: 0.0185 - accuracy: 0.9731 - mse: 0.0254 - val_loss: 0.1021 - val_dice_coef: 0.0183 - val_accuracy: 0.9796 - val_mse: 0.0202\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1277 - dice_coef: 0.0212 - accuracy: 0.9756 - mse: 0.0227\n",
            "Epoch 2: val_dice_coef improved from 0.01829 to 0.02423, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.1277 - dice_coef: 0.0212 - accuracy: 0.9756 - mse: 0.0227 - val_loss: 0.1081 - val_dice_coef: 0.0242 - val_accuracy: 0.9796 - val_mse: 0.0207\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1020 - dice_coef: 0.0441 - accuracy: 0.9757 - mse: 0.0207\n",
            "Epoch 3: val_dice_coef improved from 0.02423 to 0.05983, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.1020 - dice_coef: 0.0441 - accuracy: 0.9757 - mse: 0.0207 - val_loss: 0.0933 - val_dice_coef: 0.0598 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0777 - dice_coef: 0.1390 - accuracy: 0.9761 - mse: 0.0179\n",
            "Epoch 4: val_dice_coef improved from 0.05983 to 0.23221, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 183s 2s/step - loss: 0.0777 - dice_coef: 0.1390 - accuracy: 0.9761 - mse: 0.0179 - val_loss: 0.0644 - val_dice_coef: 0.2322 - val_accuracy: 0.9795 - val_mse: 0.0169\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0633 - dice_coef: 0.2971 - accuracy: 0.9771 - mse: 0.0156\n",
            "Epoch 5: val_dice_coef improved from 0.23221 to 0.36056, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.0633 - dice_coef: 0.2971 - accuracy: 0.9771 - mse: 0.0156 - val_loss: 0.0436 - val_dice_coef: 0.3606 - val_accuracy: 0.9847 - val_mse: 0.0117\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0492 - dice_coef: 0.3760 - accuracy: 0.9811 - mse: 0.0122\n",
            "Epoch 6: val_dice_coef did not improve from 0.36056\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0492 - dice_coef: 0.3760 - accuracy: 0.9811 - mse: 0.0122 - val_loss: 0.0518 - val_dice_coef: 0.2602 - val_accuracy: 0.9837 - val_mse: 0.0129\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0496 - dice_coef: 0.4241 - accuracy: 0.9806 - mse: 0.0123\n",
            "Epoch 7: val_dice_coef improved from 0.36056 to 0.40739, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 183s 2s/step - loss: 0.0496 - dice_coef: 0.4241 - accuracy: 0.9806 - mse: 0.0123 - val_loss: 0.0377 - val_dice_coef: 0.4074 - val_accuracy: 0.9860 - val_mse: 0.0106\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0397 - dice_coef: 0.4825 - accuracy: 0.9832 - mse: 0.0102\n",
            "Epoch 8: val_dice_coef improved from 0.40739 to 0.43700, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 184s 2s/step - loss: 0.0397 - dice_coef: 0.4825 - accuracy: 0.9832 - mse: 0.0102 - val_loss: 0.0381 - val_dice_coef: 0.4370 - val_accuracy: 0.9862 - val_mse: 0.0104\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0380 - dice_coef: 0.5048 - accuracy: 0.9837 - mse: 0.0098\n",
            "Epoch 9: val_dice_coef did not improve from 0.43700\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0380 - dice_coef: 0.5048 - accuracy: 0.9837 - mse: 0.0098 - val_loss: 0.0379 - val_dice_coef: 0.4246 - val_accuracy: 0.9860 - val_mse: 0.0103\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0399 - dice_coef: 0.5040 - accuracy: 0.9830 - mse: 0.0102\n",
            "Epoch 10: val_dice_coef did not improve from 0.43700\n",
            "100/100 [==============================] - 178s 2s/step - loss: 0.0399 - dice_coef: 0.5040 - accuracy: 0.9830 - mse: 0.0102 - val_loss: 0.0350 - val_dice_coef: 0.4206 - val_accuracy: 0.9872 - val_mse: 0.0096\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0413 - dice_coef: 0.4833 - accuracy: 0.9827 - mse: 0.0106\n",
            "Epoch 11: val_dice_coef improved from 0.43700 to 0.45761, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 185s 2s/step - loss: 0.0413 - dice_coef: 0.4833 - accuracy: 0.9827 - mse: 0.0106 - val_loss: 0.0345 - val_dice_coef: 0.4576 - val_accuracy: 0.9865 - val_mse: 0.0098\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.5559 - accuracy: 0.9854 - mse: 0.0085\n",
            "Epoch 12: val_dice_coef improved from 0.45761 to 0.50732, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.0322 - dice_coef: 0.5559 - accuracy: 0.9854 - mse: 0.0085 - val_loss: 0.0307 - val_dice_coef: 0.5073 - val_accuracy: 0.9880 - val_mse: 0.0088\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0332 - dice_coef: 0.5617 - accuracy: 0.9850 - mse: 0.0087\n",
            "Epoch 13: val_dice_coef did not improve from 0.50732\n",
            "100/100 [==============================] - 177s 2s/step - loss: 0.0332 - dice_coef: 0.5617 - accuracy: 0.9850 - mse: 0.0087 - val_loss: 0.0389 - val_dice_coef: 0.4020 - val_accuracy: 0.9859 - val_mse: 0.0107\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - dice_coef: 0.5620 - accuracy: 0.9848 - mse: 0.0088\n",
            "Epoch 14: val_dice_coef did not improve from 0.50732\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.0336 - dice_coef: 0.5620 - accuracy: 0.9848 - mse: 0.0088 - val_loss: 0.0353 - val_dice_coef: 0.4720 - val_accuracy: 0.9864 - val_mse: 0.0100\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323 - dice_coef: 0.5653 - accuracy: 0.9854 - mse: 0.0084\n",
            "Epoch 15: val_dice_coef did not improve from 0.50732\n",
            "100/100 [==============================] - 177s 2s/step - loss: 0.0323 - dice_coef: 0.5653 - accuracy: 0.9854 - mse: 0.0084 - val_loss: 0.0359 - val_dice_coef: 0.4921 - val_accuracy: 0.9863 - val_mse: 0.0102\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0297 - dice_coef: 0.5904 - accuracy: 0.9860 - mse: 0.0079\n",
            "Epoch 16: val_dice_coef improved from 0.50732 to 0.52384, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.0297 - dice_coef: 0.5904 - accuracy: 0.9860 - mse: 0.0079 - val_loss: 0.0351 - val_dice_coef: 0.5238 - val_accuracy: 0.9858 - val_mse: 0.0104\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0367 - dice_coef: 0.5410 - accuracy: 0.9837 - mse: 0.0096\n",
            "Epoch 17: val_dice_coef improved from 0.52384 to 0.53213, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.0367 - dice_coef: 0.5410 - accuracy: 0.9837 - mse: 0.0096 - val_loss: 0.0284 - val_dice_coef: 0.5321 - val_accuracy: 0.9886 - val_mse: 0.0083\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0322 - dice_coef: 0.5918 - accuracy: 0.9848 - mse: 0.0086\n",
            "Epoch 18: val_dice_coef improved from 0.53213 to 0.53758, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.0322 - dice_coef: 0.5918 - accuracy: 0.9848 - mse: 0.0086 - val_loss: 0.0278 - val_dice_coef: 0.5376 - val_accuracy: 0.9888 - val_mse: 0.0082\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0343 - dice_coef: 0.5663 - accuracy: 0.9846 - mse: 0.0089\n",
            "Epoch 19: val_dice_coef improved from 0.53758 to 0.54710, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 183s 2s/step - loss: 0.0343 - dice_coef: 0.5663 - accuracy: 0.9846 - mse: 0.0089 - val_loss: 0.0270 - val_dice_coef: 0.5471 - val_accuracy: 0.9892 - val_mse: 0.0079\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0296 - dice_coef: 0.5980 - accuracy: 0.9860 - mse: 0.0078\n",
            "Epoch 20: val_dice_coef improved from 0.54710 to 0.55368, saving model to Output/resNet_tall/resNet.hdf5\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.0296 - dice_coef: 0.5980 - accuracy: 0.9860 - mse: 0.0078 - val_loss: 0.0272 - val_dice_coef: 0.5537 - val_accuracy: 0.9893 - val_mse: 0.0079\n",
            "Total time to train: 3654.361613035202\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "resNet_tall = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "# res50 = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "# res50.load_weights('Output/resNet_tall/resNet.hdf5')\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resNet_tall\", \"resNet.hdf5\"), monitor='val_dice_coef', save_weights_only=True, mode='max', verbose=1, save_best_only=True)]\n",
        "# callbacks = []\n",
        "train_rgb_tall = TrainGenerator(4, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "resNet_tall = train(resNet_tall, callbacks, train_rgb_tall, validation_df, \"resNet_tall\", epochs=20, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OXmce0xKZ7D"
      },
      "source": [
        "### **FCN32-VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uso_zwirJ8Ir",
        "outputId": "d053429e-fd03-4060-8b82-f994af4f6d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4048 - dice_coef: 0.0358 - accuracy: 0.8626 - mse: 0.1241\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.02368, saving model to Output/fcn32_tall/fcn32_tall.hdf5\n",
            "100/100 [==============================] - 97s 850ms/step - loss: 0.4048 - dice_coef: 0.0358 - accuracy: 0.8626 - mse: 0.1241 - val_loss: 0.1212 - val_dice_coef: 0.0237 - val_accuracy: 0.9759 - val_mse: 0.0248\n",
            "Epoch 2/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1197 - dice_coef: 0.0233 - accuracy: 0.9744 - mse: 0.0230\n",
            "Epoch 2: val_dice_coef improved from 0.02368 to 0.02370, saving model to Output/fcn32_tall/fcn32_tall.hdf5\n",
            "100/100 [==============================] - 92s 921ms/step - loss: 0.1197 - dice_coef: 0.0233 - accuracy: 0.9744 - mse: 0.0230 - val_loss: 0.1149 - val_dice_coef: 0.0237 - val_accuracy: 0.9795 - val_mse: 0.0220\n",
            "Epoch 3/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1150 - dice_coef: 0.0215 - accuracy: 0.9756 - mse: 0.0217\n",
            "Epoch 3: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.1150 - dice_coef: 0.0215 - accuracy: 0.9756 - mse: 0.0217 - val_loss: 0.1038 - val_dice_coef: 0.0153 - val_accuracy: 0.9796 - val_mse: 0.0204\n",
            "Epoch 4/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1122 - dice_coef: 0.0206 - accuracy: 0.9760 - mse: 0.0212\n",
            "Epoch 4: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1122 - dice_coef: 0.0206 - accuracy: 0.9760 - mse: 0.0212 - val_loss: 0.1032 - val_dice_coef: 0.0185 - val_accuracy: 0.9796 - val_mse: 0.0204\n",
            "Epoch 5/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1148 - dice_coef: 0.0215 - accuracy: 0.9747 - mse: 0.0221\n",
            "Epoch 5: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1148 - dice_coef: 0.0215 - accuracy: 0.9747 - mse: 0.0221 - val_loss: 0.1022 - val_dice_coef: 0.0157 - val_accuracy: 0.9796 - val_mse: 0.0202\n",
            "Epoch 6/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1078 - dice_coef: 0.0198 - accuracy: 0.9765 - mse: 0.0204\n",
            "Epoch 6: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1078 - dice_coef: 0.0198 - accuracy: 0.9765 - mse: 0.0204 - val_loss: 0.1021 - val_dice_coef: 0.0147 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 7/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1130 - dice_coef: 0.0219 - accuracy: 0.9745 - mse: 0.0221\n",
            "Epoch 7: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.1130 - dice_coef: 0.0219 - accuracy: 0.9745 - mse: 0.0221 - val_loss: 0.1028 - val_dice_coef: 0.0132 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 8/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1081 - dice_coef: 0.0207 - accuracy: 0.9757 - mse: 0.0210\n",
            "Epoch 8: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1081 - dice_coef: 0.0207 - accuracy: 0.9757 - mse: 0.0210 - val_loss: 0.1041 - val_dice_coef: 0.0120 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 9/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1084 - dice_coef: 0.0199 - accuracy: 0.9757 - mse: 0.0210\n",
            "Epoch 9: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1084 - dice_coef: 0.0199 - accuracy: 0.9757 - mse: 0.0210 - val_loss: 0.1007 - val_dice_coef: 0.0183 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 10/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1138 - dice_coef: 0.0215 - accuracy: 0.9743 - mse: 0.0222\n",
            "Epoch 10: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1138 - dice_coef: 0.0215 - accuracy: 0.9743 - mse: 0.0222 - val_loss: 0.1080 - val_dice_coef: 0.0233 - val_accuracy: 0.9796 - val_mse: 0.0206\n",
            "Epoch 11/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1100 - dice_coef: 0.0205 - accuracy: 0.9752 - mse: 0.0214\n",
            "Epoch 11: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1100 - dice_coef: 0.0205 - accuracy: 0.9752 - mse: 0.0214 - val_loss: 0.1046 - val_dice_coef: 0.0113 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 12/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1043 - dice_coef: 0.0198 - accuracy: 0.9767 - mse: 0.0201\n",
            "Epoch 12: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1043 - dice_coef: 0.0198 - accuracy: 0.9767 - mse: 0.0201 - val_loss: 0.1004 - val_dice_coef: 0.0179 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 13/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1077 - dice_coef: 0.0197 - accuracy: 0.9759 - mse: 0.0208\n",
            "Epoch 13: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1077 - dice_coef: 0.0197 - accuracy: 0.9759 - mse: 0.0208 - val_loss: 0.1001 - val_dice_coef: 0.0170 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 14/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1095 - dice_coef: 0.0207 - accuracy: 0.9754 - mse: 0.0213\n",
            "Epoch 14: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1095 - dice_coef: 0.0207 - accuracy: 0.9754 - mse: 0.0213 - val_loss: 0.1008 - val_dice_coef: 0.0144 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 15/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1074 - dice_coef: 0.0201 - accuracy: 0.9758 - mse: 0.0208\n",
            "Epoch 15: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.1074 - dice_coef: 0.0201 - accuracy: 0.9758 - mse: 0.0208 - val_loss: 0.0999 - val_dice_coef: 0.0178 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 16/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1097 - dice_coef: 0.0192 - accuracy: 0.9757 - mse: 0.0210\n",
            "Epoch 16: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.1097 - dice_coef: 0.0192 - accuracy: 0.9757 - mse: 0.0210 - val_loss: 0.1025 - val_dice_coef: 0.0209 - val_accuracy: 0.9796 - val_mse: 0.0202\n",
            "Epoch 17/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1122 - dice_coef: 0.0218 - accuracy: 0.9744 - mse: 0.0220\n",
            "Epoch 17: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1122 - dice_coef: 0.0218 - accuracy: 0.9744 - mse: 0.0220 - val_loss: 0.1030 - val_dice_coef: 0.0118 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 18/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1117 - dice_coef: 0.0213 - accuracy: 0.9746 - mse: 0.0218\n",
            "Epoch 18: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1117 - dice_coef: 0.0213 - accuracy: 0.9746 - mse: 0.0218 - val_loss: 0.1018 - val_dice_coef: 0.0200 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 19/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1116 - dice_coef: 0.0216 - accuracy: 0.9746 - mse: 0.0219\n",
            "Epoch 19: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1116 - dice_coef: 0.0216 - accuracy: 0.9746 - mse: 0.0219 - val_loss: 0.1002 - val_dice_coef: 0.0148 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 20/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1083 - dice_coef: 0.0206 - accuracy: 0.9756 - mse: 0.0211\n",
            "Epoch 20: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1083 - dice_coef: 0.0206 - accuracy: 0.9756 - mse: 0.0211 - val_loss: 0.1002 - val_dice_coef: 0.0150 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 21/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1085 - dice_coef: 0.0206 - accuracy: 0.9752 - mse: 0.0213\n",
            "Epoch 21: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1085 - dice_coef: 0.0206 - accuracy: 0.9752 - mse: 0.0213 - val_loss: 0.1000 - val_dice_coef: 0.0181 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 22/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1116 - dice_coef: 0.0207 - accuracy: 0.9746 - mse: 0.0219\n",
            "Epoch 22: val_dice_coef did not improve from 0.02370\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1116 - dice_coef: 0.0207 - accuracy: 0.9746 - mse: 0.0219 - val_loss: 0.1022 - val_dice_coef: 0.0205 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 23/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1067 - dice_coef: 0.0209 - accuracy: 0.9758 - mse: 0.0208\n",
            "Epoch 23: val_dice_coef improved from 0.02370 to 0.02631, saving model to Output/fcn32_tall/fcn32_tall.hdf5\n",
            "100/100 [==============================] - 88s 878ms/step - loss: 0.1067 - dice_coef: 0.0209 - accuracy: 0.9758 - mse: 0.0208 - val_loss: 0.1177 - val_dice_coef: 0.0263 - val_accuracy: 0.9796 - val_mse: 0.0215\n",
            "Epoch 24/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1087 - dice_coef: 0.0200 - accuracy: 0.9755 - mse: 0.0211\n",
            "Epoch 24: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 72s 717ms/step - loss: 0.1087 - dice_coef: 0.0200 - accuracy: 0.9755 - mse: 0.0211 - val_loss: 0.1025 - val_dice_coef: 0.0206 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 25/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1082 - dice_coef: 0.0211 - accuracy: 0.9754 - mse: 0.0212\n",
            "Epoch 25: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1082 - dice_coef: 0.0211 - accuracy: 0.9754 - mse: 0.0212 - val_loss: 0.1004 - val_dice_coef: 0.0145 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 26/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1056 - dice_coef: 0.0206 - accuracy: 0.9759 - mse: 0.0207\n",
            "Epoch 26: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1056 - dice_coef: 0.0206 - accuracy: 0.9759 - mse: 0.0207 - val_loss: 0.1010 - val_dice_coef: 0.0134 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 27/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1098 - dice_coef: 0.0210 - accuracy: 0.9749 - mse: 0.0216\n",
            "Epoch 27: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1098 - dice_coef: 0.0210 - accuracy: 0.9749 - mse: 0.0216 - val_loss: 0.0996 - val_dice_coef: 0.0171 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 28/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1089 - dice_coef: 0.0210 - accuracy: 0.9753 - mse: 0.0213\n",
            "Epoch 28: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1089 - dice_coef: 0.0210 - accuracy: 0.9753 - mse: 0.0213 - val_loss: 0.1037 - val_dice_coef: 0.0111 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 29/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1095 - dice_coef: 0.0206 - accuracy: 0.9752 - mse: 0.0213\n",
            "Epoch 29: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1095 - dice_coef: 0.0206 - accuracy: 0.9752 - mse: 0.0213 - val_loss: 0.1001 - val_dice_coef: 0.0159 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 30/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1108 - dice_coef: 0.0210 - accuracy: 0.9745 - mse: 0.0219\n",
            "Epoch 30: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1108 - dice_coef: 0.0210 - accuracy: 0.9745 - mse: 0.0219 - val_loss: 0.1000 - val_dice_coef: 0.0180 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 31/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1112 - dice_coef: 0.0211 - accuracy: 0.9744 - mse: 0.0220\n",
            "Epoch 31: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1112 - dice_coef: 0.0211 - accuracy: 0.9744 - mse: 0.0220 - val_loss: 0.1002 - val_dice_coef: 0.0147 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 32/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1131 - dice_coef: 0.0208 - accuracy: 0.9744 - mse: 0.0221\n",
            "Epoch 32: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1131 - dice_coef: 0.0208 - accuracy: 0.9744 - mse: 0.0221 - val_loss: 0.1000 - val_dice_coef: 0.0165 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 33/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1048 - dice_coef: 0.0199 - accuracy: 0.9762 - mse: 0.0204\n",
            "Epoch 33: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1048 - dice_coef: 0.0199 - accuracy: 0.9762 - mse: 0.0204 - val_loss: 0.1013 - val_dice_coef: 0.0132 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 34/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1096 - dice_coef: 0.0202 - accuracy: 0.9750 - mse: 0.0215\n",
            "Epoch 34: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1096 - dice_coef: 0.0202 - accuracy: 0.9750 - mse: 0.0215 - val_loss: 0.0998 - val_dice_coef: 0.0179 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 35/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1072 - dice_coef: 0.0207 - accuracy: 0.9758 - mse: 0.0208\n",
            "Epoch 35: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1072 - dice_coef: 0.0207 - accuracy: 0.9758 - mse: 0.0208 - val_loss: 0.0998 - val_dice_coef: 0.0178 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 36/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1154 - dice_coef: 0.0215 - accuracy: 0.9735 - mse: 0.0228\n",
            "Epoch 36: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1154 - dice_coef: 0.0215 - accuracy: 0.9735 - mse: 0.0228 - val_loss: 0.1008 - val_dice_coef: 0.0197 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 37/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1046 - dice_coef: 0.0204 - accuracy: 0.9763 - mse: 0.0204\n",
            "Epoch 37: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1046 - dice_coef: 0.0204 - accuracy: 0.9763 - mse: 0.0204 - val_loss: 0.1011 - val_dice_coef: 0.0133 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 38/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1075 - dice_coef: 0.0199 - accuracy: 0.9756 - mse: 0.0210\n",
            "Epoch 38: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 72s 719ms/step - loss: 0.1075 - dice_coef: 0.0199 - accuracy: 0.9756 - mse: 0.0210 - val_loss: 0.1010 - val_dice_coef: 0.0197 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 39/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1099 - dice_coef: 0.0209 - accuracy: 0.9748 - mse: 0.0216\n",
            "Epoch 39: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1099 - dice_coef: 0.0209 - accuracy: 0.9748 - mse: 0.0216 - val_loss: 0.1110 - val_dice_coef: 0.0243 - val_accuracy: 0.9796 - val_mse: 0.0208\n",
            "Epoch 40/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1057 - dice_coef: 0.0194 - accuracy: 0.9763 - mse: 0.0204\n",
            "Epoch 40: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1057 - dice_coef: 0.0194 - accuracy: 0.9763 - mse: 0.0204 - val_loss: 0.1014 - val_dice_coef: 0.0198 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 41/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1126 - dice_coef: 0.0212 - accuracy: 0.9743 - mse: 0.0221\n",
            "Epoch 41: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1126 - dice_coef: 0.0212 - accuracy: 0.9743 - mse: 0.0221 - val_loss: 0.1003 - val_dice_coef: 0.0143 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 42/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1088 - dice_coef: 0.0202 - accuracy: 0.9753 - mse: 0.0212\n",
            "Epoch 42: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1088 - dice_coef: 0.0202 - accuracy: 0.9753 - mse: 0.0212 - val_loss: 0.0998 - val_dice_coef: 0.0184 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 43/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1068 - dice_coef: 0.0204 - accuracy: 0.9760 - mse: 0.0207\n",
            "Epoch 43: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1068 - dice_coef: 0.0204 - accuracy: 0.9760 - mse: 0.0207 - val_loss: 0.1015 - val_dice_coef: 0.0128 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 44/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1126 - dice_coef: 0.0212 - accuracy: 0.9743 - mse: 0.0221\n",
            "Epoch 44: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1126 - dice_coef: 0.0212 - accuracy: 0.9743 - mse: 0.0221 - val_loss: 0.1002 - val_dice_coef: 0.0145 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 45/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1126 - dice_coef: 0.0214 - accuracy: 0.9741 - mse: 0.0223\n",
            "Epoch 45: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1126 - dice_coef: 0.0214 - accuracy: 0.9741 - mse: 0.0223 - val_loss: 0.1000 - val_dice_coef: 0.0182 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 46/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1061 - dice_coef: 0.0208 - accuracy: 0.9758 - mse: 0.0208\n",
            "Epoch 46: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1061 - dice_coef: 0.0208 - accuracy: 0.9758 - mse: 0.0208 - val_loss: 0.1003 - val_dice_coef: 0.0147 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 47/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1097 - dice_coef: 0.0208 - accuracy: 0.9752 - mse: 0.0214\n",
            "Epoch 47: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1097 - dice_coef: 0.0208 - accuracy: 0.9752 - mse: 0.0214 - val_loss: 0.1001 - val_dice_coef: 0.0174 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 48/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1014 - dice_coef: 0.0193 - accuracy: 0.9771 - mse: 0.0196\n",
            "Epoch 48: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 712ms/step - loss: 0.1014 - dice_coef: 0.0193 - accuracy: 0.9771 - mse: 0.0196 - val_loss: 0.1008 - val_dice_coef: 0.0190 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 49/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1065 - dice_coef: 0.0204 - accuracy: 0.9757 - mse: 0.0209\n",
            "Epoch 49: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1065 - dice_coef: 0.0204 - accuracy: 0.9757 - mse: 0.0209 - val_loss: 0.0998 - val_dice_coef: 0.0169 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 50/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1062 - dice_coef: 0.0206 - accuracy: 0.9757 - mse: 0.0208\n",
            "Epoch 50: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1062 - dice_coef: 0.0206 - accuracy: 0.9757 - mse: 0.0208 - val_loss: 0.1002 - val_dice_coef: 0.0146 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 51/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1113 - dice_coef: 0.0209 - accuracy: 0.9745 - mse: 0.0219\n",
            "Epoch 51: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 711ms/step - loss: 0.1113 - dice_coef: 0.0209 - accuracy: 0.9745 - mse: 0.0219 - val_loss: 0.1018 - val_dice_coef: 0.0127 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 52/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1075 - dice_coef: 0.0204 - accuracy: 0.9756 - mse: 0.0210\n",
            "Epoch 52: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1075 - dice_coef: 0.0204 - accuracy: 0.9756 - mse: 0.0210 - val_loss: 0.1006 - val_dice_coef: 0.0190 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 53/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1028 - dice_coef: 0.0192 - accuracy: 0.9767 - mse: 0.0200\n",
            "Epoch 53: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1028 - dice_coef: 0.0192 - accuracy: 0.9767 - mse: 0.0200 - val_loss: 0.0997 - val_dice_coef: 0.0158 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 54/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1069 - dice_coef: 0.0198 - accuracy: 0.9758 - mse: 0.0208\n",
            "Epoch 54: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1069 - dice_coef: 0.0198 - accuracy: 0.9758 - mse: 0.0208 - val_loss: 0.0996 - val_dice_coef: 0.0164 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 55/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1079 - dice_coef: 0.0203 - accuracy: 0.9754 - mse: 0.0212\n",
            "Epoch 55: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1079 - dice_coef: 0.0203 - accuracy: 0.9754 - mse: 0.0212 - val_loss: 0.1011 - val_dice_coef: 0.0199 - val_accuracy: 0.9796 - val_mse: 0.0201\n",
            "Epoch 56/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1095 - dice_coef: 0.0200 - accuracy: 0.9750 - mse: 0.0215\n",
            "Epoch 56: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.1095 - dice_coef: 0.0200 - accuracy: 0.9750 - mse: 0.0215 - val_loss: 0.1015 - val_dice_coef: 0.0128 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 57/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1048 - dice_coef: 0.0202 - accuracy: 0.9765 - mse: 0.0202\n",
            "Epoch 57: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 709ms/step - loss: 0.1048 - dice_coef: 0.0202 - accuracy: 0.9765 - mse: 0.0202 - val_loss: 0.0999 - val_dice_coef: 0.0177 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 58/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1099 - dice_coef: 0.0210 - accuracy: 0.9750 - mse: 0.0215\n",
            "Epoch 58: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.1099 - dice_coef: 0.0210 - accuracy: 0.9750 - mse: 0.0215 - val_loss: 0.1000 - val_dice_coef: 0.0156 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 59/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1097 - dice_coef: 0.0201 - accuracy: 0.9750 - mse: 0.0215\n",
            "Epoch 59: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 70s 703ms/step - loss: 0.1097 - dice_coef: 0.0201 - accuracy: 0.9750 - mse: 0.0215 - val_loss: 0.1005 - val_dice_coef: 0.0195 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Epoch 60/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1090 - dice_coef: 0.0216 - accuracy: 0.9751 - mse: 0.0214\n",
            "Epoch 60: val_dice_coef did not improve from 0.02631\n",
            "100/100 [==============================] - 70s 702ms/step - loss: 0.1090 - dice_coef: 0.0216 - accuracy: 0.9751 - mse: 0.0214 - val_loss: 0.0997 - val_dice_coef: 0.0168 - val_accuracy: 0.9796 - val_mse: 0.0200\n",
            "Total time to train: 4322.359641313553\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC90klEQVR4nOydd1QUVxvGn116RwQFLGBBQcWuWGKLGOxiYo2xxagxtkT9YkwsaGJJ7C0ajS1GY4k1sdfYsPcuFlAUAekddu/3xzjb2M424P2ds2d3Z+/cubszO/PM266AMcZAEARBEARBSBCaewAEQRAEQRCWBgkkgiAIgiAIBUggEQRBEARBKEACiSAIgiAIQgESSARBEARBEAqQQCIIgiAIglCABBJBEARBEIQCJJAIgiAIgiAUIIFEEARBEAShAAkkgjABQ4YMgb+/v17rRkREQCAQGHZAFsaLFy8gEAiwceNGk29bIBAgIiJC8n7jxo0QCAR48eKFxnX9/f0xZMgQg46nKMeKMTh9+jQEAgFOnz4tWWZpYzQmBQUF+Pbbb1GpUiUIhUKEh4ebe0iEiSCBRJRqBAKBVg/ZiwNhHsaNGweBQICoqCiVbX744QcIBALcvn3bhCPTndevXyMiIgI3b94091AIDaxfvx7z589Hr169sGnTJnzzzTfmHhJhIqzNPQCCMCebN2+We//HH3/g2LFjhZYHBQUVaTtr166FWCzWa92pU6fiu+++K9L2SwIDBgzA8uXLsXXrVkyfPl1pm7/++gvBwcGoW7eu3tsZOHAg+vXrBzs7O7370MTr168xc+ZM+Pv7o379+nKfFeVYMRXFYYyG4uTJk6hQoQIWL15s7qEQJoYEElGq+eyzz+TeX7x4EceOHSu0XJGsrCw4OjpqvR0bGxu9xgcA1tbWsLamv2pISAiqV6+Ov/76S6lAioyMxPPnzzFv3rwibcfKygpWVlZF6qMoFOVYMRXFYYyGIj4+Hu7u7uYeBmEGyMVGEBpo27Yt6tSpg2vXrqF169ZwdHTE999/DwDYt28funTpAl9fX9jZ2aFatWr48ccfIRKJ5PpQjNngY24WLFiANWvWoFq1arCzs0OTJk1w5coVuXWVxSAJBAKMGTMGe/fuRZ06dWBnZ4fatWvj8OHDhcZ/+vRpNG7cGPb29qhWrRp+++03reOazp49i969e6Ny5cqws7NDpUqV8M033yA7O7vQ93N2dkZsbCzCw8Ph7OwMLy8vTJo0qdBvkZKSgiFDhsDNzQ3u7u4YPHgwUlJSNI4F4KxIDx8+xPXr1wt9tnXrVggEAvTv3x95eXmYPn06GjVqBDc3Nzg5OaFVq1Y4deqUxm0oi0FijOGnn35CxYoV4ejoiHbt2uHevXuF1k1KSsKkSZMQHBwMZ2dnuLq6olOnTrh165akzenTp9GkSRMAwNChQyVuXD7+Sll8T2ZmJiZOnIhKlSrBzs4ONWvWxIIFC8AYk2uny3GhjFevXiE8PBxOTk4oV64cvvnmG+Tm5hZqp2yMYrEYS5cuRXBwMOzt7eHl5YWOHTvi6tWrcu3+/PNPNGrUCA4ODvDw8EC/fv3w8uVLrcYXGxuLYcOGSf5vVapUwahRo5CXlydp8+zZM/Tu3RseHh5wdHREs2bNcODAgUJ95ebmYsaMGahevbrk2P72228l35f/j546dQr37t0jd3sphG5LCUIL3r17h06dOqFfv3747LPPUL58eQDcxdTZ2RkTJkyAs7MzTp48ienTpyMtLQ3z58/X2O/WrVuRnp6OkSNHQiAQ4JdffsHHH3+MZ8+eabxLP3fuHHbv3o2vvvoKLi4uWLZsGT755BPExMSgbNmyAIAbN26gY8eO8PHxwcyZMyESiTBr1ix4eXlp9b137tyJrKwsjBo1CmXLlsXly5exfPlyvHr1Cjt37pRrKxKJEBYWhpCQECxYsADHjx/HwoULUa1aNYwaNQoAJzR69OiBc+fO4csvv0RQUBD27NmDwYMHazWeAQMGYObMmdi6dSsaNmwot+0dO3agVatWqFy5MhITE/H777+jf//+GD58ONLT07Fu3TqEhYXh8uXLhdxampg+fTp++ukndO7cGZ07d8b169fx0UcfyV2YAe7ivHfvXvTu3RtVqlTB27dv8dtvv6FNmza4f/8+fH19ERQUhFmzZmH69OkYMWIEWrVqBQBo0aKF0m0zxtC9e3ecOnUKw4YNQ/369XHkyBH873//Q2xsbCHXjzbHhTKys7PRvn17xMTEYNy4cfD19cXmzZtx8uRJrX6jYcOGYePGjejUqRO++OILFBQU4OzZs7h48SIaN24MAJg9ezamTZuGPn364IsvvkBCQgKWL1+O1q1b48aNG2otNa9fv0bTpk2RkpKCESNGIDAwELGxsfj777+RlZUFW1tbvH37Fi1atEBWVhbGjRuHsmXLYtOmTejevTv+/vtv9OzZEwAn5rp3745z585hxIgRCAoKwp07d7B48WI8fvwYe/fuhZeXFzZv3ozZs2cjIyMDc+fOBVB0dztRjGAEQUgYPXo0U/xbtGnThgFgq1evLtQ+Kyur0LKRI0cyR0dHlpOTI1k2ePBg5ufnJ3n//PlzBoCVLVuWJSUlSZbv27ePAWD//POPZNmMGTMKjQkAs7W1ZVFRUZJlt27dYgDY8uXLJcu6devGHB0dWWxsrGTZkydPmLW1daE+laHs+82dO5cJBAIWHR0t9/0AsFmzZsm1bdCgAWvUqJHk/d69exkA9ssvv0iWFRQUsFatWjEAbMOGDRrH1KRJE1axYkUmEokkyw4fPswAsN9++03SZ25urtx6ycnJrHz58uzzzz+XWw6AzZgxQ/J+w4YNDAB7/vw5Y4yx+Ph4Zmtry7p06cLEYrGk3ffff88AsMGDB0uW5eTkyI2LMW5f29nZyf02V65cUfl9FY8V/jf76aef5Nr16tWLCQQCuWNA2+NCGUuWLGEA2I4dOyTLMjMzWfXq1RkAdurUKZVjPHnyJAPAxo0bV6hf/jd78eIFs7KyYrNnz5b7/M6dO8za2rrQckUGDRrEhEIhu3LlisptfP311wwAO3v2rOSz9PR0VqVKFebv7y/ZN5s3b2ZCoVCuHWOMrV69mgFg58+flyxr06YNq127ttqxESUTcrERhBbY2dlh6NChhZY7ODhIXqenpyMxMRGtWrVCVlYWHj58qLHfvn37okyZMpL3vDXh2bNnGtcNDQ1FtWrVJO/r1q0LV1dXyboikQjHjx9HeHg4fH19Je2qV6+OTp06aewfkP9+mZmZSExMRIsWLcAYw40bNwq1//LLL+Xet2rVSu67HDx4ENbW1hKLEsDF/IwdO1ar8QBc3NirV69w5swZybKtW7fC1tYWvXv3lvRpa2sLgLMWJCUloaCgAI0bN1bqnlPH8ePHkZeXh7Fjx8q5Jb/++utCbe3s7CAUcqdVkUiEd+/ewdnZGTVr1tR5uzwHDx6ElZUVxo0bJ7d84sSJYIzh0KFDcss1HRfqtuPj44NevXpJljk6OmLEiBEax7hr1y4IBALMmDGj0Gf8b7Z7926IxWL06dMHiYmJkoe3tzcCAgLUuj/FYjH27t2Lbt26SaxRyrZx8OBBNG3aFB988IHkM2dnZ4wYMQIvXrzA/fv3AXCW0aCgIAQGBsqN5cMPPwQArVyxRMmHBBJBaEGFChUkF1xZ7t27h549e8LNzQ2urq7w8vKSBHinpqZq7Ldy5cpy73mxlJycrPO6/Pr8uvHx8cjOzkb16tULtVO2TBkxMTEYMmQIPDw8JHFFbdq0AVD4+/FxJ6rGAwDR0dHw8fGBs7OzXLuaNWtqNR4A6NevH6ysrLB161YAQE5ODvbs2YNOnTrJic1Nmzahbt26sLe3R9myZeHl5YUDBw5otV9kiY6OBgAEBATILffy8pLbHsBdyBcvXoyAgADY2dnB09MTXl5euH37ts7bld2+r68vXFxc5Jbzrh5+fDyajgt126levXqh2DRt9s3Tp0/h6+sLDw8PlW2ePHkCxhgCAgLg5eUl93jw4AHi4+NVrpuQkIC0tDTUqVNH43dQNl7F3+rJkye4d+9eoXHUqFEDANSOhSg9UAwSQWiBrCWFJyUlBW3atIGrqytmzZqFatWqwd7eHtevX8fkyZO1SoNWlS3FFIJvDb2uNohEInTo0AFJSUmYPHkyAgMD4eTkhNjYWAwZMqTQ9zNV5le5cuXQoUMH7Nq1CytXrsQ///yD9PR0DBgwQNLmzz//xJAhQxAeHo7//e9/KFeuHKysrDB37lw8ffrUaGObM2cOpk2bhs8//xw//vgjPDw8IBQK8fXXX5ssLd7Yx4W+iMViCAQCHDp0SOkYFUWzsccSHByMRYsWKf28UqVKJhsLYbmQQCIIPTl9+jTevXuH3bt3o3Xr1pLlz58/N+OopJQrVw729vZKCyuqK7bIc+fOHTx+/BibNm3CoEGDJMuPHTum95j8/Pxw4sQJZGRkyF0QHz16pFM/AwYMwOHDh3Ho0CFs3boVrq6u6Natm+Tzv//+G1WrVsXu3bvlLCLKXEDajBngrA5Vq1aVLE9ISChklfn777/Rrl07rFu3Tm55SkoKPD09Je91qYzu5+eH48ePIz09Xc6KxLtw+fEVFT8/P9y9exeMMbnxabNvqlWrhiNHjiApKUmlFalatWpgjKFKlSoSS422eHl5wdXVFXfv3tX4HZSNV/G3qlatGm7duoX27duX+Cr1hP6Qi40g9IS/C5a9M8/Ly8Ovv/5qriHJYWVlhdDQUOzduxevX7+WLI+KiioUt6JqfUD++zHGsHTpUr3H1LlzZxQUFGDVqlWSZSKRCMuXL9epn/DwcDg6OuLXX3/FoUOH8PHHH8Pe3l7t2C9duoTIyEidxxwaGgobGxssX75crr8lS5YUamtlZVXIUrNz507ExsbKLXNycgIArcobdO7cGSKRCCtWrJBbvnjxYggEAq3jybTZzuvXr/H3339LlmVlZWHNmjUa1/3kk0/AGMPMmTMLfcb/Hh9//DGsrKwwc+bMQr8RYwzv3r1T2T8/xcc///xTqGyA7DY6d+6My5cvy+3nzMxMrFmzBv7+/qhVqxYAoE+fPoiNjcXatWsL9ZWdnY3MzEyN35ko+ZAFiSD0pEWLFihTpgwGDx4smQZj8+bNZndlyBIREYGjR4+iZcuWGDVqlORCW6dOHY3TXAQGBqJatWqYNGkSYmNj4erqil27dmkVH6WKbt26oWXLlvjuu+/w4sUL1KpVC7t379Y5PsfZ2Rnh4eGSOCRZ9xoAdO3aFbt370bPnj3RpUsXPH/+HKtXr0atWrWQkZGh07b4ek5z585F165d0blzZ9y4cQOHDh2Sswrx2501axaGDh2KFi1a4M6dO9iyZYuc5QngLBju7u5YvXo1XFxc4OTkhJCQEFSpUqXQ9rt164Z27drhhx9+wIsXL1CvXj0cPXoU+/btw9dffy0XkF0Uhg8fjhUrVmDQoEG4du0afHx8sHnzZq0KorZr1w4DBw7EsmXL8OTJE3Ts2BFisRhnz55Fu3btMGbMGFSrVg0//fQTpkyZghcvXiA8PBwuLi54/vw59uzZgxEjRmDSpEkqtzFnzhwcPXoUbdq0kaTmv3nzBjt37sS5c+fg7u6O7777Dn/99Rc6deqEcePGwcPDA5s2bcLz58+xa9cuSQD9wIEDsWPHDnz55Zc4deoUWrZsCZFIhIcPH2LHjh04cuSI0mBwopRh2qQ5grBsVKX5q0rzPX/+PGvWrBlzcHBgvr6+7Ntvv2VHjhzRmBbNp/nPnz+/UJ9QSDtXleY/evToQuv6+fnJpZ0zxtiJEydYgwYNmK2tLatWrRr7/fff2cSJE5m9vb2KX0HK/fv3WWhoKHN2dmaenp5s+PDhkrRx2RT1wYMHMycnp0LrKxv7u3fv2MCBA5mrqytzc3NjAwcOZDdu3NA6zZ/nwIEDDADz8fEplFovFovZnDlzmJ+fH7Ozs2MNGjRg//77b6H9wJjmNH/GGBOJRGzmzJnMx8eHOTg4sLZt27K7d+8W+r1zcnLYxIkTJe1atmzJIiMjWZs2bVibNm3ktrtv3z5Wq1YtSckF/rsrG2N6ejr75ptvmK+vL7OxsWEBAQFs/vz5cmUH+O+i7XGhjOjoaNa9e3fm6OjIPD092fjx4yUlFNQdz4xxpRXmz5/PAgMDma2tLfPy8mKdOnVi165dk2u3a9cu9sEHHzAnJyfm5OTEAgMD2ejRo9mjR4+0Gt+gQYOYl5cXs7OzY1WrVmWjR4+WK+nw9OlT1qtXL+bu7s7s7e1Z06ZN2b///luor7y8PPbzzz+z2rVrMzs7O1amTBnWqFEjNnPmTJaamippR2n+pRcBYxZ0u0sQhEkIDw/HvXv38OTJE3MPhSAIwiKhGCSCKOEoTgvy5MkTHDx4EG3btjXPgAiCIIoBZEEiiBKOj48PhgwZgqpVqyI6OhqrVq1Cbm4ubty4Uai2D0EQBMFBQdoEUcLp2LEj/vrrL8TFxcHOzg7NmzfHnDlzSBwRBEGogSxIBEEQBEEQClAMEkEQBEEQhAIkkAiCIAiCIBSgGCQ9EYvFeP36NVxcXKhUPUEQBEEUExhjSE9Ph6+vr6R4qDJIIOnJ69evaUJDgiAIgiimvHz5EhUrVlT5OQkkPeEnjXz58iVcXV3NPBqCIAiCILQhLS0NlSpVkpv8WRkkkPSEd6u5urqSQCIIgiCIYoam8BgK0iYIgiAIglCABBJBEARBEIQCJJAIgiAIgiAUoBgkgiCIUohYLEZeXp65h0EQBsfGxgZWVlZF7ocEEkEQRCkjLy8Pz58/h1gsNvdQCMIouLu7w9vbu0h1CkkgEQRBlCIYY3jz5g2srKxQqVIltYXyCKK4wRhDVlYW4uPjAQA+Pj5690UCiSAIohRRUFCArKws+Pr6wtHR0dzDIQiD4+DgAACIj49HuXLl9Ha30a0DQRBEKUIkEgEAbG1tzTwSgjAevPjPz8/Xuw8SSARBEKUQmkOSKMkY4vgmgUQQBEEQBKEACSSCIAiiVOLv748lS5Zo3f706dMQCARISUkx2phUsXHjRri7u0veR0REoH79+iYfh6FZs2aNJFlAl31hCkggEQRBEBaNQCBQ+4iIiNCr3ytXrmDEiBFat2/RogXevHkDNzc3vbZnSCZNmoQTJ06YexhFIi0tDWPGjMHkyZMRGxur074wBZTFZmEkZSchNScVno6ecLFTP9MwQRBEaeDNmzeS19u3b8f06dPx6NEjyTJnZ2fJa8YYRCIRrK01X968vLx0GoetrS28vb11WsdYODs7y33v4khMTAzy8/PRpUuXIqXjGwuyIFkYvXb0QtVlVXHgyQFzD4UgCMIi8Pb2ljzc3NwgEAgk7x8+fAgXFxccOnQIjRo1gp2dHc6dO4enT5+iR48eKF++PJydndGkSRMcP35crl9FF5tAIMDvv/+Onj17wtHREQEBAdi/f7/kc0UXG+/2OnLkCIKCguDs7IyOHTvKCbqCggKMGzcO7u7uKFu2LCZPnozBgwcjPDxc7XfeuHEjKleuDEdHR/Ts2RPv3r2T+1yZi239+vWoXbs27Ozs4OPjgzFjxkg+S0lJwRdffAEvLy+4urriww8/xK1bt9SO4dWrV+jfvz88PDzg5OSExo0b49KlS5LPV61ahWrVqsHW1hY1a9bE5s2b5dZXt82NGzciODgYAFC1alUIBAK8ePFC7XhMDQkkC8PJ1gkAkJGXYeaREARRGmCMITMv0ywPxpjBvsd3332HefPm4cGDB6hbty4yMjLQuXNnnDhxAjdu3EDHjh3RrVs3xMTEqO1n5syZ6NOnD27fvo3OnTtjwIABSEpKUtk+KysLCxYswObNm3HmzBnExMRg0qRJks9//vlnbNmyBRs2bMD58+eRlpaGvXv3qh3DpUuXMGzYMIwZMwY3b95Eu3bt8NNPP6ldZ9WqVRg9ejRGjBiBO3fuYP/+/ahevbrk8969eyM+Ph6HDh3CtWvX0LBhQ7Rv317ld8vIyECbNm0QGxuL/fv349atW/j2228l1df37NmD8ePHY+LEibh79y5GjhyJoUOH4tSpU1pts2/fvhLBevnyZbx58waVKlVS+x1NDbnYLAxnW85kmpmXaeaREARRGsjKz4LzXPO4ajKmZEhuCovKrFmz0KFDB8l7Dw8P1KtXT/L+xx9/xJ49e7B//345y4oiQ4YMQf/+/QEAc+bMwbJly3D58mV07NhRafv8/HysXr0a1apVAwCMGTMGs2bNkny+fPlyTJkyBT179gQArFixAgcPHlT7XZYuXYqOHTvi22+/BQDUqFEDFy5cwOHDh1Wu89NPP2HixIkYP368ZFmTJk0AAOfOncPly5cRHx8POzs7AMCCBQuwd+9e/P3330pjf7Zu3YqEhARcuXIFHh4eACAnuBYsWIAhQ4bgq6++AgBMmDABFy9exIIFC9CuXTuttlm2bFkAnKvTUlyXspAFycJwsiELEkEQhK40btxY7n1GRgYmTZqEoKAguLu7w9nZGQ8ePNBoQapbt67ktZOTE1xdXSXTVijD0dFRIo4AbmoLvn1qairevn2Lpk2bSj63srJCo0aN1I7hwYMHCAkJkVvWvHlzle3j4+Px+vVrtG/fXunnt27dQkZGBsqWLSuJXXJ2dsbz58/x9OlTpevcvHkTDRo0kIgjZWNs2bKl3LKWLVviwYMHem/T0iALkoUhsSDlkwWJIAjj42jjiIwp5rkhc7Qx3FQnTk7ylqhJkybh2LFjWLBgAapXrw4HBwf06tULeXl5avuxsbGRey8QCNRO6qusvSFdh9rAT62hioyMDPj4+OD06dOFPpMtHaBLn5rQZ5uWBgkkC4MsSARBmBKBQGAwN5clcf78eQwZMkTi2srIyDB5ELCbmxvKly+PK1euoHXr1gC4qV6uX7+utoZRUFCQXDA0AFy8eFFlexcXF/j7++PEiRNo165doc8bNmyIuLg4WFtbw9/fX6ux161bF7///juSkpKUWpGCgoJw/vx5DB48WLLs/PnzqFWrlt7btDTIxWZhUAwSQRBE0QkICMDu3btx8+ZN3Lp1C59++qlaS5CxGDt2LObOnYt9+/bh0aNHGD9+PJKTk9VOhTFu3DgcPnwYCxYswJMnT7BixQq18UcAl9W2cOFCLFu2DE+ePMH169exfPlyAEBoaCiaN2+O8PBwHD16FC9evMCFCxfwww8/4OrVq0r769+/P7y9vREeHo7z58/j2bNn2LVrFyIjIwEA//vf/7Bx40asWrUKT548waJFi7B7925JgLo+27Q0SCBZGJIstnyyIBEEQejLokWLUKZMGbRo0QLdunVDWFgYGjZsaPJxTJ48Gf3798egQYPQvHlzODs7IywsDPb29irXadasGdauXYulS5eiXr16OHr0KKZOnap2O4MHD8aSJUvw66+/onbt2ujatSuePHkCgLMSHjx4EK1bt8bQoUNRo0YN9OvXD9HR0ShfvrzS/mxtbXH06FGUK1cOnTt3RnBwMObNmwcrKysAQHh4OJYuXYoFCxagdu3a+O2337Bhwwa0bdtW721aHMwCWLFiBfPz82N2dnasadOm7NKlS2rb79ixg9WsWZPZ2dmxOnXqsAMHDsh9PmPGDFazZk3m6OjI3N3dWfv27dnFixfl2vj5+TEAco+5c+dqPebU1FQGgKWmpmr/RbVg3fV1DBFgXbZ0MWi/BEEQjDGWnZ3N7t+/z7Kzs809lFKJSCRiNWrUYFOnTjX3UEo06o5zba/fZrcgbd++HRMmTMCMGTNw/fp11KtXD2FhYSqzBi5cuID+/ftj2LBhuHHjBsLDwxEeHo67d+9K2tSoUQMrVqzAnTt3cO7cOfj7++Ojjz5CQkKCXF+zZs3CmzdvJI+xY8ca9btqA8UgEQRBlByio6Oxdu1aPH78GHfu3MGoUaPw/PlzfPrpp+YeGqEBswukRYsWYfjw4Rg6dChq1aqF1atXw9HREevXr1fanq8P8b///Q9BQUH48ccf0bBhQ6xYsULS5tNPP0VoaCiqVq2K2rVrY9GiRUhLS8Pt27fl+nJxcZGr0KqYBWEOeBcbZbERBEEUf4RCITZu3IgmTZqgZcuWuHPnDo4fP46goCBzD43QgFkFUl5eHq5du4bQ0FDJMqFQiNDQUEkgmCKRkZFy7QEgLCxMZfu8vDysWbMGbm5uckXDAGDevHkoW7YsGjRogPnz56OgoEDlWHNzc5GWlib3MAZ8kDZZkAiCIIo/lSpVwvnz55Gamoq0tDRcuHBBktFGWDZmTfNPTEyESCQqFLBVvnx5PHz4UOk6cXFxStvHxcXJLfv333/Rr18/ZGVlwcfHB8eOHYOnp6fk83HjxqFhw4bw8PDAhQsXMGXKFLx58waLFi1Sut25c+di5syZ+nxNneBdbJTFRhAEQRDmo8TWQWrXrh1u3ryJxMRErF27Fn369MGlS5dQrlw5AFxZdJ66devC1tYWI0eOxNy5cyVl0WWZMmWK3DppaWlGmTeGCkUSBEEQhPkxq4vN09MTVlZWePv2rdzyt2/fqpyXxdvbW6v2Tk5OqF69Opo1a4Z169bB2toa69atUzmWkJAQFBQUqCwkZmdnB1dXV7mHMaDJagmCIAjC/JhVINna2qJRo0Y4ceKEZJlYLMaJEydUzjvTvHlzufYAcOzYMbXz1PD95ubmqvz85s2bEAqFEguTueAtSHmiPOSL8s06FoIgCIIorZjdxTZhwgQMHjwYjRs3RtOmTbFkyRJkZmZi6NChAIBBgwahQoUKmDt3LgBg/PjxaNOmDRYuXIguXbpg27ZtuHr1KtasWQMAyMzMxOzZs9G9e3f4+PggMTERK1euRGxsLHr37g2AC/S+dOkS2rVrBxcXF0RGRuKbb77BZ599hjJlypjnh3gPH4MEcG42dyt38w2GIAiCIEopZhdIffv2RUJCAqZPn464uDjUr18fhw8flgRix8TEQCiUGrpatGiBrVu3YurUqfj+++8REBCAvXv3ok6dOgC4mZIfPnyITZs2ITExEWXLlkWTJk1w9uxZ1K5dGwDnLtu2bRsiIiKQm5uLKlWq4JtvvpGLMTIXtla2sBZao0BcgMy8TLjbu5t7SARBEARR6hAwZuJph0sIaWlpcHNzQ2pqqsHjkdznuSM1NxUPRz9ETc+aBu2bIIjSTU5ODp4/f44qVaqone6iJNK2bVvUr18fS5YsAQD4+/vj66+/xtdff61yHYFAgD179iA8PLxI2zZUP7oSERGBvXv34ubNmwCAIUOGICUlBXv37jXpOAxNREQEVq1ahfj4eKW/q7rjXNvrt9ktSERhnG2dkZqbSplsBEEQALp164b8/HylE7aePXsWrVu3xq1bt1C3bl2d+r1y5YrBCwQrChKeN2/emD2EA+CKLRd3u8iDBw8wc+ZM7NmzB82aNTPa70oCyQKhTDaCIAgpw4YNwyeffIJXr16hYsWKcp9t2LABjRs31lkcAYCXl5ehhqgRVZnZpsbNzc3cQygyT58+BQD06NEDAoHAaNsx+1QjRGEktZCoWCRBEAS6du0KLy8vbNy4UW55RkYGdu7ciWHDhuHdu3fo378/KlSoAEdHRwQHB+Ovv/5S26+/v7/E3QYAT548QevWrWFvb49atWrh2LFjhdaZPHkyatSoAUdHR1StWhXTpk1Dfj6Xcbxx40bMnDkTt27dgkAggEAgkIxZIBDIubXu3LmDDz/8EA4ODihbtixGjBiBjAzpTfGQIUMQHh6OBQsWwMfHB2XLlsXo0aMl21LFvHnzUL58ebi4uGDYsGHIycmR+5zvl0csFuOXX35B9erVYWdnh8qVK2P27NmSz1++fIk+ffrA3d0dHh4e6NGjh8pyODz37t1D165d4erqChcXF7Rq1UoiasRiMWbNmoWKFSvCzs5OEncsi7ptRkREoFu3bgC4mTdIIJUyaMJagiBMBWNAZqZ5Htp6eqytrTFo0CBs3LhRzj20c+dOiEQi9O/fHzk5OWjUqBEOHDiAu3fvYsSIERg4cCAuX76s1TbEYjE+/vhj2Nra4tKlS1i9ejUmT55cqJ2Liws2btyI+/fvY+nSpVi7di0WL14MgEs6mjhxImrXri2ZBL1v376F+sjMzERYWBjKlCmDK1euYOfOnTh+/DjGjBkj1+7UqVN4+vQpTp06hU2bNmHjxo2FRKIsO3bsQEREBObMmYOrV6/Cx8cHv/76q9rvPWXKFMybNw/Tpk3D/fv3sXXrVkmSVH5+PsLCwuDi4oKzZ8/i/PnzcHZ2RseOHZGXl6e0v9jYWLRu3Rp2dnY4efIkrl27hs8//1wyldfSpUuxcOFCLFiwALdv30ZYWBi6d++OJ0+eaLXNSZMmYcOGDQAg+Y2NBiP0IjU1lQFgqampBu+705+dGCLANtzYYPC+CYIo3WRnZ7P79++z7OxsxhhjGRmMcVLF9I+MDO3H/eDBAwaAnTp1SrKsVatW7LPPPlO5TpcuXdjEiRMl79u0acPGjx8vee/n58cWL17MGGPsyJEjzNramsXGxko+P3ToEAPA9uzZo3Ib8+fPZ40aNZK8nzFjBqtXr16hdrL9rFmzhpUpU4ZlyPwABw4cYEKhkMXFxTHGGBs8eDDz8/NjBQUFkja9e/dmffv2VTmW5s2bs6+++kpuWUhIiNx4Bg8ezHr06MEYYywtLY3Z2dmxtWvXKu1v8+bNrGbNmkwsFkuW5ebmMgcHB3bkyBGl60yZMoVVqVKF5eXlKf3c19eXzZ49W25ZkyZNJOPWZpt79uxhmuSL4nEui7bXb7IgWSAUg0QQBCFPYGAgWrRogfXr1wMAoqKicPbsWQwbNgwAIBKJ8OOPPyI4OBgeHh5wdnbGkSNHEBMTo1X/Dx48QKVKleDr6ytZpqwA8fbt29GyZUt4e3vD2dkZU6dO1XobstuqV6+eXIB4y5YtIRaL8ejRI8my2rVrw8rKSvLex8cH8fHxavsNCQmRW6auiPKDBw+Qm5uL9u3bK/381q1biIqKgouLC5ydneHs7AwPDw/k5ORIXGaK3Lx5E61atYKNjU2hz9LS0vD69Wu0bNlSbnnLli3x4MEDvbdpLChI2wKhGCSCIEyFoyOQYaZ7MUdH3doPGzYMY8eOxcqVK7FhwwZUq1YNbdq0AQDMnz8fS5cuxZIlSxAcHAwnJyd8/fXXKl1B+hAZGYkBAwZg5syZCAsLg5ubG7Zt24aFCxcabBuyKIoMgUAAsVhssP4dHBzUfp6RkYFGjRphy5YthT5TFeCuqU9N6LNNY0ECyQKhGCSCIEyFQAAYONPdaPTp0wfjx4/H1q1b8ccff2DUqFGSIN3z58+jR48e+OyzzwBwMUWPHz9GrVq1tOo7KCgIL1++xJs3b+Dj4wMAuHjxolybCxcuwM/PDz/88INkWXR0tFwbW1tbiEQijdvauHEjMjMzJVak8+fPQygUomZN/WvfBQUF4dKlSxg0aJBkmeJ3kCUgIAAODg44ceIEvvjii0KfN2zYENu3b0e5cuW0rvdXt25dbNq0Cfn5+YUEnqurK3x9fXH+/HmJsAW47960aVO9t2ksyMVmgfACieogEQRBSHF2dkbfvn0xZcoUvHnzBkOGDJF8FhAQgGPHjuHChQt48OABRo4cWWhic3WEhoaiRo0aGDx4MG7duoWzZ8/KCSF+GzExMdi2bRuePn2KZcuWYc+ePXJt/P398fz5c9y8eROJiYlK5wAdMGAA7O3tMXjwYNy9exenTp3C2LFjMXDgQEmAtD6MHz8e69evx4YNG/D48WPMmDED9+7dU9ne3t4ekydPxrfffos//vgDT58+xcWLFyUTuw8YMACenp7o0aMHzp49i+fPn+P06dMYN24cXr16pbTPMWPGIC0tDf369cPVq1fx5MkTbN68WeI6/N///oeff/4Z27dvx6NHj/Ddd9/h5s2bGD9+vN7bNBYkkCwQcrERBEEoZ9iwYUhOTkZYWJhcvNDUqVPRsGFDhIWFoW3btvD29taparVQKMSePXuQnZ2Npk2b4osvvpBLdweA7t2745tvvsGYMWNQv359XLhwAdOmTZNr88knn6Bjx45o164dvLy8lJYacHR0xJEjR5CUlIQmTZqgV69eaN++PVasWKHbj6FA3759MW3aNHz77bdo1KgRoqOjMWrUKLXrTJs2DRMnTsT06dMRFBSEvn37SuKcHB0dcebMGVSuXBkff/wxgoKCJKUDVFl3ypYti5MnTyIjIwNt2rRBo0aNsHbtWok1ady4cZgwYQImTpyI4OBgHD58GPv370dAQIDe2zQWNNWInhhzqpFFkYsw8ehEfBr8KbZ8XNgPSxAEoS+leaoRovRgiKlGyIJkgZAFiSAIgiDMCwkkC4SCtAmCIAjCvJBAskAkFiQK0iYIgiAIs0ACyQKhQpEEQRAEYV5IIFkgFINEEISxofwcoiRjiOObBJIFQjFIBEEYC37qCkNWmCYISyMrKwtA4WrkukCVtC0QikEiCMJYWFtbw9HREQkJCbCxsYFQSPfJRMmBMYasrCzEx8fD3d1dbi47XSGBZIHwMUhZ+VkQMzGEAjqBEQRhGAQCAXx8fPD8+fNC02QQREnB3d0d3t7eReqDBJIFwluQAE4kyb4nCIIoKra2tggICCA3G1EisbGxKZLliIcEkgXiYO0AAQRgYMjIyyCBRBCEwREKhVRJmyDUQL4bC0QgEEjcbJTJRhAEQRCmhwSShUKZbARBEARhPkggWSiUyUYQBEEQ5oMEkoVCLjaCIAiCMB8kkCwUcrERBEEQhPkggWShkIuNIAiCIMwHCSQLhSasJQiCIAjzQQLJQqEJawmCIAjCfJBAslAoBokgCIIgzAcJJAuFYpAIgiAIwnyQQLJQyIJEEARBEOaDBJKFQhYkgiAIgjAfJJAsFMpiIwiCIAjzQQLJQqEsNoIgCIIwHySQLBSKQSIIgiAI80ECyUKhGCSCIAiCMB8kkCwUikEiCIIgCPNBAslCoRgkgiAIgjAfJJAsFD4GiVxsBEEQBGF6SCBZKLIuNsaYmUdDEARBEKULEkgWCu9iEzMxckW5Zh4NQRAEQZQuSCBZKLyLDaBAbYIgCIIwNSSQLBQroRXsre0BUKA2QRAEQZgaEkgWDBWLJAiCIAjzQALJgqFikQRBEARhHkggWTBULJIgCIIgzAMJJAuGikUSBEEQhHkggWTBUAwSQRAEQZgHEkgWDMUgEQRBEIR5IIFkwVAMEkEQBEGYBxJIFoyzDcUgEQRBEIQ5IIFkwZAFiSAIgiDMAwkkC4ZikAiCIAjCPJBAsmD4LDZysREEQRCEaSGBZMHwFqSMfHKxEQRBEIQpIYFkwfAxSGRBIgiCIAjTYhECaeXKlfD394e9vT1CQkJw+fJlte137tyJwMBA2NvbIzg4GAcPHpT7PCIiAoGBgXByckKZMmUQGhqKS5cuybVJSkrCgAED4OrqCnd3dwwbNgwZGZZlqaFCkQRBEARhHswukLZv344JEyZgxowZuH79OurVq4ewsDDEx8crbX/hwgX0798fw4YNw40bNxAeHo7w8HDcvXtX0qZGjRpYsWIF7ty5g3PnzsHf3x8fffQREhISJG0GDBiAe/fu4dixY/j3339x5swZjBgxwujfVxcoSJsgCIIgzIOAMcbMOYCQkBA0adIEK1asAACIxWJUqlQJY8eOxXfffVeofd++fZGZmYl///1XsqxZs2aoX78+Vq9erXQbaWlpcHNzw/Hjx9G+fXs8ePAAtWrVwpUrV9C4cWMAwOHDh9G5c2e8evUKvr6+GsfN95mamgpXV1d9vrpGTr84jXab2iHQMxAPRj8wyjYIgiAIojSh7fXbrBakvLw8XLt2DaGhoZJlQqEQoaGhiIyMVLpOZGSkXHsACAsLU9k+Ly8Pa9asgZubG+rVqyfpw93dXSKOACA0NBRCobCQK44nNzcXaWlpcg9jQ5PVEgRBEIR5MKtASkxMhEgkQvny5eWWly9fHnFxcUrXiYuL06r9v//+C2dnZ9jb22Px4sU4duwYPD09JX2UK1dOrr21tTU8PDxUbnfu3Llwc3OTPCpVqqTTd9UHikEiCIIgCPNg9hgkY9GuXTvcvHkTFy5cQMeOHdGnTx+VcU3aMGXKFKSmpkoeL1++NOBolUMxSARBEARhHswqkDw9PWFlZYW3b9/KLX/79i28vb2VruPt7a1VeycnJ1SvXh3NmjXDunXrYG1tjXXr1kn6UBRLBQUFSEpKUrldOzs7uLq6yj2MDZ/mnyfKQ74o3+jbIwiCIAiCw6wCydbWFo0aNcKJEycky8RiMU6cOIHmzZsrXad58+Zy7QHg2LFjKtvL9pubmyvpIyUlBdeuXZN8fvLkSYjFYoSEhOj7dQwOb0ECyIpEEARBEKbE2twDmDBhAgYPHozGjRujadOmWLJkCTIzMzF06FAAwKBBg1ChQgXMnTsXADB+/Hi0adMGCxcuRJcuXbBt2zZcvXoVa9asAQBkZmZi9uzZ6N69O3x8fJCYmIiVK1ciNjYWvXv3BgAEBQWhY8eOGD58OFavXo38/HyMGTMG/fr10yqDzVTYWtnCWmiNAnEBMvIy4G7vbu4hEQRBEESpwOwCqW/fvkhISMD06dMRFxeH+vXr4/Dhw5JA7JiYGAiFUkNXixYtsHXrVkydOhXff/89AgICsHfvXtSpUwcAYGVlhYcPH2LTpk1ITExE2bJl0aRJE5w9exa1a9eW9LNlyxaMGTMG7du3h1AoxCeffIJly5aZ9strgbOtM1JyUiiTjSAIgiBMiNnrIBVXTFEHCQAqLqqI2PRYXB1+FY18GxltOwRBEARRGigWdZAIzVAmG0EQBEGYHhJIFg5NWEsQBEEQpocEkoXDW5CoWCRBEARBmA4SSBYOX02bXGwEQRAEYTpIIFk4ZEEiCIIgCNNDAsnCoRgkgiAIgjA9JJAsHJqwliAIgiBMDwkkC4fS/AmCIAjC9JBAsnDIgkQQBEEQpocEkoVDFiSCIAiCMD0kkCwcPkibLEgEQRAEYTpIIFk4EgsSZbERBEEQhMkggWThUAwSQRAEQZgeEkgWDsUgEQRBEITpIYFk4VAMEkEQBEGYHhJIFg7FIBEEQRCE6SGBZOHQZLUEQRAEYXpIIFk4vAUpKz8LYiY282gIgiAIonRAAsnC4WOQAE4kEQRBEARhfEggWTgO1g4QQACAArUJgiAIwlSQQLJwBAKBxIpEgdoEQRAEYRpIIBUD+DgksiARBEEQhGkggVQMoEw2giAIgjAtJJCKAVQskiAIgiBMCwmkYgAViyQIgiAI00ICqRhAE9YSBEEQhGkhgVQMoAlrCYIgCMK0kEAqBlAMEkEQBEGYFhJIxQBnG4pBIgiCIAhTQgKpGEAWJIIgCIIwLSSQigEUg0QQBEEQpoUEUjGACkUSBEEQhGkhgVQMoKlGCIIgCMK0kEAqBtBktQRBEARhWkggFQPIgkQQBEEQpoUEUjGAYpAIgiAIwrSQQCoGkAWJIAiCIEwLCaRiAMUgEQRBEIRpIYFUDCALEkEQBEGYFhJIxQDZGCTGmJlHQxAEQRAlHxJIxQDexSZmYuQU5Jh5NARBEARR8iGBVAzgLUgAZbIRBEEQhCkggVQMsBJawd7aHgDFIRHm5fZt4LPPgKdPzT0SgiAI40ICqZggmbCWMtkIM7JiBbBlC7Bhg7lHQhAEYVxIIBUTeDcbWZAIcxIbK/9MEARRUiGBVEyQWJAoBokwI2/eyD8TBEGUVEggFROoWCRhCZBAIgiitEACqZhAxSIJcyMSAfHx3GsSSARBlHRIIBUTaMJawtzExwNiMfc6IQHIyzPveAiCIIwJCaRiAlmQCHOjaDV6+9Y84yAIgjAFJJCKCRILEsUgEWZCUSCRm40giJIMCaRiAlmQCHNDAokgiNIECaRigiSLjWKQCDNBAokgiNKEzgLJ398fs2bNQkxMjDHGQ6iALEiEuSGBRBBEaUJngfT1119j9+7dqFq1Kjp06IBt27YhNzfXGGMjZKAsNsLc8IKoXDn59wRBECURvQTSzZs3cfnyZQQFBWHs2LHw8fHBmDFjcP36dWOMkYDUxUYWJMJc8IKoUSP59wRBECURvWOQGjZsiGXLluH169eYMWMGfv/9dzRp0gT169fH+vXrwRgz5DhLPTRZLWFueEHUsKH8e4IgiJKI3gIpPz8fO3bsQPfu3TFx4kQ0btwYv//+Oz755BN8//33GDBggNZ9rVy5Ev7+/rC3t0dISAguX76stv3OnTsRGBgIe3t7BAcH4+DBg3Ljmjx5MoKDg+Hk5ARfX18MGjQIr1+/luvD398fAoFA7jFv3jzdfgQTQpPVEuaEMSAujntNAokgiNKAta4rXL9+HRs2bMBff/0FoVCIQYMGYfHixQgMDJS06dmzJ5o0aaJVf9u3b8eECROwevVqhISEYMmSJQgLC8OjR49Qjg92kOHChQvo378/5s6di65du2Lr1q0IDw/H9evXUadOHWRlZeH69euYNm0a6tWrh+TkZIwfPx7du3fH1atX5fqaNWsWhg8fLnnv4uKi689hMmiyWsKcJCVJK2c3aMA9v33LTT9iZWW+cREEQRgNpiNCoZCFhYWxHTt2sLy8PKVtMjIy2JAhQ7Tqr2nTpmz06NGS9yKRiPn6+rK5c+cqbd+nTx/WpUsXuWUhISFs5MiRKrdx+fJlBoBFR0dLlvn5+bHFixdrNUZlpKamMgAsNTVV7z504UrsFYYIsIqLKppkewQhy507jAGMeXgwlp/PmEDAvY+LM/fICIIgdEPb67fOLrZnz57h8OHD6N27N2xsbJS2cXJywoYNGzT2lZeXh2vXriE0NFSyTCgUIjQ0FJGRkUrXiYyMlGsPAGFhYSrbA0BqaioEAgHc3d3lls+bNw9ly5ZFgwYNMH/+fBQUFKjsIzc3F2lpaXIPU0IxSIQ54d1pPj6AtTXg5SW/nCAIoqShs0CKj4/HpUuXCi2/dOlSIReWJhITEyESiVC+fHm55eXLl0ccH/CgQFxcnE7tc3JyMHnyZPTv3x+urq6S5ePGjcO2bdtw6tQpjBw5EnPmzMG3336rcqxz586Fm5ub5FGpUiVtv6ZBoBgkwpzICiTZZxJIBEGUVHQWSKNHj8bLly8LLY+NjcXo0aMNMihDkZ+fjz59+oAxhlWrVsl9NmHCBLRt2xZ169bFl19+iYULF2L58uUqazpNmTIFqampkoey38CY8BakfHE+8kX5Jt02QfD3HySQCIIoLegcpH3//n005NNYZGjQoAHu37+vU1+enp6wsrLCW4Vpwd++fQtvb2+l63h7e2vVnhdH0dHROHnypJz1SBkhISEoKCjAixcvULNmzUKf29nZwc7OTpuvZRT4OkgAF6jtbuVutrEQpQ+yIBEEUdrQ2YJkZ2dXSKAAwJs3b2BtrZvesrW1RaNGjXDixAnJMrFYjBMnTqB58+ZK12nevLlcewA4duyYXHteHD158gTHjx9H2bJlNY7l5s2bEAqFSjPnLAFbK1vYCLmYL3KzEaaGBBJBEKUNnS1IH330EaZMmYJ9+/bBzc0NAJCSkoLvv/8eHTp00HkAEyZMwODBg9G4cWM0bdoUS5YsQWZmJoYOHQoAGDRoECpUqIC5c+cCAMaPH482bdpg4cKF6NKlC7Zt24arV69izZo1ADhx1KtXL1y/fh3//vsvRCKRJD7Jw8MDtra2iIyMxKVLl9CuXTu4uLggMjIS33zzDT777DOUKVNG5+9gKpxsnZCSk0KB2oTJ4YUQb6glgUQQRElHZ4G0YMECtG7dGn5+fmjwviDKzZs3Ub58eWzevFnnAfTt2xcJCQmYPn064uLiUL9+fRw+fFgSiB0TEwOhUGroatGiBbZu3YqpU6fi+++/R0BAAPbu3Ys6deoA4GKh9u/fDwCoX7++3LZOnTqFtm3bws7ODtu2bUNERARyc3NRpUoVfPPNN5gwYYLO4zclzrbOSMlJIQsSYXLIgkQQRGlDwJjuc4JkZmZiy5YtuHXrFhwcHFC3bl30799fZdp/SSQtLQ1ubm5ITU3VGN9kKAJXBOLRu0f4b8h/aO3X2iTbJAgAcHEBMjKAR4+AGjWACxeAli0Bf3/g+XNzj44gCEJ7tL1+62xBArg6RyNGjNB7cIR+8JlsZEEiTElGBvcApJYjX1/u+c0bbhoSgcA8YyMIgjAWegkkgMtmi4mJQR4//8B7unfvXuRBEcrhM9koBokwJbwbzcmJsyQB0lik3FwgJQWw4NA9Qk+SkwE3N0Co94ydBFG80VkgPXv2DD179sSdO3cgEAjAe+gE728hRSKRYUdISCALEmEOFOOPAMDenhNFycnc5ySQShYPHgB16wIDBwLr15t7NARhHnS+Nxg/fjyqVKmC+Ph4ODo64t69ezhz5gwaN26M06dPG2GIBA9fTZsmrCVMiTKBJPv+9WvTjocwPhcuAAUFAJ3SidKMzgIpMjISs2bNgqenJ4RCIYRCIT744APMnTsX48aNM8YYiffwLjayIBGmRJNAoky2kseLF9zzy5ecUCKI0ojOAkkkEsHlfSCCp6cnXr+/ffTz88OjR48MOzpCDmcbmrCWMD0kkEof0dHcc0EBWQiJ0ovOMUh16tTBrVu3UKVKFYSEhOCXX36Bra0t1qxZg6pVqxpjjMR7yIJEmAMSSKUPXiABnDWpcmWzDYUgzIbOFqSpU6dCLBYDAGbNmoXnz5+jVatWOHjwIJYtW2bwARJS+CBtikEiTAkJpNIH72JTfE0QpQmdLUhhYWGS19WrV8fDhw+RlJSEMmXKSDLZCOPAB2mTBYkwJSSQShcFBUBsrPQ9FQIlSis6CaT8/Hw4ODjg5s2bkqk9AG6OM8Iw5OcDmZnKH49v1wFufYY4Z9NU7iYIgARSaSM2FpCt1kIWJKK0opNAsrGxQeXKlanWkREJCwNOnVL1aQcAHXDueArE31ABN8L45OYCSUncaxJIpQNFQUQCiSit6HyJ/eGHH/D9998jiT9rEgbFifOiwcoKcHXlLkLVqwP16gGBDbjfPD/dHampZhwkUWqIi+OebW0BRUMxL5BkpyIhij98gLYzF/JIAokotegcg7RixQpERUXB19cXfn5+cOKv6O+5fv26wQZXGtm2DbC25i5IiiFdJ57dQGhgMyDfCcnJVL2YMD68dcjbu/Dx6OLCCfrMTK5dQIDpx0cYHl4gtWoFHDokrYVkrffEVARRPNH5kA8PDzfCMAgeBb0ph7OtM2CfLBFIBGFsVMUf8fj4AFFRJJBKErzFKCQEOHECyMvj4pL8/Mw6LIIwOToLpBkzZhhjHIQWONk6AQ7JQHpFEkiESdBFIBElA96CVKUKJ4qePOEy2UggEaUNCvMtRkgsSECpEkhjxwJt23IZfoRp0UYgybYjij+8Bcnfn3vILiOI0oTOFiShUKi23hFluBkPVztXzoIEIDY+C4CjeQdkAkQiYPVqLgbi8WOgdm1zj6h0QQKpdCEWczFHAGcxIoFElGZ0Fkh79uyRe5+fn48bN25g06ZNmDlzpsEGRhTGw8EDbu5ipAK4FPUYQH0zj8j4vH0rnSyTMqVMD5/FRgKpdBAXx8UcWVkBFSpwbjaABBJROtFZIPXo0aPQsl69eqF27drYvn07hg0bZpCBEcqpUdELVy4BN5+/QGkQSPzdLEACyRyQBal0wQuhihW5rDWyIBGlGYPFIDVr1gwnTpwwVHeECur7c5GST18nIbcg18yjMT4kkMwLCaTSBR+gzQdkk0AiSjMGEUjZ2dlYtmwZKlSoYIjuCDUE+3G/cX6mC06/OG3ewZgAEkjmQyTiXJwACaTSgiqB9PIlJUkQpQ+dXWyKk9IyxpCeng5HR0f8+eefBh0cURgPj/eaNrsM9j3ajbDqYepXKOa8eiV9TQLJtCQkcEG7QiFQrpzyNrxASkripiWxszPd+AjDI5vBBgDly3P7NDeX+y/yMUkEURrQWSAtXrxYTiAJhUJ4eXkhJCQEZai0s9GR/MQ5ZbD/0X6s6LwCQkHJrdZAFiTzwVuFvLy4oF1leHhwVd/z8rgAX6qVU7xRtCAJhdzrx4858UQCiShN6CyQhgwZYoRhENrCCyRBjgdi02Nx7fU1NKnQxLyDMiIkkMyHpvgjgJt+xNsbiInh2pNAKt7wAom3IAGcKOIFEkGUJnQ2PWzYsAE7d+4stHznzp3YtGmTQQZFqIYXSNZ5XgCAfY/2mXE0xocEkvnQRiABgK+vfHuieMKYVATJCl0K1CZKKzoLpLlz58LT07PQ8nLlymHOnDkGGRShGl4gFWQ5AWJBiRZIBQXyF10SSKZFW4FEgdolg8REIDube12pknQ5L5CePzf5kAjCrOgskGJiYlBFiSPaz88PMTExBhkUoRpeIDEmgDDPA3fj7+Jp0lPzDspIvHnDBQnzkEAyLboKpNevjTsewrjw7jVfX/lge7IgEaUVnQVSuXLlcPv27ULLb926hbJlyxpkUIRqbG0BJyfudVMPLoOtpFqRZN1rAAkkU0MWpNKFMvcaQAKJKL3oLJD69++PcePG4dSpUxCJRBCJRDh58iTGjx+Pfv36GWOMhAK8FemDcl0BkEAijAMJpNKFYgYbD+8wiI3lshUJorSgcxbbjz/+iBcvXqB9+/awtuZWF4vFGDRoEMUgmYgyZbiaJPVcPwQAnIs5h8SsRHg6Fo4NK87wAsnREcjKIoFkakgglS4UayDxlCsH2NsDOTnceadqVVOPjCDMg84WJFtbW2zfvh2PHj3Cli1bsHv3bjx9+hTr16+Hra2tMcZIKMBbkGzzy6Ne+XoQMzEOPD5g3kEZAb5IZGAg90wCyXQwRgKptKHKgiQQkJuNKJ3oXWEwICAAvXv3RteuXeFHxU9MCi+QkpOB8MBwACXTzcZbkIKCuGcSSKYjOVnqTvH2Vt+WF0jx8VzmIVE8USWQAMpkI0onOgukTz75BD///HOh5b/88gt69+5tkEER6pEVSD1q9gAAHHl6BNn52WYcleEhgWQ+eGtQmTKce0UdXl5cxWXGOJFEFE9Uudhkl5EFiShN6CyQzpw5g86dOxda3qlTJ5w5c8YggyLUIyuQ6nvXR2W3ysjKz8LxZ8fNNqYHCQ/w7+N/DdonCSTzoa17DeCmISlfXn49oniRkgKkpXGvK1cu/DkJJKI0orNAysjIUBprZGNjgzT+H0YYFVmBJBAI0L1GdwDmc7MxxtDtr27o9lc3HHpyyCB95uVJZ5LnBVJOTsly4cRlxIExZu5hKEUXgSTbjgRS8YR3r3l5ScuIyMJnspFAIkoTOguk4OBgbN++vdDybdu2oVatWgYZFKEeDw/uOTmZe+bjkP55/A9EYpHJx/P43WM8TeaKVS6IXGCQPl+/5lw2trbyJv/MTIN0b3b+efQPfBb6oMe2HsgpyDH3cApBAql0oaoGEg9ZkIjSiM5p/tOmTcPHH3+Mp0+f4sMPuTTzEydOYOvWrfj7778NPkCiMLIWJABo7dca7vbuiM+Mx6XYS2hRqYVJxyPr2jv5/CRuxt1Efe/6ReqTd69VrMjFwFhbc9ajjAzAza1IXVsE+x/tB8CJ2u5/dcfefnvhaONo5lFJIYFUulAXoA1IBVJsLJCbK19pmyBKKjpbkLp164a9e/ciKioKX331FSZOnIjY2FicPHkS1atXN8YYCQUUBZKNlQ06B3BxYXsf7jX5eI49OwYAcLB2AAAsjFxY5D55gVSpEpdm7OzMvS8pcUiXYi9JXh97dgydtnRCem661uszxiBmYs0N9YQEUumCF0jKArQBzvXm4MBZdRULuBJESUWvNP8uXbrg/PnzyMzMxLNnz9CnTx9MmjQJ9erVM/T4CCXwAikpSbqMz2YzdRxSgbgAp16cAgAsClsEANh2dxtepb0qUr98DSR+0sySJJAy8jJwL+EeAGBXn11wtXPFmegz+OjPj5CSk6J23ZyCHPxy/hd4/OKB9n+0N5pLlQRS6UKTi41qIRGmZuXllZh+ajpiUs03x6vedZDOnDmDwYMHw9fXFwsXLsSHH36IixcvGnJshAoULUgA0LF6R9ha2eLxu8d4mPhQ5z5zC3Ix4p8RWHhBN+vP1ddXkZabhjL2ZTC84XC08WuDAnEBll1apvMYZJF1sQElSyBdfX0VYiZGJddK+DjoY5wYdAJl7Mvg4quLaP9He7zLeldoHcYYtt/djsAVgZh8fDJSclJw+sVp/Hn7T6OMkQRS8eDSq0t4nV70WYI1udgAEkiE6RAzMeZfmI8fz/yIczHnzDYOnQRSXFwc5s2bJykS6erqitzcXOzduxfz5s1DkyZNjDVOQgZeIKWmAqL3BgRXO1d8WIWLCdvzYI/OfS6KXIS119fi2+PfIj5T+2I2x55y7rUPq3wIK6EVJrWYBABYc22NTi4jRWRdbAP3DERM9n0AJUMgXXrFuddCKoYAABr7NsbpIafh5eiF62+uo92mdnib8VbSPvJlJFqsb4F+u/ohOjUaFVwqoFetXgCAaaemGSXIOy6OeyaBZLnsur8LzdY1Q5uNbZAnKtokaZpcbEDxyWSzxKQHQjdOPj+J6NRouNu7o2dgT7ONQ2uB1K1bN9SsWRO3b9/GkiVL8Pr1ayxfvtyYYyNUwAskgBNJPL2CuIvmgsgFchdYTcSkxuCnsz8B4JT77ge7tV73+HMuQLtD1Q4AgM4BnVGzbE2k5qZi3Y11WvejiCTOwfUl/rz9J7IE3PcpCQLpYixnaQ2pECJZVrd8Xfw35D/4OPvgTvwdtN3UFhdeXkC/v/uhxfoWuPjqIhxtHDGr7Sw8HvsYf4T/gYquFfEy7SWWXzLs/zAzE0h/r211FUhxcVycCmFc3ma8xZcHvgQARCVFYcONDXr3lZkJJCZyr4urBSmnIAdb72zFh5s+hMNsB4w/NN5iS2gQmuGvHZ/W+RQONg5mG4fWAunQoUMYNmwYZs6ciS5dusDKysqY4yLUYGMjrVUi62YbVG8QGng3QFJ2EsYcGqN1fxOOTEBWfhbsrLjUlB33dmi1XkZeBiJfRgIAQquGAgCEAiEmNJ8AAFhycQkKxPoVLuIF0o0sLtsLtpwyuvvqhV79WQqMMYkFqVnFZnKfBXkF4czQM6jkWgkPEx+i5fqW2H5vOwQQ4PP6n+PJ2CeY1mYaHG0c4WDjgB/b/QgAmHNuDpKykwptS194K5CTE+Diot06/HQk+fnAu8IeQsKAMMbw5YEvkZiVKMl8/PHMj3pbTnjrkZub+gxRS5xu5Pbb2xh3aBx8F/piwO4BknjIZZeXYd65eWYeHaEPSdlJEi/IsIbDzDoWrQXSuXPnkJ6ejkaNGiEkJAQrVqxAIn/bQZgcZXFINlY2WNd9HawEVvj7/t9aWYKORB3Brge7YCWwws7eOwEA/0X/p5UF6kz0GeSL81HFvQqqeVSTLB9YdyC8HL0QnRqNXfd36fbFwBWETEjgXh97tx4A4OTE3Q1uurLLLLWeDMWrtFd4k/EGVgIrNPRpWOjz6h7VcWboGVQtw02Z3r5Ke9wYeQPreqyDr4uvXNuBdQciuFwwUnJSMPfsXIONUdf4I4CrV1W2rPz6hHH48/af2PtwL2yENjg1+BQqulZEbHosfrv6m179aeNek/3c3Bak9Nx0rL22FiG/h6De6npYfnk5knOSUdmtMma2nSm5cfj+5PfYfGuzeQdL6MyW21uQK8pFfe/6Ss+RpkRrgdSsWTOsXbsWb968wciRI7Ft2zb4+vpCLBbj2LFjSE/XP96E0B3FYpE8DXwaYHLLyQCA0QdHIzlboYEMuQW5GHtoLABgbNOx6FazGxr7NtbazcbHH/HWIx4HGwd81eQrAFzKv66m7thY7tnWTozo3OtwsnFClzptAQAvE5Lw+/XfderPkuDT++uWr6uy7pG/uz9ujryJGyNv4NjAY6jnrTw71EpohXmh3F3y8svLEZ0SbZAx6iOQZNuXJIGUnZ+Nq6+vYtf9XUjITDD3cPAq7ZXkPxvRNgJNKzTFtNbTAHCWxMw83Supaspg4+EF0uvXXC0kVTDGMO7QOAzdN1RvC7IqXqe/RtDKIIz4dwQux16GjdAGvWr1wpHPjuDZuGeY3mY6praeiknNuVjIz/d/btYpmAjdWX+Tuyn+vP7nZh6JHllsTk5O+Pzzz3Hu3DncuXMHEydOxLx581CuXDl0797dGGMklKDMgsQzrc00BHoGIi4jDhOOTlDZx6LIRXiS9ATezt6IaBsBAOhTqw8AYOf9nRrHoBh/JMtXTb6CvbU9rry+onMWAu9ecyibCAiAnkE94VvWlVuY54wpJ6ZYxMVKHy6+Khx/pAwXOxfU964PgUCgtl2n6p3Qzr8dckW5mHZqmkHGaCyBlJKTgqH7huK3q7/pFR+SlpuG62+u40HCA7xIeYG3GW+RlpuGfFG+zn0pwhhDbFosDj45iLln56Lf3/0QtDIIznOd0WRtE/Ta2QvVl1fH4sjFBtmevmP8Yv8XSM1NRdMKTfFty28BAEPrD0XVMlURnxmPFZdX6NyvthYkT0/A8b2mj1GTeX03/i6WX16OjTc3YuXllTqPRxViJsagPYMQmx6Lym6VsaDDArya8Ao7e+/ER9U+gpVQGvbxc4ef0a9OPxSIC/Dx9o9xK+6WwcZBGI/rb67jZtxN2FnZYUDdAeYejv5p/gBQs2ZN/PLLL3j16hX++usvQ42J0AJ1Asne2h7ruq+DAAJsvLkRR58eLdQmJjUGP57hTNELOiyAmz0XfMBnR2lys71Jf4O78XchgECSPSdLOadyGFR3EADdC0fyAinLkStXMCB4gCTN39O6CpJzkvHd8e906tNS4C1IfAZbUREIBPilwy8AONeLIS4ExhJIc87OwcabG/HlgS8x/vB4nVylR6KOwG+JHxqtaYRav9ZClaVV4L3QG27z3GD7ky2sZ1mjzM9lMPrAaGTk6RbJf+nVJdRZVQcVF1dEl61d8P3J77H93nY8THwIMRPD09ETVctURVpuGiYcnYB6q+sp/U8Zm7XX1+LI0yOwt7bHpvBNsBZyEyHYWNlgRpsZAICfz/+M1JxUdd0UQlsLkkCgXSbbrgdSt/q0U9MMUoYAABZeWIgTz0/A0cYRRz87ioktJqKcUzmlbYUCITb22Ii2/m2RnpeOzls7m7WeTmkkJScF9VbXQ9uNbbXOslx3nQvO7hnUEx4OHsYcnlYUSSDxWFlZITw8HPv37zdEd4QWKCsWKUuLSi0wtilnih/xz4hCF41vjnyD7IJstPZrjU+DP5Usr1KmCpr4NtHoZjvx/AQAoKFPQ5R1LKu0zTfNvwHATavx+N1jrb4XIC0Sme/0DF6OXgitGioRSE29ODG2/uZ6XHh5Qes+LYF8UT6uvb4GoHCAdlFo7NsYfWv3BQPD5OOTi9wfL3D4wGttUSeQ4jPjsfKK1Jqw/PJy9NvVT2NgMWMMCy8sROetnZGSkwJ3e3eUsS8De2t7uXYiJkJKTgp+vforGvzWQGKpU0e+KB8RpyPQcn1L3E+4DyuBFWp51UL/Ov0xr/08HBpwCK8nvEb8pHg8HvMYa7uthZejFx4kPkDYn2EI3xaOZ8nPNP8wBuBZ8jNMOMJZg+d8OAeBnoFynw8IHoBAz0Ak5yRjycUlOvWtTQ0kHm0Ctf++z0055WLrgvS8dHxz5BudxqOMq6+v4vuT3wMAlnZcipqeNTWuY2dthz1996C2V228Tn+NTls6qQ05MCdRSVH4/frvOotbS2bikYm4/fY2/ov+D4siF2lsn52fja13twKwDPcaYCCBRJgedRYkntntZ8Pf3R/RqdGYcnyKZPmRqCPY/WA3rARWWNFpRSE3Tu9avQGod7Px04soxh/JEugZiK41uoKBYXHkYk1fSYI0xf8V+tbuC2uhtUQgObJykj/P6IOjDR7jYEhWrQL++EP6/m78XWQXZMPNzg01ytYw6LZmfzgbNkIbHHl6BCeenShSX8osSNEp0fjz9p/48t8v8dHmj3D77e1C6/n6yq8vy8ILC5GVn4XGvo2x7ZNtsLWyxd/3/8ZHmz9SedHKKcjB4L2DMenYJIiZGMMaDEPcxDgkTU5C9g/ZEE8XI+v7LLz79h1effMKBz49gIquFRGVFIWW61ti+qnpKt1hT949wQcbPsDM/2ZCxET4NPhTJPwvAfe+uoetn2zF5A8mo2P1jvBx8YFAIICV0ApfNPwCj8c+xtchX8NKYIV9j/ah1spa+OHEDzpbrXRBzMQYum8oMvMz0dqvNcY3G1+ojZXQCjPbzgQALLq4SGmxUVUoc7G9TH2JVhtaFSohoSlQ+2HiQ9xLuAcboQ32998PoUCIHfd2FMnilpGXgf67+qNAXIBPgj7BsAbaZza527vj0IBDqOBSAfcT7iN8ezhyCwoHUDHG8C7rHe4n3Ncrjktfbry5gb5/90XNFTUx/J/haLWhFWLTYk22fWNxJOqIJJYIAGb9NwvPk9WnP+55uAcpOSnwc/ND+6rtjT1ErSCBVEzRRiA52zpjbbe1AIAVV1bgXMw5ucDscSHjEFw+uNB6vWtzAkmVm40xJgl8VCeQAEiCJTfe2ojELO2yHl9Evxc9bi8lfmjZStrzQuehjH0Z3Iy7iVVXVmnVp6l59Qr46ivgiy+4SXYBafxR0wpNIRQY9q9XzaMaRjUeBQD49vi3RZqn7c0bLj7oato/+HTXp6i8uDL8l/pj4J6B+O3abzj27Bg+2/1ZIfHBC6rXCh6VhMwErLjCxcbMaDMDfev0xeEBh+Fq54qzMWfxwYYP8DJVfoKv1+mv0WZjG2y+vRlWAiss67gMa7uthZ21dJZUgUAABxsHeDh4oIJrBXQO6Iw7o+5gQPAAiJkYP575Ec3XNceDhAeSdRhjWHNtDer/Vh+XYy/D3d4df33yF7Z8vAVlHMpAE+727ljccTFuj7qN0KqhyBXlYs65Oaj9a22juXCWXVqGM9Fn4GTjhA09Nqg8dnrV6oV65eshLTcNCy4s0KrvnBypoJW1IP3v2P9wLuYcvj/5vZz40ySQ+KzV0KqhaOvfVmLFHn1wtN5lCMYdGoeopChUdK2INd3WaIzLU6SSWyUcGnBIMqVP17+64qsDX6Hn9p5o9nsz+C3xg/1se3jO90TtX2uj5fqWRq2hxBjDfy/+Q6ctndBwTUPsuLcDYiaGs60z7sTfKXTMFjfSctMw/J/hAIBxTcehnX87ZBdkY/TB0Wp/V7720dD6Qw1+ftQXyxgFoTPaCCSAO1Hxd1zD9g/D7LOzCwVmK+Lv7q/WzfYg8QFep7+GvbU9Pqj8gdrtt/ZrjUY+jZBTkKO1mLn/lMuI9PYtkAQzywokLycvzGk/BwAw9dRUxGXEadWvriRkJmDw3sH49/G/Oq974wb3nJ8PpKVxryXxRxoCtPVlauupcLF1wfU317H97nat1hGJRXiQ8ABbbm/BxCMT0W5TO9x7xvltVzz4Hn/d/Qsv017CWmiNphWaYkKzCSjrUBZ34u9g6aWlcn2pcrEtjOSsR418GqFLQBcAQLsq7XBu6Dn4uvjifsJ9NF/XHHfe3gHAxQQ1XtMYl2Mvw8PBA0c+O4KxIWO1ujC627vjz4//xPZe21HGvgyuvbmGhmsaYtmlZYjLiEP3bd0x8t+RyMrPwodVPsTtL2+jX51+Wv1WstTyqoWjnx3Fnr574Ofmh5jUGIkLzJA8THyIKSc46+/CjxZKyj8oQygQSlLcl11eplWpDt5a6+goLdNw4eUFbL/HHT8ZeRlyx5ImgfT3A869xscyzmo3C74uvohKitKrLtH2u9ux4eYGCCDAlo+36B2XElw+GHv67oGN0AbHnx3HqqursPfhXlyKvYSY1Bi5GJlbb28ZxX0vZmLsf7QfLde3RNtNbXE46jCEAiH61+mPmyNv4s6oO6hZtiZepr1Ey/UtcT7mvMHHYAomH5uMl2kvUbVMVcxpPweruqyCrZUtDkUdkrhfFXme/Bwnn5+EAAIMqT/EtANWByP0IjU1lQFgqampZtn+li2MAYx9+KHmtsnZycxngQ9DBCSPP2/9qXad+efnM0SAtd3YttBnSy8uZYgAC/0jVKuxbr29lSECzHWuK4tJidHY3sY5lQGMjVi7XLLs8GHu+zZowL0vEBWwxmsaM0SAfbb7M63GoStD9w5liACznmXN9j/cr9O6P/7IjRdg7OlTblngikCGCLB/Hv1jhNFy/PTfTwwRYFWWVGGvUl+xR4mP2KVXl9jRqKNsx90dbM3VNWz++flszIExrMW6FsxxtqPccYGpNpJxt175MZt5eiY78ewEy8jNkGxj/fX1DBFgjrMdWXRKtGR5VBS3noMDY2IxtywhM4E5zXZiiIDS3zA6JZoFrQhiiABzm+vGpp6Yyux+tGOIAKu9sjaLehel92/xKvUV+2jzR5LvZjPLhiECzPZHW7bowiImEov07luWO2/vMKuZVgwRYEejjhqkT8YYe5n6ktVeWZshAuyjzR8xMf+jqkEsFrOma5syRIB9fehrje2PHeP2Wa1a3HuRWCRZ3+sXL4YIsJC1IZL2V69y7X18CvcV9S6KIQLMaqYVS8xMlCzffne75Hd/nPhY8xd/z4vkF8xtrhtDBNjUE1O1Xk8dBx8fZCP2j2BTT0xlKy+vZLvv72aRLyPZi+QXLCc/hw3eM5ghAmzE/hEG2R5jjGXnZ7Pfr/0u2ZeIALP70Y59+c+X7GnSU7m2CZkJrNnvzRgiwOx/smd7Huwx2DhMwclnJyXf8eSzk5Ll009OZ4gA81ngw1JzCl8zp52cxhAB1uGPDiYZp7bXbxJIemJugXTwoLxg0MTeB3slB27rDa01nmyfJz9niAATzhSyN+lv5D7rurUrQwTYz+d+1mrbBaICyZ/+w00fqr0wRSckSC7QF588kiw/d45bFhAgbXsl9goTRAgYIsBOPz+t1Vi05VbcLUnf/AntxLMTWq/fq5dUIF27xolUvq/4jHiDjlWWjNyMQmJY08NpthNrua4lG3twLFtwcAcDGLOxETNVh4hYLGatN7RmiADr/ld3yfLMTOl3Tknhln137DuGCLCGvzVUecy9y3rHWq5rKTemHn/1YGk5aUX+PcRiMVtxaQVz+MmBIQIs+NdgdjvudpH7VWT8ofEMEWCBKwJZbkFukfu7FXeLVVhYgSECzHuBN3uZ+lLrdY9GHZUcs5rWW7uW21+dOnHv+ZsZp9lO7FbcLWY9y5ohApLfLDFRuo+zs+X7+vncz0pvnMRisUSoaiv08kX5kmOi2e/NWF5BntbfvyiceHaCIQLMfZ47y87P1ryCGuLS49iMUzMkQhMRYC5zXNi3R79lr9Neq1wvMy9Tco4VzhSyVVdWFWkcpiIjN4NVXVqVIQLsy3++lPssOz+bBSwLYIgAG3twrNxnBaICVnFRRYYIsG13tplkrNpev8nFVkxRVShSFT0Ce+DLRl/C29kbq7qs0uiu8Hf3R9MKTQu52fJF+Tj94jQAzfFHPFZCK/wR/gccbRxx8vlJtbVa1p/mgjmFdlloWk0ayCzrYuNp7NsYIxuNBMAVhDPkdBvfHvsWDAwfB32M8MBw5Ipy0f2v7lplRwHAbZkY5pQU4ErsFQBA1TJV4eXkZbBxKuJk64RFYYsgFAghgABudm7wc/ND3fJ10dqvNbrV6IaBdQdiUvNJ2PLxFjwY/QCp36Xi3OfnsKzTMjR34+LPvL0FUHWICAQCrOqyCtZCa+x/tB/7Hu4DwLlpXN+Xq3rzBkjMSpSLPVJ1zHk4eODYwGPoXas3rARWmNpqKnb33Q0XOy3nOVGDQCDA6KajcWfUHWzuuRlXhl9RGndXVCLaRqCcUzk8THyIZZeWFamvY0+P4YP1HyA2PRZBnkGIHBaJiq4VtV4/tGooWvu1Rq4oF7PPzFbbVjaDLTs/W5IFOeWDKahbvi561OwBAJLirB4e0v8ivy4P7z7h54TkEQgEWNl5Jeys7HD06VGtaqzNOTsH51+eh4utC7Z8vAU2VjYa1zEEbf3bopJrJaTkpOjlWge4ZIxh+4bBb4kfZv43EwlZCajkWgnzO8xHzDcx+LnDz/BxUV1Dw9HGEXv67sHwhsMhZmKMOjAK005Os/i55X44+QOeJT9DJddK+LnDz3Kf2Vvb49cuvwIAVlxegauvr0o+O/bsGF6lvUIZ+zLoEdjDpGPWiEnkWgnE3BakR4+4uzg3N+NtQ5mb7Wz0WYYIsLI/l9XZRfHr5V8lpuP78feVtqk9cRwDGCvnlyi3nHffuLjIt0/KSmJVllSR3Lnmi/J1GpMy+Dtwm1k2LOpdFMvJz2Ghf4RK7ixvxd1Su35GBmMCgfROe9cuxmadnsUQAdb/7/5FHp825Bbk6uVCWrSIG3OXLprbTjk+hSECrNKiSiw9N50xxliNGtz6p09LP2+wuoFWVgPGuLvn4sqGGxsYIsCc5ziz2LRYvfpYf329xGrTZkMblpSVpFc//734T+IeVuemHDiQ21/z5jE2+8xsyf7MystijDF26MkhhgiwMvPKSCwqdepw6xw+LO3nRfILicUjLj1O6bYiTkWodbMwxlhaThrbfGszE84UahUKYAx4q2e3rd10Wu/a62uswx8d5CyhTdc2ZdvubNPLAiYWiyW/GSLAvtj3hdb/I1NzLvqcxOJ++Mlhle0+3fWpxKLMn6t77+it1LJkTMiCVMLhg7RTUwGRkaYm49P9/3vxnyQQms9ea1+1vc6ZBl82/hJh1cKQU5CDgXsGFsqCepHyAveiuDoggVWd5D7jJ+fNyIDcbPFlHMpgX799cLJxwvFnx/HtsW91GpMiIrEI/zv2PwBcNfBqHtVgZ22HvX33okWlFkjJSUGHzR3U1nW6e1d+jCkpxg/QVsTWylavTJBz74uef6A+9h4AFxTu7+6Pl2kvMfM0l2LO1056Ep2O5Ze5FHF11iNFVE2/UhwYVG8QmlVshoy8DJ3rUTHGEHE6Ap/v/xwF4gJ8Gvwpjnx2RKvMOmW09muNj6p9hAJxATpu6ahyGho+2NqtfArmnuPm85sXOk8yg3qHqh1Q2a0yknOSJRlqygK1eStzq8qtUN65vNJtTf5gMqp7VMebjDeYfmo6AC5w+errq5hzdg7abmyLsr+UxcA9AyFmYnxW9zOzVFMeWG8gAOBQ1CGtK/an56bjo80f4dizYxAKhOhVqxfOf34eF4ddRN86ffWygAkEAsxoOwNruq6BUCDE7zd+x6GoQzr3Y2yy87Px+f7PwcAwtP5QhFUPU9l20UeL4G7vjutvrmPl5ZVIzErE3od7AUCn8g2mggRSMcXdXfo6JcU42/Bz90PTCk3BwCQnQF4gKZteRBMCgQDruq+TZBf9dOYnuc//uvMXkMa5EqpXkS8EyJv1GQOys+X7DS4fjD96/gEAWHxxMTbd3KTz2Hj+vP0nbr29BTc7N8kcVwDnujrw6QHU966P+Mx4hP4RqvKic0uhmHVyMjN4BW1jwJhuAsnRxhErO3PFHxdfXIxbcbckAmn7pf+QkZeB+t710b1m6ZiCSCgQcnXFIMCft//E2eizWq2XJ8rD0H1DMfM/TmR+/8H32Nxzs1xJA31Y3WU1/N39EZUUhVYbWuFR4qNCbXg32aGEVcjIy0DTCk3lsvqshFaSC9fa61zJEGUCSTF7TRn21vb4tTPnZll+eTl67eiFcvPLocnaJvjh5A/4L/o/yeTX3zT7Bqu6mKeERy2vWmjs2xgF4gJsu7tNq3WWX16Od9nvEOARgKixUdjZeydaVGqhc0kCZQxvNBzfNOOKbf545keDutqSspPw6a5P0WNbD9yMu6lXHzNOz8Djd4/h4+yDRWHqC0KWdy6Pee25bMapp6bi53M/I1+cj4Y+DVXOOWlOLEIgrVy5Ev7+/rC3t0dISAguX76stv3OnTsRGBgIe3t7BAcH4+DBg5LP8vPzMXnyZAQHB8PJyQm+vr4YNGgQXisUZ0lKSsKAAQPg6uoKd3d3DBs2DBkZxiv2ZmhsbKSiQds4JH3g52bbcW8H0nLTJDE42sYfKVLBtYLEFz377GxcjuX2NWMMW+5sAdIqAQAqKoRcOMoYFpTtpo+DPsb01txd6ch/R+LSq0s6jy07PxtTT00FAHzf6vtCFcLd7d1x9LOjCPQMxMu0lwjdHKq0xICiQHoRl4LErETYWtmigXcDncdlKqKigPh4wNYWaNxYu3U6B3RGr1q9IGIifHngS5Qvz528z9zjLsa6WI9KAo18G2FEoxEAgDGHxmgsZPou6x06b+mMTbc2wUpghTVd12B2+9kGqQNTpUwVnB16VnK8ttrQSu4iWFAgnRh6/1vO2rc4bHGhbfN1af6L/g+P3z0uNN1IbFqsJC2+Z2BPtWPqUK0D+tbuCzETY9eDXXiX/Q4uti7oUbMHfu38K6LGRuHZ+GdYFLYIzrbORf4N9IWfJumP239obCtbd2pGmxmoUqaKwcczqcUk2FnZ4eKrizj14pRB+rzz9g6arG2Cv+7+hf2P9qPhbw3x+b7PdZoa5sSzE5KppH7r+hvc7d01rjO80XA0r9gcGXkZWBDJ/W6WaD0CLEAgbd++HRMmTMCMGTNw/fp11KtXD2FhYYiPj1fa/sKFC+jfvz+GDRuGGzduIDw8HOHh4bh79y4AICsrC9evX8e0adNw/fp17N69G48ePSo0ke6AAQNw7949HDt2DP/++y/OnDmDESNGGP37GhJtayEVBf6O8Ez0GWy/ux0iJkJ1j+rwd/fXu89+dfqhX51+EDERBu4ZiKz8LNx+exv3Eu5BkMZVq6tUSX4doVDezaaMGW1noEfNHsgV5aLn9p46zwG19NJSvEp7hcpulTEuZJzSNl5OXjg28JjkzrzD5g5IyUmRa8MHaPN32o9fc8dyfe/6RbYKGBPeetSkCWBvr76tLEvClsDZ1hkXX13ESzEXjJ6X6oF65etJgnxLE7M/nI0y9mVw++1t/Hb1N6Vt8kX5WHZpGQKWB+DE8xNwtnXGP/3/wfBGww06loquFXFmyBk08G6AhKwEtN3YViJmXr3i3PMC6zzAKQ59avdBi0otCvVRya0SOlbvCICbK0txupE9D/cA4KY3quBaQeOYlndajmENhmFa62k4O/Qs3n37Dnv77cWoJqNQzaNa0b+0AehXpx+shda4+voq7ifcV9t22aVlSM5JRqBnoF41tbTB29kbXzT8AgAKWd71Ydf9XWi+rjmeJT+Dv7s/etfqDQaGDTc3IGB5AGaenqmyonh8ZjyWXFyCBr81QOjmUIiZGAOCB6BbzW5abVsoEGJ119WwEnCTC9tb28tNd2VRmCIgSh1NmzZlo0ePlrwXiUTM19eXzZ07V2n7Pn36sC4KEaQhISFs5MiRKrdx+fJlBoBFR3M1W+7fv88AsCtXrkjaHDp0iAkEAhYbq11wpbmDtBljrG5dLljyyBHjbidkbQhDBJjnL55KUzj14V3WO+a70JchAmzMgTHs26PfcrWSKr0oFADKU748931vqYmRTstJk9QbCVkbonWqbnxGPHOd68oQAbb51maN7aPeRUnS6T/f+7lkuVjMmKsrN85Bg7jnwA8v6RyEeP06Y0uWMCYyTKkerRg2jBvv5Mm6r7skcglDBJhDr6+44PTqB9nu+7sNP8hiAp+Q4D7PvVBZh0NPDklqPyECrO6quuzGmxtGHU9Kdgr7YP0HkvpVx54eY6dPv08k8HjE7H60Y8+Tn6tcf8+DPQwRYOXml2MXL+cxgPs/MsZYmw1tGCLAFl1YZNTvYGq6be3GEAH23bHvVLZJzk5m7vPcGSLA/rrzl1HHE50SLQngPx9zXq8+CkQF7IcTP0iOvfab2ktqVkW+jGTNf28u+cx3oS/bcGMDE4lFLCc/h/1972/WbWs3yRj4RJa+O/vqlUzAn/MH7xms13cpCsUiSDsvLw/Xrl1DaKjUXSMUChEaGorIyEil60RGRsq1B4CwsDCV7QEgNTUVAoEA7u8DdyIjI+Hu7o7GMn6E0NBQCIVCXLqk3DWTm5uLtLQ0uYe5MYUFCZAGa/NThXSopnv8kSIeDh5Y352bq2fFlRVYfW01AKAghUt/VbQgAcpT/RVxsXPBvn77UMa+DC7FXsKoA6O08tn/eOZHpOWmoaFPQ63uZqp5VMPO3jshgADrb66XzH/24gVXOdvWFmj2fj7auHfc3E+6BGiPHQt8/TVw8qTWqxQZXeKPFBnddDQaeDdAth03eat9ThXLS9k1ISMajUB97/pIyUnB9ye4SVYfv3uMrlu7otOWTniQ+ACejp74retvuD7iOup71zfqeNzs3XDksyMIqxaGrPwsdNnaBTvOvw9lcI/G182+VmsV7hLQBd7O3ojPjMeDfC5Q+O1b4EXCW5yN4WKtPg762KjfwdQMqse52f6886fKqXuWXlyKlJwU1PKqJTlPGovKbpUxuN5gAFx4gq6k5KSgx7YeknUnNp+Iw58dRnp8WTx9yk2gff7z89jRawequFfB6/TXGLpvKOr8Wgc+C33Qa2cv/PP4HxSIC9DEtwlWdFqBNxPfYFuvbXolE8xpPwcHPz2I5Z2Wa25sJswqkBITEyESiVC+vHzWQ/ny5REXp3z6iLi4OJ3a5+TkYPLkyejfvz9c3xdpiYuLQ7ly5eTaWVtbw8PDQ2U/c+fOhZubm+RRSdkV3MToWgtJX2QDL4UCIdr5tzNIv2HVw/BV468AcH58V1RAVrotgMIxSIB2AgngxMv2XtshFAix8eZGSTaVKp68e4JVV7mA0Pkd5msd/9Gyckt81YQb/4h/RyArP0sSf1SrFuD1vtxRagr3rEuANh8b8sw0k8UjIQF49D6Gt0VhL4tGrIXWWN11NeDMTW9hn+NvMfMpmQMrITcRNMDNMTV031DU/rU2Djw5AGuhNSY0m4AnY59gRKMRsBJamWRMjjaO2NdvHz4J+gR5ojz8eoyr82Nf9i2+b/W92nVtrGwwpN4QAMC2Z6vg8r5E1ab/TkPMxGji2wR+7n6qOyiGdK3RFW52bniV9kpS+02WlJwULL7ITcI9o80Mk+zH7z74DkKBEAefHMT1N9e1Xu9BwgM0XdsUB54cgL21Pf7s+ScWfLQATGSNJk2ARo24efkEAgF61+6NB6MfYH6H+XCzc8ODxAdIzkmGr4svJrecjHtf3cPl4ZcxuunoQnGaumAltEKngE4GqXdmLEr0GSw/Px99+vQBYwyrVhUtI2LKlClITU2VPF6+fKl5JSNjKguSn7ufxPrR2Lex3qnHyvilwy8I8AgAAISWHQKAKzbIFxyURVuBBHBWrvkd5gMAJhyZgE92fII119bgRcqLQm2nnJiCAnEBOgd0xodVPtRp/HPbz0VF14p4lvwMM07NkAikevWkmYYs2w1lHcqiWhnt4yv4ffrqlU7D0Zvz76d9ql1bKrx1pWmFplje+wcAQFqSndHKTxQXWlZuiUH1BoGBYePNjSgQF6Brja6499U9LAxbqFVAq6Gxs7bDtl7buPmuUjlB81GjGnC1U/KHU4CPgTn69AgqVOLmLtt3iTvg1WWvFVfsre3Rt3ZfAMAftwoHay+OXIzU3FTUKVfHZN+/ukd19K/TH4D2VqTDUYcR8nsIniQ9QSXXSjj/+XlJ+YSoKCAxkSsXI2sbsLO2w6QWkxA1Lgqru6zGkc+OIObrGMwLnYdaXrUM/r0sFbMKJE9PT1hZWeHtW/lJFd++fQtvPl9YAW9vb63a8+IoOjoax44dk1iP+D4Ug8ALCgqQlJSkcrt2dnZwdXWVe5gbUwkkABjdZDQA4LPgzwzar5OtE/b3349RjUfhkwpfA1DuXgN0E0gA8E2zb/B5/c8hYiLsfrAbI/8diSpLq6DG8hoYe3As/nn0D44+PYpdD3ZBKBDi59CfNXeqgIudC1Z34dyDiy4uwulL3M6QFUjIcUdIxRCts7lEIu6EBUgtScamKO41Wb5s8wkEAkAsFiAxsejjKu78HPozqpapiuBywTg84DD+6f8PapStoXlFLREr9/yoxVpojXXd16G6kHOV92zWSKv1qnlUw4dVPgQDg9idM23efMAdqJ8EfaL7QIoBvJvt7/t/ywUtJ2cnY8mlJQA465EpraW8tW/3g924F39PbdujT4+ix7YeSM9LRxu/Nrg64ioa+jSUfP7ggbStsv+rp6MnRjYeiY+qfWQyS6clYVaBZGtri0aNGuHEiROSZWKxGCdOnEDz5s2VrtO8eXO59gBw7Ngxufa8OHry5AmOHz+OsmXLFuojJSUF165dkyw7efIkxGIxQkIst06NIrxASjLcDBsqGVhvIN5OeosxTccYvO9Az0D82uVXZCd5AjCcQBIIBPi9+++4OOwiZrWdhQ8qfwArgRWeJD3Biisr0H1bd4T9yRU1G1p/KOqUq6PX+LvU6IL+dfpDzMS4cDUdAFC3roJA0iH+SLaulaksSIYSSNbWUteiCm91qcLb2RtRY6Nwe9RttQX09OHVK8DHB/j8c93XFQqEYCmVAQBVq2h/4fuiAWdFihVwsZos3Rv1vetbTPaZoWlRqQWqlqmKzPxMSUFDAFgUuQhpuWmoW76uyWOvannVkgjSOefmqGx3+sVphG8LR54oDz0De+LYwGMo5yQfWqJJIJV2zO5imzBhAtauXYtNmzbhwYMHGDVqFDIzMzF06FAAwKBBgzBlyhRJ+/Hjx+Pw4cNYuHAhHj58iIiICFy9ehVjxnAX7vz8fPTq1QtXr17Fli1bIBKJEBcXh7i4OOTlcWbhoKAgdOzYEcOHD8fly5dx/vx5jBkzBv369YOvr6/pfwQ9MaUFCQDKOZUzak0bXgwYSiABnEgKqRiCaW2kKcV7+u7BqMajULVMVQBcfaNZ7WYVYeTA0o5L4SH0Q14Cd9GRsyDluaJx+WZa9yUreE1hQcrKAvh7hZYti94fb4QlgcRhrP/M9u1c3SqZMnBaw5j0/1a5svbr9QzqCQ8HD2Tava8kn+5bYq1HALfvBtblKmvzNZHeZb3D0ktLAZjeesTzQyvOlb3t7jZEJUUV+vx8zHl03doV2QXZ6BLQBdt6bVNazfvhQ+lrEkiFMbtA6tu3LxYsWIDp06ejfv36uHnzJg4fPiwJxI6JicGbN28k7Vu0aIGtW7dizZo1qFevHv7++2/s3bsXdepwd/+xsbHYv38/Xr16hfr168PHx0fyuHDhgqSfLVu2IDAwEO3bt0fnzp3xwQcfYM2aNab98kXE1ALJ2PBhXcoCtAH9BJIibvZuCA8Mx69dfsXTcU/xbNwzPBj9AL4uRRPGXk5eGF2Zc7XBJRbv8Aj5NtIzTqBLU637MrVAunyZKxro6yut3VQUSCCZhn/fz6WakKC7qy0tDcjlkitRXvnMIEqxt7bniii6vK8xllahRMYfycILpOPPjiM2LRYLIxciPS8d9crXQ3hguFnG1MCnAboEdIGYiTHv3Dy5zy7HXkanLZ2QmZ+JDlU74O8+f8PWylZpP2RBUo/ZBRIAjBkzBtHR0cjNzcWlS5fk3FynT5/Gxo0b5dr37t0bjx49Qm5uLu7evYvOnTtLPvP39wdjTOmjbdu2knYeHh7YunUr0tPTkZqaivXr18PZ2XyVW/WhpAokQ1qQNFGlTBV4OyuPO9MV78z3LpTytzDi3xG49vYiYPN+sLnuWvcjuz9TUoBM5fXaDIase80Qxg4SSMYnORk4+34mE7EYePdOt/X5ME4XF8DBQbd1v2j4hUQg2WVXRaBnoG4dFDOqeVRDy0otIWZiLLu0TJIVG9E2wqyZmrwVadOtTYhJjQEA3Iy7ibA/w5Cel462/m2xt99e2Fsrr/oqFpvXgvTgAReK8M8/pt2uLliEQCL0gwSSZXH7NqcubHzv40z0GUw6OgmwTwGg23x5ijFlxrYiGSr+iIcEkvE5fFh+kmoVEw+ohBdIuliPeGqXq416AVygmTBDhbm3hMFbkX658Asy8jLQwLuB2avEN6/UHB9W+RAF4gL8cv4X3I2/i9A/QpGSk4IWlVrgn/7/qJ38+dUr+ZsvUwukzZuBO3eAJUtMu11dIIFUjClpAskYMUimhJ9ipH9obQDAo3eP9BJIivvTmAJJJAL4GqskkIoPvHuNRyGxVyO8oNJHIAHA6v7cvIfZaY7IydGvj+JEn9p95NxUM9vOtIg5Bqe24uaO/P3672j/R3u8y36HJr5NcPDTgxrnspO1HgGmF0hPnnDPV67ol41pCkggFWP4ejVpaSj2NWdSU4F0LgHMqDFIxkIslgqkST0/kmatGcCCZMxMtrt3uePHxQUIDjZMn7xA0vWiTWhHQQFwiCtmLakXputvzbdXqJerNSHVa8Du/bSCMiGiJZYyDmXQvSY3n2dj38boWqOrmUfE0da/LVpUaoFcUS7iM+NR37s+jnx2BG72bhrX5eOPrK25Z3MJpPR0aZFaS4MEUjFGkiUF3S7AlgjvXitTRjoprSKWLJCePePM1XZ2QFCgFdZ1Xwc7KzvYOmcDsFwXG+9ea95ceqIsKmRBMi4XLnBWxrJlgQ7vZ/0xpYsN4GLVKryfl/a1bnNCF1tmfzgbvWr1wu/dfrcI6xHAZdnNbDsTAFCnXB0cG3hM60K+vEBq9L4MlikFEmNckUqey5dNt21dIIFUjLG2hqTkf3F3s2mKPwIsWyDxFbTr1OH2S+1ytXFn1B10qsPV59LHxWb73qJvCoFkKPcaQALJ2PBBrZ07c5mHgOldbIB026VFINUoWwM7eu1EPe965h6KHKFVQ/Fw9ENc/uIyPB09tV6PF0itWnHPphRIcXHy8U8kkAijYMpikcakpAikejLnzoCyAahYjhu0PhakWu8r+hvLxcaYNBPKGAIpOVmaSk4YDl4gdesmdZGZ2sUGSAWSqaq9m5tduwArK2DLFnOPpDA1PWvCwUa3dEQ+Bql1a+45MZE7J5gC3r3Go2KOeLNDAqmYU1ICtTUFaAOWLZD4+KN6CjeXvBtUHwvS+9JeRrsAxcRwfVtbA021L9OkEXd3qfWL4pAMy5MnXLyGtTXw0UdSC5CpXWxA6bMgLVzICYj1602/7Z9+AoYMMVwwc1KS9Jjhi8OKRKYL1eAFUo33s+7cugWLDPYngVTMKSkCSVORSMCyBRJvQapbV365PgKJtyDxfRlLIPHutYYNVcd96YNAQG42Y8Fnr7VpA7i5SQWOvhakogik0hSD9OKFNNvzwgXTXszFYmDWLGDTJuDGDcP0ybvXKlXikn34UA1Tudl4gdShAzc1UUEBcPOmabatCySQijklTSAVRwtSaip3AgUMa0His8ri4rgTiKHhBZIhphdRhASSceDda13fJ1HxLjJdLUh8e0O42EqDQNqxQ/o6Jwe4eNF0205OBvLzudd37himT14gBQVxz57vQ5dMLZACAgC+LrQlxiGRQCrmlEaBlJ8PvJ9WzyLg3WuVKkn3B4+uAokxqQWpZk3OlSIWG0doGCNAm4cEkuFJSZHGjHXrxj3LWpC0jR/JzpaW1DCEi600xCBt28Y98+egkydNt21Z6yB/rikqfPyRuQQSn8EWECB175NAIgxOSRBIshNnqhNIsm4gS7IiKQvQ5tFVIGVnSwOby5Y13kUoOZmrgQSQBam4cOQIZ0kMCgKqVeOW8RagnByp6NEEf8G1s5PWUdKH0mJBevSIc21ZWwM/cLN74NQp021fViCVBAuSbIq/rECyxEBtEkjFHL5YZHEWSMnJ3IzygDSuQRk2NpAUp7MkgaQqQBvg4kQA7QUSvx+trLi4AP73MHQmGz9vc0BA0awIqiCBZHj4+KOuMjUKnZykNw7autlkU/yLUs6HF0gZGdqLs+LI9u3cc4cOQJ8+3OuLF40/RyKPMSxIvEAKfD+NnikF0uvX3PneyoqbHLtJE255VJTlZWOTQCrm6GJBOn4cmDRJ6s+2FHj3mqen5okzLTEOSVWANqC7BYk/QZQpI1+Mz9AWpPPnuWdjuNcAqegigWQYCgqAgwe517x7jUfXQG1DpPgD3H+Rt0CVVCsSY8Bff3Gv+/UDqlQBKlfm9gfvojY2svs1Pl73eDNFsrOlMZPmsCDx8Uf+/txNr4cHUL06t+zKFeNvXxdIIBVzdBFI48dzqaq7dhl3TLqiTfwRj6UJJJFIavZW52JLT9cu0Jrfj7xlkM/qM7RAMmb8EUAWJEMTGcmJ5zJluKrnsugaqG2IDDYefVzAKSnAyJFSkW7J3LnDxevY2QE9enA3LR9+yH1mKjebovAtqpvt8WNO+Hl4cBlkgHkEUkCAdJmlBmqTQCrmaFsoMidHOt/N1avGHZOuFGeBFBXF3ZE5OEjvgmThXWwAN+eZJvj9yAskY7jYcnOlJyISSMUD3r3WuXPhKWF0tSAZooo2jz6p/jt2AGvWAD/+WPTtGxs+OLtzZ+l/mRdIpgrUVvwPFdXNJht/xLtYzS2QLDVQmwRSMUdbC9LDh9IJbS1NIGkToM1jaQKJd68FB3M+dUVsbQFHR+61Nm42WRcbYBwX27VrnEjy8pI/SRkSWYFkquq8JRnZ6tmKmMvFBugXqP34MfdszEmYDQFjUoHUr590ebt23PO1a1yJD2PD7y/emlxUC5Ji/BFgOQLp0iXLOl+QQCrmaCuQZP9U168briKrIeBPrvzJVh2WJpDUBWjz6BKHpOhiM4ZAknWvGWvOTf6iLZtSTujH06fcRc3aGggLK/x5cXOxPX3KPRsjbonPkOJvBovClSvA8+dcEHyXLtLlFStyF3exGDhzpujb0QS/v/iJiYtqQVJM8QdMK5BkM9h46tfnju+EBCA62vhj0BYSSMUcXiBpinGRFUjp6fIzKZsbXU7YliaQ1KX48+gikBQtSPxd46tXhruzMnb8EcBdVPjqvORmKxq8e61VK+mxJIu+FiRDCiRdxA4vkJKTDV+Retcu7sI7fXrR++KtR927F640b0o3G7+/QkO553v3iiYAFVP8AdMJJLFYeu2RDUmwt5eeQy3JzUYCqZgje8JUdwFWNMtakptNl5gISxVIyjLYeIpiQeIvQDk5hivlwNcbadHCMP2pguKQDINi9WxFdJ2w1hBVtHl0jUFiDHj2TPr+zZuij0EWvpAm/6wvIpE0vV/WvcbDu9mMHajNmHR/NW/OuetzcvS/wRWJpC5OZS625GTjVO3niY3lxm9tzWWxyWKJgdokkIo51tbSO3V1F1BeIDVsyD1fu2bccelCcbUgJSVJA8wNJZAUg7Tt7bmCkYBh3Gxv33InXIFA/ZgNQXESSElJpokn0ZXUVOC//7jXyuKPAN0nrDWnBentW/n6QYZ2s/GJKPfvF62fc+e4sbm7K3drtm3LPd+6ZVyrS0qKdNYAHx+gdm3utb5xSM+fc/GH9vaAn590OX++Ycy4NfX4+KMqVQonG1hioDYJpBKApmKRycnSi+vgwdyzpQgk2Tskbe5o9RFIfGVqQ8PHAvj7y2erKaKPBUl2yhJZN1tR4cccECANHjcWxUUgpaVxF56mTU0fm/fsGdC/P/Dll8CiRcCBA5x1gL+LP3qUe12zpuqAel1cbPn5wLt38usVBVmBpI0LmHev8RjagsTH17x7x8Wz6AvvXvv4Y2lxWlnKlwfq1OFenz6t/3Y0we9TNzdO1PA3NfrGIfG/T82a8kkl1tbS60hRfjdNKAvQ5uEF0rVrxrVi6QIJpBKApkBtfkqJypWlpmFLCdSWvUMyhgVpyRLu5LJnjz6jU482AdpA0SxIgGEDtfkxG9t6BBQfgXT8ODfGx4+lBfRMxerV3MX4t9+AiRM5NxovXoOCgG+/5dqpcq8B0huL1FTNNwO8tUMolFomi4KPD/eclycVXupQFEiGtCBlZwMxMdL3fKyNruTnA3//zb1W5l7jMYWbjf/v8OdGfgJrfS1IyuKPeEwRh6ROINWsyXlDsrK4OCtLgARSCUCTQOL/TMHB3B/DwYEL1OYPVnPCW49cXbk7JE3oKpCOHeMuGiNHancC1wVtArSBogVpA4YVSNrETBmK4iKQjhyRvuZvJkwFL8hCQ4Hevbn9Ym/PXaQfPpR+Hh6uuo8yZbiKxIBmNxtvkfDy4kRSUbG1lRYb1EbsGFMgPXkib8XS18128iQnEry8pCJIGaYI1FZ0h/L/26IKJNn4Ix59BFJOjm5ZZ8oy2HiEQum0I5biZiOBVALQVCxSViBZW3MplYBluNl0jYfQVSDxF4yEBOB//9NtbJqQ/V3VUZQgbcA4LjYSSByMmVcg8ReX0aO5Aoq3bnExOi9ecO615cuBP/9Un3EoEGgfqG3I+CMeXeKQeIHEW68MKZD4+CMefS1IvHutd+/CcTKytGnD/fYPHxpvqhXF/cWfa54+1S8O09AWpK+/BqpW1X7aFXUWJMDyArVJIJUAdLEgAUCjRtyzJWSy6Vq0Tl+BBAAbNhjubk8slt6h8rEIqtBWIInF0jbGsCDl50vHTAKJ49Ej+TtgQ82Wri28S6hyZekyoZALoO3QARgzBhgwQHM/2tZCMmQVbR5daiHxAqllS+7ZkDFIvEDiLdH6CKTcXGD3bu61OvcawP1HGzTgXhsrDklRIHl6St2aurqhGFNeA4lHH4F07hx33uJdkuoQi6X7X9msA4DlBWqTQCoBqBNIjEnvihUFkiVYkHQ9YesikGQDwDt14p5HjOBiFYpKTAx3p29rq/rPzsMLJE1ZUqmpUheBMQTSo0ecSHJxkc9gMRbFQSDx1iM+YN2UFqTcXOlvIyuQ9EHbQG1DVtHm0SXVn79Atmql/TrawgskvqCiPi62w4e5oP0KFaQiTh3GdrMps/jx53FdA7XfvuVuwIRC5RYcfQQSn8V74oR2bXNzOXewquOdF0h371pGpjIJpBKAOoH06hV34bW25oLgAKBxY+7ZEgK1jeliy8iQFqL7/XfuTvfpU8PMAcXfvdWsqd4MD2hvQeJdpE5O8pkzhnKx8SfU4GDDxJ9oghdI8fGGqWxsDHiBNGwY9/zwoTRpwNjwFxcHh6IHTBcHF1t6ujRDypgCqWdP7jk2Vrv5D2Xh3Wt9+2r3H+FjlIwtkPj/EqB/oDZvUatSRXm8p64CKS1N+vvevav52OPda1Wrqj5n+vpy4lQs5q5P5oYEUglAnUDi/0Q1a3LWDoAL0HNw4AQEXzTMXBjTxcZbjxwduT/eypXc+/nzi16unxdItWppbqutQFKW4g9I79CTkopm/dI2685QeHlxMRoikeED5A1BTo7UNfLFF5xlraDAdMkLvHvNz6/oU75oWwvJmAJJk4WTtx55ekpv1lJSDGPRZUwqkEJCpIKCdylpQ2YmsH8/91qTe42nVSsuXf75c+NkQCpmsQH6p/qriz8CdBdIvMDn0ZTNpyn+iMeS3GwkkEoA2ggk2UBiSwrUNqaLjb9b5cVXeDh3d1lQwF0Qi2LV4AUSX7hNHbpakGQDtPn1HRy410Vxs5kyQBvgTOn8SdcS3Wxnz3IXZ19f7v/Bx5KZKg5JWfyRvmjrYjNkFW0ebS1IslNMuLlJj2lDxCHFxXHWDKEQqFZNeuOii5vt0iUuxbxiRamVXRMuLtILujHS/dW52O7c0W36IXXxR0DRBZImK5q6DDZZLClQmwRSCUBdoUhVmVb8CcDcgdrGdLEpuxisWMGVFLhyRWpR0gf+xKuLQEpLUy/KlKX4A5x1gXezFSeBBFh2HBLvXgsL435jXiCZKg6JDw43hEDSNkjbGBYkbWOQeAtStWrc763PPG6q4K1HVapw7mleBOgSqH3lCvfcrJluFj1judkYU76/goI4q1VSkm6/nbEsSPw8dZrikMiCRJgFXS1IgOUEausrkLKzNVuAlAkkX1/g55+5199/L19YTltkM9i0EUiyVbbVxUQoS/HnKWqg9rt30nU1Zd0ZEkMKpPh4w2Y9HT7MPfNTSZhaIMm62IqKrkHaxnCxvX2rvgKyrEACpNlYhtinvEDiXXdFEUh8LR5t4QO1T50y3ITSABc7qqyIrr09UKMG91oXa6e6GkiA/gKpRw9OsD17pt7NyAskTUktjRpxAjU6Wvv5BY0FCaQSgCqBlJ8v/VOosiDduGHeAFp9Y5AA+TmdlKHKnTBiBJehkpkJfPWV7ie16GjOFG9rKz3Zq8PWVpolpc7NpsqCBEgFkr6B2vyJtEoVzoJmKgwlkEQiLqW6dm3DzAD/6hXnJhUKpbOk8/8RUwskU7nYxGKp29mQAsnLi7tAisXqt68okIxhQeIFkj4uNt6arqtAatGC+4/Hxho2fo3/LV1cpO5IHl3jkNLSpDdImixI6enaTc/ECyR+mh5AtRVNJJJOUqzJguTqKh2jua1IJJBKAPwFNT2dE0U8jx9z752dC5+EAwO5i7Y5A7UzM6UiR9sTtp2ddA4hTW42VQJJKATWrOFiZA4cAHbu1H7MgDT+KDBQcwYbjzZxSOosSEV1sZnDvQYYTiC9eMFdSJOTDVMw8+hR7rlJE2kGGW9BevZMs/g2BMZwsSUmqr7hkZ2pna9+bQisrKTWIHVix5QCib/APn+unaBOSOD2h0Agta5ri4MD0Lw599qQcUjqrH26ZrLxv4+3t/RcpIibm/Tcqk1SBS+QKlUC2rfnXqsSSDExnDXM1pZrrwlLiUMigVQCkD3gZS/A/J1wnTqFU1atrMwfqM0LGHt77i5JGwQC7eOQ1AWk1qrFudgAYNw43VK7dQnQ5tFGIKkK0gaK7mIzt0AqqqlctkqyIdx1iu41gBMN5cpxFsWizgavCcYM62LjBY9YrPrixu+DMmWkGa2GQpPYycuTXlCN6WLj3Ufly3P/ObFYuxtA3r1Ws6Z+FlZj1ENSluLPo+uUI5rijwD5+fm0cbPJCiTZ76/MIs9b1qpVk58kVxWWEodEAqkEYGUl/VPLutk0TYXBu9nMJZBk3Wu6BEUaQiABwJQp3Anh7VvO1agtuqT48+gikIzhYjPlHGyyGMqCZEiBJBJxE9QCQMeO8p+Zys2WkMC5MQQC6b4tCtbW0oubKjFqjCraPJoE0osXnFhxcpJu31AWpNxczlIESC1IAoFUDGgjdvWNP+IxRhySshR/Hv44vX9f3mugCk3xRzy80OZdsapgTF4gNW/O3ei+eaO8tIK2GWw8sgLJkHFdukICqYSgLA5Jk0Ay95Qj+p6wDSWQ7OykpvGLF7XfvrEsSMZysYlE0gt+SRBIRbVGXbnC/dbu7oUviKYK1OatRz4+hrPmaKqFZIwq2jyaaiHx7rWqVaU3Q4YSSFFRnPhydZU/l/A3MNoEahdVIDVtyoUsJCQY7thR52Lz8+Os7vn52lnItLEgAdoHasvWZKtYkRNHfOVxZVY0bTPYeIKDufNzSop5J1UngVRCKIpAMlegtr4ZNboKJHXxFs2acc/aCiSxWHqyMZaLTZ0F6c0b3fdVVBQXh+HgoF1QuSGxRAsS714LDS0cQ2aqWkh8/JEhp3zRFKhtjAw2Hk2p/orxR4DhXGyy8UeylmhtM9kYkwokbesfKWJrKxUIhopDUre/BALdphzRVAOJR1uBxFuPypWTVv3n45CUpftrm8HGY2MDNGzIvTanm40EUglBUSClp0vNzqrSuvlA7cxM8wRq63tHq41Aks3YUde/rgLpxQvuzsnOTjexUVQLUvnyXIyASKS7BUV2ihFt/P+GhBdISUnaZcaowpACia9/pOheA0xvQTJEgDaPplpIxhRImqxBygQSv05KCpcVqi+KAdo82rrYXr7kfjPZArr6wNdDMoVAArQP1M7Lk7q4DC2QZAOueTfj6dOFb+J0tSABXDmWixeBXr20X8fQkEAqISgWi+TdQN7e0oNeESsr6WzU5nCzGdPFlpQknWdO1fcHOJO6QMAJH20uvLIZbLqIjaIGaVtbS++4dXWzmStAG+CEu40N91pTEUNVpKfLWxmKIpCSkqR3pLIB2jy8VfDNG+2nRxGJ1Nf/UYYxBJImC5IxqmjzaOtikxVIrq7S8hdFsSKpEki8i+3xY/X7h7ce1alTOJ1eF3iB9N9/hpnjUpNA0jbVPyqKO0ZdXKT7SRVFEUiNGnH7NDkZuHlTurygQPsUf1lateKy2ZTNG2cqSCCVEBQtSPwdsCr3Go85C0Ya08XGXww0Zey4ukovipcuad62PvFHgGaBlJMj9ekrc7EB+meymVMgCQRFd7MpWjeLIpCOH+cuXrVqSeO6ZHFxAfz9udf8vtbEl19yKdK8xVYbSpqLTR8LkkCgXXkATagSSJUrcwIsP196gVZGUeOPeBo14s5NycnSpIiiYCgLkmyAtqZkmKIIJGtroE0b7rVsHFJ0NCeS7O2V/+csGRJIJQT+ospbITTFH/GYM5PNFAJJm7tl3s0WGam5rbEEEi9shULVacb6ZrKZUyABRRdI/AWQ3+9FEUjq3Gs8usQhpaUBmzZxLiI+M04bSpqLTXZCZcW6Q2KxVKAouqV5YaWvBUl2klpFgSQUSpepc7PpWyBSERsbzuoBFN3Nxpj0OFeW5g9Iz+0xMeot09rGHwFFE0iA1M0mG4fEu/eqVStcbsbSKWbDJVShaEHSViDxFqTr100fqK2vyV8bgaRN/BGPLnFI+qT4A5oFEi9s3d1Vn0T0yWRLTZWW/9d0LBgLQwkkPgj27Vv9Un8Zk59/TRW6xCEdOSJNs9bW4gSY18VmDIHk7i51hSiKndevOdFkbV3YYlbUTLbERO6cJxAod99oymQTiw0nkAD5dP+ikJYmjdlTtb/c3aUCRdWxmpUF7N7NvTaFQOIDtc+eldaW0yf+yFIggVRCkBVIjGkvkGrW5GqTZGXJB8KaAkuxIPGp/leuqI9VEIn0y2ADtLcgKYs/4tHHxcafOCtWVN+3MTGUQOLvzvPzlc87qIl797jfzsEBaN1adTtdaiHt3y99rW1xyawsqYA3pItNnQVJduJTY8QgyU4+q3h88u41P7/CWYNFdbHxx4afn/L4IU2ZbFFR3E2Evb3u/2ll8HFIZ87oHpcmC7+vnJ2lcVrKUBeHVFAA9O/P3fy6uwP9+mneblEFUu3aXNZwVpY0ZIEEEmF2ZAXS27fcAS4QaLZ0yAZqm9LNlp8vtZqYWyAFBnJuraws9RdFftoCe3uunosuaGtBUhV/BOjnYjO3ew0wnEAKDpb+Pvr0xVuP2rRRH/gpa0FSZ6kqKOCmquHR1oLEX1xcXOQnMi4qshYkxXFnZEhj3IxhQQJUp/oriz/iKaqLjXcfKbrXeDRlsvHxRw0aSJMJikL9+tx/PS1Nt+Kzimh786gqDokxYPRoTsDb2wP//CONrVOHrEBSdeyLxdJzkKJAEgoLVxXXNcXfkiCBVEKQFUj8n6V6de2yMsxRMJIXMFZWuls2DC2QhELp3D/q3Gz8SVbXDDbAMBYkfVxsxV0gyU4VUbNm0frSxr3Gb8fKittX6n7r8+e5/caLnNev1ceC8Mi613SpIK8J/ljPzeUu0LLwF1wnJ+5hDFS5y7QRSEW1IKkSSPwN4sOHyjPLilr/SBErK6l1sihuNm0FkqopR2bN4uabFAqBrVuBDz7Qbru8QMrJUV16IT6eu8EVCpVnxSnGIZEFiTA7ygSStjEn5gjUli3iqGvgnqEFEqBdHJK+AdqAVCClpSmP9VKX4s8j62LTNganuAuk2FjuRG1tzVnt9O0rK4tzewDqA7QBrsZVjRrca3UWxX/+4Z579JCKV23cbMbIYAM4Vwz/31B0sxkzxZ9HH4FkKBebKoFUrRp37GRmKre8GiqDTRZD1EPSx4LEnxPWrgUiIrjXK1YAPXtqv10nJ2nhR1VuNt4C6uOjfLJuPg7p4kXOfclnd5JAIsyGrEDSNsWfxxwVtYuSUVMcBZKsK0Xx7h7QzcWWmcmdeDQhFkvFcnEVSLz1qGpVzgWi7+S3//3HWVYqV1Z9MZVFUxwSY8C+fdzr7t2lx4Q2bjZjBGjzqArUNmYGG4+mGCRjuNg0CSQbG+mFWVG8FhRI3WDGEEhnz2o3T5oytN1fNWty3zEtjTuu9u/nyk4AwNSpwKhRum1XINAch6Qq/oinalXu2M7PB/78k7umODhorsFkiZBAKiHwloeMDOmfXluBVKOGNFBb2USDxsDSBBLvYnv0SCpWFCmKQLK1lQZbKnPDaONic3SUCiht3GwvXnBFFm1ttRMFxkJWIOmafaZ4AdRXbMm617Rxa2nKZHv0iAvwtbUFPvpI6srRxoJUUgVSUWKQUlM54a8LsvWN1B3fqjLZ7t3j4rJcXaUWQ0MQHMxNHJyZqX/YgqYUfx4bG2mc1W+/cYHYYjHw+eecm00f+KmZ9BVIAoHUivTbb9xz9erFL8UfIIFUYpC1UPBFyrQVSFZW0nlvTOVmK4rJ3xgCqWxZ6Z2msrl/RCKpeNQ1xZ9HXRySNhYkQLdMNt69Vru2clO4qeAvyllZmufPU0RRIPF96SqQ+AsVf3evCU21kPjstQ8/5IKtdbEg8S42YwgkVZls5nKxJSdLxb+yxAYXF2lMlK5WpGfPOCuQk5P0f6EMVZls/DHRqJFhL95CobRgor5uNl0ELX+enzuXE3ydOwOrV+sf38ZbkPhMS0U0CSRAGofE/3+Ko3sNIIFUYrCykookxrjMBV3mCjN1oLYxLUh5eVIRom6iWkXUudmePZNmsFWpon2fsqgTSNpYkADdMtksIf4I4C5g+hZ5NJQFibfaaJt9yF907t9X7nbmBVL37tyzPhYkQ8cgAZbhYpMVSLz1yNtbeXC4bDVtXQWSqklqFVGVyWaM+CMeXogrm9leG3TZX7L/76ZNgR07ipaRp8nFxh+/2ggknuKYwQaQQCpRyFofatXSLdPK1FOOGFMg8Xc+VlaaLTKyqBNIvGUgKEj/CV/NZUEyt0AC9Bc2/EWQd4Ho009BgfT30tZqU6UKFzeRk1N4moqEBODCBe51t27cMy+QYmPVZ7KJxdI7cFNakEwpkDIypHF26txriuvpGqitKcWfR9bFJuviNYVAOn9ev0maddlffH2wgADg33+LnqVY1BgkgNungYHS92RBIsyO7MVV16rJfAzO5cvS0vDGxFAuNmUxLfpmyPEC6dKlwinBRYk/4jGEBUmXVP/iLpCys6XuKEULki5B2m/ecPvTxkZ7gWBlJb2wKsYhHTjAHXcNG0r3h5ubVLyqsyLFxXGxM1ZWxglaVWVBMmYVbR4nJ/mSB4BxBZKmAG0e3sKUlCS9ecrJkf4/jCGQatXizm05OdrN8SiLbFFPbfZX8+ac2Lt6VTeLuSoMIZAAeSsSCSTC7BRFIAUEAJ06cXfbP/xg2HEpwxAWJMakxe9k0Vd81a3LWQ1SUgpXFecvesYSSNqk+QPau9gyM6VCt7gKpKgobh+7uUn3Jd9PQoL2GZe8S6BiRd0Es6o4JEX3Gg9/bKgTSPxYKlQwTlyYJhebMWOQgMJiRxuBZAgXmzocHKRFEvl9c+sWd67z9DSOJU8gANq25V7rGoekT1HPxo1Vz+GoK+oEUkGBdD9pEkh8oDZAAomwAIoikABg3jzuj71jh9T8bCyKIpBkS+8rc7PpK5CsraV3k4puNmNakMRiqQXJUC62e/c4cVG+vPEvitqgj0BSFmPi6cmJHLFYdRCpIvpmjSlL9c/JkWbEqRJI6gK1jZnBBpjXxQYUTvW3BAsSUDhQW9a9ZshinbLoWw+J/4/Ixu6ZEnUC6fVr7a2x7dpxfdWoIRXBxQ0SSCWIogqkunWBgQO515Mn6zchqDbIXtz0uXgLhVI/uyEFEqA8Dkk2g80YAik9XerS0ySQtHWxWZJ7DSi6QOKxspK6EbTtS19RoizV/+RJLhuvYkVuWglZtAnUNmYGG6DcgpSTI62bZWyBpJjqLzuTuyr0EUhJSdILuDYp+oqp/saMP+LhBVJkpHJLtypMJWZVoU4g8e61ChU0W2PLlOGsr5GRxhOhxoYEUgmCd894eGiun6GKWbO42i6nTknvlA1NUpLUPaKvdUNdoHZRxJcygfT0KRdoKWuq1wdVAol3r9nba54ahr8AJSSoD/4sCQJJdoqRovRVVIH0+LH0t5Z1ryme9HWxIBkjgw2QXlTT0jhhBEj/DzY20mPQWMiKnexsqZBXl8Wkj4uNF8+VKmkXlKyYyWYKgcRbTvLyOJGgLcVBIGlyr/F4e5tvkmxDQAKpBMFbH4KD9Vfsfn7A2LHc68mTlc9fVFT4E4CHh/7pqOoEUlEsSHyw+t27nGUHkM9gK0q9FFUCSdsAbYCr18RPBaDujrskCCRVLhRd+9I3a8zXl9tnvAVRLJZOL6LoXgOkF2F1mWzGdrG5uXE3OID0fyAbf2TsO3lZgcRPMeHqyh232qyjLbq41wB5F1t6utQibEyBJBDo52azJIGk6EXQVSAVd8wukFauXAl/f3/Y29sjJCQEl5VV6ZNh586dCAwMhL29PYKDg3Hw4EG5z3fv3o2PPvoIZcuWhUAgwM2bNwv10bZtWwgEArnHl3x99mJMu3bciejTT4vWz5Qp3In29m1uokNDY4gTgLEEkq8vd/ESi6U1oQwRfwRotiBpU5JAINAcqM2YVCDVq6frKI2DrqKGMc0CSdtMNm3qtihDIJCPQ7p+nbuIOztLA3BlcXeX7hvFooSKYzGWQBIIpMc9//uY8oIrG4MkG3+kTpjx66SlaV9IVF+B9Po1J1YY444HY/8mxVEg8WJWJCo8pREJJBOyfft2TJgwATNmzMD169dRr149hIWFIV4xwvA9Fy5cQP/+/TFs2DDcuHED4eHhCA8Px12ZIIHMzEx88MEH+Pnnn9Vue/jw4Xjz5o3k8csvvxj0u5mDkBDOnD5iRNH6KVuWE0kAN58Pb6o3FIao6mssgQQUdrMZWyDpYkECNAdqx8ZyfVpby9ciMSeyokYbq2RCAvc7CQSF3TOmcrEB8nFIvHutY0epFU8RTW42Y01UK4tioLYpqmjzyMYgaROgDehXTVvbGkg87u5SV97mzdyzMa1HPLxAunxZ+6lUzC2Q7O2l51dFNxsJJBOyaNEiDB8+HEOHDkWtWrWwevVqODo6Yv369UrbL126FB07dsT//vc/BAUF4ccff0TDhg2xYsUKSZuBAwdi+vTpCA0NVbttR0dHeHt7Sx6uhsqRNDOGMqGPG8ed7KKjgVWrDNMnjyVbkIDCAskQKf6AZguSoQQSP9VMYKDqC7mp4feFSAS8e6e5PW8hqFy5cFyWLtONpKdLBag+J3XZVH9V6f2yqAvULupYtEUxUNscFqTXr7UL0FZcT1uBpKsFCZBakfj9aAqBVLUqt6/z87mikdpgboEEqI5DIoFkIvLy8nDt2jU5ISMUChEaGopIFRFtkZGRhYRPWFiYyvbq2LJlCzw9PVGnTh1MmTIFWVlZatvn5uYiLS1N7lGScXAAZs7kXv/0k3azx2uLMQUSY4YVSAUFhslgAwzjYgOkmWyKLrbkZGDhQmDMGO69pcQfAVysGX/S1UbYqLsA6mJB4k/o7u761YnhXWxnz3LCUyjk5rpShToLUlHHoi3mFEj8vsnPl85pqItA0iYOqaBAKr50EUi8eM3L454bN9Z+XX3RJw5J24lqjQkJJA6zCaTExESIRCKUV/jXli9fHnEqznxxcXE6tVfFp59+ij///BOnTp3ClClTsHnzZnz22Wdq15k7dy7c3Nwkj0ql4AgZPJg7qSQlARo8ljphTBdbZqY0pVbf/hs25AJd4+OB48e5E6qjY9HdIrxASkuTL3JYVBfbnTucW7VCBWDSJODFC25bn39etPEaGl2EjaEFkr5/V17w8PdDH3ygPuCYvwgrE0imcK8Bql1sphBItrbS7V+/zj1rI5B495c2AunFC06AOTjotl95CxKPKQQSoLtAsgQLEl9KQ1Yg5eZKj6VScPkDYAFB2uZgxIgRCAsLQ3BwMAYMGIA//vgDe/bswVPeaa6EKVOmIDU1VfJ4yZ95SzDW1twM0QCwZIl201togzEtSPwf2MFB/zmJ7OyABg241+vWcc9FzWADpNMwANILLqC7BYkXSFeucMHCdesCa9dywjA4GFizhttXspVsLQFDCyRtgrSLGhTt4SE/JYg69xogPyebotXV2AHaPKosSKYqGMr/XvxNgKFdbPyxERCg239SViAFBBi/5AEPL5CuXpVmxqrDEgSSMgsSb7G2t1d/k1CSMJtA8vT0hJWVFd4qnOXevn0LbxW2RW9vb53aa0vI+9zuKDWTkNnZ2cHV1VXuURro1g1o2ZK7+PIut6JiCoFU1IsB72bbt497Lqp7DeDurvkq4LJuNl0tSLyL7cX/27v3sKjLRA/g30GYEUEuity8YppoKhgqTbp2Uh7JPPukkanHEquzroZmUefR3Urc7ZTubtbWrotrtdWzm1m4alhqESVtpqkIXvKSmYapiB5vQCkE7/nj3XduzOAMzMzvN/D9PA/PDDM/xndeZ37znfd6AigpkYsnTpkir+/dC/ziF/arjeuFJwHJ1RpIto9z8eL1NwL1RihR45CA6wck25lsjuOQ/BWQHFuQ/P2BaxsoQ0Ksr1d3/sadFiQVkDydgKDCK+Cf8UdK795yLFJDg+yqbU5NjVyIFNBHQLJdrd62NTZQF370lGYByWg0Ii0tDcXFxZbbGhsbUVxcDLPZ7PRvzGaz3fEAUFRU5PJ4d6mlABICdT10HzIYADXB77XXXE9f9kQgBaT6ennpjYAEOB+H5Okg7SFD5Ek3NlbOMjxxQm4PM2aMvk9c7rb81NdbZ0A5C0hRUda1fq73WN4IJWocUnKye3tKuRqo7a8uNi3HIAH2ASkpSQb46/Gki60lA7QB+X5RrbT+DEiA+91s6v8qNFSbbUYUZy1I7W38EaBxF1tubi5eeeUVvPnmmzh06BDmzp2L2tpaPPDAAwCAmTNn4ldqvjmABQsWYMuWLVi+fDkOHz6MJUuWYPfu3ZinRqUCuHDhAsrLy3Hw32enI0eOoLy83DJO6dixY3jmmWdQWlqKEydOoLCwEDNnzsSYMWMwVE+jWnXk1luBSZPk9Oxly1r3WN4YRA34LyAp/ghI7naxhYfLUHTmDPDMM+59Q9cDd1uQjh+XA3FDQ62tMbYMBvdnsnkjIE2ZIqeiP/aYe8e7GqitRRdbQ4P1Q85fXWy2/2fudK8BnnWxeTrFXzEY5AD7jh3lxtz+pAKSw/f7JmzDrJZfdhiQJE0D0tSpU/H8889j8eLFSE1NRXl5ObZs2WIZiF1RUYEzNu+YW2+9FatXr8aqVauQkpKCtWvXYsOGDRhs0wZeWFiIYcOGYeLEiQCAadOmYdiwYVi5ciUA2XL18ccfY/z48UhOTsbjjz+OrKwsbFRL5JJTCxfKy4KC1s1oq662rquk5xak3r3ty+fLgORpF5vS2jFR/qYCkqsFLhXVQnDjja6fo7thyxsn9fR0OWbM3fXFXA3U9ncX2/nz8gNXCPlhqz70fM22BcnTgOTLFiRAtoKfOtWyv20NNR6wrKz5EKiH8UdA8wHJ169fPQnWugDz5s2zawGytXXr1ia3TZkyBVOmTHH5eLNmzcKsWbNc3t+zZ0+UlJR4Wsx2Lz1dnvgPHgTWrAF++cuWPY46AYSHt26cjK8DksEgW5Hee08O9vbWScEbLUiBSm3u+q9/yQ85Vx9S7nwAutNd19iozUldhWnbLraffrIGQ193scXEyNevENYyxMTISRf+0JKApLrYqqvle9pV95IKfYB7m9Q6Mpm0WRssPl526+3aBWzaBDz0kPPj9DDFH2ALkhJg30FJKwaD9U2tZna1hLcCjKuA1JqNah2pbrZBg7zXWqNmsqmAVFdnXWE3kDd1dMdNNwF33SWDy29/6/o4TwJScy1IVVWyfoOC7D+0fU21IH3/vbW19cwZ2d0VEuL7D7/gYOsHnNpyxl/da4B9XTe3Sa2tzp2t7+nmWljUIo9Dh/p2LSlf+HenBj74wPUxgdCCxIBE5MT998sT/K5dcu2dlvDWCcDXLUiAXAdqzBggN7f1j6U4tiCp7jXAfhmAtmrJEnn59tvOV5sG3AtI7oxBUl1aiYkt3xS5JaKirCFBPUdVlh49/NM1ql7/6n3qzw/cloxBAtzrZnv3XXk5darn5dKaCkhFRa5nX+otIF28KFs/AQYkomZ162ad5tzSVqRACkgJCXLq/LRprX8sxVVAiopyb7ZPoEtNBbKyZPePq2UjvNWC5K8xP844drOpGWz+Kot6f2kRkLp1k8Goe3fvBqT/+z+5cCsgB84Hmptvlq/bmhrgs8+cH6OXgKRas4WQ56jaWv9sk6M3DEjkEdXN9ve/X38NGmd83cXmz405W8IxIHk6xb8tyMuTl+++27Ql8tIl6/9hc2NM3AlIWn7jdRyorcKar8cfKer1r/59f37gBgXJ9bgOH7Yux+AONQ7JVRfbunWym3LYMPeWW9Ab221qXHWz6SUgBQdbx0SeP299L0VEBF7XZmswIJFHxo+X3QQXLlgXUfSEL1uQGhu9OwbJF1wFpLY+QNvWkCHAvffK66rLTVELRCYkNH8idmeQtp5akPxdFvX+UjNG/f1+CAvzfB2f67UgBXL3mvKf/ykv339fts440ktAAuzHIbXH7jWAAYk81KEDoCYJtqSbzdsBqb7euvnkxYvW7Q38NaXZU6662NpTCxIgW5EMBtkqUFZmvd12in9z9N7F5tiCpFUXm6vf9ai5gHTuHPDJJ/J6IHavKRkZcjzcsWPWLwO21OtZD/9fDEgMSNQC/17HE0VF1hO/u7wVkGz3WVOtSKprJjras6Z9f2ILkjRoEDB9urxu24rk7ho36vVTW9u0m1XRQwuSmsmmVReboocP3OtpbjXtdetkC/Hw4XLbjkDVubPcPxGQrUi2amutM1q1nuYP2G9Yy4BE5Ka+fYGxY2UT8RtvePa33hojFBJiXc/EMSCpN7YesQXJavFiOS6jsFBu5Am4H5DCw60h2VUrkgolWpzUbWeyHTqkXRebotcuZ1vNraatutdU12wgczXdX3157NhRBimtsQWJAYlaSA3Wfv11+c3OXd7sY3cch6T3AdoAW5BsDRgA3HefvK4GbnuySnJz3WxXr1pfD1qt/Ku62b74Qq7EDfjvA6YtdbGdPQuoNYMDuXtNUeOQ/vUv+10J9LLNiMKAxIBELTR5svyw/+676+8vpFy9av2gaO8B6coVOV6qPc5is/X003Jc26ZNMkgcPSpvb21AUqtWd+qkXd2qbrbNm+VlTIx917AvOb4H9PyeUFQXW02NXFFb+ec/5ZewkSOBPn00KZpX3XCDfH3/9BPw0UfW2/U0QBuwBqRz5xiQiDwSGgrMmCGvuztYWwUYo9E7iyIGYkCyfd5XrrTvLjZArrScnS2v//KXMkSHhLj3QdjcTDbbLi2tvo2rFiS15o0/W7Js3wMREbLbRu/Cw61dS7bdbG2pe02xnc2mMCDpDwMStZjqZlu/Xi7idj3qBBAb650PrUAMSCaTDJeA7GZrz11sylNPyXVXDhyQv/fr596+Yc21IGk5QFtRLUhqlqU/yxIaag0bevnAdYdjN9uZM9aAec892pTJF9Q4pM2brTNv9RqQjh2znmN79NCuPFpgQKIWGzZM/tTVAW+9df3jvX0CCMSABNiPQ2rvLUgAkJQEPPig9Xd3NyFtbrsRLQdoK6oFSfHXDDZF1Y9ePnDd4TiT7Z//lJNBbrnF//XnS6NHy5a9c+fk1k2Avqb4A9aA9M038rJr19ZtMB6IGJCoVWw3sHW28JktFWB8FZD0vkikYhuQ2IIkPfmkdb80d8YfAc23IKkuAS1bkKKjrR/4WpQlEAOS40y2trA4pDMhIUBmpryuZrOpL5B6mOIPWAOSOq+3t+41gAGJWum//kt2G+3bB5SWNn+sbRebNwR6C9LFi2xBUnr1Av7nf+T1O+5w72/03sUGWLvZAP+XRb0P9P5+sGXbxXbqFPD55/L3ttS9pqhxSI4BSS+B1nGxXQYkIg9FR8vNR4HrD9ZmF5ukAtL331t3ym7vLUgA8L//Kweu3367e8e7O0hbS7bdbP7uIkpKsr8MBLZdbGvXytaLUaPa5tiXCRPkWMyyMhkG9RaQIiPtN9BmQCJqAdXNtno18MMPro/zZUCqq7O2xgRKQPr2W3lpNLa/vn1nDAbPFsizbUGy7d4VQh9jkABtW5AWLgTy8+XswEBh28XWFmev2erWDUhPl9c3bdJfQAoKkuOOFK3fS1pgQKJW+4//kKtrX7kC/P3vro/zdguPbUA6f15e79BB/60xKiAdPy4vu3TRx8JwgUa9jurrreEYkOO6VFDXuuVBtSCZTP5f4T02FpgzJ7B2X1cBad8+uS6WwWBtoW6L1Gy2ggLr2k96CUiAfTcbAxJRCwQFAY88Iq+/8ILrlbV92YJku81IkM5f1Y4tSHoPdHplMlnrznYckmo9io21LqmglZEjgTvvBHJz9f+61APVxaYC7+jRQPfu2pXH19Q4pI8/lpfeWiPOWxiQiLzgwQflG/vrr5vuMaT4IyDpvXsNcN6CRC3jbKC2HmawKUajfD8895zWJQkMtrP+gLbbvaakpMgAqLqI4+P11ZrMgETkBZ07W8c6PP980/t/+sm6mKQvutgCYaNaRQUktXM3W5BaztlAbb0M0CbPhYdbuwTbevcaIJ+j6mYD9NW9BljPpwZD227Jc4UBibzmkUfkCsiffWZd/Ew5f15+SwoKajp9tKUCvQVJYQtSyzlrQdLLAG1qGTUOacyYpi1KbZGeA5I6V8fFydbQ9oYBibyme3dg+nR5ffly+/vUN/yYGPupo63BgETOVtNmC1Jgu+EGeTltmrbl8Jdx4+R4OkC/Aam9ftlgQCKvevxxebl2LXDihPV2b6+iDbSdgMQutpZrrgWJASkwLV8OrFgB/OIXWpfEP8LCrGt/6WUVbWXoUHk5YoS25dCKG1tCErkvJQXIyJCzMl56CXjxRXm7t1fRBtpOQGILUsvpfZA2eW7AAPe3m2krli6VMy7/+7+1Lom9sWOBo0fb1j54nmALEnndE0/Iy1dflfuNAb5ZBK2tBCS2ILWcY0Cqr7dudMqARIEiNRVYtw7o00frkjTVr591n8T2hgGJvG78eGDwYBlcVq2St/kyIP34o/UDMhACkuM6J2xBajnHWWynT8t1uEJCAuO1QET6xYBEXmcwWMcivfyy3AbEFy08KiABcl8zbz++r5hM9gsYsgWp5VTgPncOaGiwn8HGhRmJqDV4CiGfmD5dfrs/dQp45x3ftCCZTNYZcWqhtUAISIB9NxtbkFpOrZze2ChDEgdoE5G3MCCRT5hMwPz58vry5b4JSAaDfStSaKicERIIGJC8o0MH62J2lZUcoE1E3sOARD4zZ47cpX7vXvkDeH+dD9uAFBurr2X6m2MbkBwHbZNnbAdqc5FIIvIWBiTymS5d5B5tgHUDW293gTkGpEChQlFEhFx9nFrOdqA2u9iIyFsYkMinHn3UfrAsA5KkAhIHaLeesxYkBiQiai0GJPKpG24AJk+W16OirEvqe4ttQAqEjWoVFZA4/qj1bLcbYUAiIm9hQCKfW7hQdiOlpnr/sdmCRKoF6euvgcuX5XWOQSKi1uLoB/K5ESOAr76ybnzoTYEakFQwYgtS66mAtGuXvIyKAjp31qw4RNRGMCCRX9x4o28eN1ADUlYWUFQkZ/pR66iAdO6cvGT3GhF5AwMSBbRADUh9+wIffaR1KdoGxx3QGZCIyBs4BokCWqAGJPIex7W1GJCIyBsYkCigMSBRdLT9buMMSETkDQxIFNACdZo/eY/BYN/NxhlsROQNDEgU0FRAiooCjEZNi0Iasg1IbEEiIm9gQKKApgISu9faNwYkIvI2BiQKaIMGyS6Wm2/WuiSkJTVQOygISEzUtixE1DZwmj8FtEGDgO+/5/ij9k61ICUmcvNfIvIOnkoo4LHFgFRAYvcaEXkLu9iIKOCNHw/06wfcd5/WJSGitoItSEQU8Pr3B44e1boURNSWsAWJiIiIyAEDEhEREZEDBiQiIiIiBwxIRERERA4YkIiIiIgcMCAREREROWBAIiIiInLAgERERETkgAGJiIiIyIHmAWnFihXo06cPOnbsiPT0dOzcubPZ4wsKCpCcnIyOHTtiyJAh2LRpk93969atw/jx49G1a1cYDAaUl5c3eYyrV68iJycHXbt2RXh4OLKysnD27FlvPi0iIiIKYJoGpHfeeQe5ubnIy8vDnj17kJKSgszMTFRVVTk9/osvvsD06dPx0EMPoaysDJMmTcKkSZNw4MAByzG1tbUYPXo0fve737n8dx977DFs3LgRBQUFKCkpwenTp3H33Xd7/fkRERFRYDIIIYRW/3h6ejpGjBiBP//5zwCAxsZG9OzZE/Pnz8eiRYuaHD916lTU1tbi/ffft9x2yy23IDU1FStXrrQ79sSJE0hKSkJZWRlSU1Mtt1++fBndunXD6tWrcc899wAADh8+jIEDB2L79u245ZZb3Cr7lStXEBkZicuXLyMiIsLTp05EREQacPfzW7MWpLq6OpSWliIjI8NamKAgZGRkYPv27U7/Zvv27XbHA0BmZqbL450pLS1FfX293eMkJyejV69ezT7OtWvXcOXKFbsfIiIiaps0C0jnz59HQ0MD4uLi7G6Pi4tDZWWl07+prKz06HhXj2E0GhEVFeXR4yxduhSRkZGWn549e7r9bxIREVFgCda6AIHiV7/6FXJzcy2/X758Gb169WJLEhERUQBRn9vXG2GkWUCKiYlBhw4dmsweO3v2LOLj453+TXx8vEfHu3qMuro6XLp0ya4V6XqPYzKZYDKZLL+rCmZLEhERUeCprq5GZGSky/s1C0hGoxFpaWkoLi7GpEmTAMhB2sXFxZg3b57TvzGbzSguLsajjz5qua2oqAhms9ntfzctLQ0hISEoLi5GVlYWAODIkSOoqKjw6HESExNx8uRJdO7cGQaDwe2/A2S46tmzJ06ePMkB3m5gfXmOdeYZ1pdnWF+eY515xpf1JYRAdXU1EhMTmz1O0y623NxcZGdnY/jw4Rg5ciT++Mc/ora2Fg888AAAYObMmejevTuWLl0KAFiwYAFuu+02LF++HBMnTsSaNWuwe/durFq1yvKYFy5cQEVFBU6fPg1Ahh9AthzFx8cjMjISDz30EHJzc9GlSxdERERg/vz5MJvNbs9gA+SA8h49erTq+UdERPCN4gHWl+dYZ55hfXmG9eU51plnfFVfzbUcKZoGpKlTp+LcuXNYvHgxKisrkZqaii1btlgGYldUVCAoyDqO/NZbb8Xq1avx1FNP4de//jX69++PDRs2YPDgwZZjCgsLLQELAKZNmwYAyMvLw5IlSwAAL774IoKCgpCVlYVr164hMzMTf/nLX/zwjImIiCgQaLoOUnvFNZQ8w/ryHOvMM6wvz7C+PMc684we6kvzrUbaI5PJhLy8PLtB3+Qa68tzrDPPsL48w/ryHOvMM3qoL7YgERERETlgCxIRERGRAwYkIiIiIgcMSEREREQOGJCIiIiIHDAg+dmKFSvQp08fdOzYEenp6di5c6fWRdKNzz77DD//+c+RmJgIg8GADRs22N0vhMDixYuRkJCA0NBQZGRk4OjRo9oUVgeWLl2KESNGoHPnzoiNjcWkSZMsC6MqV69eRU5ODrp27Yrw8HBkZWU12a6nvcjPz8fQoUMtC8+ZzWZs3rzZcj/rqnnLli2DwWCw28mAdWZvyZIlMBgMdj/JycmW+1lfTZ06dQr33XcfunbtitDQUAwZMgS7d++23K/leZ8ByY/eeecd5ObmIi8vD3v27EFKSgoyMzNRVVWlddF0oba2FikpKVixYoXT+3//+9/j5ZdfxsqVK/Hll18iLCwMmZmZuHr1qp9Lqg8lJSXIycnBjh07UFRUhPr6eowfPx61tbWWYx577DFs3LgRBQUFKCkpwenTp3H33XdrWGrt9OjRA8uWLUNpaSl2796NsWPH4q677sJXX30FgHXVnF27duGvf/0rhg4danc766ypm266CWfOnLH8fP7555b7WF/2Ll68iFGjRiEkJASbN2/GwYMHsXz5ckRHR1uO0fS8L8hvRo4cKXJyciy/NzQ0iMTERLF06VINS6VPAMT69estvzc2Nor4+Hjxhz/8wXLbpUuXhMlkEm+//bYGJdSfqqoqAUCUlJQIIWT9hISEiIKCAssxhw4dEgDE9u3btSqmrkRHR4tXX32VddWM6upq0b9/f1FUVCRuu+02sWDBAiEEX1/O5OXliZSUFKf3sb6aWrhwoRg9erTL+7U+77MFyU/q6upQWlqKjIwMy21BQUHIyMjA9u3bNSxZYDh+/DgqKyvt6i8yMhLp6emsv3+7fPkyAKBLly4AgNLSUtTX19vVWXJyMnr16tXu66yhoQFr1qxBbW0tzGYz66oZOTk5mDhxol3dAHx9uXL06FEkJiaib9++mDFjBioqKgCwvpwpLCzE8OHDMWXKFMTGxmLYsGF45ZVXLPdrfd5nQPKT8+fPo6GhwbLPnBIXF4fKykqNShU4VB2x/pxrbGzEo48+ilGjRln2JqysrITRaERUVJTdse25zvbv34/w8HCYTCbMmTMH69evx6BBg1hXLqxZswZ79uyxbBhui3XWVHp6Ot544w1s2bIF+fn5OH78OH72s5+hurqa9eXEt99+i/z8fPTv3x8ffvgh5s6di0ceeQRvvvkmAO3P+5puVktE3pGTk4MDBw7YjXegpgYMGIDy8nJcvnwZa9euRXZ2NkpKSrQuli6dPHkSCxYsQFFRETp27Kh1cQLChAkTLNeHDh2K9PR09O7dG++++y5CQ0M1LJk+NTY2Yvjw4XjuuecAAMOGDcOBAwewcuVKZGdna1w6tiD5TUxMDDp06NBkxsLZs2cRHx+vUakCh6oj1l9T8+bNw/vvv49PP/0UPXr0sNweHx+Puro6XLp0ye749lxnRqMR/fr1Q1paGpYuXYqUlBS89NJLrCsnSktLUVVVhZtvvhnBwcEIDg5GSUkJXn75ZQQHByMuLo51dh1RUVG48cYb8c033/A15kRCQgIGDRpkd9vAgQMt3ZJan/cZkPzEaDQiLS0NxcXFltsaGxtRXFwMs9msYckCQ1JSEuLj4+3q78qVK/jyyy/bbf0JITBv3jysX78en3zyCZKSkuzuT0tLQ0hIiF2dHTlyBBUVFe22zhw1Njbi2rVrrCsnxo0bh/3796O8vNzyM3z4cMyYMcNynXXWvJqaGhw7dgwJCQl8jTkxatSoJkuTfP311+jduzcAHZz3fT4MnCzWrFkjTCaTeOONN8TBgwfF7NmzRVRUlKisrNS6aLpQXV0tysrKRFlZmQAgXnjhBVFWVia+++47IYQQy5YtE1FRUeK9994T+/btE3fddZdISkoSP/74o8Yl18bcuXNFZGSk2Lp1qzhz5ozl54cffrAcM2fOHNGrVy/xySefiN27dwuz2SzMZrOGpdbOokWLRElJiTh+/LjYt2+fWLRokTAYDOKjjz4SQrCu3GE7i00I1pmjxx9/XGzdulUcP35cbNu2TWRkZIiYmBhRVVUlhGB9Odq5c6cIDg4Wzz77rDh69Kh46623RKdOncQ//vEPyzFanvcZkPzsT3/6k+jVq5cwGo1i5MiRYseOHVoXSTc+/fRTAaDJT3Z2thBCTvl8+umnRVxcnDCZTGLcuHHiyJEj2hZaQ87qCoB4/fXXLcf8+OOP4uGHHxbR0dGiU6dOYvLkyeLMmTPaFVpDDz74oOjdu7cwGo2iW7duYty4cZZwJATryh2OAYl1Zm/q1KkiISFBGI1G0b17dzF16lTxzTffWO5nfTW1ceNGMXjwYGEymURycrJYtWqV3f1anvcNQgjh+3YqIiIiosDBMUhEREREDhiQiIiIiBwwIBERERE5YEAiIiIicsCAREREROSAAYmIiIjIAQMSERERkQMGJCIiLzEYDNiwYYPWxSAiL2BAIqI2YdasWTAYDE1+7rjjDq2LRkQBKFjrAhARecsdd9yB119/3e42k8mkUWmIKJCxBYmI2gyTyYT4+Hi7n+joaACy+ys/Px8TJkxAaGgo+vbti7Vr19r9/f79+zF27FiEhoaia9eumD17NmpqauyO+dvf/oabbroJJpMJCQkJmDdvnt3958+fx+TJk9GpUyf0798fhYWFvn3SROQTDEhE1G48/fTTyMrKwt69ezFjxgxMmzYNhw4dAgDU1tYiMzMT0dHR2LVrFwoKCvDxxx/bBaD8/Hzk5ORg9uzZ2L9/PwoLC9GvXz+7f+M3v/kN7r33Xuzbtw933nknZsyYgQsXLvj1eRKRF/hlS1wiIh/Lzs4WHTp0EGFhYXY/zz77rBBCCABizpw5dn+Tnp4u5s6dK4QQYtWqVSI6OlrU1NRY7v/ggw9EUFCQqKysFEIIkZiYKJ588kmXZQAgnnrqKcvvNTU1AoDYvHmz154nEfkHxyARUZtx++23Iz8/3+62Ll26WK6bzWa7+8xmM8rLywEAhw4dQkpKCsLCwiz3jxo1Co2NjThy5AgMBgNOnz6NcePGNVuGoUOHWq6HhYUhIiICVVVVLX1KRKQRBiQiajPCwsKadHl5S2hoqFvHhYSE2P1uMBjQ2NjoiyIRkQ9xDBIRtRs7duxo8vvAgQMBAAMHDsTevXtRW1truX/btm0ICgrCgAED0LlzZ/Tp0wfFxcV+LTMRaYMtSETUZly7dg2VlZV2twUHByMmJgYAUFBQgOHDh2P06NF46623sHPnTrz22msAgBkzZiAvLw/Z2dlYsmQJzp07h/nz5+P+++9HXFwcAGDJkiWYM2cOYmNjMWHCBFRXV2Pbtm2YP3++f58oEfkcAxIRtRlbtmxBQkKC3W0DBgzA4cOHAcgZZmvWrMHDDz+MhIQEvP322xg0aBAAoFOnTvjwww+xYMECjBgxAp06dUJWVhZeeOEFy2NlZ2fj6tWrePHFF/HEE08gJiYG99xzj/+eIBH5jUEIIbQuBBGRrxkMBqxfvx6TJk3SuihEFAA4BomIiIjIAQMSERERkQOOQSKidoGjCYjIE2xBIiIiInLAgERERETkgAGJiIiIyAEDEhEREZEDBiQiIiIiBwxIRERERA4YkIiIiIgcMCAREREROWBAIiIiInLw/+LHRN6Xxv3VAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train FCN32 with generator\n",
        "fcn32_tall = fcn_32(input_size=(tileSize,tileSize,3), lr=0.0005)\n",
        "#fcn_tall = load_model('Output/fcn32_tall/fcn32_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/fcn32_tall\", \"fcn32_tall\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_tall = TrainGenerator(4, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "fcn32_tall = train(fcn32_tall, callbacks, train_rgb_tall, validation_df, \"fcn32_tall\", epochs=60, steps_per_epoch=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn870enXKVpK"
      },
      "source": [
        "### **ResUNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvZnoFbJKIeJ",
        "outputId": "0e873024-b5d1-4ed7-f3dc-ecaeb2b0d04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1488 - dice_coef: 0.2433 - accuracy: 0.9520 - mse: 0.0377\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.09832, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 139s 1s/step - loss: 0.1488 - dice_coef: 0.2433 - accuracy: 0.9520 - mse: 0.0377 - val_loss: 0.0735 - val_dice_coef: 0.0983 - val_accuracy: 0.9803 - val_mse: 0.0167\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0467 - dice_coef: 0.4317 - accuracy: 0.9826 - mse: 0.0108\n",
            "Epoch 2: val_dice_coef did not improve from 0.09832\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0467 - dice_coef: 0.4317 - accuracy: 0.9826 - mse: 0.0108 - val_loss: 0.0972 - val_dice_coef: 0.0230 - val_accuracy: 0.9796 - val_mse: 0.0198\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0413 - dice_coef: 0.4990 - accuracy: 0.9828 - mse: 0.0104\n",
            "Epoch 3: val_dice_coef did not improve from 0.09832\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0413 - dice_coef: 0.4990 - accuracy: 0.9828 - mse: 0.0104 - val_loss: 0.0779 - val_dice_coef: 0.0861 - val_accuracy: 0.9799 - val_mse: 0.0181\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0369 - dice_coef: 0.5206 - accuracy: 0.9841 - mse: 0.0094\n",
            "Epoch 4: val_dice_coef improved from 0.09832 to 0.30521, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0369 - dice_coef: 0.5206 - accuracy: 0.9841 - mse: 0.0094 - val_loss: 0.0486 - val_dice_coef: 0.3052 - val_accuracy: 0.9837 - val_mse: 0.0128\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0352 - dice_coef: 0.5558 - accuracy: 0.9845 - mse: 0.0091\n",
            "Epoch 5: val_dice_coef improved from 0.30521 to 0.37072, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0352 - dice_coef: 0.5558 - accuracy: 0.9845 - mse: 0.0091 - val_loss: 0.0406 - val_dice_coef: 0.3707 - val_accuracy: 0.9855 - val_mse: 0.0111\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0353 - dice_coef: 0.5613 - accuracy: 0.9842 - mse: 0.0092\n",
            "Epoch 6: val_dice_coef improved from 0.37072 to 0.44778, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0353 - dice_coef: 0.5613 - accuracy: 0.9842 - mse: 0.0092 - val_loss: 0.0338 - val_dice_coef: 0.4478 - val_accuracy: 0.9872 - val_mse: 0.0095\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0329 - dice_coef: 0.5666 - accuracy: 0.9852 - mse: 0.0086\n",
            "Epoch 7: val_dice_coef improved from 0.44778 to 0.47153, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0329 - dice_coef: 0.5666 - accuracy: 0.9852 - mse: 0.0086 - val_loss: 0.0309 - val_dice_coef: 0.4715 - val_accuracy: 0.9882 - val_mse: 0.0087\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323 - dice_coef: 0.5704 - accuracy: 0.9854 - mse: 0.0084\n",
            "Epoch 8: val_dice_coef did not improve from 0.47153\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0323 - dice_coef: 0.5704 - accuracy: 0.9854 - mse: 0.0084 - val_loss: 0.0333 - val_dice_coef: 0.4684 - val_accuracy: 0.9874 - val_mse: 0.0093\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0311 - dice_coef: 0.5891 - accuracy: 0.9857 - mse: 0.0082\n",
            "Epoch 9: val_dice_coef improved from 0.47153 to 0.51894, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0311 - dice_coef: 0.5891 - accuracy: 0.9857 - mse: 0.0082 - val_loss: 0.0301 - val_dice_coef: 0.5189 - val_accuracy: 0.9884 - val_mse: 0.0085\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0313 - dice_coef: 0.6039 - accuracy: 0.9853 - mse: 0.0083\n",
            "Epoch 10: val_dice_coef improved from 0.51894 to 0.52129, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0313 - dice_coef: 0.6039 - accuracy: 0.9853 - mse: 0.0083 - val_loss: 0.0301 - val_dice_coef: 0.5213 - val_accuracy: 0.9887 - val_mse: 0.0084\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0308 - dice_coef: 0.6199 - accuracy: 0.9854 - mse: 0.0081\n",
            "Epoch 11: val_dice_coef improved from 0.52129 to 0.53684, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0308 - dice_coef: 0.6199 - accuracy: 0.9854 - mse: 0.0081 - val_loss: 0.0289 - val_dice_coef: 0.5368 - val_accuracy: 0.9889 - val_mse: 0.0082\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0294 - dice_coef: 0.6106 - accuracy: 0.9860 - mse: 0.0078\n",
            "Epoch 12: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0294 - dice_coef: 0.6106 - accuracy: 0.9860 - mse: 0.0078 - val_loss: 0.0300 - val_dice_coef: 0.5085 - val_accuracy: 0.9888 - val_mse: 0.0084\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0299 - dice_coef: 0.6060 - accuracy: 0.9858 - mse: 0.0079\n",
            "Epoch 13: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0299 - dice_coef: 0.6060 - accuracy: 0.9858 - mse: 0.0079 - val_loss: 0.0304 - val_dice_coef: 0.5084 - val_accuracy: 0.9886 - val_mse: 0.0085\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0282 - dice_coef: 0.6256 - accuracy: 0.9865 - mse: 0.0075\n",
            "Epoch 14: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0282 - dice_coef: 0.6256 - accuracy: 0.9865 - mse: 0.0075 - val_loss: 0.0362 - val_dice_coef: 0.4561 - val_accuracy: 0.9861 - val_mse: 0.0103\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0278 - dice_coef: 0.6236 - accuracy: 0.9867 - mse: 0.0073\n",
            "Epoch 15: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0278 - dice_coef: 0.6236 - accuracy: 0.9867 - mse: 0.0073 - val_loss: 0.0322 - val_dice_coef: 0.4816 - val_accuracy: 0.9883 - val_mse: 0.0089\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0284 - dice_coef: 0.6267 - accuracy: 0.9864 - mse: 0.0075\n",
            "Epoch 16: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0284 - dice_coef: 0.6267 - accuracy: 0.9864 - mse: 0.0075 - val_loss: 0.0359 - val_dice_coef: 0.5361 - val_accuracy: 0.9859 - val_mse: 0.0104\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0295 - dice_coef: 0.6233 - accuracy: 0.9859 - mse: 0.0078\n",
            "Epoch 17: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0295 - dice_coef: 0.6233 - accuracy: 0.9859 - mse: 0.0078 - val_loss: 0.0517 - val_dice_coef: 0.4664 - val_accuracy: 0.9814 - val_mse: 0.0144\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - dice_coef: 0.6304 - accuracy: 0.9860 - mse: 0.0077\n",
            "Epoch 18: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0291 - dice_coef: 0.6304 - accuracy: 0.9860 - mse: 0.0077 - val_loss: 0.0318 - val_dice_coef: 0.5078 - val_accuracy: 0.9882 - val_mse: 0.0089\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - dice_coef: 0.6206 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 19: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0287 - dice_coef: 0.6206 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0519 - val_dice_coef: 0.4679 - val_accuracy: 0.9808 - val_mse: 0.0146\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0326 - dice_coef: 0.5774 - accuracy: 0.9850 - mse: 0.0086\n",
            "Epoch 20: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0326 - dice_coef: 0.5774 - accuracy: 0.9850 - mse: 0.0086 - val_loss: 0.0349 - val_dice_coef: 0.4345 - val_accuracy: 0.9869 - val_mse: 0.0098\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - dice_coef: 0.6181 - accuracy: 0.9863 - mse: 0.0076\n",
            "Epoch 21: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0287 - dice_coef: 0.6181 - accuracy: 0.9863 - mse: 0.0076 - val_loss: 0.0400 - val_dice_coef: 0.5037 - val_accuracy: 0.9848 - val_mse: 0.0114\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0297 - dice_coef: 0.6065 - accuracy: 0.9859 - mse: 0.0079\n",
            "Epoch 22: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0297 - dice_coef: 0.6065 - accuracy: 0.9859 - mse: 0.0079 - val_loss: 0.0431 - val_dice_coef: 0.4759 - val_accuracy: 0.9841 - val_mse: 0.0121\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0284 - dice_coef: 0.6140 - accuracy: 0.9863 - mse: 0.0075\n",
            "Epoch 23: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0284 - dice_coef: 0.6140 - accuracy: 0.9863 - mse: 0.0075 - val_loss: 0.0343 - val_dice_coef: 0.4517 - val_accuracy: 0.9875 - val_mse: 0.0095\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - dice_coef: 0.6337 - accuracy: 0.9871 - mse: 0.0070\n",
            "Epoch 24: val_dice_coef did not improve from 0.53684\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0262 - dice_coef: 0.6337 - accuracy: 0.9871 - mse: 0.0070 - val_loss: 0.0290 - val_dice_coef: 0.5250 - val_accuracy: 0.9889 - val_mse: 0.0083\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0264 - dice_coef: 0.6647 - accuracy: 0.9869 - mse: 0.0070\n",
            "Epoch 25: val_dice_coef improved from 0.53684 to 0.54599, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0264 - dice_coef: 0.6647 - accuracy: 0.9869 - mse: 0.0070 - val_loss: 0.0284 - val_dice_coef: 0.5460 - val_accuracy: 0.9891 - val_mse: 0.0081\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - dice_coef: 0.6104 - accuracy: 0.9863 - mse: 0.0077\n",
            "Epoch 26: val_dice_coef did not improve from 0.54599\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0291 - dice_coef: 0.6104 - accuracy: 0.9863 - mse: 0.0077 - val_loss: 0.0298 - val_dice_coef: 0.5424 - val_accuracy: 0.9885 - val_mse: 0.0085\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0279 - dice_coef: 0.6304 - accuracy: 0.9864 - mse: 0.0074\n",
            "Epoch 27: val_dice_coef did not improve from 0.54599\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0279 - dice_coef: 0.6304 - accuracy: 0.9864 - mse: 0.0074 - val_loss: 0.0280 - val_dice_coef: 0.5392 - val_accuracy: 0.9892 - val_mse: 0.0080\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - dice_coef: 0.6446 - accuracy: 0.9871 - mse: 0.0070\n",
            "Epoch 28: val_dice_coef did not improve from 0.54599\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0262 - dice_coef: 0.6446 - accuracy: 0.9871 - mse: 0.0070 - val_loss: 0.0398 - val_dice_coef: 0.4436 - val_accuracy: 0.9866 - val_mse: 0.0104\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0267 - dice_coef: 0.6286 - accuracy: 0.9871 - mse: 0.0071\n",
            "Epoch 29: val_dice_coef did not improve from 0.54599\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0267 - dice_coef: 0.6286 - accuracy: 0.9871 - mse: 0.0071 - val_loss: 0.0428 - val_dice_coef: 0.4940 - val_accuracy: 0.9833 - val_mse: 0.0124\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0264 - dice_coef: 0.6470 - accuracy: 0.9870 - mse: 0.0070\n",
            "Epoch 30: val_dice_coef improved from 0.54599 to 0.57267, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0264 - dice_coef: 0.6470 - accuracy: 0.9870 - mse: 0.0070 - val_loss: 0.0267 - val_dice_coef: 0.5727 - val_accuracy: 0.9893 - val_mse: 0.0078\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - dice_coef: 0.6505 - accuracy: 0.9870 - mse: 0.0070\n",
            "Epoch 31: val_dice_coef did not improve from 0.57267\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0262 - dice_coef: 0.6505 - accuracy: 0.9870 - mse: 0.0070 - val_loss: 0.0266 - val_dice_coef: 0.5624 - val_accuracy: 0.9896 - val_mse: 0.0077\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0249 - dice_coef: 0.6447 - accuracy: 0.9876 - mse: 0.0066\n",
            "Epoch 32: val_dice_coef did not improve from 0.57267\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0249 - dice_coef: 0.6447 - accuracy: 0.9876 - mse: 0.0066 - val_loss: 0.0336 - val_dice_coef: 0.4949 - val_accuracy: 0.9868 - val_mse: 0.0097\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0255 - dice_coef: 0.6593 - accuracy: 0.9874 - mse: 0.0067\n",
            "Epoch 33: val_dice_coef did not improve from 0.57267\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0255 - dice_coef: 0.6593 - accuracy: 0.9874 - mse: 0.0067 - val_loss: 0.0271 - val_dice_coef: 0.5672 - val_accuracy: 0.9893 - val_mse: 0.0078\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0252 - dice_coef: 0.6631 - accuracy: 0.9873 - mse: 0.0067\n",
            "Epoch 34: val_dice_coef improved from 0.57267 to 0.58776, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0252 - dice_coef: 0.6631 - accuracy: 0.9873 - mse: 0.0067 - val_loss: 0.0276 - val_dice_coef: 0.5878 - val_accuracy: 0.9894 - val_mse: 0.0079\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0248 - dice_coef: 0.6654 - accuracy: 0.9876 - mse: 0.0066\n",
            "Epoch 35: val_dice_coef did not improve from 0.58776\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0248 - dice_coef: 0.6654 - accuracy: 0.9876 - mse: 0.0066 - val_loss: 0.0380 - val_dice_coef: 0.4984 - val_accuracy: 0.9851 - val_mse: 0.0110\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0249 - dice_coef: 0.6624 - accuracy: 0.9875 - mse: 0.0066\n",
            "Epoch 36: val_dice_coef did not improve from 0.58776\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0249 - dice_coef: 0.6624 - accuracy: 0.9875 - mse: 0.0066 - val_loss: 0.0276 - val_dice_coef: 0.5766 - val_accuracy: 0.9889 - val_mse: 0.0081\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0245 - dice_coef: 0.6590 - accuracy: 0.9877 - mse: 0.0065\n",
            "Epoch 37: val_dice_coef did not improve from 0.58776\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0245 - dice_coef: 0.6590 - accuracy: 0.9877 - mse: 0.0065 - val_loss: 0.0263 - val_dice_coef: 0.5734 - val_accuracy: 0.9897 - val_mse: 0.0076\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0248 - dice_coef: 0.6663 - accuracy: 0.9874 - mse: 0.0066\n",
            "Epoch 38: val_dice_coef did not improve from 0.58776\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0248 - dice_coef: 0.6663 - accuracy: 0.9874 - mse: 0.0066 - val_loss: 0.0269 - val_dice_coef: 0.5673 - val_accuracy: 0.9893 - val_mse: 0.0078\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0236 - dice_coef: 0.6754 - accuracy: 0.9880 - mse: 0.0063\n",
            "Epoch 39: val_dice_coef improved from 0.58776 to 0.59414, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0236 - dice_coef: 0.6754 - accuracy: 0.9880 - mse: 0.0063 - val_loss: 0.0250 - val_dice_coef: 0.5941 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0255 - dice_coef: 0.6474 - accuracy: 0.9872 - mse: 0.0068\n",
            "Epoch 40: val_dice_coef improved from 0.59414 to 0.59552, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0255 - dice_coef: 0.6474 - accuracy: 0.9872 - mse: 0.0068 - val_loss: 0.0290 - val_dice_coef: 0.5955 - val_accuracy: 0.9886 - val_mse: 0.0085\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0262 - dice_coef: 0.6464 - accuracy: 0.9870 - mse: 0.0070\n",
            "Epoch 41: val_dice_coef did not improve from 0.59552\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0262 - dice_coef: 0.6464 - accuracy: 0.9870 - mse: 0.0070 - val_loss: 0.0281 - val_dice_coef: 0.5623 - val_accuracy: 0.9893 - val_mse: 0.0080\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0240 - dice_coef: 0.6796 - accuracy: 0.9877 - mse: 0.0064\n",
            "Epoch 42: val_dice_coef did not improve from 0.59552\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0240 - dice_coef: 0.6796 - accuracy: 0.9877 - mse: 0.0064 - val_loss: 0.0242 - val_dice_coef: 0.5909 - val_accuracy: 0.9903 - val_mse: 0.0071\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0236 - dice_coef: 0.6768 - accuracy: 0.9878 - mse: 0.0063\n",
            "Epoch 43: val_dice_coef did not improve from 0.59552\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0236 - dice_coef: 0.6768 - accuracy: 0.9878 - mse: 0.0063 - val_loss: 0.0302 - val_dice_coef: 0.5441 - val_accuracy: 0.9888 - val_mse: 0.0084\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0229 - dice_coef: 0.6759 - accuracy: 0.9882 - mse: 0.0061\n",
            "Epoch 44: val_dice_coef improved from 0.59552 to 0.60342, saving model to Output/resUNet_tall/resUNet_tall.hdf5\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0229 - dice_coef: 0.6759 - accuracy: 0.9882 - mse: 0.0061 - val_loss: 0.0266 - val_dice_coef: 0.6034 - val_accuracy: 0.9893 - val_mse: 0.0078\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0233 - dice_coef: 0.6727 - accuracy: 0.9880 - mse: 0.0062\n",
            "Epoch 45: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0233 - dice_coef: 0.6727 - accuracy: 0.9880 - mse: 0.0062 - val_loss: 0.0347 - val_dice_coef: 0.5481 - val_accuracy: 0.9880 - val_mse: 0.0092\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0249 - dice_coef: 0.6479 - accuracy: 0.9876 - mse: 0.0066\n",
            "Epoch 46: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0249 - dice_coef: 0.6479 - accuracy: 0.9876 - mse: 0.0066 - val_loss: 0.0241 - val_dice_coef: 0.5899 - val_accuracy: 0.9902 - val_mse: 0.0071\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0251 - dice_coef: 0.6676 - accuracy: 0.9872 - mse: 0.0067\n",
            "Epoch 47: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0251 - dice_coef: 0.6676 - accuracy: 0.9872 - mse: 0.0067 - val_loss: 0.0274 - val_dice_coef: 0.5589 - val_accuracy: 0.9893 - val_mse: 0.0079\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0233 - dice_coef: 0.6721 - accuracy: 0.9881 - mse: 0.0062\n",
            "Epoch 48: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0233 - dice_coef: 0.6721 - accuracy: 0.9881 - mse: 0.0062 - val_loss: 0.0250 - val_dice_coef: 0.5954 - val_accuracy: 0.9900 - val_mse: 0.0073\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0236 - dice_coef: 0.6921 - accuracy: 0.9879 - mse: 0.0063\n",
            "Epoch 49: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0236 - dice_coef: 0.6921 - accuracy: 0.9879 - mse: 0.0063 - val_loss: 0.0272 - val_dice_coef: 0.5791 - val_accuracy: 0.9891 - val_mse: 0.0080\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0256 - dice_coef: 0.6512 - accuracy: 0.9872 - mse: 0.0069\n",
            "Epoch 50: val_dice_coef did not improve from 0.60342\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0256 - dice_coef: 0.6512 - accuracy: 0.9872 - mse: 0.0069 - val_loss: 0.0694 - val_dice_coef: 0.3808 - val_accuracy: 0.9741 - val_mse: 0.0194\n",
            "Total time to train: 5489.0919053554535\n",
            "cp: error writing 'sv_para/Output/fcn32_tall/fcn32_tall.hdf5': Transport endpoint is not connected\n",
            "cp: failed to close 'sv_para/Output/fcn32_tall/fcn32_tall.hdf5': Transport endpoint is not connected\n",
            "cp: failed to close 'Output/fcn32_tall/fcn32_tall.hdf5': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_Loss.csv': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_ValLoss.csv': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_ValDiceCoef.csv': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_DiceCoef.csv': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_Training_Validation_Loss.png': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/fcn32_tall/fcn32_tall_Training_ValidationDiceCoef.png': Transport endpoint is not connected\n",
            "cp: cannot stat 'Output/resUNet_tall': Transport endpoint is not connected\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-0bcedec9d5c0>\", line 10, in <cell line: 10>\n",
            "    resUNet_tall = train(resUNet_tall, callbacks, train_rgb_tall, validation_df, \"resUNet_tall\", epochs=50, steps_per_epoch=100)\n",
            "  File \"<ipython-input-22-324a31e325bb>\", line 23, in train\n",
            "    np.savetxt(fullOutPath+\"/%s_Loss.csv\" % (modelName),\n",
            "  File \"<__array_function__ internals>\", line 180, in savetxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1383, in savetxt\n",
            "    open(fname, 'wt').close()\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Output/resUNet_tall/resUNet_tall_Loss.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-0bcedec9d5c0>\", line 10, in <cell line: 10>\n",
            "    resUNet_tall = train(resUNet_tall, callbacks, train_rgb_tall, validation_df, \"resUNet_tall\", epochs=50, steps_per_epoch=100)\n",
            "  File \"<ipython-input-22-324a31e325bb>\", line 23, in train\n",
            "    np.savetxt(fullOutPath+\"/%s_Loss.csv\" % (modelName),\n",
            "  File \"<__array_function__ internals>\", line 180, in savetxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1383, in savetxt\n",
            "    open(fname, 'wt').close()\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Output/resUNet_tall/resUNet_tall_Loss.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-0bcedec9d5c0>\", line 10, in <cell line: 10>\n",
            "    resUNet_tall = train(resUNet_tall, callbacks, train_rgb_tall, validation_df, \"resUNet_tall\", epochs=50, steps_per_epoch=100)\n",
            "  File \"<ipython-input-22-324a31e325bb>\", line 23, in train\n",
            "    np.savetxt(fullOutPath+\"/%s_Loss.csv\" % (modelName),\n",
            "  File \"<__array_function__ internals>\", line 180, in savetxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 1383, in savetxt\n",
            "    open(fname, 'wt').close()\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Output/resUNet_tall/resUNet_tall_Loss.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "# Train ResUNet with generator\n",
        "resUNet_tall = res_unet(tileSize, [32, 64, 128, 256], 3, 3, 1)\n",
        "# resUNet = load_model('Output/resUNet_tall/resUNet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resUNet_tall\", \"resUNet_tall\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_tall = TrainGenerator(8, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "resUNet_tall = train(resUNet_tall, callbacks, train_rgb_tall, validation_df, \"resUNet_tall\", epochs=50, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKU_s4_y5AIf"
      },
      "source": [
        "### **Attention ResUNet**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R2evDFrcKJ-h",
        "outputId": "c602a9f6-a240-45e2-8299-78b4abae5d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1314 - dice_coef: 0.4515 - accuracy: 0.9494 - mse: 0.0335\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.02065, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 75s 499ms/step - loss: 0.1314 - dice_coef: 0.4515 - accuracy: 0.9494 - mse: 0.0335 - val_loss: 1.9700 - val_dice_coef: 0.0207 - val_accuracy: 0.9528 - val_mse: 0.0467\n",
            "Epoch 2/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0892 - dice_coef: 0.4886 - accuracy: 0.9619 - mse: 0.0235\n",
            "Epoch 2: val_dice_coef improved from 0.02065 to 0.09833, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 59s 589ms/step - loss: 0.0892 - dice_coef: 0.4886 - accuracy: 0.9619 - mse: 0.0235 - val_loss: 0.2020 - val_dice_coef: 0.0983 - val_accuracy: 0.9526 - val_mse: 0.0425\n",
            "Epoch 3/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0838 - dice_coef: 0.5207 - accuracy: 0.9640 - mse: 0.0220\n",
            "Epoch 3: val_dice_coef improved from 0.09833 to 0.30705, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 51s 514ms/step - loss: 0.0838 - dice_coef: 0.5207 - accuracy: 0.9640 - mse: 0.0220 - val_loss: 0.1176 - val_dice_coef: 0.3071 - val_accuracy: 0.9611 - val_mse: 0.0305\n",
            "Epoch 4/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0805 - dice_coef: 0.5475 - accuracy: 0.9646 - mse: 0.0212\n",
            "Epoch 4: val_dice_coef improved from 0.30705 to 0.38395, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 51s 516ms/step - loss: 0.0805 - dice_coef: 0.5475 - accuracy: 0.9646 - mse: 0.0212 - val_loss: 0.0854 - val_dice_coef: 0.3839 - val_accuracy: 0.9663 - val_mse: 0.0248\n",
            "Epoch 5/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0761 - dice_coef: 0.5401 - accuracy: 0.9660 - mse: 0.0202\n",
            "Epoch 5: val_dice_coef improved from 0.38395 to 0.40171, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 52s 518ms/step - loss: 0.0761 - dice_coef: 0.5401 - accuracy: 0.9660 - mse: 0.0202 - val_loss: 0.0826 - val_dice_coef: 0.4017 - val_accuracy: 0.9661 - val_mse: 0.0245\n",
            "Epoch 6/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0749 - dice_coef: 0.5587 - accuracy: 0.9666 - mse: 0.0198\n",
            "Epoch 6: val_dice_coef improved from 0.40171 to 0.51094, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 0.0749 - dice_coef: 0.5587 - accuracy: 0.9666 - mse: 0.0198 - val_loss: 0.0725 - val_dice_coef: 0.5109 - val_accuracy: 0.9737 - val_mse: 0.0203\n",
            "Epoch 7/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0722 - dice_coef: 0.5857 - accuracy: 0.9671 - mse: 0.0191\n",
            "Epoch 7: val_dice_coef did not improve from 0.51094\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0722 - dice_coef: 0.5857 - accuracy: 0.9671 - mse: 0.0191 - val_loss: 0.0772 - val_dice_coef: 0.4199 - val_accuracy: 0.9674 - val_mse: 0.0231\n",
            "Epoch 8/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0732 - dice_coef: 0.5690 - accuracy: 0.9669 - mse: 0.0193\n",
            "Epoch 8: val_dice_coef did not improve from 0.51094\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0732 - dice_coef: 0.5690 - accuracy: 0.9669 - mse: 0.0193 - val_loss: 0.1796 - val_dice_coef: 0.4070 - val_accuracy: 0.9231 - val_mse: 0.0547\n",
            "Epoch 9/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0744 - dice_coef: 0.5675 - accuracy: 0.9661 - mse: 0.0199\n",
            "Epoch 9: val_dice_coef did not improve from 0.51094\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0744 - dice_coef: 0.5675 - accuracy: 0.9661 - mse: 0.0199 - val_loss: 0.1148 - val_dice_coef: 0.4656 - val_accuracy: 0.9535 - val_mse: 0.0337\n",
            "Epoch 10/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0693 - dice_coef: 0.5944 - accuracy: 0.9681 - mse: 0.0184\n",
            "Epoch 10: val_dice_coef did not improve from 0.51094\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0693 - dice_coef: 0.5944 - accuracy: 0.9681 - mse: 0.0184 - val_loss: 0.1043 - val_dice_coef: 0.5099 - val_accuracy: 0.9552 - val_mse: 0.0317\n",
            "Epoch 11/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0705 - dice_coef: 0.5934 - accuracy: 0.9682 - mse: 0.0185\n",
            "Epoch 11: val_dice_coef improved from 0.51094 to 0.54480, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 54s 545ms/step - loss: 0.0705 - dice_coef: 0.5934 - accuracy: 0.9682 - mse: 0.0185 - val_loss: 0.0668 - val_dice_coef: 0.5448 - val_accuracy: 0.9743 - val_mse: 0.0190\n",
            "Epoch 12/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0691 - dice_coef: 0.6014 - accuracy: 0.9684 - mse: 0.0182\n",
            "Epoch 12: val_dice_coef did not improve from 0.54480\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 0.0691 - dice_coef: 0.6014 - accuracy: 0.9684 - mse: 0.0182 - val_loss: 0.1668 - val_dice_coef: 0.3936 - val_accuracy: 0.9278 - val_mse: 0.0508\n",
            "Epoch 13/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0675 - dice_coef: 0.6054 - accuracy: 0.9691 - mse: 0.0177\n",
            "Epoch 13: val_dice_coef did not improve from 0.54480\n",
            "100/100 [==============================] - 46s 466ms/step - loss: 0.0675 - dice_coef: 0.6054 - accuracy: 0.9691 - mse: 0.0177 - val_loss: 0.0720 - val_dice_coef: 0.5436 - val_accuracy: 0.9717 - val_mse: 0.0208\n",
            "Epoch 14/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0667 - dice_coef: 0.6180 - accuracy: 0.9693 - mse: 0.0176\n",
            "Epoch 14: val_dice_coef did not improve from 0.54480\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.0667 - dice_coef: 0.6180 - accuracy: 0.9693 - mse: 0.0176 - val_loss: 0.2342 - val_dice_coef: 0.3868 - val_accuracy: 0.8923 - val_mse: 0.0742\n",
            "Epoch 15/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0618 - dice_coef: 0.6208 - accuracy: 0.9710 - mse: 0.0164\n",
            "Epoch 15: val_dice_coef improved from 0.54480 to 0.54591, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 51s 512ms/step - loss: 0.0618 - dice_coef: 0.6208 - accuracy: 0.9710 - mse: 0.0164 - val_loss: 0.0743 - val_dice_coef: 0.5459 - val_accuracy: 0.9699 - val_mse: 0.0219\n",
            "Epoch 16/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0672 - dice_coef: 0.6155 - accuracy: 0.9692 - mse: 0.0176\n",
            "Epoch 16: val_dice_coef did not improve from 0.54591\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 0.0672 - dice_coef: 0.6155 - accuracy: 0.9692 - mse: 0.0176 - val_loss: 0.0777 - val_dice_coef: 0.5074 - val_accuracy: 0.9712 - val_mse: 0.0218\n",
            "Epoch 17/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0648 - dice_coef: 0.6331 - accuracy: 0.9696 - mse: 0.0171\n",
            "Epoch 17: val_dice_coef improved from 0.54591 to 0.58443, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 0.0648 - dice_coef: 0.6331 - accuracy: 0.9696 - mse: 0.0171 - val_loss: 0.0594 - val_dice_coef: 0.5844 - val_accuracy: 0.9767 - val_mse: 0.0172\n",
            "Epoch 18/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0638 - dice_coef: 0.6284 - accuracy: 0.9702 - mse: 0.0168\n",
            "Epoch 18: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0638 - dice_coef: 0.6284 - accuracy: 0.9702 - mse: 0.0168 - val_loss: 0.0887 - val_dice_coef: 0.5459 - val_accuracy: 0.9640 - val_mse: 0.0262\n",
            "Epoch 19/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0622 - dice_coef: 0.6419 - accuracy: 0.9711 - mse: 0.0163\n",
            "Epoch 19: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.0622 - dice_coef: 0.6419 - accuracy: 0.9711 - mse: 0.0163 - val_loss: 0.0845 - val_dice_coef: 0.5463 - val_accuracy: 0.9627 - val_mse: 0.0259\n",
            "Epoch 20/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0606 - dice_coef: 0.6476 - accuracy: 0.9718 - mse: 0.0157\n",
            "Epoch 20: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0606 - dice_coef: 0.6476 - accuracy: 0.9718 - mse: 0.0157 - val_loss: 0.0655 - val_dice_coef: 0.5467 - val_accuracy: 0.9748 - val_mse: 0.0187\n",
            "Epoch 21/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0590 - dice_coef: 0.6484 - accuracy: 0.9717 - mse: 0.0156\n",
            "Epoch 21: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0590 - dice_coef: 0.6484 - accuracy: 0.9717 - mse: 0.0156 - val_loss: 0.0738 - val_dice_coef: 0.5608 - val_accuracy: 0.9699 - val_mse: 0.0219\n",
            "Epoch 22/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0602 - dice_coef: 0.6603 - accuracy: 0.9714 - mse: 0.0158\n",
            "Epoch 22: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0602 - dice_coef: 0.6603 - accuracy: 0.9714 - mse: 0.0158 - val_loss: 0.0726 - val_dice_coef: 0.5226 - val_accuracy: 0.9725 - val_mse: 0.0206\n",
            "Epoch 23/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0610 - dice_coef: 0.6339 - accuracy: 0.9712 - mse: 0.0161\n",
            "Epoch 23: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0610 - dice_coef: 0.6339 - accuracy: 0.9712 - mse: 0.0161 - val_loss: 0.0590 - val_dice_coef: 0.5648 - val_accuracy: 0.9772 - val_mse: 0.0169\n",
            "Epoch 24/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0566 - dice_coef: 0.6704 - accuracy: 0.9729 - mse: 0.0148\n",
            "Epoch 24: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0566 - dice_coef: 0.6704 - accuracy: 0.9729 - mse: 0.0148 - val_loss: 0.0575 - val_dice_coef: 0.5516 - val_accuracy: 0.9773 - val_mse: 0.0167\n",
            "Epoch 25/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0604 - dice_coef: 0.6497 - accuracy: 0.9714 - mse: 0.0159\n",
            "Epoch 25: val_dice_coef did not improve from 0.58443\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.0604 - dice_coef: 0.6497 - accuracy: 0.9714 - mse: 0.0159 - val_loss: 0.0613 - val_dice_coef: 0.5701 - val_accuracy: 0.9778 - val_mse: 0.0170\n",
            "Epoch 26/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0581 - dice_coef: 0.6466 - accuracy: 0.9728 - mse: 0.0152\n",
            "Epoch 26: val_dice_coef improved from 0.58443 to 0.61160, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 0.0581 - dice_coef: 0.6466 - accuracy: 0.9728 - mse: 0.0152 - val_loss: 0.0626 - val_dice_coef: 0.6116 - val_accuracy: 0.9757 - val_mse: 0.0181\n",
            "Epoch 27/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0588 - dice_coef: 0.6515 - accuracy: 0.9724 - mse: 0.0153\n",
            "Epoch 27: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.0588 - dice_coef: 0.6515 - accuracy: 0.9724 - mse: 0.0153 - val_loss: 0.0707 - val_dice_coef: 0.5572 - val_accuracy: 0.9722 - val_mse: 0.0205\n",
            "Epoch 28/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0568 - dice_coef: 0.6543 - accuracy: 0.9728 - mse: 0.0149\n",
            "Epoch 28: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.0568 - dice_coef: 0.6543 - accuracy: 0.9728 - mse: 0.0149 - val_loss: 0.0694 - val_dice_coef: 0.5706 - val_accuracy: 0.9740 - val_mse: 0.0196\n",
            "Epoch 29/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0572 - dice_coef: 0.6622 - accuracy: 0.9724 - mse: 0.0151\n",
            "Epoch 29: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0572 - dice_coef: 0.6622 - accuracy: 0.9724 - mse: 0.0151 - val_loss: 0.0646 - val_dice_coef: 0.5458 - val_accuracy: 0.9762 - val_mse: 0.0180\n",
            "Epoch 30/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0579 - dice_coef: 0.6560 - accuracy: 0.9725 - mse: 0.0151\n",
            "Epoch 30: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0579 - dice_coef: 0.6560 - accuracy: 0.9725 - mse: 0.0151 - val_loss: 0.0529 - val_dice_coef: 0.6102 - val_accuracy: 0.9789 - val_mse: 0.0154\n",
            "Epoch 31/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0568 - dice_coef: 0.6596 - accuracy: 0.9730 - mse: 0.0149\n",
            "Epoch 31: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0568 - dice_coef: 0.6596 - accuracy: 0.9730 - mse: 0.0149 - val_loss: 0.0558 - val_dice_coef: 0.5687 - val_accuracy: 0.9791 - val_mse: 0.0157\n",
            "Epoch 32/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0571 - dice_coef: 0.6523 - accuracy: 0.9729 - mse: 0.0149\n",
            "Epoch 32: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0571 - dice_coef: 0.6523 - accuracy: 0.9729 - mse: 0.0149 - val_loss: 0.0730 - val_dice_coef: 0.5461 - val_accuracy: 0.9725 - val_mse: 0.0209\n",
            "Epoch 33/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0592 - dice_coef: 0.6545 - accuracy: 0.9721 - mse: 0.0154\n",
            "Epoch 33: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0592 - dice_coef: 0.6545 - accuracy: 0.9721 - mse: 0.0154 - val_loss: 0.0517 - val_dice_coef: 0.5855 - val_accuracy: 0.9797 - val_mse: 0.0149\n",
            "Epoch 34/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0572 - dice_coef: 0.6708 - accuracy: 0.9721 - mse: 0.0151\n",
            "Epoch 34: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.0572 - dice_coef: 0.6708 - accuracy: 0.9721 - mse: 0.0151 - val_loss: 0.0566 - val_dice_coef: 0.5979 - val_accuracy: 0.9775 - val_mse: 0.0166\n",
            "Epoch 35/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0526 - dice_coef: 0.6699 - accuracy: 0.9747 - mse: 0.0137\n",
            "Epoch 35: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0526 - dice_coef: 0.6699 - accuracy: 0.9747 - mse: 0.0137 - val_loss: 0.0661 - val_dice_coef: 0.5698 - val_accuracy: 0.9739 - val_mse: 0.0191\n",
            "Epoch 36/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0583 - dice_coef: 0.6591 - accuracy: 0.9722 - mse: 0.0152\n",
            "Epoch 36: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0583 - dice_coef: 0.6591 - accuracy: 0.9722 - mse: 0.0152 - val_loss: 0.0564 - val_dice_coef: 0.5705 - val_accuracy: 0.9777 - val_mse: 0.0163\n",
            "Epoch 37/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0602 - dice_coef: 0.6519 - accuracy: 0.9716 - mse: 0.0157\n",
            "Epoch 37: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0602 - dice_coef: 0.6519 - accuracy: 0.9716 - mse: 0.0157 - val_loss: 0.0613 - val_dice_coef: 0.5983 - val_accuracy: 0.9758 - val_mse: 0.0178\n",
            "Epoch 38/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0561 - dice_coef: 0.6635 - accuracy: 0.9729 - mse: 0.0148\n",
            "Epoch 38: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0561 - dice_coef: 0.6635 - accuracy: 0.9729 - mse: 0.0148 - val_loss: 0.0623 - val_dice_coef: 0.5940 - val_accuracy: 0.9751 - val_mse: 0.0183\n",
            "Epoch 39/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0552 - dice_coef: 0.6803 - accuracy: 0.9730 - mse: 0.0145\n",
            "Epoch 39: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0552 - dice_coef: 0.6803 - accuracy: 0.9730 - mse: 0.0145 - val_loss: 0.0535 - val_dice_coef: 0.5794 - val_accuracy: 0.9793 - val_mse: 0.0153\n",
            "Epoch 40/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0542 - dice_coef: 0.6758 - accuracy: 0.9734 - mse: 0.0143\n",
            "Epoch 40: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.0542 - dice_coef: 0.6758 - accuracy: 0.9734 - mse: 0.0143 - val_loss: 0.1102 - val_dice_coef: 0.5028 - val_accuracy: 0.9546 - val_mse: 0.0327\n",
            "Epoch 41/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0538 - dice_coef: 0.6803 - accuracy: 0.9738 - mse: 0.0140\n",
            "Epoch 41: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 46s 466ms/step - loss: 0.0538 - dice_coef: 0.6803 - accuracy: 0.9738 - mse: 0.0140 - val_loss: 0.0561 - val_dice_coef: 0.6014 - val_accuracy: 0.9781 - val_mse: 0.0161\n",
            "Epoch 42/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0566 - dice_coef: 0.6703 - accuracy: 0.9725 - mse: 0.0149\n",
            "Epoch 42: val_dice_coef did not improve from 0.61160\n",
            "100/100 [==============================] - 46s 466ms/step - loss: 0.0566 - dice_coef: 0.6703 - accuracy: 0.9725 - mse: 0.0149 - val_loss: 0.0615 - val_dice_coef: 0.5599 - val_accuracy: 0.9770 - val_mse: 0.0173\n",
            "Epoch 43/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0532 - dice_coef: 0.6798 - accuracy: 0.9738 - mse: 0.0139\n",
            "Epoch 43: val_dice_coef improved from 0.61160 to 0.64248, saving model to Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5\n",
            "100/100 [==============================] - 54s 539ms/step - loss: 0.0532 - dice_coef: 0.6798 - accuracy: 0.9738 - mse: 0.0139 - val_loss: 0.0495 - val_dice_coef: 0.6425 - val_accuracy: 0.9799 - val_mse: 0.0147\n",
            "Epoch 44/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0551 - dice_coef: 0.6744 - accuracy: 0.9730 - mse: 0.0145\n",
            "Epoch 44: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.0551 - dice_coef: 0.6744 - accuracy: 0.9730 - mse: 0.0145 - val_loss: 0.0553 - val_dice_coef: 0.6210 - val_accuracy: 0.9772 - val_mse: 0.0165\n",
            "Epoch 45/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0518 - dice_coef: 0.6784 - accuracy: 0.9743 - mse: 0.0137\n",
            "Epoch 45: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 46s 466ms/step - loss: 0.0518 - dice_coef: 0.6784 - accuracy: 0.9743 - mse: 0.0137 - val_loss: 0.0531 - val_dice_coef: 0.5796 - val_accuracy: 0.9795 - val_mse: 0.0152\n",
            "Epoch 46/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0535 - dice_coef: 0.6795 - accuracy: 0.9740 - mse: 0.0139\n",
            "Epoch 46: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 0.0535 - dice_coef: 0.6795 - accuracy: 0.9740 - mse: 0.0139 - val_loss: 0.0562 - val_dice_coef: 0.5288 - val_accuracy: 0.9780 - val_mse: 0.0161\n",
            "Epoch 47/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0544 - dice_coef: 0.6692 - accuracy: 0.9738 - mse: 0.0142\n",
            "Epoch 47: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 0.0544 - dice_coef: 0.6692 - accuracy: 0.9738 - mse: 0.0142 - val_loss: 0.0727 - val_dice_coef: 0.5213 - val_accuracy: 0.9742 - val_mse: 0.0200\n",
            "Epoch 48/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0545 - dice_coef: 0.6839 - accuracy: 0.9733 - mse: 0.0142\n",
            "Epoch 48: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0545 - dice_coef: 0.6839 - accuracy: 0.9733 - mse: 0.0142 - val_loss: 0.0563 - val_dice_coef: 0.5908 - val_accuracy: 0.9781 - val_mse: 0.0161\n",
            "Epoch 49/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0568 - dice_coef: 0.6607 - accuracy: 0.9731 - mse: 0.0148\n",
            "Epoch 49: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0568 - dice_coef: 0.6607 - accuracy: 0.9731 - mse: 0.0148 - val_loss: 0.0746 - val_dice_coef: 0.5123 - val_accuracy: 0.9748 - val_mse: 0.0201\n",
            "Epoch 50/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0559 - dice_coef: 0.6757 - accuracy: 0.9730 - mse: 0.0147\n",
            "Epoch 50: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 0.0559 - dice_coef: 0.6757 - accuracy: 0.9730 - mse: 0.0147 - val_loss: 0.0590 - val_dice_coef: 0.5613 - val_accuracy: 0.9782 - val_mse: 0.0165\n",
            "Epoch 51/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0541 - dice_coef: 0.6813 - accuracy: 0.9735 - mse: 0.0142\n",
            "Epoch 51: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 57s 571ms/step - loss: 0.0541 - dice_coef: 0.6813 - accuracy: 0.9735 - mse: 0.0142 - val_loss: 0.0850 - val_dice_coef: 0.5101 - val_accuracy: 0.9678 - val_mse: 0.0243\n",
            "Epoch 52/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0535 - dice_coef: 0.6768 - accuracy: 0.9739 - mse: 0.0140\n",
            "Epoch 52: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 0.0535 - dice_coef: 0.6768 - accuracy: 0.9739 - mse: 0.0140 - val_loss: 0.0593 - val_dice_coef: 0.5676 - val_accuracy: 0.9778 - val_mse: 0.0167\n",
            "Epoch 53/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0548 - dice_coef: 0.6779 - accuracy: 0.9730 - mse: 0.0144\n",
            "Epoch 53: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 46s 466ms/step - loss: 0.0548 - dice_coef: 0.6779 - accuracy: 0.9730 - mse: 0.0144 - val_loss: 0.0535 - val_dice_coef: 0.5896 - val_accuracy: 0.9794 - val_mse: 0.0152\n",
            "Epoch 54/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0551 - dice_coef: 0.6805 - accuracy: 0.9729 - mse: 0.0145\n",
            "Epoch 54: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0551 - dice_coef: 0.6805 - accuracy: 0.9729 - mse: 0.0145 - val_loss: 0.0561 - val_dice_coef: 0.5604 - val_accuracy: 0.9785 - val_mse: 0.0160\n",
            "Epoch 55/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0508 - dice_coef: 0.6834 - accuracy: 0.9748 - mse: 0.0133\n",
            "Epoch 55: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0508 - dice_coef: 0.6834 - accuracy: 0.9748 - mse: 0.0133 - val_loss: 0.0585 - val_dice_coef: 0.5999 - val_accuracy: 0.9770 - val_mse: 0.0169\n",
            "Epoch 56/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0515 - dice_coef: 0.6906 - accuracy: 0.9744 - mse: 0.0136\n",
            "Epoch 56: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0515 - dice_coef: 0.6906 - accuracy: 0.9744 - mse: 0.0136 - val_loss: 0.0706 - val_dice_coef: 0.5641 - val_accuracy: 0.9734 - val_mse: 0.0200\n",
            "Epoch 57/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0529 - dice_coef: 0.6875 - accuracy: 0.9741 - mse: 0.0138\n",
            "Epoch 57: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0529 - dice_coef: 0.6875 - accuracy: 0.9741 - mse: 0.0138 - val_loss: 0.1021 - val_dice_coef: 0.4735 - val_accuracy: 0.9600 - val_mse: 0.0296\n",
            "Epoch 58/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0539 - dice_coef: 0.6750 - accuracy: 0.9734 - mse: 0.0142\n",
            "Epoch 58: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.0539 - dice_coef: 0.6750 - accuracy: 0.9734 - mse: 0.0142 - val_loss: 0.0499 - val_dice_coef: 0.6176 - val_accuracy: 0.9802 - val_mse: 0.0145\n",
            "Epoch 59/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0510 - dice_coef: 0.6919 - accuracy: 0.9742 - mse: 0.0136\n",
            "Epoch 59: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0510 - dice_coef: 0.6919 - accuracy: 0.9742 - mse: 0.0136 - val_loss: 0.1243 - val_dice_coef: 0.4562 - val_accuracy: 0.9494 - val_mse: 0.0368\n",
            "Epoch 60/60\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0572 - dice_coef: 0.6647 - accuracy: 0.9724 - mse: 0.0150\n",
            "Epoch 60: val_dice_coef did not improve from 0.64248\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.0572 - dice_coef: 0.6647 - accuracy: 0.9724 - mse: 0.0150 - val_loss: 0.0590 - val_dice_coef: 0.5828 - val_accuracy: 0.9772 - val_mse: 0.0168\n",
            "Total time to train: 2899.3750755786896\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train Res Attention UNet with generator        内存不足改为tilesize 128\n",
        "# resaunet_tall_ = att_res_unet(tileSize, [64, 128, 256, 512], 3, 3, 1, lr = 0.0005)\n",
        "#aresUNet = load_model('Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "aresUNet =  att_res_unet(tileSize, [64, 128, 256, 512], 3, 3, 1, lr = 0.0005)\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resaunet_tall_512x512\", \"resaunet_tall_512x512\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "\n",
        "train_rgb_tall = TrainGenerator(16, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "resaunet_tall = train(aresUNet, callbacks, train_rgb_tall, validation_df, \"resaunet_tall_512x512\", epochs=60, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-2FM9W2gs5"
      },
      "source": [
        "### **UNet++**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9N6Hsfv2gMC",
        "outputId": "3e7990a6-0afc-4ebf-9d05-4b2655ef4d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1999 - dice_coef: 0.0192 - accuracy: 0.9665 - mse: 0.0482\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.01059, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 188s 2s/step - loss: 0.1999 - dice_coef: 0.0192 - accuracy: 0.9665 - mse: 0.0482 - val_loss: 0.1204 - val_dice_coef: 0.0106 - val_accuracy: 0.9769 - val_mse: 0.0228\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1036 - dice_coef: 0.0289 - accuracy: 0.9763 - mse: 0.0204\n",
            "Epoch 2: val_dice_coef improved from 0.01059 to 0.05068, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.1036 - dice_coef: 0.0289 - accuracy: 0.9763 - mse: 0.0204 - val_loss: 0.0969 - val_dice_coef: 0.0507 - val_accuracy: 0.9769 - val_mse: 0.0222\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0762 - dice_coef: 0.1300 - accuracy: 0.9762 - mse: 0.0178\n",
            "Epoch 3: val_dice_coef improved from 0.05068 to 0.27018, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0762 - dice_coef: 0.1300 - accuracy: 0.9762 - mse: 0.0178 - val_loss: 0.0517 - val_dice_coef: 0.2702 - val_accuracy: 0.9769 - val_mse: 0.0146\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0456 - dice_coef: 0.3823 - accuracy: 0.9808 - mse: 0.0119\n",
            "Epoch 4: val_dice_coef improved from 0.27018 to 0.45055, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0456 - dice_coef: 0.3823 - accuracy: 0.9808 - mse: 0.0119 - val_loss: 0.0391 - val_dice_coef: 0.4505 - val_accuracy: 0.9851 - val_mse: 0.0111\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0411 - dice_coef: 0.4467 - accuracy: 0.9827 - mse: 0.0107\n",
            "Epoch 5: val_dice_coef did not improve from 0.45055\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0411 - dice_coef: 0.4467 - accuracy: 0.9827 - mse: 0.0107 - val_loss: 0.0449 - val_dice_coef: 0.3178 - val_accuracy: 0.9815 - val_mse: 0.0131\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0401 - dice_coef: 0.4585 - accuracy: 0.9830 - mse: 0.0105\n",
            "Epoch 6: val_dice_coef improved from 0.45055 to 0.45819, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0401 - dice_coef: 0.4585 - accuracy: 0.9830 - mse: 0.0105 - val_loss: 0.0367 - val_dice_coef: 0.4582 - val_accuracy: 0.9860 - val_mse: 0.0104\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0400 - dice_coef: 0.4769 - accuracy: 0.9830 - mse: 0.0104\n",
            "Epoch 7: val_dice_coef did not improve from 0.45819\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0400 - dice_coef: 0.4769 - accuracy: 0.9830 - mse: 0.0104 - val_loss: 0.0376 - val_dice_coef: 0.4316 - val_accuracy: 0.9855 - val_mse: 0.0108\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0363 - dice_coef: 0.5027 - accuracy: 0.9840 - mse: 0.0095\n",
            "Epoch 8: val_dice_coef did not improve from 0.45819\n",
            "100/100 [==============================] - 150s 2s/step - loss: 0.0363 - dice_coef: 0.5027 - accuracy: 0.9840 - mse: 0.0095 - val_loss: 0.0384 - val_dice_coef: 0.4262 - val_accuracy: 0.9850 - val_mse: 0.0111\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0378 - dice_coef: 0.4903 - accuracy: 0.9836 - mse: 0.0099\n",
            "Epoch 9: val_dice_coef improved from 0.45819 to 0.45943, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 153s 2s/step - loss: 0.0378 - dice_coef: 0.4903 - accuracy: 0.9836 - mse: 0.0099 - val_loss: 0.0363 - val_dice_coef: 0.4594 - val_accuracy: 0.9853 - val_mse: 0.0106\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0358 - dice_coef: 0.5092 - accuracy: 0.9841 - mse: 0.0095\n",
            "Epoch 10: val_dice_coef improved from 0.45943 to 0.51434, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 153s 2s/step - loss: 0.0358 - dice_coef: 0.5092 - accuracy: 0.9841 - mse: 0.0095 - val_loss: 0.0327 - val_dice_coef: 0.5143 - val_accuracy: 0.9870 - val_mse: 0.0095\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0334 - dice_coef: 0.5450 - accuracy: 0.9849 - mse: 0.0089\n",
            "Epoch 11: val_dice_coef did not improve from 0.51434\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0334 - dice_coef: 0.5450 - accuracy: 0.9849 - mse: 0.0089 - val_loss: 0.0323 - val_dice_coef: 0.5136 - val_accuracy: 0.9871 - val_mse: 0.0094\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323 - dice_coef: 0.5536 - accuracy: 0.9851 - mse: 0.0087\n",
            "Epoch 12: val_dice_coef improved from 0.51434 to 0.55083, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0323 - dice_coef: 0.5536 - accuracy: 0.9851 - mse: 0.0087 - val_loss: 0.0328 - val_dice_coef: 0.5508 - val_accuracy: 0.9869 - val_mse: 0.0095\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0316 - dice_coef: 0.5563 - accuracy: 0.9855 - mse: 0.0084\n",
            "Epoch 13: val_dice_coef did not improve from 0.55083\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0316 - dice_coef: 0.5563 - accuracy: 0.9855 - mse: 0.0084 - val_loss: 0.0375 - val_dice_coef: 0.4799 - val_accuracy: 0.9860 - val_mse: 0.0105\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0311 - dice_coef: 0.5637 - accuracy: 0.9857 - mse: 0.0083\n",
            "Epoch 14: val_dice_coef did not improve from 0.55083\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0311 - dice_coef: 0.5637 - accuracy: 0.9857 - mse: 0.0083 - val_loss: 0.0339 - val_dice_coef: 0.4762 - val_accuracy: 0.9868 - val_mse: 0.0097\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323 - dice_coef: 0.5727 - accuracy: 0.9852 - mse: 0.0085\n",
            "Epoch 15: val_dice_coef did not improve from 0.55083\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0323 - dice_coef: 0.5727 - accuracy: 0.9852 - mse: 0.0085 - val_loss: 0.0331 - val_dice_coef: 0.4830 - val_accuracy: 0.9868 - val_mse: 0.0096\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0315 - dice_coef: 0.5508 - accuracy: 0.9858 - mse: 0.0082\n",
            "Epoch 16: val_dice_coef did not improve from 0.55083\n",
            "100/100 [==============================] - 150s 2s/step - loss: 0.0315 - dice_coef: 0.5508 - accuracy: 0.9858 - mse: 0.0082 - val_loss: 0.0314 - val_dice_coef: 0.5251 - val_accuracy: 0.9879 - val_mse: 0.0089\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0284 - dice_coef: 0.5916 - accuracy: 0.9866 - mse: 0.0075\n",
            "Epoch 17: val_dice_coef improved from 0.55083 to 0.55164, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0284 - dice_coef: 0.5916 - accuracy: 0.9866 - mse: 0.0075 - val_loss: 0.0314 - val_dice_coef: 0.5516 - val_accuracy: 0.9875 - val_mse: 0.0091\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0288 - dice_coef: 0.6088 - accuracy: 0.9865 - mse: 0.0076\n",
            "Epoch 18: val_dice_coef did not improve from 0.55164\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0288 - dice_coef: 0.6088 - accuracy: 0.9865 - mse: 0.0076 - val_loss: 0.0310 - val_dice_coef: 0.5504 - val_accuracy: 0.9879 - val_mse: 0.0089\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0295 - dice_coef: 0.5752 - accuracy: 0.9865 - mse: 0.0077\n",
            "Epoch 19: val_dice_coef improved from 0.55164 to 0.55180, saving model to Output/unet_plus_tall/unet_plus_tall.hdf5\n",
            "100/100 [==============================] - 151s 2s/step - loss: 0.0295 - dice_coef: 0.5752 - accuracy: 0.9865 - mse: 0.0077 - val_loss: 0.0290 - val_dice_coef: 0.5518 - val_accuracy: 0.9887 - val_mse: 0.0084\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0282 - dice_coef: 0.5965 - accuracy: 0.9868 - mse: 0.0074\n",
            "Epoch 20: val_dice_coef did not improve from 0.55180\n",
            "100/100 [==============================] - 152s 2s/step - loss: 0.0282 - dice_coef: 0.5965 - accuracy: 0.9868 - mse: 0.0074 - val_loss: 0.0324 - val_dice_coef: 0.5269 - val_accuracy: 0.9874 - val_mse: 0.0092\n",
            "Total time to train: 3067.418916463852\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train ResUNet with generator\n",
        "uNetplus_tall = unet_plus([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3))\n",
        "# uNetplus_tall = load_model('Output/unet_plus_tall/unet_plus_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/unet_plus_tall\", \"unet_plus_tall\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_tall = TrainGenerator(8, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "uNetplus_tall = train(uNetplus_tall, callbacks, train_rgb_tall, validation_df, \"unet_plus_tall\", epochs=20, steps_per_epoch=100)\n",
        "# Total 70 epochs total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF8PNbo67TuS"
      },
      "source": [
        "### **R2 U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hoVKIO6G7ZJd",
        "outputId": "1979939a-fc29-429e-de2d-2a6648a7d856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1319 - dice_coef: 0.0116 - accuracy: 0.9773 - mse: 0.0220\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.01044, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 70s 662ms/step - loss: 0.1319 - dice_coef: 0.0116 - accuracy: 0.9773 - mse: 0.0220 - val_loss: 0.1241 - val_dice_coef: 0.0104 - val_accuracy: 0.9769 - val_mse: 0.0229\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1085 - dice_coef: 0.0197 - accuracy: 0.9780 - mse: 0.0197\n",
            "Epoch 2: val_dice_coef improved from 0.01044 to 0.04224, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.1085 - dice_coef: 0.0197 - accuracy: 0.9780 - mse: 0.0197 - val_loss: 0.1029 - val_dice_coef: 0.0422 - val_accuracy: 0.9769 - val_mse: 0.0221\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1029 - dice_coef: 0.0264 - accuracy: 0.9804 - mse: 0.0182\n",
            "Epoch 3: val_dice_coef did not improve from 0.04224\n",
            "100/100 [==============================] - 66s 662ms/step - loss: 0.1029 - dice_coef: 0.0264 - accuracy: 0.9804 - mse: 0.0182 - val_loss: 0.1273 - val_dice_coef: 0.0094 - val_accuracy: 0.9769 - val_mse: 0.0231\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1122 - dice_coef: 0.0399 - accuracy: 0.9755 - mse: 0.0217\n",
            "Epoch 4: val_dice_coef improved from 0.04224 to 0.05686, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.1122 - dice_coef: 0.0399 - accuracy: 0.9755 - mse: 0.0217 - val_loss: 0.0958 - val_dice_coef: 0.0569 - val_accuracy: 0.9769 - val_mse: 0.0217\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0920 - dice_coef: 0.0762 - accuracy: 0.9762 - mse: 0.0199\n",
            "Epoch 5: val_dice_coef improved from 0.05686 to 0.22047, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 715ms/step - loss: 0.0920 - dice_coef: 0.0762 - accuracy: 0.9762 - mse: 0.0199 - val_loss: 0.0839 - val_dice_coef: 0.2205 - val_accuracy: 0.9777 - val_mse: 0.0193\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0746 - dice_coef: 0.1656 - accuracy: 0.9752 - mse: 0.0171\n",
            "Epoch 6: val_dice_coef did not improve from 0.22047\n",
            "100/100 [==============================] - 66s 659ms/step - loss: 0.0746 - dice_coef: 0.1656 - accuracy: 0.9752 - mse: 0.0171 - val_loss: 0.0768 - val_dice_coef: 0.1193 - val_accuracy: 0.9769 - val_mse: 0.0189\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0577 - dice_coef: 0.2163 - accuracy: 0.9804 - mse: 0.0130\n",
            "Epoch 7: val_dice_coef improved from 0.22047 to 0.29330, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 713ms/step - loss: 0.0577 - dice_coef: 0.2163 - accuracy: 0.9804 - mse: 0.0130 - val_loss: 0.0582 - val_dice_coef: 0.2933 - val_accuracy: 0.9823 - val_mse: 0.0141\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0596 - dice_coef: 0.2672 - accuracy: 0.9794 - mse: 0.0139\n",
            "Epoch 8: val_dice_coef improved from 0.29330 to 0.34858, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 706ms/step - loss: 0.0596 - dice_coef: 0.2672 - accuracy: 0.9794 - mse: 0.0139 - val_loss: 0.0492 - val_dice_coef: 0.3486 - val_accuracy: 0.9845 - val_mse: 0.0127\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0700 - dice_coef: 0.2080 - accuracy: 0.9776 - mse: 0.0161\n",
            "Epoch 9: val_dice_coef improved from 0.34858 to 0.37704, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 714ms/step - loss: 0.0700 - dice_coef: 0.2080 - accuracy: 0.9776 - mse: 0.0161 - val_loss: 0.0501 - val_dice_coef: 0.3770 - val_accuracy: 0.9838 - val_mse: 0.0128\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0488 - dice_coef: 0.3552 - accuracy: 0.9822 - mse: 0.0116\n",
            "Epoch 10: val_dice_coef improved from 0.37704 to 0.44319, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 710ms/step - loss: 0.0488 - dice_coef: 0.3552 - accuracy: 0.9822 - mse: 0.0116 - val_loss: 0.0458 - val_dice_coef: 0.4432 - val_accuracy: 0.9852 - val_mse: 0.0117\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0466 - dice_coef: 0.3407 - accuracy: 0.9819 - mse: 0.0115\n",
            "Epoch 11: val_dice_coef did not improve from 0.44319\n",
            "100/100 [==============================] - 66s 658ms/step - loss: 0.0466 - dice_coef: 0.3407 - accuracy: 0.9819 - mse: 0.0115 - val_loss: 0.0644 - val_dice_coef: 0.1999 - val_accuracy: 0.9790 - val_mse: 0.0165\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0612 - dice_coef: 0.2821 - accuracy: 0.9779 - mse: 0.0148\n",
            "Epoch 12: val_dice_coef did not improve from 0.44319\n",
            "100/100 [==============================] - 66s 658ms/step - loss: 0.0612 - dice_coef: 0.2821 - accuracy: 0.9779 - mse: 0.0148 - val_loss: 0.0455 - val_dice_coef: 0.4431 - val_accuracy: 0.9856 - val_mse: 0.0113\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0507 - dice_coef: 0.3010 - accuracy: 0.9824 - mse: 0.0119\n",
            "Epoch 13: val_dice_coef did not improve from 0.44319\n",
            "100/100 [==============================] - 65s 656ms/step - loss: 0.0507 - dice_coef: 0.3010 - accuracy: 0.9824 - mse: 0.0119 - val_loss: 0.0703 - val_dice_coef: 0.3202 - val_accuracy: 0.9810 - val_mse: 0.0156\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0440 - dice_coef: 0.3968 - accuracy: 0.9818 - mse: 0.0113\n",
            "Epoch 14: val_dice_coef improved from 0.44319 to 0.47488, saving model to Output/r2_unet_tall_256/r2_unet_tall_256.hdf5\n",
            "100/100 [==============================] - 71s 708ms/step - loss: 0.0440 - dice_coef: 0.3968 - accuracy: 0.9818 - mse: 0.0113 - val_loss: 0.0420 - val_dice_coef: 0.4749 - val_accuracy: 0.9855 - val_mse: 0.0112\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0384 - dice_coef: 0.3915 - accuracy: 0.9845 - mse: 0.0097\n",
            "Epoch 15: val_dice_coef did not improve from 0.47488\n",
            "100/100 [==============================] - 66s 658ms/step - loss: 0.0384 - dice_coef: 0.3915 - accuracy: 0.9845 - mse: 0.0097 - val_loss: 0.0725 - val_dice_coef: 0.2774 - val_accuracy: 0.9776 - val_mse: 0.0184\n",
            "Total time to train: 1033.5541005134583\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train ResUNet with generator\n",
        "r2_unet_tall = r2_unet([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3))\n",
        "#r2_unet = load_model('Output/r2_unet_tall_256/r2_unet_tall_256.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/r2_unet_tall_256\", \"r2_unet_tall_256\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_tall = TrainGenerator(1, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "# Trained for 100 epochs total\n",
        "r2_unet_tall = train(r2_unet_tall, callbacks, train_rgb_tall, validation_df, \"r2_unet_tall_256\", epochs=100, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new train without curve\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "def train(model, callbacks, inGen, valGen, modelName, batch_size=1, epochs=20, steps_per_epoch=100):\n",
        "    fullOutPath = os.path.join(\"Output\", modelName)\n",
        "    if not os.path.exists(fullOutPath):\n",
        "        os.mkdir(fullOutPath)\n",
        "\n",
        "    startTime = time.time()\n",
        "    history = model.fit(\n",
        "        inGen,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data=valGen,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[callbacks]\n",
        "    )\n",
        "    trainTime = time.time() - startTime\n",
        "    print(\"Total time to train:\", trainTime)\n",
        "\n",
        "    # Saving to drive\n",
        "    save_to_drive()\n",
        "\n",
        "    # Rest of the code...\n",
        "    return model"
      ],
      "metadata": {
        "id": "6VWpV5aeYiuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COJF72oVsC0v"
      },
      "source": [
        "### **U^2 Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVY4eOLksLRo",
        "outputId": "c71f3c50-98ea-4169-f192-157927fb5586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "The depth of u2net_2d = len(filter_num_down) + len(filter_4f_num) = 6\n",
            "----------\n",
            "deep_supervision = True\n",
            "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
            "\"final\" is the final output layer):\n",
            "\n",
            "\tu2net_output_sup0_activation\n",
            "\tu2net_output_sup1_activation\n",
            "\tu2net_output_sup2_activation\n",
            "\tu2net_output_sup3_activation\n",
            "\tu2net_output_sup4_activation\n",
            "\tu2net_output_sup5_activation\n",
            "\tu2net_output_final_activation\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.4798 - u2net_output_sup0_activation_loss: 0.1472 - u2net_output_sup1_activation_loss: 0.5327 - u2net_output_sup2_activation_loss: 0.6856 - u2net_output_sup3_activation_loss: 0.6848 - u2net_output_sup4_activation_loss: 0.6849 - u2net_output_sup5_activation_loss: 0.6908 - u2net_output_final_activation_loss: 1.0539 - u2net_output_sup0_activation_dice_coef: 0.1365 - u2net_output_sup0_activation_accuracy: 0.9685 - u2net_output_sup0_activation_mse: 0.0317 - u2net_output_sup1_activation_dice_coef: 0.0506 - u2net_output_sup1_activation_accuracy: 0.8340 - u2net_output_sup1_activation_mse: 0.1796 - u2net_output_sup2_activation_dice_coef: 0.0420 - u2net_output_sup2_activation_accuracy: 0.7351 - u2net_output_sup2_activation_mse: 0.2446 - u2net_output_sup3_activation_dice_coef: 0.0418 - u2net_output_sup3_activation_accuracy: 0.9187 - u2net_output_sup3_activation_mse: 0.2453 - u2net_output_sup4_activation_dice_coef: 0.0417 - u2net_output_sup4_activation_accuracy: 0.9643 - u2net_output_sup4_activation_mse: 0.2457 - u2net_output_sup5_activation_dice_coef: 0.0417 - u2net_output_sup5_activation_accuracy: 0.9720 - u2net_output_sup5_activation_mse: 0.2481 - u2net_output_final_activation_dice_coef: 0.0425 - u2net_output_final_activation_accuracy: 0.0198 - u2net_output_final_activation_mse: 0.4228"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 166s 1s/step - loss: 4.4798 - u2net_output_sup0_activation_loss: 0.1472 - u2net_output_sup1_activation_loss: 0.5327 - u2net_output_sup2_activation_loss: 0.6856 - u2net_output_sup3_activation_loss: 0.6848 - u2net_output_sup4_activation_loss: 0.6849 - u2net_output_sup5_activation_loss: 0.6908 - u2net_output_final_activation_loss: 1.0539 - u2net_output_sup0_activation_dice_coef: 0.1365 - u2net_output_sup0_activation_accuracy: 0.9685 - u2net_output_sup0_activation_mse: 0.0317 - u2net_output_sup1_activation_dice_coef: 0.0506 - u2net_output_sup1_activation_accuracy: 0.8340 - u2net_output_sup1_activation_mse: 0.1796 - u2net_output_sup2_activation_dice_coef: 0.0420 - u2net_output_sup2_activation_accuracy: 0.7351 - u2net_output_sup2_activation_mse: 0.2446 - u2net_output_sup3_activation_dice_coef: 0.0418 - u2net_output_sup3_activation_accuracy: 0.9187 - u2net_output_sup3_activation_mse: 0.2453 - u2net_output_sup4_activation_dice_coef: 0.0417 - u2net_output_sup4_activation_accuracy: 0.9643 - u2net_output_sup4_activation_mse: 0.2457 - u2net_output_sup5_activation_dice_coef: 0.0417 - u2net_output_sup5_activation_accuracy: 0.9720 - u2net_output_sup5_activation_mse: 0.2481 - u2net_output_final_activation_dice_coef: 0.0425 - u2net_output_final_activation_accuracy: 0.0198 - u2net_output_final_activation_mse: 0.4228 - val_loss: 4.4571 - val_u2net_output_sup0_activation_loss: 0.1910 - val_u2net_output_sup1_activation_loss: 0.4833 - val_u2net_output_sup2_activation_loss: 0.6802 - val_u2net_output_sup3_activation_loss: 0.6805 - val_u2net_output_sup4_activation_loss: 0.6823 - val_u2net_output_sup5_activation_loss: 0.6883 - val_u2net_output_final_activation_loss: 1.0515 - val_u2net_output_sup0_activation_dice_coef: 0.0361 - val_u2net_output_sup0_activation_accuracy: 0.9768 - val_u2net_output_sup0_activation_mse: 0.0362 - val_u2net_output_sup1_activation_dice_coef: 0.0418 - val_u2net_output_sup1_activation_accuracy: 0.9730 - val_u2net_output_sup1_activation_mse: 0.1574 - val_u2net_output_sup2_activation_dice_coef: 0.0430 - val_u2net_output_sup2_activation_accuracy: 0.7384 - val_u2net_output_sup2_activation_mse: 0.2435 - val_u2net_output_sup3_activation_dice_coef: 0.0430 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2439 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9656 - val_u2net_output_sup4_activation_mse: 0.2449 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9730 - val_u2net_output_sup5_activation_mse: 0.2476 - val_u2net_output_final_activation_dice_coef: 0.0438 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.4226\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.1974 - u2net_output_sup0_activation_loss: 0.0637 - u2net_output_sup1_activation_loss: 0.3739 - u2net_output_sup2_activation_loss: 0.6751 - u2net_output_sup3_activation_loss: 0.6779 - u2net_output_sup4_activation_loss: 0.6789 - u2net_output_sup5_activation_loss: 0.6860 - u2net_output_final_activation_loss: 1.0418 - u2net_output_sup0_activation_dice_coef: 0.2431 - u2net_output_sup0_activation_accuracy: 0.9799 - u2net_output_sup0_activation_mse: 0.0135 - u2net_output_sup1_activation_dice_coef: 0.0581 - u2net_output_sup1_activation_accuracy: 0.9694 - u2net_output_sup1_activation_mse: 0.1143 - u2net_output_sup2_activation_dice_coef: 0.0396 - u2net_output_sup2_activation_accuracy: 0.7380 - u2net_output_sup2_activation_mse: 0.2395 - u2net_output_sup3_activation_dice_coef: 0.0392 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2422 - u2net_output_sup4_activation_dice_coef: 0.0391 - u2net_output_sup4_activation_accuracy: 0.9661 - u2net_output_sup4_activation_mse: 0.2430 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9738 - u2net_output_sup5_activation_mse: 0.2458 - u2net_output_final_activation_dice_coef: 0.0396 - u2net_output_final_activation_accuracy: 0.0185 - u2net_output_final_activation_mse: 0.4174"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 4.1974 - u2net_output_sup0_activation_loss: 0.0637 - u2net_output_sup1_activation_loss: 0.3739 - u2net_output_sup2_activation_loss: 0.6751 - u2net_output_sup3_activation_loss: 0.6779 - u2net_output_sup4_activation_loss: 0.6789 - u2net_output_sup5_activation_loss: 0.6860 - u2net_output_final_activation_loss: 1.0418 - u2net_output_sup0_activation_dice_coef: 0.2431 - u2net_output_sup0_activation_accuracy: 0.9799 - u2net_output_sup0_activation_mse: 0.0135 - u2net_output_sup1_activation_dice_coef: 0.0581 - u2net_output_sup1_activation_accuracy: 0.9694 - u2net_output_sup1_activation_mse: 0.1143 - u2net_output_sup2_activation_dice_coef: 0.0396 - u2net_output_sup2_activation_accuracy: 0.7380 - u2net_output_sup2_activation_mse: 0.2395 - u2net_output_sup3_activation_dice_coef: 0.0392 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2422 - u2net_output_sup4_activation_dice_coef: 0.0391 - u2net_output_sup4_activation_accuracy: 0.9661 - u2net_output_sup4_activation_mse: 0.2430 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9738 - u2net_output_sup5_activation_mse: 0.2458 - u2net_output_final_activation_dice_coef: 0.0396 - u2net_output_final_activation_accuracy: 0.0185 - u2net_output_final_activation_mse: 0.4174 - val_loss: 4.1947 - val_u2net_output_sup0_activation_loss: 0.1121 - val_u2net_output_sup1_activation_loss: 0.3411 - val_u2net_output_sup2_activation_loss: 0.6706 - val_u2net_output_sup3_activation_loss: 0.6745 - val_u2net_output_sup4_activation_loss: 0.6764 - val_u2net_output_sup5_activation_loss: 0.6835 - val_u2net_output_final_activation_loss: 1.0365 - val_u2net_output_sup0_activation_dice_coef: 0.0170 - val_u2net_output_sup0_activation_accuracy: 0.9768 - val_u2net_output_sup0_activation_mse: 0.0229 - val_u2net_output_sup1_activation_dice_coef: 0.0400 - val_u2net_output_sup1_activation_accuracy: 0.9749 - val_u2net_output_sup1_activation_mse: 0.0945 - val_u2net_output_sup2_activation_dice_coef: 0.0429 - val_u2net_output_sup2_activation_accuracy: 0.7384 - val_u2net_output_sup2_activation_mse: 0.2386 - val_u2net_output_sup3_activation_dice_coef: 0.0430 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2412 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9656 - val_u2net_output_sup4_activation_mse: 0.2423 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9732 - val_u2net_output_sup5_activation_mse: 0.2452 - val_u2net_output_final_activation_dice_coef: 0.0438 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.4157\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 4.0542 - u2net_output_sup0_activation_loss: 0.0538 - u2net_output_sup1_activation_loss: 0.2781 - u2net_output_sup2_activation_loss: 0.6656 - u2net_output_sup3_activation_loss: 0.6717 - u2net_output_sup4_activation_loss: 0.6737 - u2net_output_sup5_activation_loss: 0.6812 - u2net_output_final_activation_loss: 1.0301 - u2net_output_sup0_activation_dice_coef: 0.3070 - u2net_output_sup0_activation_accuracy: 0.9808 - u2net_output_sup0_activation_mse: 0.0124 - u2net_output_sup1_activation_dice_coef: 0.0726 - u2net_output_sup1_activation_accuracy: 0.9775 - u2net_output_sup1_activation_mse: 0.0756 - u2net_output_sup2_activation_dice_coef: 0.0398 - u2net_output_sup2_activation_accuracy: 0.7380 - u2net_output_sup2_activation_mse: 0.2347 - u2net_output_sup3_activation_dice_coef: 0.0392 - u2net_output_sup3_activation_accuracy: 0.9323 - u2net_output_sup3_activation_mse: 0.2392 - u2net_output_sup4_activation_dice_coef: 0.0390 - u2net_output_sup4_activation_accuracy: 0.9671 - u2net_output_sup4_activation_mse: 0.2405 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9745 - u2net_output_sup5_activation_mse: 0.2434 - u2net_output_final_activation_dice_coef: 0.0393 - u2net_output_final_activation_accuracy: 0.0186 - u2net_output_final_activation_mse: 0.4121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 4.0542 - u2net_output_sup0_activation_loss: 0.0538 - u2net_output_sup1_activation_loss: 0.2781 - u2net_output_sup2_activation_loss: 0.6656 - u2net_output_sup3_activation_loss: 0.6717 - u2net_output_sup4_activation_loss: 0.6737 - u2net_output_sup5_activation_loss: 0.6812 - u2net_output_final_activation_loss: 1.0301 - u2net_output_sup0_activation_dice_coef: 0.3070 - u2net_output_sup0_activation_accuracy: 0.9808 - u2net_output_sup0_activation_mse: 0.0124 - u2net_output_sup1_activation_dice_coef: 0.0726 - u2net_output_sup1_activation_accuracy: 0.9775 - u2net_output_sup1_activation_mse: 0.0756 - u2net_output_sup2_activation_dice_coef: 0.0398 - u2net_output_sup2_activation_accuracy: 0.7380 - u2net_output_sup2_activation_mse: 0.2347 - u2net_output_sup3_activation_dice_coef: 0.0392 - u2net_output_sup3_activation_accuracy: 0.9323 - u2net_output_sup3_activation_mse: 0.2392 - u2net_output_sup4_activation_dice_coef: 0.0390 - u2net_output_sup4_activation_accuracy: 0.9671 - u2net_output_sup4_activation_mse: 0.2405 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9745 - u2net_output_sup5_activation_mse: 0.2434 - u2net_output_final_activation_dice_coef: 0.0393 - u2net_output_final_activation_accuracy: 0.0186 - u2net_output_final_activation_mse: 0.4121 - val_loss: 4.1009 - val_u2net_output_sup0_activation_loss: 0.1271 - val_u2net_output_sup1_activation_loss: 0.2690 - val_u2net_output_sup2_activation_loss: 0.6611 - val_u2net_output_sup3_activation_loss: 0.6685 - val_u2net_output_sup4_activation_loss: 0.6713 - val_u2net_output_sup5_activation_loss: 0.6788 - val_u2net_output_final_activation_loss: 1.0251 - val_u2net_output_sup0_activation_dice_coef: 0.0082 - val_u2net_output_sup0_activation_accuracy: 0.9768 - val_u2net_output_sup0_activation_mse: 0.0231 - val_u2net_output_sup1_activation_dice_coef: 0.0377 - val_u2net_output_sup1_activation_accuracy: 0.9757 - val_u2net_output_sup1_activation_mse: 0.0630 - val_u2net_output_sup2_activation_dice_coef: 0.0428 - val_u2net_output_sup2_activation_accuracy: 0.7384 - val_u2net_output_sup2_activation_mse: 0.2338 - val_u2net_output_sup3_activation_dice_coef: 0.0429 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2384 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2399 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2428 - val_u2net_output_final_activation_dice_coef: 0.0438 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.4104\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.9458 - u2net_output_sup0_activation_loss: 0.0531 - u2net_output_sup1_activation_loss: 0.2096 - u2net_output_sup2_activation_loss: 0.6558 - u2net_output_sup3_activation_loss: 0.6656 - u2net_output_sup4_activation_loss: 0.6687 - u2net_output_sup5_activation_loss: 0.6765 - u2net_output_final_activation_loss: 1.0167 - u2net_output_sup0_activation_dice_coef: 0.3373 - u2net_output_sup0_activation_accuracy: 0.9795 - u2net_output_sup0_activation_mse: 0.0131 - u2net_output_sup1_activation_dice_coef: 0.0970 - u2net_output_sup1_activation_accuracy: 0.9772 - u2net_output_sup1_activation_mse: 0.0513 - u2net_output_sup2_activation_dice_coef: 0.0423 - u2net_output_sup2_activation_accuracy: 0.7377 - u2net_output_sup2_activation_mse: 0.2298 - u2net_output_sup3_activation_dice_coef: 0.0414 - u2net_output_sup3_activation_accuracy: 0.9313 - u2net_output_sup3_activation_mse: 0.2364 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9686 - u2net_output_sup4_activation_mse: 0.2380 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9741 - u2net_output_sup5_activation_mse: 0.2410 - u2net_output_final_activation_dice_coef: 0.0412 - u2net_output_final_activation_accuracy: 0.0196 - u2net_output_final_activation_mse: 0.4059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.9458 - u2net_output_sup0_activation_loss: 0.0531 - u2net_output_sup1_activation_loss: 0.2096 - u2net_output_sup2_activation_loss: 0.6558 - u2net_output_sup3_activation_loss: 0.6656 - u2net_output_sup4_activation_loss: 0.6687 - u2net_output_sup5_activation_loss: 0.6765 - u2net_output_final_activation_loss: 1.0167 - u2net_output_sup0_activation_dice_coef: 0.3373 - u2net_output_sup0_activation_accuracy: 0.9795 - u2net_output_sup0_activation_mse: 0.0131 - u2net_output_sup1_activation_dice_coef: 0.0970 - u2net_output_sup1_activation_accuracy: 0.9772 - u2net_output_sup1_activation_mse: 0.0513 - u2net_output_sup2_activation_dice_coef: 0.0423 - u2net_output_sup2_activation_accuracy: 0.7377 - u2net_output_sup2_activation_mse: 0.2298 - u2net_output_sup3_activation_dice_coef: 0.0414 - u2net_output_sup3_activation_accuracy: 0.9313 - u2net_output_sup3_activation_mse: 0.2364 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9686 - u2net_output_sup4_activation_mse: 0.2380 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9741 - u2net_output_sup5_activation_mse: 0.2410 - u2net_output_final_activation_dice_coef: 0.0412 - u2net_output_final_activation_accuracy: 0.0196 - u2net_output_final_activation_mse: 0.4059 - val_loss: 4.0240 - val_u2net_output_sup0_activation_loss: 0.1318 - val_u2net_output_sup1_activation_loss: 0.2272 - val_u2net_output_sup2_activation_loss: 0.6510 - val_u2net_output_sup3_activation_loss: 0.6628 - val_u2net_output_sup4_activation_loss: 0.6663 - val_u2net_output_sup5_activation_loss: 0.6741 - val_u2net_output_final_activation_loss: 1.0106 - val_u2net_output_sup0_activation_dice_coef: 0.0068 - val_u2net_output_sup0_activation_accuracy: 0.9768 - val_u2net_output_sup0_activation_mse: 0.0231 - val_u2net_output_sup1_activation_dice_coef: 0.0352 - val_u2net_output_sup1_activation_accuracy: 0.9768 - val_u2net_output_sup1_activation_mse: 0.0458 - val_u2net_output_sup2_activation_dice_coef: 0.0428 - val_u2net_output_sup2_activation_accuracy: 0.7384 - val_u2net_output_sup2_activation_mse: 0.2286 - val_u2net_output_sup3_activation_dice_coef: 0.0429 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2357 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2375 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2405 - val_u2net_output_final_activation_dice_coef: 0.0438 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.4038\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.8489 - u2net_output_sup0_activation_loss: 0.0479 - u2net_output_sup1_activation_loss: 0.1589 - u2net_output_sup2_activation_loss: 0.6451 - u2net_output_sup3_activation_loss: 0.6593 - u2net_output_sup4_activation_loss: 0.6635 - u2net_output_sup5_activation_loss: 0.6717 - u2net_output_final_activation_loss: 1.0025 - u2net_output_sup0_activation_dice_coef: 0.3481 - u2net_output_sup0_activation_accuracy: 0.9810 - u2net_output_sup0_activation_mse: 0.0120 - u2net_output_sup1_activation_dice_coef: 0.1150 - u2net_output_sup1_activation_accuracy: 0.9796 - u2net_output_sup1_activation_mse: 0.0352 - u2net_output_sup2_activation_dice_coef: 0.0401 - u2net_output_sup2_activation_accuracy: 0.7389 - u2net_output_sup2_activation_mse: 0.2246 - u2net_output_sup3_activation_dice_coef: 0.0389 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2335 - u2net_output_sup4_activation_dice_coef: 0.0385 - u2net_output_sup4_activation_accuracy: 0.9698 - u2net_output_sup4_activation_mse: 0.2356 - u2net_output_sup5_activation_dice_coef: 0.0384 - u2net_output_sup5_activation_accuracy: 0.9754 - u2net_output_sup5_activation_mse: 0.2387 - u2net_output_final_activation_dice_coef: 0.0385 - u2net_output_final_activation_accuracy: 0.0185 - u2net_output_final_activation_mse: 0.3994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.8489 - u2net_output_sup0_activation_loss: 0.0479 - u2net_output_sup1_activation_loss: 0.1589 - u2net_output_sup2_activation_loss: 0.6451 - u2net_output_sup3_activation_loss: 0.6593 - u2net_output_sup4_activation_loss: 0.6635 - u2net_output_sup5_activation_loss: 0.6717 - u2net_output_final_activation_loss: 1.0025 - u2net_output_sup0_activation_dice_coef: 0.3481 - u2net_output_sup0_activation_accuracy: 0.9810 - u2net_output_sup0_activation_mse: 0.0120 - u2net_output_sup1_activation_dice_coef: 0.1150 - u2net_output_sup1_activation_accuracy: 0.9796 - u2net_output_sup1_activation_mse: 0.0352 - u2net_output_sup2_activation_dice_coef: 0.0401 - u2net_output_sup2_activation_accuracy: 0.7389 - u2net_output_sup2_activation_mse: 0.2246 - u2net_output_sup3_activation_dice_coef: 0.0389 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2335 - u2net_output_sup4_activation_dice_coef: 0.0385 - u2net_output_sup4_activation_accuracy: 0.9698 - u2net_output_sup4_activation_mse: 0.2356 - u2net_output_sup5_activation_dice_coef: 0.0384 - u2net_output_sup5_activation_accuracy: 0.9754 - u2net_output_sup5_activation_mse: 0.2387 - u2net_output_final_activation_dice_coef: 0.0385 - u2net_output_final_activation_accuracy: 0.0185 - u2net_output_final_activation_mse: 0.3994 - val_loss: 3.9491 - val_u2net_output_sup0_activation_loss: 0.1288 - val_u2net_output_sup1_activation_loss: 0.1967 - val_u2net_output_sup2_activation_loss: 0.6406 - val_u2net_output_sup3_activation_loss: 0.6568 - val_u2net_output_sup4_activation_loss: 0.6613 - val_u2net_output_sup5_activation_loss: 0.6695 - val_u2net_output_final_activation_loss: 0.9953 - val_u2net_output_sup0_activation_dice_coef: 0.0094 - val_u2net_output_sup0_activation_accuracy: 0.9768 - val_u2net_output_sup0_activation_mse: 0.0230 - val_u2net_output_sup1_activation_dice_coef: 0.0352 - val_u2net_output_sup1_activation_accuracy: 0.9768 - val_u2net_output_sup1_activation_mse: 0.0351 - val_u2net_output_sup2_activation_dice_coef: 0.0428 - val_u2net_output_sup2_activation_accuracy: 0.7389 - val_u2net_output_sup2_activation_mse: 0.2235 - val_u2net_output_sup3_activation_dice_coef: 0.0429 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2329 - val_u2net_output_sup4_activation_dice_coef: 0.0429 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2351 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2382 - val_u2net_output_final_activation_dice_coef: 0.0437 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.3968\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7755 - u2net_output_sup0_activation_loss: 0.0478 - u2net_output_sup1_activation_loss: 0.1284 - u2net_output_sup2_activation_loss: 0.6345 - u2net_output_sup3_activation_loss: 0.6533 - u2net_output_sup4_activation_loss: 0.6585 - u2net_output_sup5_activation_loss: 0.6671 - u2net_output_final_activation_loss: 0.9858 - u2net_output_sup0_activation_dice_coef: 0.3793 - u2net_output_sup0_activation_accuracy: 0.9807 - u2net_output_sup0_activation_mse: 0.0122 - u2net_output_sup1_activation_dice_coef: 0.1502 - u2net_output_sup1_activation_accuracy: 0.9794 - u2net_output_sup1_activation_mse: 0.0267 - u2net_output_sup2_activation_dice_coef: 0.0439 - u2net_output_sup2_activation_accuracy: 0.7623 - u2net_output_sup2_activation_mse: 0.2195 - u2net_output_sup3_activation_dice_coef: 0.0424 - u2net_output_sup3_activation_accuracy: 0.9316 - u2net_output_sup3_activation_mse: 0.2307 - u2net_output_sup4_activation_dice_coef: 0.0419 - u2net_output_sup4_activation_accuracy: 0.9689 - u2net_output_sup4_activation_mse: 0.2332 - u2net_output_sup5_activation_dice_coef: 0.0418 - u2net_output_sup5_activation_accuracy: 0.9745 - u2net_output_sup5_activation_mse: 0.2363 - u2net_output_final_activation_dice_coef: 0.0418 - u2net_output_final_activation_accuracy: 0.0193 - u2net_output_final_activation_mse: 0.3917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.7755 - u2net_output_sup0_activation_loss: 0.0478 - u2net_output_sup1_activation_loss: 0.1284 - u2net_output_sup2_activation_loss: 0.6345 - u2net_output_sup3_activation_loss: 0.6533 - u2net_output_sup4_activation_loss: 0.6585 - u2net_output_sup5_activation_loss: 0.6671 - u2net_output_final_activation_loss: 0.9858 - u2net_output_sup0_activation_dice_coef: 0.3793 - u2net_output_sup0_activation_accuracy: 0.9807 - u2net_output_sup0_activation_mse: 0.0122 - u2net_output_sup1_activation_dice_coef: 0.1502 - u2net_output_sup1_activation_accuracy: 0.9794 - u2net_output_sup1_activation_mse: 0.0267 - u2net_output_sup2_activation_dice_coef: 0.0439 - u2net_output_sup2_activation_accuracy: 0.7623 - u2net_output_sup2_activation_mse: 0.2195 - u2net_output_sup3_activation_dice_coef: 0.0424 - u2net_output_sup3_activation_accuracy: 0.9316 - u2net_output_sup3_activation_mse: 0.2307 - u2net_output_sup4_activation_dice_coef: 0.0419 - u2net_output_sup4_activation_accuracy: 0.9689 - u2net_output_sup4_activation_mse: 0.2332 - u2net_output_sup5_activation_dice_coef: 0.0418 - u2net_output_sup5_activation_accuracy: 0.9745 - u2net_output_sup5_activation_mse: 0.2363 - u2net_output_final_activation_dice_coef: 0.0418 - u2net_output_final_activation_accuracy: 0.0193 - u2net_output_final_activation_mse: 0.3917 - val_loss: 3.8073 - val_u2net_output_sup0_activation_loss: 0.0817 - val_u2net_output_sup1_activation_loss: 0.1460 - val_u2net_output_sup2_activation_loss: 0.6296 - val_u2net_output_sup3_activation_loss: 0.6505 - val_u2net_output_sup4_activation_loss: 0.6563 - val_u2net_output_sup5_activation_loss: 0.6649 - val_u2net_output_final_activation_loss: 0.9783 - val_u2net_output_sup0_activation_dice_coef: 0.1631 - val_u2net_output_sup0_activation_accuracy: 0.9779 - val_u2net_output_sup0_activation_mse: 0.0191 - val_u2net_output_sup1_activation_dice_coef: 0.0815 - val_u2net_output_sup1_activation_accuracy: 0.9781 - val_u2net_output_sup1_activation_mse: 0.0263 - val_u2net_output_sup2_activation_dice_coef: 0.0435 - val_u2net_output_sup2_activation_accuracy: 0.8181 - val_u2net_output_sup2_activation_mse: 0.2181 - val_u2net_output_sup3_activation_dice_coef: 0.0431 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2300 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2327 - val_u2net_output_sup5_activation_dice_coef: 0.0430 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2359 - val_u2net_output_final_activation_dice_coef: 0.0435 - val_u2net_output_final_activation_accuracy: 0.0232 - val_u2net_output_final_activation_mse: 0.3889\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7041 - u2net_output_sup0_activation_loss: 0.0444 - u2net_output_sup1_activation_loss: 0.1044 - u2net_output_sup2_activation_loss: 0.6232 - u2net_output_sup3_activation_loss: 0.6471 - u2net_output_sup4_activation_loss: 0.6535 - u2net_output_sup5_activation_loss: 0.6624 - u2net_output_final_activation_loss: 0.9690 - u2net_output_sup0_activation_dice_coef: 0.3950 - u2net_output_sup0_activation_accuracy: 0.9819 - u2net_output_sup0_activation_mse: 0.0113 - u2net_output_sup1_activation_dice_coef: 0.1766 - u2net_output_sup1_activation_accuracy: 0.9807 - u2net_output_sup1_activation_mse: 0.0207 - u2net_output_sup2_activation_dice_coef: 0.0418 - u2net_output_sup2_activation_accuracy: 0.8478 - u2net_output_sup2_activation_mse: 0.2142 - u2net_output_sup3_activation_dice_coef: 0.0397 - u2net_output_sup3_activation_accuracy: 0.9323 - u2net_output_sup3_activation_mse: 0.2278 - u2net_output_sup4_activation_dice_coef: 0.0391 - u2net_output_sup4_activation_accuracy: 0.9696 - u2net_output_sup4_activation_mse: 0.2307 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9752 - u2net_output_sup5_activation_mse: 0.2340 - u2net_output_final_activation_dice_coef: 0.0388 - u2net_output_final_activation_accuracy: 0.0187 - u2net_output_final_activation_mse: 0.3839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.7041 - u2net_output_sup0_activation_loss: 0.0444 - u2net_output_sup1_activation_loss: 0.1044 - u2net_output_sup2_activation_loss: 0.6232 - u2net_output_sup3_activation_loss: 0.6471 - u2net_output_sup4_activation_loss: 0.6535 - u2net_output_sup5_activation_loss: 0.6624 - u2net_output_final_activation_loss: 0.9690 - u2net_output_sup0_activation_dice_coef: 0.3950 - u2net_output_sup0_activation_accuracy: 0.9819 - u2net_output_sup0_activation_mse: 0.0113 - u2net_output_sup1_activation_dice_coef: 0.1766 - u2net_output_sup1_activation_accuracy: 0.9807 - u2net_output_sup1_activation_mse: 0.0207 - u2net_output_sup2_activation_dice_coef: 0.0418 - u2net_output_sup2_activation_accuracy: 0.8478 - u2net_output_sup2_activation_mse: 0.2142 - u2net_output_sup3_activation_dice_coef: 0.0397 - u2net_output_sup3_activation_accuracy: 0.9323 - u2net_output_sup3_activation_mse: 0.2278 - u2net_output_sup4_activation_dice_coef: 0.0391 - u2net_output_sup4_activation_accuracy: 0.9696 - u2net_output_sup4_activation_mse: 0.2307 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9752 - u2net_output_sup5_activation_mse: 0.2340 - u2net_output_final_activation_dice_coef: 0.0388 - u2net_output_final_activation_accuracy: 0.0187 - u2net_output_final_activation_mse: 0.3839 - val_loss: 3.6896 - val_u2net_output_sup0_activation_loss: 0.0515 - val_u2net_output_sup1_activation_loss: 0.1043 - val_u2net_output_sup2_activation_loss: 0.6179 - val_u2net_output_sup3_activation_loss: 0.6450 - val_u2net_output_sup4_activation_loss: 0.6513 - val_u2net_output_sup5_activation_loss: 0.6603 - val_u2net_output_final_activation_loss: 0.9593 - val_u2net_output_sup0_activation_dice_coef: 0.3611 - val_u2net_output_sup0_activation_accuracy: 0.9812 - val_u2net_output_sup0_activation_mse: 0.0144 - val_u2net_output_sup1_activation_dice_coef: 0.1623 - val_u2net_output_sup1_activation_accuracy: 0.9801 - val_u2net_output_sup1_activation_mse: 0.0211 - val_u2net_output_sup2_activation_dice_coef: 0.0446 - val_u2net_output_sup2_activation_accuracy: 0.8578 - val_u2net_output_sup2_activation_mse: 0.2128 - val_u2net_output_sup3_activation_dice_coef: 0.0432 - val_u2net_output_sup3_activation_accuracy: 0.9321 - val_u2net_output_sup3_activation_mse: 0.2275 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2303 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2336 - val_u2net_output_final_activation_dice_coef: 0.0431 - val_u2net_output_final_activation_accuracy: 0.0233 - val_u2net_output_final_activation_mse: 0.3799\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6425 - u2net_output_sup0_activation_loss: 0.0428 - u2net_output_sup1_activation_loss: 0.0893 - u2net_output_sup2_activation_loss: 0.6118 - u2net_output_sup3_activation_loss: 0.6409 - u2net_output_sup4_activation_loss: 0.6485 - u2net_output_sup5_activation_loss: 0.6578 - u2net_output_final_activation_loss: 0.9514 - u2net_output_sup0_activation_dice_coef: 0.4248 - u2net_output_sup0_activation_accuracy: 0.9828 - u2net_output_sup0_activation_mse: 0.0108 - u2net_output_sup1_activation_dice_coef: 0.2077 - u2net_output_sup1_activation_accuracy: 0.9818 - u2net_output_sup1_activation_mse: 0.0171 - u2net_output_sup2_activation_dice_coef: 0.0424 - u2net_output_sup2_activation_accuracy: 0.8584 - u2net_output_sup2_activation_mse: 0.2090 - u2net_output_sup3_activation_dice_coef: 0.0398 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2250 - u2net_output_sup4_activation_dice_coef: 0.0392 - u2net_output_sup4_activation_accuracy: 0.9698 - u2net_output_sup4_activation_mse: 0.2284 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9754 - u2net_output_sup5_activation_mse: 0.2317 - u2net_output_final_activation_dice_coef: 0.0389 - u2net_output_final_activation_accuracy: 0.0186 - u2net_output_final_activation_mse: 0.3756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 3.6425 - u2net_output_sup0_activation_loss: 0.0428 - u2net_output_sup1_activation_loss: 0.0893 - u2net_output_sup2_activation_loss: 0.6118 - u2net_output_sup3_activation_loss: 0.6409 - u2net_output_sup4_activation_loss: 0.6485 - u2net_output_sup5_activation_loss: 0.6578 - u2net_output_final_activation_loss: 0.9514 - u2net_output_sup0_activation_dice_coef: 0.4248 - u2net_output_sup0_activation_accuracy: 0.9828 - u2net_output_sup0_activation_mse: 0.0108 - u2net_output_sup1_activation_dice_coef: 0.2077 - u2net_output_sup1_activation_accuracy: 0.9818 - u2net_output_sup1_activation_mse: 0.0171 - u2net_output_sup2_activation_dice_coef: 0.0424 - u2net_output_sup2_activation_accuracy: 0.8584 - u2net_output_sup2_activation_mse: 0.2090 - u2net_output_sup3_activation_dice_coef: 0.0398 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2250 - u2net_output_sup4_activation_dice_coef: 0.0392 - u2net_output_sup4_activation_accuracy: 0.9698 - u2net_output_sup4_activation_mse: 0.2284 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9754 - u2net_output_sup5_activation_mse: 0.2317 - u2net_output_final_activation_dice_coef: 0.0389 - u2net_output_final_activation_accuracy: 0.0186 - u2net_output_final_activation_mse: 0.3756 - val_loss: 3.6254 - val_u2net_output_sup0_activation_loss: 0.0473 - val_u2net_output_sup1_activation_loss: 0.0905 - val_u2net_output_sup2_activation_loss: 0.6064 - val_u2net_output_sup3_activation_loss: 0.6381 - val_u2net_output_sup4_activation_loss: 0.6464 - val_u2net_output_sup5_activation_loss: 0.6557 - val_u2net_output_final_activation_loss: 0.9412 - val_u2net_output_sup0_activation_dice_coef: 0.3839 - val_u2net_output_sup0_activation_accuracy: 0.9825 - val_u2net_output_sup0_activation_mse: 0.0132 - val_u2net_output_sup1_activation_dice_coef: 0.1926 - val_u2net_output_sup1_activation_accuracy: 0.9817 - val_u2net_output_sup1_activation_mse: 0.0186 - val_u2net_output_sup2_activation_dice_coef: 0.0462 - val_u2net_output_sup2_activation_accuracy: 0.8587 - val_u2net_output_sup2_activation_mse: 0.2075 - val_u2net_output_sup3_activation_dice_coef: 0.0439 - val_u2net_output_sup3_activation_accuracy: 0.9323 - val_u2net_output_sup3_activation_mse: 0.2243 - val_u2net_output_sup4_activation_dice_coef: 0.0431 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2279 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2313 - val_u2net_output_final_activation_dice_coef: 0.0431 - val_u2net_output_final_activation_accuracy: 0.0233 - val_u2net_output_final_activation_mse: 0.3714\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5870 - u2net_output_sup0_activation_loss: 0.0421 - u2net_output_sup1_activation_loss: 0.0791 - u2net_output_sup2_activation_loss: 0.6004 - u2net_output_sup3_activation_loss: 0.6349 - u2net_output_sup4_activation_loss: 0.6436 - u2net_output_sup5_activation_loss: 0.6533 - u2net_output_final_activation_loss: 0.9336 - u2net_output_sup0_activation_dice_coef: 0.4423 - u2net_output_sup0_activation_accuracy: 0.9829 - u2net_output_sup0_activation_mse: 0.0107 - u2net_output_sup1_activation_dice_coef: 0.2405 - u2net_output_sup1_activation_accuracy: 0.9818 - u2net_output_sup1_activation_mse: 0.0152 - u2net_output_sup2_activation_dice_coef: 0.0434 - u2net_output_sup2_activation_accuracy: 0.8589 - u2net_output_sup2_activation_mse: 0.2040 - u2net_output_sup3_activation_dice_coef: 0.0403 - u2net_output_sup3_activation_accuracy: 0.9322 - u2net_output_sup3_activation_mse: 0.2222 - u2net_output_sup4_activation_dice_coef: 0.0395 - u2net_output_sup4_activation_accuracy: 0.9695 - u2net_output_sup4_activation_mse: 0.2260 - u2net_output_sup5_activation_dice_coef: 0.0393 - u2net_output_sup5_activation_accuracy: 0.9751 - u2net_output_sup5_activation_mse: 0.2295 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.0189 - u2net_output_final_activation_mse: 0.3672"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.5870 - u2net_output_sup0_activation_loss: 0.0421 - u2net_output_sup1_activation_loss: 0.0791 - u2net_output_sup2_activation_loss: 0.6004 - u2net_output_sup3_activation_loss: 0.6349 - u2net_output_sup4_activation_loss: 0.6436 - u2net_output_sup5_activation_loss: 0.6533 - u2net_output_final_activation_loss: 0.9336 - u2net_output_sup0_activation_dice_coef: 0.4423 - u2net_output_sup0_activation_accuracy: 0.9829 - u2net_output_sup0_activation_mse: 0.0107 - u2net_output_sup1_activation_dice_coef: 0.2405 - u2net_output_sup1_activation_accuracy: 0.9818 - u2net_output_sup1_activation_mse: 0.0152 - u2net_output_sup2_activation_dice_coef: 0.0434 - u2net_output_sup2_activation_accuracy: 0.8589 - u2net_output_sup2_activation_mse: 0.2040 - u2net_output_sup3_activation_dice_coef: 0.0403 - u2net_output_sup3_activation_accuracy: 0.9322 - u2net_output_sup3_activation_mse: 0.2222 - u2net_output_sup4_activation_dice_coef: 0.0395 - u2net_output_sup4_activation_accuracy: 0.9695 - u2net_output_sup4_activation_mse: 0.2260 - u2net_output_sup5_activation_dice_coef: 0.0393 - u2net_output_sup5_activation_accuracy: 0.9751 - u2net_output_sup5_activation_mse: 0.2295 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.0189 - u2net_output_final_activation_mse: 0.3672 - val_loss: 3.5860 - val_u2net_output_sup0_activation_loss: 0.0519 - val_u2net_output_sup1_activation_loss: 0.0907 - val_u2net_output_sup2_activation_loss: 0.5957 - val_u2net_output_sup3_activation_loss: 0.6322 - val_u2net_output_sup4_activation_loss: 0.6415 - val_u2net_output_sup5_activation_loss: 0.6512 - val_u2net_output_final_activation_loss: 0.9228 - val_u2net_output_sup0_activation_dice_coef: 0.3139 - val_u2net_output_sup0_activation_accuracy: 0.9806 - val_u2net_output_sup0_activation_mse: 0.0146 - val_u2net_output_sup1_activation_dice_coef: 0.1848 - val_u2net_output_sup1_activation_accuracy: 0.9805 - val_u2net_output_sup1_activation_mse: 0.0195 - val_u2net_output_sup2_activation_dice_coef: 0.0460 - val_u2net_output_sup2_activation_accuracy: 0.8614 - val_u2net_output_sup2_activation_mse: 0.2027 - val_u2net_output_sup3_activation_dice_coef: 0.0443 - val_u2net_output_sup3_activation_accuracy: 0.9327 - val_u2net_output_sup3_activation_mse: 0.2215 - val_u2net_output_sup4_activation_dice_coef: 0.0431 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2256 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2291 - val_u2net_output_final_activation_dice_coef: 0.0431 - val_u2net_output_final_activation_accuracy: 0.0235 - val_u2net_output_final_activation_mse: 0.3627\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5335 - u2net_output_sup0_activation_loss: 0.0410 - u2net_output_sup1_activation_loss: 0.0713 - u2net_output_sup2_activation_loss: 0.5890 - u2net_output_sup3_activation_loss: 0.6290 - u2net_output_sup4_activation_loss: 0.6390 - u2net_output_sup5_activation_loss: 0.6489 - u2net_output_final_activation_loss: 0.9154 - u2net_output_sup0_activation_dice_coef: 0.4793 - u2net_output_sup0_activation_accuracy: 0.9827 - u2net_output_sup0_activation_mse: 0.0105 - u2net_output_sup1_activation_dice_coef: 0.2879 - u2net_output_sup1_activation_accuracy: 0.9815 - u2net_output_sup1_activation_mse: 0.0142 - u2net_output_sup2_activation_dice_coef: 0.0485 - u2net_output_sup2_activation_accuracy: 0.8792 - u2net_output_sup2_activation_mse: 0.1991 - u2net_output_sup3_activation_dice_coef: 0.0440 - u2net_output_sup3_activation_accuracy: 0.9308 - u2net_output_sup3_activation_mse: 0.2195 - u2net_output_sup4_activation_dice_coef: 0.0431 - u2net_output_sup4_activation_accuracy: 0.9678 - u2net_output_sup4_activation_mse: 0.2237 - u2net_output_sup5_activation_dice_coef: 0.0428 - u2net_output_sup5_activation_accuracy: 0.9734 - u2net_output_sup5_activation_mse: 0.2273 - u2net_output_final_activation_dice_coef: 0.0426 - u2net_output_final_activation_accuracy: 0.0224 - u2net_output_final_activation_mse: 0.3584"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.5335 - u2net_output_sup0_activation_loss: 0.0410 - u2net_output_sup1_activation_loss: 0.0713 - u2net_output_sup2_activation_loss: 0.5890 - u2net_output_sup3_activation_loss: 0.6290 - u2net_output_sup4_activation_loss: 0.6390 - u2net_output_sup5_activation_loss: 0.6489 - u2net_output_final_activation_loss: 0.9154 - u2net_output_sup0_activation_dice_coef: 0.4793 - u2net_output_sup0_activation_accuracy: 0.9827 - u2net_output_sup0_activation_mse: 0.0105 - u2net_output_sup1_activation_dice_coef: 0.2879 - u2net_output_sup1_activation_accuracy: 0.9815 - u2net_output_sup1_activation_mse: 0.0142 - u2net_output_sup2_activation_dice_coef: 0.0485 - u2net_output_sup2_activation_accuracy: 0.8792 - u2net_output_sup2_activation_mse: 0.1991 - u2net_output_sup3_activation_dice_coef: 0.0440 - u2net_output_sup3_activation_accuracy: 0.9308 - u2net_output_sup3_activation_mse: 0.2195 - u2net_output_sup4_activation_dice_coef: 0.0431 - u2net_output_sup4_activation_accuracy: 0.9678 - u2net_output_sup4_activation_mse: 0.2237 - u2net_output_sup5_activation_dice_coef: 0.0428 - u2net_output_sup5_activation_accuracy: 0.9734 - u2net_output_sup5_activation_mse: 0.2273 - u2net_output_final_activation_dice_coef: 0.0426 - u2net_output_final_activation_accuracy: 0.0224 - u2net_output_final_activation_mse: 0.3584 - val_loss: 3.5252 - val_u2net_output_sup0_activation_loss: 0.0477 - val_u2net_output_sup1_activation_loss: 0.0798 - val_u2net_output_sup2_activation_loss: 0.5836 - val_u2net_output_sup3_activation_loss: 0.6262 - val_u2net_output_sup4_activation_loss: 0.6367 - val_u2net_output_sup5_activation_loss: 0.6467 - val_u2net_output_final_activation_loss: 0.9046 - val_u2net_output_sup0_activation_dice_coef: 0.4372 - val_u2net_output_sup0_activation_accuracy: 0.9818 - val_u2net_output_sup0_activation_mse: 0.0135 - val_u2net_output_sup1_activation_dice_coef: 0.2690 - val_u2net_output_sup1_activation_accuracy: 0.9796 - val_u2net_output_sup1_activation_mse: 0.0185 - val_u2net_output_sup2_activation_dice_coef: 0.0494 - val_u2net_output_sup2_activation_accuracy: 0.9185 - val_u2net_output_sup2_activation_mse: 0.1976 - val_u2net_output_sup3_activation_dice_coef: 0.0441 - val_u2net_output_sup3_activation_accuracy: 0.9325 - val_u2net_output_sup3_activation_mse: 0.2189 - val_u2net_output_sup4_activation_dice_coef: 0.0432 - val_u2net_output_sup4_activation_accuracy: 0.9693 - val_u2net_output_sup4_activation_mse: 0.2233 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2269 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.0314 - val_u2net_output_final_activation_mse: 0.3540\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4798 - u2net_output_sup0_activation_loss: 0.0388 - u2net_output_sup1_activation_loss: 0.0643 - u2net_output_sup2_activation_loss: 0.5773 - u2net_output_sup3_activation_loss: 0.6227 - u2net_output_sup4_activation_loss: 0.6340 - u2net_output_sup5_activation_loss: 0.6443 - u2net_output_final_activation_loss: 0.8985 - u2net_output_sup0_activation_dice_coef: 0.4798 - u2net_output_sup0_activation_accuracy: 0.9838 - u2net_output_sup0_activation_mse: 0.0099 - u2net_output_sup1_activation_dice_coef: 0.3002 - u2net_output_sup1_activation_accuracy: 0.9826 - u2net_output_sup1_activation_mse: 0.0128 - u2net_output_sup2_activation_dice_coef: 0.0461 - u2net_output_sup2_activation_accuracy: 0.9185 - u2net_output_sup2_activation_mse: 0.1941 - u2net_output_sup3_activation_dice_coef: 0.0415 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2167 - u2net_output_sup4_activation_dice_coef: 0.0404 - u2net_output_sup4_activation_accuracy: 0.9693 - u2net_output_sup4_activation_mse: 0.2213 - u2net_output_sup5_activation_dice_coef: 0.0401 - u2net_output_sup5_activation_accuracy: 0.9749 - u2net_output_sup5_activation_mse: 0.2250 - u2net_output_final_activation_dice_coef: 0.0399 - u2net_output_final_activation_accuracy: 0.0314 - u2net_output_final_activation_mse: 0.3504"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.4798 - u2net_output_sup0_activation_loss: 0.0388 - u2net_output_sup1_activation_loss: 0.0643 - u2net_output_sup2_activation_loss: 0.5773 - u2net_output_sup3_activation_loss: 0.6227 - u2net_output_sup4_activation_loss: 0.6340 - u2net_output_sup5_activation_loss: 0.6443 - u2net_output_final_activation_loss: 0.8985 - u2net_output_sup0_activation_dice_coef: 0.4798 - u2net_output_sup0_activation_accuracy: 0.9838 - u2net_output_sup0_activation_mse: 0.0099 - u2net_output_sup1_activation_dice_coef: 0.3002 - u2net_output_sup1_activation_accuracy: 0.9826 - u2net_output_sup1_activation_mse: 0.0128 - u2net_output_sup2_activation_dice_coef: 0.0461 - u2net_output_sup2_activation_accuracy: 0.9185 - u2net_output_sup2_activation_mse: 0.1941 - u2net_output_sup3_activation_dice_coef: 0.0415 - u2net_output_sup3_activation_accuracy: 0.9324 - u2net_output_sup3_activation_mse: 0.2167 - u2net_output_sup4_activation_dice_coef: 0.0404 - u2net_output_sup4_activation_accuracy: 0.9693 - u2net_output_sup4_activation_mse: 0.2213 - u2net_output_sup5_activation_dice_coef: 0.0401 - u2net_output_sup5_activation_accuracy: 0.9749 - u2net_output_sup5_activation_mse: 0.2250 - u2net_output_final_activation_dice_coef: 0.0399 - u2net_output_final_activation_accuracy: 0.0314 - u2net_output_final_activation_mse: 0.3504 - val_loss: 3.4820 - val_u2net_output_sup0_activation_loss: 0.0475 - val_u2net_output_sup1_activation_loss: 0.0778 - val_u2net_output_sup2_activation_loss: 0.5743 - val_u2net_output_sup3_activation_loss: 0.6202 - val_u2net_output_sup4_activation_loss: 0.6319 - val_u2net_output_sup5_activation_loss: 0.6423 - val_u2net_output_final_activation_loss: 0.8881 - val_u2net_output_sup0_activation_dice_coef: 0.4286 - val_u2net_output_sup0_activation_accuracy: 0.9826 - val_u2net_output_sup0_activation_mse: 0.0132 - val_u2net_output_sup1_activation_dice_coef: 0.2829 - val_u2net_output_sup1_activation_accuracy: 0.9786 - val_u2net_output_sup1_activation_mse: 0.0191 - val_u2net_output_sup2_activation_dice_coef: 0.0521 - val_u2net_output_sup2_activation_accuracy: 0.9179 - val_u2net_output_sup2_activation_mse: 0.1938 - val_u2net_output_sup3_activation_dice_coef: 0.0448 - val_u2net_output_sup3_activation_accuracy: 0.9345 - val_u2net_output_sup3_activation_mse: 0.2161 - val_u2net_output_sup4_activation_dice_coef: 0.0433 - val_u2net_output_sup4_activation_accuracy: 0.9694 - val_u2net_output_sup4_activation_mse: 0.2210 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2247 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.0367 - val_u2net_output_final_activation_mse: 0.3461\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4357 - u2net_output_sup0_activation_loss: 0.0407 - u2net_output_sup1_activation_loss: 0.0619 - u2net_output_sup2_activation_loss: 0.5661 - u2net_output_sup3_activation_loss: 0.6169 - u2net_output_sup4_activation_loss: 0.6293 - u2net_output_sup5_activation_loss: 0.6399 - u2net_output_final_activation_loss: 0.8809 - u2net_output_sup0_activation_dice_coef: 0.4678 - u2net_output_sup0_activation_accuracy: 0.9830 - u2net_output_sup0_activation_mse: 0.0104 - u2net_output_sup1_activation_dice_coef: 0.3174 - u2net_output_sup1_activation_accuracy: 0.9821 - u2net_output_sup1_activation_mse: 0.0129 - u2net_output_sup2_activation_dice_coef: 0.0484 - u2net_output_sup2_activation_accuracy: 0.9178 - u2net_output_sup2_activation_mse: 0.1895 - u2net_output_sup3_activation_dice_coef: 0.0429 - u2net_output_sup3_activation_accuracy: 0.9337 - u2net_output_sup3_activation_mse: 0.2140 - u2net_output_sup4_activation_dice_coef: 0.0418 - u2net_output_sup4_activation_accuracy: 0.9682 - u2net_output_sup4_activation_mse: 0.2191 - u2net_output_sup5_activation_dice_coef: 0.0414 - u2net_output_sup5_activation_accuracy: 0.9738 - u2net_output_sup5_activation_mse: 0.2228 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.0449 - u2net_output_final_activation_mse: 0.3419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 3.4357 - u2net_output_sup0_activation_loss: 0.0407 - u2net_output_sup1_activation_loss: 0.0619 - u2net_output_sup2_activation_loss: 0.5661 - u2net_output_sup3_activation_loss: 0.6169 - u2net_output_sup4_activation_loss: 0.6293 - u2net_output_sup5_activation_loss: 0.6399 - u2net_output_final_activation_loss: 0.8809 - u2net_output_sup0_activation_dice_coef: 0.4678 - u2net_output_sup0_activation_accuracy: 0.9830 - u2net_output_sup0_activation_mse: 0.0104 - u2net_output_sup1_activation_dice_coef: 0.3174 - u2net_output_sup1_activation_accuracy: 0.9821 - u2net_output_sup1_activation_mse: 0.0129 - u2net_output_sup2_activation_dice_coef: 0.0484 - u2net_output_sup2_activation_accuracy: 0.9178 - u2net_output_sup2_activation_mse: 0.1895 - u2net_output_sup3_activation_dice_coef: 0.0429 - u2net_output_sup3_activation_accuracy: 0.9337 - u2net_output_sup3_activation_mse: 0.2140 - u2net_output_sup4_activation_dice_coef: 0.0418 - u2net_output_sup4_activation_accuracy: 0.9682 - u2net_output_sup4_activation_mse: 0.2191 - u2net_output_sup5_activation_dice_coef: 0.0414 - u2net_output_sup5_activation_accuracy: 0.9738 - u2net_output_sup5_activation_mse: 0.2228 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.0449 - u2net_output_final_activation_mse: 0.3419 - val_loss: 3.4300 - val_u2net_output_sup0_activation_loss: 0.0464 - val_u2net_output_sup1_activation_loss: 0.0727 - val_u2net_output_sup2_activation_loss: 0.5612 - val_u2net_output_sup3_activation_loss: 0.6140 - val_u2net_output_sup4_activation_loss: 0.6271 - val_u2net_output_sup5_activation_loss: 0.6378 - val_u2net_output_final_activation_loss: 0.8708 - val_u2net_output_sup0_activation_dice_coef: 0.4283 - val_u2net_output_sup0_activation_accuracy: 0.9830 - val_u2net_output_sup0_activation_mse: 0.0128 - val_u2net_output_sup1_activation_dice_coef: 0.2871 - val_u2net_output_sup1_activation_accuracy: 0.9813 - val_u2net_output_sup1_activation_mse: 0.0169 - val_u2net_output_sup2_activation_dice_coef: 0.0512 - val_u2net_output_sup2_activation_accuracy: 0.9193 - val_u2net_output_sup2_activation_mse: 0.1883 - val_u2net_output_sup3_activation_dice_coef: 0.0446 - val_u2net_output_sup3_activation_accuracy: 0.9443 - val_u2net_output_sup3_activation_mse: 0.2134 - val_u2net_output_sup4_activation_dice_coef: 0.0433 - val_u2net_output_sup4_activation_accuracy: 0.9694 - val_u2net_output_sup4_activation_mse: 0.2187 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2225 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.0510 - val_u2net_output_final_activation_mse: 0.3377\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3825 - u2net_output_sup0_activation_loss: 0.0370 - u2net_output_sup1_activation_loss: 0.0558 - u2net_output_sup2_activation_loss: 0.5546 - u2net_output_sup3_activation_loss: 0.6107 - u2net_output_sup4_activation_loss: 0.6243 - u2net_output_sup5_activation_loss: 0.6354 - u2net_output_final_activation_loss: 0.8647 - u2net_output_sup0_activation_dice_coef: 0.4929 - u2net_output_sup0_activation_accuracy: 0.9843 - u2net_output_sup0_activation_mse: 0.0096 - u2net_output_sup1_activation_dice_coef: 0.3383 - u2net_output_sup1_activation_accuracy: 0.9831 - u2net_output_sup1_activation_mse: 0.0118 - u2net_output_sup2_activation_dice_coef: 0.0470 - u2net_output_sup2_activation_accuracy: 0.9190 - u2net_output_sup2_activation_mse: 0.1849 - u2net_output_sup3_activation_dice_coef: 0.0411 - u2net_output_sup3_activation_accuracy: 0.9570 - u2net_output_sup3_activation_mse: 0.2113 - u2net_output_sup4_activation_dice_coef: 0.0399 - u2net_output_sup4_activation_accuracy: 0.9696 - u2net_output_sup4_activation_mse: 0.2167 - u2net_output_sup5_activation_dice_coef: 0.0395 - u2net_output_sup5_activation_accuracy: 0.9751 - u2net_output_sup5_activation_mse: 0.2206 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.0487 - u2net_output_final_activation_mse: 0.3341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.3825 - u2net_output_sup0_activation_loss: 0.0370 - u2net_output_sup1_activation_loss: 0.0558 - u2net_output_sup2_activation_loss: 0.5546 - u2net_output_sup3_activation_loss: 0.6107 - u2net_output_sup4_activation_loss: 0.6243 - u2net_output_sup5_activation_loss: 0.6354 - u2net_output_final_activation_loss: 0.8647 - u2net_output_sup0_activation_dice_coef: 0.4929 - u2net_output_sup0_activation_accuracy: 0.9843 - u2net_output_sup0_activation_mse: 0.0096 - u2net_output_sup1_activation_dice_coef: 0.3383 - u2net_output_sup1_activation_accuracy: 0.9831 - u2net_output_sup1_activation_mse: 0.0118 - u2net_output_sup2_activation_dice_coef: 0.0470 - u2net_output_sup2_activation_accuracy: 0.9190 - u2net_output_sup2_activation_mse: 0.1849 - u2net_output_sup3_activation_dice_coef: 0.0411 - u2net_output_sup3_activation_accuracy: 0.9570 - u2net_output_sup3_activation_mse: 0.2113 - u2net_output_sup4_activation_dice_coef: 0.0399 - u2net_output_sup4_activation_accuracy: 0.9696 - u2net_output_sup4_activation_mse: 0.2167 - u2net_output_sup5_activation_dice_coef: 0.0395 - u2net_output_sup5_activation_accuracy: 0.9751 - u2net_output_sup5_activation_mse: 0.2206 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.0487 - u2net_output_final_activation_mse: 0.3341 - val_loss: 3.4104 - val_u2net_output_sup0_activation_loss: 0.0628 - val_u2net_output_sup1_activation_loss: 0.0787 - val_u2net_output_sup2_activation_loss: 0.5508 - val_u2net_output_sup3_activation_loss: 0.6085 - val_u2net_output_sup4_activation_loss: 0.6223 - val_u2net_output_sup5_activation_loss: 0.6334 - val_u2net_output_final_activation_loss: 0.8539 - val_u2net_output_sup0_activation_dice_coef: 0.4226 - val_u2net_output_sup0_activation_accuracy: 0.9755 - val_u2net_output_sup0_activation_mse: 0.0181 - val_u2net_output_sup1_activation_dice_coef: 0.3150 - val_u2net_output_sup1_activation_accuracy: 0.9748 - val_u2net_output_sup1_activation_mse: 0.0204 - val_u2net_output_sup2_activation_dice_coef: 0.0512 - val_u2net_output_sup2_activation_accuracy: 0.9187 - val_u2net_output_sup2_activation_mse: 0.1842 - val_u2net_output_sup3_activation_dice_coef: 0.0442 - val_u2net_output_sup3_activation_accuracy: 0.9620 - val_u2net_output_sup3_activation_mse: 0.2109 - val_u2net_output_sup4_activation_dice_coef: 0.0434 - val_u2net_output_sup4_activation_accuracy: 0.9695 - val_u2net_output_sup4_activation_mse: 0.2164 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2203 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.0584 - val_u2net_output_final_activation_mse: 0.3295\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3374 - u2net_output_sup0_activation_loss: 0.0368 - u2net_output_sup1_activation_loss: 0.0535 - u2net_output_sup2_activation_loss: 0.5435 - u2net_output_sup3_activation_loss: 0.6048 - u2net_output_sup4_activation_loss: 0.6196 - u2net_output_sup5_activation_loss: 0.6310 - u2net_output_final_activation_loss: 0.8482 - u2net_output_sup0_activation_dice_coef: 0.4950 - u2net_output_sup0_activation_accuracy: 0.9841 - u2net_output_sup0_activation_mse: 0.0096 - u2net_output_sup1_activation_dice_coef: 0.3524 - u2net_output_sup1_activation_accuracy: 0.9831 - u2net_output_sup1_activation_mse: 0.0116 - u2net_output_sup2_activation_dice_coef: 0.0481 - u2net_output_sup2_activation_accuracy: 0.9188 - u2net_output_sup2_activation_mse: 0.1805 - u2net_output_sup3_activation_dice_coef: 0.0415 - u2net_output_sup3_activation_accuracy: 0.9620 - u2net_output_sup3_activation_mse: 0.2086 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9693 - u2net_output_sup4_activation_mse: 0.2144 - u2net_output_sup5_activation_dice_coef: 0.0398 - u2net_output_sup5_activation_accuracy: 0.9747 - u2net_output_sup5_activation_mse: 0.2184 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.0626 - u2net_output_final_activation_mse: 0.3261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.3374 - u2net_output_sup0_activation_loss: 0.0368 - u2net_output_sup1_activation_loss: 0.0535 - u2net_output_sup2_activation_loss: 0.5435 - u2net_output_sup3_activation_loss: 0.6048 - u2net_output_sup4_activation_loss: 0.6196 - u2net_output_sup5_activation_loss: 0.6310 - u2net_output_final_activation_loss: 0.8482 - u2net_output_sup0_activation_dice_coef: 0.4950 - u2net_output_sup0_activation_accuracy: 0.9841 - u2net_output_sup0_activation_mse: 0.0096 - u2net_output_sup1_activation_dice_coef: 0.3524 - u2net_output_sup1_activation_accuracy: 0.9831 - u2net_output_sup1_activation_mse: 0.0116 - u2net_output_sup2_activation_dice_coef: 0.0481 - u2net_output_sup2_activation_accuracy: 0.9188 - u2net_output_sup2_activation_mse: 0.1805 - u2net_output_sup3_activation_dice_coef: 0.0415 - u2net_output_sup3_activation_accuracy: 0.9620 - u2net_output_sup3_activation_mse: 0.2086 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9693 - u2net_output_sup4_activation_mse: 0.2144 - u2net_output_sup5_activation_dice_coef: 0.0398 - u2net_output_sup5_activation_accuracy: 0.9747 - u2net_output_sup5_activation_mse: 0.2184 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.0626 - u2net_output_final_activation_mse: 0.3261 - val_loss: 3.3307 - val_u2net_output_sup0_activation_loss: 0.0418 - val_u2net_output_sup1_activation_loss: 0.0619 - val_u2net_output_sup2_activation_loss: 0.5394 - val_u2net_output_sup3_activation_loss: 0.6028 - val_u2net_output_sup4_activation_loss: 0.6175 - val_u2net_output_sup5_activation_loss: 0.6291 - val_u2net_output_final_activation_loss: 0.8381 - val_u2net_output_sup0_activation_dice_coef: 0.4104 - val_u2net_output_sup0_activation_accuracy: 0.9844 - val_u2net_output_sup0_activation_mse: 0.0116 - val_u2net_output_sup1_activation_dice_coef: 0.2885 - val_u2net_output_sup1_activation_accuracy: 0.9837 - val_u2net_output_sup1_activation_mse: 0.0146 - val_u2net_output_sup2_activation_dice_coef: 0.0508 - val_u2net_output_sup2_activation_accuracy: 0.9193 - val_u2net_output_sup2_activation_mse: 0.1795 - val_u2net_output_sup3_activation_dice_coef: 0.0441 - val_u2net_output_sup3_activation_accuracy: 0.9621 - val_u2net_output_sup3_activation_mse: 0.2084 - val_u2net_output_sup4_activation_dice_coef: 0.0434 - val_u2net_output_sup4_activation_accuracy: 0.9699 - val_u2net_output_sup4_activation_mse: 0.2141 - val_u2net_output_sup5_activation_dice_coef: 0.0429 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2181 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.0871 - val_u2net_output_final_activation_mse: 0.3218\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2875 - u2net_output_sup0_activation_loss: 0.0342 - u2net_output_sup1_activation_loss: 0.0490 - u2net_output_sup2_activation_loss: 0.5321 - u2net_output_sup3_activation_loss: 0.5985 - u2net_output_sup4_activation_loss: 0.6146 - u2net_output_sup5_activation_loss: 0.6264 - u2net_output_final_activation_loss: 0.8326 - u2net_output_sup0_activation_dice_coef: 0.5147 - u2net_output_sup0_activation_accuracy: 0.9852 - u2net_output_sup0_activation_mse: 0.0088 - u2net_output_sup1_activation_dice_coef: 0.3767 - u2net_output_sup1_activation_accuracy: 0.9841 - u2net_output_sup1_activation_mse: 0.0107 - u2net_output_sup2_activation_dice_coef: 0.0476 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1761 - u2net_output_sup3_activation_dice_coef: 0.0402 - u2net_output_sup3_activation_accuracy: 0.9632 - u2net_output_sup3_activation_mse: 0.2059 - u2net_output_sup4_activation_dice_coef: 0.0388 - u2net_output_sup4_activation_accuracy: 0.9726 - u2net_output_sup4_activation_mse: 0.2121 - u2net_output_sup5_activation_dice_coef: 0.0383 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.2162 - u2net_output_final_activation_dice_coef: 0.0378 - u2net_output_final_activation_accuracy: 0.0842 - u2net_output_final_activation_mse: 0.3185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 3.2875 - u2net_output_sup0_activation_loss: 0.0342 - u2net_output_sup1_activation_loss: 0.0490 - u2net_output_sup2_activation_loss: 0.5321 - u2net_output_sup3_activation_loss: 0.5985 - u2net_output_sup4_activation_loss: 0.6146 - u2net_output_sup5_activation_loss: 0.6264 - u2net_output_final_activation_loss: 0.8326 - u2net_output_sup0_activation_dice_coef: 0.5147 - u2net_output_sup0_activation_accuracy: 0.9852 - u2net_output_sup0_activation_mse: 0.0088 - u2net_output_sup1_activation_dice_coef: 0.3767 - u2net_output_sup1_activation_accuracy: 0.9841 - u2net_output_sup1_activation_mse: 0.0107 - u2net_output_sup2_activation_dice_coef: 0.0476 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1761 - u2net_output_sup3_activation_dice_coef: 0.0402 - u2net_output_sup3_activation_accuracy: 0.9632 - u2net_output_sup3_activation_mse: 0.2059 - u2net_output_sup4_activation_dice_coef: 0.0388 - u2net_output_sup4_activation_accuracy: 0.9726 - u2net_output_sup4_activation_mse: 0.2121 - u2net_output_sup5_activation_dice_coef: 0.0383 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.2162 - u2net_output_final_activation_dice_coef: 0.0378 - u2net_output_final_activation_accuracy: 0.0842 - u2net_output_final_activation_mse: 0.3185 - val_loss: 3.3150 - val_u2net_output_sup0_activation_loss: 0.0500 - val_u2net_output_sup1_activation_loss: 0.0814 - val_u2net_output_sup2_activation_loss: 0.5292 - val_u2net_output_sup3_activation_loss: 0.5965 - val_u2net_output_sup4_activation_loss: 0.6128 - val_u2net_output_sup5_activation_loss: 0.6247 - val_u2net_output_final_activation_loss: 0.8203 - val_u2net_output_sup0_activation_dice_coef: 0.4171 - val_u2net_output_sup0_activation_accuracy: 0.9805 - val_u2net_output_sup0_activation_mse: 0.0143 - val_u2net_output_sup1_activation_dice_coef: 0.3301 - val_u2net_output_sup1_activation_accuracy: 0.9747 - val_u2net_output_sup1_activation_mse: 0.0218 - val_u2net_output_sup2_activation_dice_coef: 0.0555 - val_u2net_output_sup2_activation_accuracy: 0.9198 - val_u2net_output_sup2_activation_mse: 0.1756 - val_u2net_output_sup3_activation_dice_coef: 0.0453 - val_u2net_output_sup3_activation_accuracy: 0.9623 - val_u2net_output_sup3_activation_mse: 0.2056 - val_u2net_output_sup4_activation_dice_coef: 0.0435 - val_u2net_output_sup4_activation_accuracy: 0.9732 - val_u2net_output_sup4_activation_mse: 0.2118 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2160 - val_u2net_output_final_activation_dice_coef: 0.0419 - val_u2net_output_final_activation_accuracy: 0.0948 - val_u2net_output_final_activation_mse: 0.3131\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2448 - u2net_output_sup0_activation_loss: 0.0344 - u2net_output_sup1_activation_loss: 0.0471 - u2net_output_sup2_activation_loss: 0.5215 - u2net_output_sup3_activation_loss: 0.5927 - u2net_output_sup4_activation_loss: 0.6099 - u2net_output_sup5_activation_loss: 0.6222 - u2net_output_final_activation_loss: 0.8170 - u2net_output_sup0_activation_dice_coef: 0.5122 - u2net_output_sup0_activation_accuracy: 0.9850 - u2net_output_sup0_activation_mse: 0.0089 - u2net_output_sup1_activation_dice_coef: 0.3883 - u2net_output_sup1_activation_accuracy: 0.9842 - u2net_output_sup1_activation_mse: 0.0105 - u2net_output_sup2_activation_dice_coef: 0.0492 - u2net_output_sup2_activation_accuracy: 0.9199 - u2net_output_sup2_activation_mse: 0.1720 - u2net_output_sup3_activation_dice_coef: 0.0412 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.2033 - u2net_output_sup4_activation_dice_coef: 0.0397 - u2net_output_sup4_activation_accuracy: 0.9737 - u2net_output_sup4_activation_mse: 0.2098 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9755 - u2net_output_sup5_activation_mse: 0.2141 - u2net_output_final_activation_dice_coef: 0.0386 - u2net_output_final_activation_accuracy: 0.0921 - u2net_output_final_activation_mse: 0.3108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.2448 - u2net_output_sup0_activation_loss: 0.0344 - u2net_output_sup1_activation_loss: 0.0471 - u2net_output_sup2_activation_loss: 0.5215 - u2net_output_sup3_activation_loss: 0.5927 - u2net_output_sup4_activation_loss: 0.6099 - u2net_output_sup5_activation_loss: 0.6222 - u2net_output_final_activation_loss: 0.8170 - u2net_output_sup0_activation_dice_coef: 0.5122 - u2net_output_sup0_activation_accuracy: 0.9850 - u2net_output_sup0_activation_mse: 0.0089 - u2net_output_sup1_activation_dice_coef: 0.3883 - u2net_output_sup1_activation_accuracy: 0.9842 - u2net_output_sup1_activation_mse: 0.0105 - u2net_output_sup2_activation_dice_coef: 0.0492 - u2net_output_sup2_activation_accuracy: 0.9199 - u2net_output_sup2_activation_mse: 0.1720 - u2net_output_sup3_activation_dice_coef: 0.0412 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.2033 - u2net_output_sup4_activation_dice_coef: 0.0397 - u2net_output_sup4_activation_accuracy: 0.9737 - u2net_output_sup4_activation_mse: 0.2098 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9755 - u2net_output_sup5_activation_mse: 0.2141 - u2net_output_final_activation_dice_coef: 0.0386 - u2net_output_final_activation_accuracy: 0.0921 - u2net_output_final_activation_mse: 0.3108 - val_loss: 3.2443 - val_u2net_output_sup0_activation_loss: 0.0411 - val_u2net_output_sup1_activation_loss: 0.0578 - val_u2net_output_sup2_activation_loss: 0.5180 - val_u2net_output_sup3_activation_loss: 0.5909 - val_u2net_output_sup4_activation_loss: 0.6080 - val_u2net_output_sup5_activation_loss: 0.6204 - val_u2net_output_final_activation_loss: 0.8080 - val_u2net_output_sup0_activation_dice_coef: 0.4554 - val_u2net_output_sup0_activation_accuracy: 0.9848 - val_u2net_output_sup0_activation_mse: 0.0116 - val_u2net_output_sup1_activation_dice_coef: 0.3345 - val_u2net_output_sup1_activation_accuracy: 0.9838 - val_u2net_output_sup1_activation_mse: 0.0138 - val_u2net_output_sup2_activation_dice_coef: 0.0513 - val_u2net_output_sup2_activation_accuracy: 0.9194 - val_u2net_output_sup2_activation_mse: 0.1714 - val_u2net_output_sup3_activation_dice_coef: 0.0442 - val_u2net_output_sup3_activation_accuracy: 0.9621 - val_u2net_output_sup3_activation_mse: 0.2031 - val_u2net_output_sup4_activation_dice_coef: 0.0433 - val_u2net_output_sup4_activation_accuracy: 0.9732 - val_u2net_output_sup4_activation_mse: 0.2095 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9749 - val_u2net_output_sup5_activation_mse: 0.2139 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.0979 - val_u2net_output_final_activation_mse: 0.3070\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2145 - u2net_output_sup0_activation_loss: 0.0387 - u2net_output_sup1_activation_loss: 0.0511 - u2net_output_sup2_activation_loss: 0.5121 - u2net_output_sup3_activation_loss: 0.5874 - u2net_output_sup4_activation_loss: 0.6055 - u2net_output_sup5_activation_loss: 0.6182 - u2net_output_final_activation_loss: 0.8015 - u2net_output_sup0_activation_dice_coef: 0.5062 - u2net_output_sup0_activation_accuracy: 0.9833 - u2net_output_sup0_activation_mse: 0.0101 - u2net_output_sup1_activation_dice_coef: 0.3928 - u2net_output_sup1_activation_accuracy: 0.9824 - u2net_output_sup1_activation_mse: 0.0117 - u2net_output_sup2_activation_dice_coef: 0.0534 - u2net_output_sup2_activation_accuracy: 0.9182 - u2net_output_sup2_activation_mse: 0.1685 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9608 - u2net_output_sup3_activation_mse: 0.2008 - u2net_output_sup4_activation_dice_coef: 0.0425 - u2net_output_sup4_activation_accuracy: 0.9718 - u2net_output_sup4_activation_mse: 0.2076 - u2net_output_sup5_activation_dice_coef: 0.0419 - u2net_output_sup5_activation_accuracy: 0.9734 - u2net_output_sup5_activation_mse: 0.2121 - u2net_output_final_activation_dice_coef: 0.0415 - u2net_output_final_activation_accuracy: 0.0947 - u2net_output_final_activation_mse: 0.3031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.2145 - u2net_output_sup0_activation_loss: 0.0387 - u2net_output_sup1_activation_loss: 0.0511 - u2net_output_sup2_activation_loss: 0.5121 - u2net_output_sup3_activation_loss: 0.5874 - u2net_output_sup4_activation_loss: 0.6055 - u2net_output_sup5_activation_loss: 0.6182 - u2net_output_final_activation_loss: 0.8015 - u2net_output_sup0_activation_dice_coef: 0.5062 - u2net_output_sup0_activation_accuracy: 0.9833 - u2net_output_sup0_activation_mse: 0.0101 - u2net_output_sup1_activation_dice_coef: 0.3928 - u2net_output_sup1_activation_accuracy: 0.9824 - u2net_output_sup1_activation_mse: 0.0117 - u2net_output_sup2_activation_dice_coef: 0.0534 - u2net_output_sup2_activation_accuracy: 0.9182 - u2net_output_sup2_activation_mse: 0.1685 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9608 - u2net_output_sup3_activation_mse: 0.2008 - u2net_output_sup4_activation_dice_coef: 0.0425 - u2net_output_sup4_activation_accuracy: 0.9718 - u2net_output_sup4_activation_mse: 0.2076 - u2net_output_sup5_activation_dice_coef: 0.0419 - u2net_output_sup5_activation_accuracy: 0.9734 - u2net_output_sup5_activation_mse: 0.2121 - u2net_output_final_activation_dice_coef: 0.0415 - u2net_output_final_activation_accuracy: 0.0947 - u2net_output_final_activation_mse: 0.3031 - val_loss: 3.2018 - val_u2net_output_sup0_activation_loss: 0.0405 - val_u2net_output_sup1_activation_loss: 0.0552 - val_u2net_output_sup2_activation_loss: 0.5076 - val_u2net_output_sup3_activation_loss: 0.5847 - val_u2net_output_sup4_activation_loss: 0.6032 - val_u2net_output_sup5_activation_loss: 0.6162 - val_u2net_output_final_activation_loss: 0.7945 - val_u2net_output_sup0_activation_dice_coef: 0.4586 - val_u2net_output_sup0_activation_accuracy: 0.9847 - val_u2net_output_sup0_activation_mse: 0.0115 - val_u2net_output_sup1_activation_dice_coef: 0.3333 - val_u2net_output_sup1_activation_accuracy: 0.9836 - val_u2net_output_sup1_activation_mse: 0.0133 - val_u2net_output_sup2_activation_dice_coef: 0.0536 - val_u2net_output_sup2_activation_accuracy: 0.9199 - val_u2net_output_sup2_activation_mse: 0.1676 - val_u2net_output_sup3_activation_dice_coef: 0.0459 - val_u2net_output_sup3_activation_accuracy: 0.9624 - val_u2net_output_sup3_activation_mse: 0.2003 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9740 - val_u2net_output_sup4_activation_mse: 0.2072 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9750 - val_u2net_output_sup5_activation_mse: 0.2118 - val_u2net_output_final_activation_dice_coef: 0.0430 - val_u2net_output_final_activation_accuracy: 0.0965 - val_u2net_output_final_activation_mse: 0.3004\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1623 - u2net_output_sup0_activation_loss: 0.0338 - u2net_output_sup1_activation_loss: 0.0449 - u2net_output_sup2_activation_loss: 0.5010 - u2net_output_sup3_activation_loss: 0.5812 - u2net_output_sup4_activation_loss: 0.6004 - u2net_output_sup5_activation_loss: 0.6137 - u2net_output_final_activation_loss: 0.7872 - u2net_output_sup0_activation_dice_coef: 0.5387 - u2net_output_sup0_activation_accuracy: 0.9849 - u2net_output_sup0_activation_mse: 0.0088 - u2net_output_sup1_activation_dice_coef: 0.4230 - u2net_output_sup1_activation_accuracy: 0.9839 - u2net_output_sup1_activation_mse: 0.0103 - u2net_output_sup2_activation_dice_coef: 0.0524 - u2net_output_sup2_activation_accuracy: 0.9195 - u2net_output_sup2_activation_mse: 0.1645 - u2net_output_sup3_activation_dice_coef: 0.0425 - u2net_output_sup3_activation_accuracy: 0.9620 - u2net_output_sup3_activation_mse: 0.1982 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9756 - u2net_output_sup4_activation_mse: 0.2052 - u2net_output_sup5_activation_dice_coef: 0.0400 - u2net_output_sup5_activation_accuracy: 0.9747 - u2net_output_sup5_activation_mse: 0.2099 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.0946 - u2net_output_final_activation_mse: 0.2961"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.1623 - u2net_output_sup0_activation_loss: 0.0338 - u2net_output_sup1_activation_loss: 0.0449 - u2net_output_sup2_activation_loss: 0.5010 - u2net_output_sup3_activation_loss: 0.5812 - u2net_output_sup4_activation_loss: 0.6004 - u2net_output_sup5_activation_loss: 0.6137 - u2net_output_final_activation_loss: 0.7872 - u2net_output_sup0_activation_dice_coef: 0.5387 - u2net_output_sup0_activation_accuracy: 0.9849 - u2net_output_sup0_activation_mse: 0.0088 - u2net_output_sup1_activation_dice_coef: 0.4230 - u2net_output_sup1_activation_accuracy: 0.9839 - u2net_output_sup1_activation_mse: 0.0103 - u2net_output_sup2_activation_dice_coef: 0.0524 - u2net_output_sup2_activation_accuracy: 0.9195 - u2net_output_sup2_activation_mse: 0.1645 - u2net_output_sup3_activation_dice_coef: 0.0425 - u2net_output_sup3_activation_accuracy: 0.9620 - u2net_output_sup3_activation_mse: 0.1982 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9756 - u2net_output_sup4_activation_mse: 0.2052 - u2net_output_sup5_activation_dice_coef: 0.0400 - u2net_output_sup5_activation_accuracy: 0.9747 - u2net_output_sup5_activation_mse: 0.2099 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.0946 - u2net_output_final_activation_mse: 0.2961 - val_loss: 3.1620 - val_u2net_output_sup0_activation_loss: 0.0426 - val_u2net_output_sup1_activation_loss: 0.0536 - val_u2net_output_sup2_activation_loss: 0.4972 - val_u2net_output_sup3_activation_loss: 0.5788 - val_u2net_output_sup4_activation_loss: 0.5984 - val_u2net_output_sup5_activation_loss: 0.6119 - val_u2net_output_final_activation_loss: 0.7795 - val_u2net_output_sup0_activation_dice_coef: 0.3860 - val_u2net_output_sup0_activation_accuracy: 0.9829 - val_u2net_output_sup0_activation_mse: 0.0124 - val_u2net_output_sup1_activation_dice_coef: 0.3111 - val_u2net_output_sup1_activation_accuracy: 0.9828 - val_u2net_output_sup1_activation_mse: 0.0137 - val_u2net_output_sup2_activation_dice_coef: 0.0541 - val_u2net_output_sup2_activation_accuracy: 0.9199 - val_u2net_output_sup2_activation_mse: 0.1638 - val_u2net_output_sup3_activation_dice_coef: 0.0456 - val_u2net_output_sup3_activation_accuracy: 0.9625 - val_u2net_output_sup3_activation_mse: 0.1977 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.2049 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9753 - val_u2net_output_sup5_activation_mse: 0.2097 - val_u2net_output_final_activation_dice_coef: 0.0428 - val_u2net_output_final_activation_accuracy: 0.0985 - val_u2net_output_final_activation_mse: 0.2930\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1196 - u2net_output_sup0_activation_loss: 0.0326 - u2net_output_sup1_activation_loss: 0.0430 - u2net_output_sup2_activation_loss: 0.4908 - u2net_output_sup3_activation_loss: 0.5753 - u2net_output_sup4_activation_loss: 0.5954 - u2net_output_sup5_activation_loss: 0.6094 - u2net_output_final_activation_loss: 0.7731 - u2net_output_sup0_activation_dice_coef: 0.5335 - u2net_output_sup0_activation_accuracy: 0.9855 - u2net_output_sup0_activation_mse: 0.0085 - u2net_output_sup1_activation_dice_coef: 0.4234 - u2net_output_sup1_activation_accuracy: 0.9844 - u2net_output_sup1_activation_mse: 0.0100 - u2net_output_sup2_activation_dice_coef: 0.0525 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1608 - u2net_output_sup3_activation_dice_coef: 0.0419 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.1956 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9772 - u2net_output_sup4_activation_mse: 0.2028 - u2net_output_sup5_activation_dice_coef: 0.0392 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.2078 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.1023 - u2net_output_final_activation_mse: 0.2892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.1196 - u2net_output_sup0_activation_loss: 0.0326 - u2net_output_sup1_activation_loss: 0.0430 - u2net_output_sup2_activation_loss: 0.4908 - u2net_output_sup3_activation_loss: 0.5753 - u2net_output_sup4_activation_loss: 0.5954 - u2net_output_sup5_activation_loss: 0.6094 - u2net_output_final_activation_loss: 0.7731 - u2net_output_sup0_activation_dice_coef: 0.5335 - u2net_output_sup0_activation_accuracy: 0.9855 - u2net_output_sup0_activation_mse: 0.0085 - u2net_output_sup1_activation_dice_coef: 0.4234 - u2net_output_sup1_activation_accuracy: 0.9844 - u2net_output_sup1_activation_mse: 0.0100 - u2net_output_sup2_activation_dice_coef: 0.0525 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1608 - u2net_output_sup3_activation_dice_coef: 0.0419 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.1956 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9772 - u2net_output_sup4_activation_mse: 0.2028 - u2net_output_sup5_activation_dice_coef: 0.0392 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.2078 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.1023 - u2net_output_final_activation_mse: 0.2892 - val_loss: 3.1297 - val_u2net_output_sup0_activation_loss: 0.0443 - val_u2net_output_sup1_activation_loss: 0.0578 - val_u2net_output_sup2_activation_loss: 0.4880 - val_u2net_output_sup3_activation_loss: 0.5732 - val_u2net_output_sup4_activation_loss: 0.5934 - val_u2net_output_sup5_activation_loss: 0.6077 - val_u2net_output_final_activation_loss: 0.7653 - val_u2net_output_sup0_activation_dice_coef: 0.4945 - val_u2net_output_sup0_activation_accuracy: 0.9842 - val_u2net_output_sup0_activation_mse: 0.0122 - val_u2net_output_sup1_activation_dice_coef: 0.3735 - val_u2net_output_sup1_activation_accuracy: 0.9823 - val_u2net_output_sup1_activation_mse: 0.0143 - val_u2net_output_sup2_activation_dice_coef: 0.0560 - val_u2net_output_sup2_activation_accuracy: 0.9201 - val_u2net_output_sup2_activation_mse: 0.1605 - val_u2net_output_sup3_activation_dice_coef: 0.0462 - val_u2net_output_sup3_activation_accuracy: 0.9625 - val_u2net_output_sup3_activation_mse: 0.1953 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.2025 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9758 - val_u2net_output_sup5_activation_mse: 0.2076 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.1073 - val_u2net_output_final_activation_mse: 0.2859\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.0862 - u2net_output_sup0_activation_loss: 0.0347 - u2net_output_sup1_activation_loss: 0.0448 - u2net_output_sup2_activation_loss: 0.4816 - u2net_output_sup3_activation_loss: 0.5698 - u2net_output_sup4_activation_loss: 0.5908 - u2net_output_sup5_activation_loss: 0.6053 - u2net_output_final_activation_loss: 0.7592 - u2net_output_sup0_activation_dice_coef: 0.5284 - u2net_output_sup0_activation_accuracy: 0.9848 - u2net_output_sup0_activation_mse: 0.0090 - u2net_output_sup1_activation_dice_coef: 0.4240 - u2net_output_sup1_activation_accuracy: 0.9837 - u2net_output_sup1_activation_mse: 0.0105 - u2net_output_sup2_activation_dice_coef: 0.0538 - u2net_output_sup2_activation_accuracy: 0.9195 - u2net_output_sup2_activation_mse: 0.1575 - u2net_output_sup3_activation_dice_coef: 0.0427 - u2net_output_sup3_activation_accuracy: 0.9621 - u2net_output_sup3_activation_mse: 0.1931 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9766 - u2net_output_sup4_activation_mse: 0.2005 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9755 - u2net_output_sup5_activation_mse: 0.2058 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.1057 - u2net_output_final_activation_mse: 0.2822"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.0862 - u2net_output_sup0_activation_loss: 0.0347 - u2net_output_sup1_activation_loss: 0.0448 - u2net_output_sup2_activation_loss: 0.4816 - u2net_output_sup3_activation_loss: 0.5698 - u2net_output_sup4_activation_loss: 0.5908 - u2net_output_sup5_activation_loss: 0.6053 - u2net_output_final_activation_loss: 0.7592 - u2net_output_sup0_activation_dice_coef: 0.5284 - u2net_output_sup0_activation_accuracy: 0.9848 - u2net_output_sup0_activation_mse: 0.0090 - u2net_output_sup1_activation_dice_coef: 0.4240 - u2net_output_sup1_activation_accuracy: 0.9837 - u2net_output_sup1_activation_mse: 0.0105 - u2net_output_sup2_activation_dice_coef: 0.0538 - u2net_output_sup2_activation_accuracy: 0.9195 - u2net_output_sup2_activation_mse: 0.1575 - u2net_output_sup3_activation_dice_coef: 0.0427 - u2net_output_sup3_activation_accuracy: 0.9621 - u2net_output_sup3_activation_mse: 0.1931 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9766 - u2net_output_sup4_activation_mse: 0.2005 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9755 - u2net_output_sup5_activation_mse: 0.2058 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.1057 - u2net_output_final_activation_mse: 0.2822 - val_loss: 3.0824 - val_u2net_output_sup0_activation_loss: 0.0393 - val_u2net_output_sup1_activation_loss: 0.0532 - val_u2net_output_sup2_activation_loss: 0.4784 - val_u2net_output_sup3_activation_loss: 0.5674 - val_u2net_output_sup4_activation_loss: 0.5887 - val_u2net_output_sup5_activation_loss: 0.6036 - val_u2net_output_final_activation_loss: 0.7518 - val_u2net_output_sup0_activation_dice_coef: 0.4761 - val_u2net_output_sup0_activation_accuracy: 0.9852 - val_u2net_output_sup0_activation_mse: 0.0111 - val_u2net_output_sup1_activation_dice_coef: 0.3535 - val_u2net_output_sup1_activation_accuracy: 0.9842 - val_u2net_output_sup1_activation_mse: 0.0131 - val_u2net_output_sup2_activation_dice_coef: 0.0582 - val_u2net_output_sup2_activation_accuracy: 0.9203 - val_u2net_output_sup2_activation_mse: 0.1570 - val_u2net_output_sup3_activation_dice_coef: 0.0459 - val_u2net_output_sup3_activation_accuracy: 0.9626 - val_u2net_output_sup3_activation_mse: 0.1928 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.2003 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9758 - val_u2net_output_sup5_activation_mse: 0.2056 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.1104 - val_u2net_output_final_activation_mse: 0.2792\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.0414 - u2net_output_sup0_activation_loss: 0.0321 - u2net_output_sup1_activation_loss: 0.0412 - u2net_output_sup2_activation_loss: 0.4716 - u2net_output_sup3_activation_loss: 0.5639 - u2net_output_sup4_activation_loss: 0.5859 - u2net_output_sup5_activation_loss: 0.6010 - u2net_output_final_activation_loss: 0.7459 - u2net_output_sup0_activation_dice_coef: 0.5322 - u2net_output_sup0_activation_accuracy: 0.9857 - u2net_output_sup0_activation_mse: 0.0084 - u2net_output_sup1_activation_dice_coef: 0.4306 - u2net_output_sup1_activation_accuracy: 0.9847 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0538 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1540 - u2net_output_sup3_activation_dice_coef: 0.0421 - u2net_output_sup3_activation_accuracy: 0.9630 - u2net_output_sup3_activation_mse: 0.1906 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9775 - u2net_output_sup4_activation_mse: 0.1983 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9764 - u2net_output_sup5_activation_mse: 0.2037 - u2net_output_final_activation_dice_coef: 0.0386 - u2net_output_final_activation_accuracy: 0.1134 - u2net_output_final_activation_mse: 0.2757"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.0414 - u2net_output_sup0_activation_loss: 0.0321 - u2net_output_sup1_activation_loss: 0.0412 - u2net_output_sup2_activation_loss: 0.4716 - u2net_output_sup3_activation_loss: 0.5639 - u2net_output_sup4_activation_loss: 0.5859 - u2net_output_sup5_activation_loss: 0.6010 - u2net_output_final_activation_loss: 0.7459 - u2net_output_sup0_activation_dice_coef: 0.5322 - u2net_output_sup0_activation_accuracy: 0.9857 - u2net_output_sup0_activation_mse: 0.0084 - u2net_output_sup1_activation_dice_coef: 0.4306 - u2net_output_sup1_activation_accuracy: 0.9847 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0538 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1540 - u2net_output_sup3_activation_dice_coef: 0.0421 - u2net_output_sup3_activation_accuracy: 0.9630 - u2net_output_sup3_activation_mse: 0.1906 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9775 - u2net_output_sup4_activation_mse: 0.1983 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9764 - u2net_output_sup5_activation_mse: 0.2037 - u2net_output_final_activation_dice_coef: 0.0386 - u2net_output_final_activation_accuracy: 0.1134 - u2net_output_final_activation_mse: 0.2757 - val_loss: 3.0650 - val_u2net_output_sup0_activation_loss: 0.0516 - val_u2net_output_sup1_activation_loss: 0.0596 - val_u2net_output_sup2_activation_loss: 0.4692 - val_u2net_output_sup3_activation_loss: 0.5626 - val_u2net_output_sup4_activation_loss: 0.5844 - val_u2net_output_sup5_activation_loss: 0.5994 - val_u2net_output_final_activation_loss: 0.7382 - val_u2net_output_sup0_activation_dice_coef: 0.4596 - val_u2net_output_sup0_activation_accuracy: 0.9806 - val_u2net_output_sup0_activation_mse: 0.0147 - val_u2net_output_sup1_activation_dice_coef: 0.3867 - val_u2net_output_sup1_activation_accuracy: 0.9809 - val_u2net_output_sup1_activation_mse: 0.0157 - val_u2net_output_sup2_activation_dice_coef: 0.0605 - val_u2net_output_sup2_activation_accuracy: 0.9202 - val_u2net_output_sup2_activation_mse: 0.1538 - val_u2net_output_sup3_activation_dice_coef: 0.0472 - val_u2net_output_sup3_activation_accuracy: 0.9624 - val_u2net_output_sup3_activation_mse: 0.1905 - val_u2net_output_sup4_activation_dice_coef: 0.0439 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1982 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9758 - val_u2net_output_sup5_activation_mse: 0.2036 - val_u2net_output_final_activation_dice_coef: 0.0422 - val_u2net_output_final_activation_accuracy: 0.1209 - val_u2net_output_final_activation_mse: 0.2725\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.0042 - u2net_output_sup0_activation_loss: 0.0324 - u2net_output_sup1_activation_loss: 0.0406 - u2net_output_sup2_activation_loss: 0.4622 - u2net_output_sup3_activation_loss: 0.5582 - u2net_output_sup4_activation_loss: 0.5814 - u2net_output_sup5_activation_loss: 0.5967 - u2net_output_final_activation_loss: 0.7328 - u2net_output_sup0_activation_dice_coef: 0.5286 - u2net_output_sup0_activation_accuracy: 0.9856 - u2net_output_sup0_activation_mse: 0.0085 - u2net_output_sup1_activation_dice_coef: 0.4353 - u2net_output_sup1_activation_accuracy: 0.9848 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0545 - u2net_output_sup2_activation_accuracy: 0.9206 - u2net_output_sup2_activation_mse: 0.1508 - u2net_output_sup3_activation_dice_coef: 0.0421 - u2net_output_sup3_activation_accuracy: 0.9633 - u2net_output_sup3_activation_mse: 0.1882 - u2net_output_sup4_activation_dice_coef: 0.0399 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1961 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9767 - u2net_output_sup5_activation_mse: 0.2016 - u2net_output_final_activation_dice_coef: 0.0383 - u2net_output_final_activation_accuracy: 0.1187 - u2net_output_final_activation_mse: 0.2691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 3.0042 - u2net_output_sup0_activation_loss: 0.0324 - u2net_output_sup1_activation_loss: 0.0406 - u2net_output_sup2_activation_loss: 0.4622 - u2net_output_sup3_activation_loss: 0.5582 - u2net_output_sup4_activation_loss: 0.5814 - u2net_output_sup5_activation_loss: 0.5967 - u2net_output_final_activation_loss: 0.7328 - u2net_output_sup0_activation_dice_coef: 0.5286 - u2net_output_sup0_activation_accuracy: 0.9856 - u2net_output_sup0_activation_mse: 0.0085 - u2net_output_sup1_activation_dice_coef: 0.4353 - u2net_output_sup1_activation_accuracy: 0.9848 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0545 - u2net_output_sup2_activation_accuracy: 0.9206 - u2net_output_sup2_activation_mse: 0.1508 - u2net_output_sup3_activation_dice_coef: 0.0421 - u2net_output_sup3_activation_accuracy: 0.9633 - u2net_output_sup3_activation_mse: 0.1882 - u2net_output_sup4_activation_dice_coef: 0.0399 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1961 - u2net_output_sup5_activation_dice_coef: 0.0389 - u2net_output_sup5_activation_accuracy: 0.9767 - u2net_output_sup5_activation_mse: 0.2016 - u2net_output_final_activation_dice_coef: 0.0383 - u2net_output_final_activation_accuracy: 0.1187 - u2net_output_final_activation_mse: 0.2691 - val_loss: 3.0059 - val_u2net_output_sup0_activation_loss: 0.0373 - val_u2net_output_sup1_activation_loss: 0.0486 - val_u2net_output_sup2_activation_loss: 0.4603 - val_u2net_output_sup3_activation_loss: 0.5583 - val_u2net_output_sup4_activation_loss: 0.5800 - val_u2net_output_sup5_activation_loss: 0.5953 - val_u2net_output_final_activation_loss: 0.7261 - val_u2net_output_sup0_activation_dice_coef: 0.4880 - val_u2net_output_sup0_activation_accuracy: 0.9855 - val_u2net_output_sup0_activation_mse: 0.0108 - val_u2net_output_sup1_activation_dice_coef: 0.3823 - val_u2net_output_sup1_activation_accuracy: 0.9843 - val_u2net_output_sup1_activation_mse: 0.0124 - val_u2net_output_sup2_activation_dice_coef: 0.0550 - val_u2net_output_sup2_activation_accuracy: 0.9197 - val_u2net_output_sup2_activation_mse: 0.1508 - val_u2net_output_sup3_activation_dice_coef: 0.0437 - val_u2net_output_sup3_activation_accuracy: 0.9620 - val_u2net_output_sup3_activation_mse: 0.1886 - val_u2net_output_sup4_activation_dice_coef: 0.0435 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1961 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9758 - val_u2net_output_sup5_activation_mse: 0.2016 - val_u2net_output_final_activation_dice_coef: 0.0422 - val_u2net_output_final_activation_accuracy: 0.1248 - val_u2net_output_final_activation_mse: 0.2665\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9704 - u2net_output_sup0_activation_loss: 0.0331 - u2net_output_sup1_activation_loss: 0.0408 - u2net_output_sup2_activation_loss: 0.4534 - u2net_output_sup3_activation_loss: 0.5529 - u2net_output_sup4_activation_loss: 0.5773 - u2net_output_sup5_activation_loss: 0.5928 - u2net_output_final_activation_loss: 0.7201 - u2net_output_sup0_activation_dice_coef: 0.5483 - u2net_output_sup0_activation_accuracy: 0.9854 - u2net_output_sup0_activation_mse: 0.0086 - u2net_output_sup1_activation_dice_coef: 0.4573 - u2net_output_sup1_activation_accuracy: 0.9846 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0561 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1478 - u2net_output_sup3_activation_dice_coef: 0.0426 - u2net_output_sup3_activation_accuracy: 0.9625 - u2net_output_sup3_activation_mse: 0.1859 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1942 - u2net_output_sup5_activation_dice_coef: 0.0393 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1997 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.1237 - u2net_output_final_activation_mse: 0.2628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.9704 - u2net_output_sup0_activation_loss: 0.0331 - u2net_output_sup1_activation_loss: 0.0408 - u2net_output_sup2_activation_loss: 0.4534 - u2net_output_sup3_activation_loss: 0.5529 - u2net_output_sup4_activation_loss: 0.5773 - u2net_output_sup5_activation_loss: 0.5928 - u2net_output_final_activation_loss: 0.7201 - u2net_output_sup0_activation_dice_coef: 0.5483 - u2net_output_sup0_activation_accuracy: 0.9854 - u2net_output_sup0_activation_mse: 0.0086 - u2net_output_sup1_activation_dice_coef: 0.4573 - u2net_output_sup1_activation_accuracy: 0.9846 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0561 - u2net_output_sup2_activation_accuracy: 0.9201 - u2net_output_sup2_activation_mse: 0.1478 - u2net_output_sup3_activation_dice_coef: 0.0426 - u2net_output_sup3_activation_accuracy: 0.9625 - u2net_output_sup3_activation_mse: 0.1859 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1942 - u2net_output_sup5_activation_dice_coef: 0.0393 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1997 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.1237 - u2net_output_final_activation_mse: 0.2628 - val_loss: 2.9759 - val_u2net_output_sup0_activation_loss: 0.0405 - val_u2net_output_sup1_activation_loss: 0.0522 - val_u2net_output_sup2_activation_loss: 0.4517 - val_u2net_output_sup3_activation_loss: 0.5511 - val_u2net_output_sup4_activation_loss: 0.5759 - val_u2net_output_sup5_activation_loss: 0.5912 - val_u2net_output_final_activation_loss: 0.7132 - val_u2net_output_sup0_activation_dice_coef: 0.4916 - val_u2net_output_sup0_activation_accuracy: 0.9850 - val_u2net_output_sup0_activation_mse: 0.0114 - val_u2net_output_sup1_activation_dice_coef: 0.3905 - val_u2net_output_sup1_activation_accuracy: 0.9841 - val_u2net_output_sup1_activation_mse: 0.0131 - val_u2net_output_sup2_activation_dice_coef: 0.0620 - val_u2net_output_sup2_activation_accuracy: 0.9205 - val_u2net_output_sup2_activation_mse: 0.1478 - val_u2net_output_sup3_activation_dice_coef: 0.0462 - val_u2net_output_sup3_activation_accuracy: 0.9626 - val_u2net_output_sup3_activation_mse: 0.1857 - val_u2net_output_sup4_activation_dice_coef: 0.0440 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1942 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1996 - val_u2net_output_final_activation_dice_coef: 0.0423 - val_u2net_output_final_activation_accuracy: 0.1347 - val_u2net_output_final_activation_mse: 0.2600\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9325 - u2net_output_sup0_activation_loss: 0.0315 - u2net_output_sup1_activation_loss: 0.0391 - u2net_output_sup2_activation_loss: 0.4446 - u2net_output_sup3_activation_loss: 0.5474 - u2net_output_sup4_activation_loss: 0.5733 - u2net_output_sup5_activation_loss: 0.5888 - u2net_output_final_activation_loss: 0.7077 - u2net_output_sup0_activation_dice_coef: 0.5600 - u2net_output_sup0_activation_accuracy: 0.9858 - u2net_output_sup0_activation_mse: 0.0082 - u2net_output_sup1_activation_dice_coef: 0.4706 - u2net_output_sup1_activation_accuracy: 0.9848 - u2net_output_sup1_activation_mse: 0.0094 - u2net_output_sup2_activation_dice_coef: 0.0590 - u2net_output_sup2_activation_accuracy: 0.9200 - u2net_output_sup2_activation_mse: 0.1449 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9623 - u2net_output_sup3_activation_mse: 0.1835 - u2net_output_sup4_activation_dice_coef: 0.0415 - u2net_output_sup4_activation_accuracy: 0.9767 - u2net_output_sup4_activation_mse: 0.1923 - u2net_output_sup5_activation_dice_coef: 0.0404 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1977 - u2net_output_final_activation_dice_coef: 0.0397 - u2net_output_final_activation_accuracy: 0.1827 - u2net_output_final_activation_mse: 0.2566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.9325 - u2net_output_sup0_activation_loss: 0.0315 - u2net_output_sup1_activation_loss: 0.0391 - u2net_output_sup2_activation_loss: 0.4446 - u2net_output_sup3_activation_loss: 0.5474 - u2net_output_sup4_activation_loss: 0.5733 - u2net_output_sup5_activation_loss: 0.5888 - u2net_output_final_activation_loss: 0.7077 - u2net_output_sup0_activation_dice_coef: 0.5600 - u2net_output_sup0_activation_accuracy: 0.9858 - u2net_output_sup0_activation_mse: 0.0082 - u2net_output_sup1_activation_dice_coef: 0.4706 - u2net_output_sup1_activation_accuracy: 0.9848 - u2net_output_sup1_activation_mse: 0.0094 - u2net_output_sup2_activation_dice_coef: 0.0590 - u2net_output_sup2_activation_accuracy: 0.9200 - u2net_output_sup2_activation_mse: 0.1449 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9623 - u2net_output_sup3_activation_mse: 0.1835 - u2net_output_sup4_activation_dice_coef: 0.0415 - u2net_output_sup4_activation_accuracy: 0.9767 - u2net_output_sup4_activation_mse: 0.1923 - u2net_output_sup5_activation_dice_coef: 0.0404 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1977 - u2net_output_final_activation_dice_coef: 0.0397 - u2net_output_final_activation_accuracy: 0.1827 - u2net_output_final_activation_mse: 0.2566 - val_loss: 2.9477 - val_u2net_output_sup0_activation_loss: 0.0429 - val_u2net_output_sup1_activation_loss: 0.0553 - val_u2net_output_sup2_activation_loss: 0.4427 - val_u2net_output_sup3_activation_loss: 0.5459 - val_u2net_output_sup4_activation_loss: 0.5719 - val_u2net_output_sup5_activation_loss: 0.5872 - val_u2net_output_final_activation_loss: 0.7018 - val_u2net_output_sup0_activation_dice_coef: 0.4440 - val_u2net_output_sup0_activation_accuracy: 0.9841 - val_u2net_output_sup0_activation_mse: 0.0122 - val_u2net_output_sup1_activation_dice_coef: 0.3470 - val_u2net_output_sup1_activation_accuracy: 0.9823 - val_u2net_output_sup1_activation_mse: 0.0138 - val_u2net_output_sup2_activation_dice_coef: 0.0580 - val_u2net_output_sup2_activation_accuracy: 0.9201 - val_u2net_output_sup2_activation_mse: 0.1449 - val_u2net_output_sup3_activation_dice_coef: 0.0452 - val_u2net_output_sup3_activation_accuracy: 0.9623 - val_u2net_output_sup3_activation_mse: 0.1834 - val_u2net_output_sup4_activation_dice_coef: 0.0438 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1923 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1976 - val_u2net_output_final_activation_dice_coef: 0.0428 - val_u2net_output_final_activation_accuracy: 0.3169 - val_u2net_output_final_activation_mse: 0.2544\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.8954 - u2net_output_sup0_activation_loss: 0.0304 - u2net_output_sup1_activation_loss: 0.0377 - u2net_output_sup2_activation_loss: 0.4358 - u2net_output_sup3_activation_loss: 0.5420 - u2net_output_sup4_activation_loss: 0.5692 - u2net_output_sup5_activation_loss: 0.5846 - u2net_output_final_activation_loss: 0.6956 - u2net_output_sup0_activation_dice_coef: 0.5680 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4812 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0587 - u2net_output_sup2_activation_accuracy: 0.9203 - u2net_output_sup2_activation_mse: 0.1420 - u2net_output_sup3_activation_dice_coef: 0.0432 - u2net_output_sup3_activation_accuracy: 0.9625 - u2net_output_sup3_activation_mse: 0.1812 - u2net_output_sup4_activation_dice_coef: 0.0405 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1903 - u2net_output_sup5_activation_dice_coef: 0.0394 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1957 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.3598 - u2net_output_final_activation_mse: 0.2506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.8954 - u2net_output_sup0_activation_loss: 0.0304 - u2net_output_sup1_activation_loss: 0.0377 - u2net_output_sup2_activation_loss: 0.4358 - u2net_output_sup3_activation_loss: 0.5420 - u2net_output_sup4_activation_loss: 0.5692 - u2net_output_sup5_activation_loss: 0.5846 - u2net_output_final_activation_loss: 0.6956 - u2net_output_sup0_activation_dice_coef: 0.5680 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4812 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0587 - u2net_output_sup2_activation_accuracy: 0.9203 - u2net_output_sup2_activation_mse: 0.1420 - u2net_output_sup3_activation_dice_coef: 0.0432 - u2net_output_sup3_activation_accuracy: 0.9625 - u2net_output_sup3_activation_mse: 0.1812 - u2net_output_sup4_activation_dice_coef: 0.0405 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1903 - u2net_output_sup5_activation_dice_coef: 0.0394 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1957 - u2net_output_final_activation_dice_coef: 0.0387 - u2net_output_final_activation_accuracy: 0.3598 - u2net_output_final_activation_mse: 0.2506 - val_loss: 2.9004 - val_u2net_output_sup0_activation_loss: 0.0381 - val_u2net_output_sup1_activation_loss: 0.0454 - val_u2net_output_sup2_activation_loss: 0.4348 - val_u2net_output_sup3_activation_loss: 0.5406 - val_u2net_output_sup4_activation_loss: 0.5683 - val_u2net_output_sup5_activation_loss: 0.5832 - val_u2net_output_final_activation_loss: 0.6900 - val_u2net_output_sup0_activation_dice_coef: 0.5284 - val_u2net_output_sup0_activation_accuracy: 0.9853 - val_u2net_output_sup0_activation_mse: 0.0110 - val_u2net_output_sup1_activation_dice_coef: 0.4265 - val_u2net_output_sup1_activation_accuracy: 0.9839 - val_u2net_output_sup1_activation_mse: 0.0122 - val_u2net_output_sup2_activation_dice_coef: 0.0606 - val_u2net_output_sup2_activation_accuracy: 0.9202 - val_u2net_output_sup2_activation_mse: 0.1424 - val_u2net_output_sup3_activation_dice_coef: 0.0470 - val_u2net_output_sup3_activation_accuracy: 0.9626 - val_u2net_output_sup3_activation_mse: 0.1811 - val_u2net_output_sup4_activation_dice_coef: 0.0441 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1905 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1956 - val_u2net_output_final_activation_dice_coef: 0.0425 - val_u2net_output_final_activation_accuracy: 0.4101 - val_u2net_output_final_activation_mse: 0.2485\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.8635 - u2net_output_sup0_activation_loss: 0.0312 - u2net_output_sup1_activation_loss: 0.0382 - u2net_output_sup2_activation_loss: 0.4276 - u2net_output_sup3_activation_loss: 0.5366 - u2net_output_sup4_activation_loss: 0.5654 - u2net_output_sup5_activation_loss: 0.5806 - u2net_output_final_activation_loss: 0.6839 - u2net_output_sup0_activation_dice_coef: 0.5646 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0081 - u2net_output_sup1_activation_dice_coef: 0.4787 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0093 - u2net_output_sup2_activation_dice_coef: 0.0604 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1393 - u2net_output_sup3_activation_dice_coef: 0.0439 - u2net_output_sup3_activation_accuracy: 0.9626 - u2net_output_sup3_activation_mse: 0.1789 - u2net_output_sup4_activation_dice_coef: 0.0409 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1885 - u2net_output_sup5_activation_dice_coef: 0.0398 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1938 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.4827 - u2net_output_final_activation_mse: 0.2448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.8635 - u2net_output_sup0_activation_loss: 0.0312 - u2net_output_sup1_activation_loss: 0.0382 - u2net_output_sup2_activation_loss: 0.4276 - u2net_output_sup3_activation_loss: 0.5366 - u2net_output_sup4_activation_loss: 0.5654 - u2net_output_sup5_activation_loss: 0.5806 - u2net_output_final_activation_loss: 0.6839 - u2net_output_sup0_activation_dice_coef: 0.5646 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0081 - u2net_output_sup1_activation_dice_coef: 0.4787 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0093 - u2net_output_sup2_activation_dice_coef: 0.0604 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1393 - u2net_output_sup3_activation_dice_coef: 0.0439 - u2net_output_sup3_activation_accuracy: 0.9626 - u2net_output_sup3_activation_mse: 0.1789 - u2net_output_sup4_activation_dice_coef: 0.0409 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1885 - u2net_output_sup5_activation_dice_coef: 0.0398 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1938 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.4827 - u2net_output_final_activation_mse: 0.2448 - val_loss: 2.8850 - val_u2net_output_sup0_activation_loss: 0.0439 - val_u2net_output_sup1_activation_loss: 0.0593 - val_u2net_output_sup2_activation_loss: 0.4267 - val_u2net_output_sup3_activation_loss: 0.5351 - val_u2net_output_sup4_activation_loss: 0.5644 - val_u2net_output_sup5_activation_loss: 0.5792 - val_u2net_output_final_activation_loss: 0.6763 - val_u2net_output_sup0_activation_dice_coef: 0.4927 - val_u2net_output_sup0_activation_accuracy: 0.9829 - val_u2net_output_sup0_activation_mse: 0.0126 - val_u2net_output_sup1_activation_dice_coef: 0.3898 - val_u2net_output_sup1_activation_accuracy: 0.9792 - val_u2net_output_sup1_activation_mse: 0.0164 - val_u2net_output_sup2_activation_dice_coef: 0.0661 - val_u2net_output_sup2_activation_accuracy: 0.9202 - val_u2net_output_sup2_activation_mse: 0.1397 - val_u2net_output_sup3_activation_dice_coef: 0.0476 - val_u2net_output_sup3_activation_accuracy: 0.9627 - val_u2net_output_sup3_activation_mse: 0.1789 - val_u2net_output_sup4_activation_dice_coef: 0.0442 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1886 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1937 - val_u2net_output_final_activation_dice_coef: 0.0419 - val_u2net_output_final_activation_accuracy: 0.5485 - val_u2net_output_final_activation_mse: 0.2416\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.8349 - u2net_output_sup0_activation_loss: 0.0322 - u2net_output_sup1_activation_loss: 0.0395 - u2net_output_sup2_activation_loss: 0.4203 - u2net_output_sup3_activation_loss: 0.5317 - u2net_output_sup4_activation_loss: 0.5618 - u2net_output_sup5_activation_loss: 0.5769 - u2net_output_final_activation_loss: 0.6725 - u2net_output_sup0_activation_dice_coef: 0.5642 - u2net_output_sup0_activation_accuracy: 0.9854 - u2net_output_sup0_activation_mse: 0.0084 - u2net_output_sup1_activation_dice_coef: 0.4759 - u2net_output_sup1_activation_accuracy: 0.9842 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0634 - u2net_output_sup2_activation_accuracy: 0.9196 - u2net_output_sup2_activation_mse: 0.1369 - u2net_output_sup3_activation_dice_coef: 0.0463 - u2net_output_sup3_activation_accuracy: 0.9618 - u2net_output_sup3_activation_mse: 0.1768 - u2net_output_sup4_activation_dice_coef: 0.0431 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1867 - u2net_output_sup5_activation_dice_coef: 0.0419 - u2net_output_sup5_activation_accuracy: 0.9750 - u2net_output_sup5_activation_mse: 0.1919 - u2net_output_final_activation_dice_coef: 0.0412 - u2net_output_final_activation_accuracy: 0.6606 - u2net_output_final_activation_mse: 0.2390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.8349 - u2net_output_sup0_activation_loss: 0.0322 - u2net_output_sup1_activation_loss: 0.0395 - u2net_output_sup2_activation_loss: 0.4203 - u2net_output_sup3_activation_loss: 0.5317 - u2net_output_sup4_activation_loss: 0.5618 - u2net_output_sup5_activation_loss: 0.5769 - u2net_output_final_activation_loss: 0.6725 - u2net_output_sup0_activation_dice_coef: 0.5642 - u2net_output_sup0_activation_accuracy: 0.9854 - u2net_output_sup0_activation_mse: 0.0084 - u2net_output_sup1_activation_dice_coef: 0.4759 - u2net_output_sup1_activation_accuracy: 0.9842 - u2net_output_sup1_activation_mse: 0.0097 - u2net_output_sup2_activation_dice_coef: 0.0634 - u2net_output_sup2_activation_accuracy: 0.9196 - u2net_output_sup2_activation_mse: 0.1369 - u2net_output_sup3_activation_dice_coef: 0.0463 - u2net_output_sup3_activation_accuracy: 0.9618 - u2net_output_sup3_activation_mse: 0.1768 - u2net_output_sup4_activation_dice_coef: 0.0431 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1867 - u2net_output_sup5_activation_dice_coef: 0.0419 - u2net_output_sup5_activation_accuracy: 0.9750 - u2net_output_sup5_activation_mse: 0.1919 - u2net_output_final_activation_dice_coef: 0.0412 - u2net_output_final_activation_accuracy: 0.6606 - u2net_output_final_activation_mse: 0.2390 - val_loss: 2.8390 - val_u2net_output_sup0_activation_loss: 0.0379 - val_u2net_output_sup1_activation_loss: 0.0506 - val_u2net_output_sup2_activation_loss: 0.4185 - val_u2net_output_sup3_activation_loss: 0.5302 - val_u2net_output_sup4_activation_loss: 0.5605 - val_u2net_output_sup5_activation_loss: 0.5752 - val_u2net_output_final_activation_loss: 0.6662 - val_u2net_output_sup0_activation_dice_coef: 0.5082 - val_u2net_output_sup0_activation_accuracy: 0.9854 - val_u2net_output_sup0_activation_mse: 0.0109 - val_u2net_output_sup1_activation_dice_coef: 0.3964 - val_u2net_output_sup1_activation_accuracy: 0.9840 - val_u2net_output_sup1_activation_mse: 0.0131 - val_u2net_output_sup2_activation_dice_coef: 0.0630 - val_u2net_output_sup2_activation_accuracy: 0.9206 - val_u2net_output_sup2_activation_mse: 0.1366 - val_u2net_output_sup3_activation_dice_coef: 0.0466 - val_u2net_output_sup3_activation_accuracy: 0.9627 - val_u2net_output_sup3_activation_mse: 0.1767 - val_u2net_output_sup4_activation_dice_coef: 0.0439 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1867 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1918 - val_u2net_output_final_activation_dice_coef: 0.0421 - val_u2net_output_final_activation_accuracy: 0.9178 - val_u2net_output_final_activation_mse: 0.2366\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7982 - u2net_output_sup0_activation_loss: 0.0309 - u2net_output_sup1_activation_loss: 0.0377 - u2net_output_sup2_activation_loss: 0.4118 - u2net_output_sup3_activation_loss: 0.5262 - u2net_output_sup4_activation_loss: 0.5577 - u2net_output_sup5_activation_loss: 0.5727 - u2net_output_final_activation_loss: 0.6614 - u2net_output_sup0_activation_dice_coef: 0.5687 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4858 - u2net_output_sup1_activation_accuracy: 0.9851 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0616 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1342 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.1745 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1848 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1899 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9177 - u2net_output_final_activation_mse: 0.2335"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.7982 - u2net_output_sup0_activation_loss: 0.0309 - u2net_output_sup1_activation_loss: 0.0377 - u2net_output_sup2_activation_loss: 0.4118 - u2net_output_sup3_activation_loss: 0.5262 - u2net_output_sup4_activation_loss: 0.5577 - u2net_output_sup5_activation_loss: 0.5727 - u2net_output_final_activation_loss: 0.6614 - u2net_output_sup0_activation_dice_coef: 0.5687 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4858 - u2net_output_sup1_activation_accuracy: 0.9851 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0616 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1342 - u2net_output_sup3_activation_dice_coef: 0.0442 - u2net_output_sup3_activation_accuracy: 0.9627 - u2net_output_sup3_activation_mse: 0.1745 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1848 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1899 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9177 - u2net_output_final_activation_mse: 0.2335 - val_loss: 2.8130 - val_u2net_output_sup0_activation_loss: 0.0405 - val_u2net_output_sup1_activation_loss: 0.0547 - val_u2net_output_sup2_activation_loss: 0.4103 - val_u2net_output_sup3_activation_loss: 0.5247 - val_u2net_output_sup4_activation_loss: 0.5569 - val_u2net_output_sup5_activation_loss: 0.5714 - val_u2net_output_final_activation_loss: 0.6545 - val_u2net_output_sup0_activation_dice_coef: 0.4742 - val_u2net_output_sup0_activation_accuracy: 0.9842 - val_u2net_output_sup0_activation_mse: 0.0116 - val_u2net_output_sup1_activation_dice_coef: 0.3716 - val_u2net_output_sup1_activation_accuracy: 0.9825 - val_u2net_output_sup1_activation_mse: 0.0145 - val_u2net_output_sup2_activation_dice_coef: 0.0651 - val_u2net_output_sup2_activation_accuracy: 0.9207 - val_u2net_output_sup2_activation_mse: 0.1340 - val_u2net_output_sup3_activation_dice_coef: 0.0472 - val_u2net_output_sup3_activation_accuracy: 0.9628 - val_u2net_output_sup3_activation_mse: 0.1743 - val_u2net_output_sup4_activation_dice_coef: 0.0442 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1850 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1899 - val_u2net_output_final_activation_dice_coef: 0.0418 - val_u2net_output_final_activation_accuracy: 0.9217 - val_u2net_output_final_activation_mse: 0.2308\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7633 - u2net_output_sup0_activation_loss: 0.0299 - u2net_output_sup1_activation_loss: 0.0358 - u2net_output_sup2_activation_loss: 0.4036 - u2net_output_sup3_activation_loss: 0.5209 - u2net_output_sup4_activation_loss: 0.5538 - u2net_output_sup5_activation_loss: 0.5687 - u2net_output_final_activation_loss: 0.6505 - u2net_output_sup0_activation_dice_coef: 0.5696 - u2net_output_sup0_activation_accuracy: 0.9863 - u2net_output_sup0_activation_mse: 0.0078 - u2net_output_sup1_activation_dice_coef: 0.4889 - u2net_output_sup1_activation_accuracy: 0.9854 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0615 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1316 - u2net_output_sup3_activation_dice_coef: 0.0433 - u2net_output_sup3_activation_accuracy: 0.9629 - u2net_output_sup3_activation_mse: 0.1723 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9772 - u2net_output_sup4_activation_mse: 0.1829 - u2net_output_sup5_activation_dice_coef: 0.0388 - u2net_output_sup5_activation_accuracy: 0.9761 - u2net_output_sup5_activation_mse: 0.1880 - u2net_output_final_activation_dice_coef: 0.0381 - u2net_output_final_activation_accuracy: 0.9332 - u2net_output_final_activation_mse: 0.2281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.7633 - u2net_output_sup0_activation_loss: 0.0299 - u2net_output_sup1_activation_loss: 0.0358 - u2net_output_sup2_activation_loss: 0.4036 - u2net_output_sup3_activation_loss: 0.5209 - u2net_output_sup4_activation_loss: 0.5538 - u2net_output_sup5_activation_loss: 0.5687 - u2net_output_final_activation_loss: 0.6505 - u2net_output_sup0_activation_dice_coef: 0.5696 - u2net_output_sup0_activation_accuracy: 0.9863 - u2net_output_sup0_activation_mse: 0.0078 - u2net_output_sup1_activation_dice_coef: 0.4889 - u2net_output_sup1_activation_accuracy: 0.9854 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0615 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1316 - u2net_output_sup3_activation_dice_coef: 0.0433 - u2net_output_sup3_activation_accuracy: 0.9629 - u2net_output_sup3_activation_mse: 0.1723 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9772 - u2net_output_sup4_activation_mse: 0.1829 - u2net_output_sup5_activation_dice_coef: 0.0388 - u2net_output_sup5_activation_accuracy: 0.9761 - u2net_output_sup5_activation_mse: 0.1880 - u2net_output_final_activation_dice_coef: 0.0381 - u2net_output_final_activation_accuracy: 0.9332 - u2net_output_final_activation_mse: 0.2281 - val_loss: 2.7678 - val_u2net_output_sup0_activation_loss: 0.0345 - val_u2net_output_sup1_activation_loss: 0.0434 - val_u2net_output_sup2_activation_loss: 0.4041 - val_u2net_output_sup3_activation_loss: 0.5200 - val_u2net_output_sup4_activation_loss: 0.5530 - val_u2net_output_sup5_activation_loss: 0.5674 - val_u2net_output_final_activation_loss: 0.6454 - val_u2net_output_sup0_activation_dice_coef: 0.5168 - val_u2net_output_sup0_activation_accuracy: 0.9865 - val_u2net_output_sup0_activation_mse: 0.0100 - val_u2net_output_sup1_activation_dice_coef: 0.4125 - val_u2net_output_sup1_activation_accuracy: 0.9841 - val_u2net_output_sup1_activation_mse: 0.0120 - val_u2net_output_sup2_activation_dice_coef: 0.0619 - val_u2net_output_sup2_activation_accuracy: 0.9202 - val_u2net_output_sup2_activation_mse: 0.1325 - val_u2net_output_sup3_activation_dice_coef: 0.0467 - val_u2net_output_sup3_activation_accuracy: 0.9626 - val_u2net_output_sup3_activation_mse: 0.1725 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1830 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1880 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.9625 - val_u2net_output_final_activation_mse: 0.2262\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7337 - u2net_output_sup0_activation_loss: 0.0295 - u2net_output_sup1_activation_loss: 0.0355 - u2net_output_sup2_activation_loss: 0.3967 - u2net_output_sup3_activation_loss: 0.5162 - u2net_output_sup4_activation_loss: 0.5504 - u2net_output_sup5_activation_loss: 0.5651 - u2net_output_final_activation_loss: 0.6402 - u2net_output_sup0_activation_dice_coef: 0.5934 - u2net_output_sup0_activation_accuracy: 0.9862 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5114 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0657 - u2net_output_sup2_activation_accuracy: 0.9200 - u2net_output_sup2_activation_mse: 0.1293 - u2net_output_sup3_activation_dice_coef: 0.0456 - u2net_output_sup3_activation_accuracy: 0.9619 - u2net_output_sup3_activation_mse: 0.1703 - u2net_output_sup4_activation_dice_coef: 0.0418 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1812 - u2net_output_sup5_activation_dice_coef: 0.0406 - u2net_output_sup5_activation_accuracy: 0.9750 - u2net_output_sup5_activation_mse: 0.1862 - u2net_output_final_activation_dice_coef: 0.0399 - u2net_output_final_activation_accuracy: 0.9620 - u2net_output_final_activation_mse: 0.2229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.7337 - u2net_output_sup0_activation_loss: 0.0295 - u2net_output_sup1_activation_loss: 0.0355 - u2net_output_sup2_activation_loss: 0.3967 - u2net_output_sup3_activation_loss: 0.5162 - u2net_output_sup4_activation_loss: 0.5504 - u2net_output_sup5_activation_loss: 0.5651 - u2net_output_final_activation_loss: 0.6402 - u2net_output_sup0_activation_dice_coef: 0.5934 - u2net_output_sup0_activation_accuracy: 0.9862 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5114 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0657 - u2net_output_sup2_activation_accuracy: 0.9200 - u2net_output_sup2_activation_mse: 0.1293 - u2net_output_sup3_activation_dice_coef: 0.0456 - u2net_output_sup3_activation_accuracy: 0.9619 - u2net_output_sup3_activation_mse: 0.1703 - u2net_output_sup4_activation_dice_coef: 0.0418 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1812 - u2net_output_sup5_activation_dice_coef: 0.0406 - u2net_output_sup5_activation_accuracy: 0.9750 - u2net_output_sup5_activation_mse: 0.1862 - u2net_output_final_activation_dice_coef: 0.0399 - u2net_output_final_activation_accuracy: 0.9620 - u2net_output_final_activation_mse: 0.2229 - val_loss: 2.7688 - val_u2net_output_sup0_activation_loss: 0.0510 - val_u2net_output_sup1_activation_loss: 0.0582 - val_u2net_output_sup2_activation_loss: 0.3973 - val_u2net_output_sup3_activation_loss: 0.5146 - val_u2net_output_sup4_activation_loss: 0.5491 - val_u2net_output_sup5_activation_loss: 0.5635 - val_u2net_output_final_activation_loss: 0.6350 - val_u2net_output_sup0_activation_dice_coef: 0.3938 - val_u2net_output_sup0_activation_accuracy: 0.9827 - val_u2net_output_sup0_activation_mse: 0.0136 - val_u2net_output_sup1_activation_dice_coef: 0.3313 - val_u2net_output_sup1_activation_accuracy: 0.9821 - val_u2net_output_sup1_activation_mse: 0.0144 - val_u2net_output_sup2_activation_dice_coef: 0.0591 - val_u2net_output_sup2_activation_accuracy: 0.9196 - val_u2net_output_sup2_activation_mse: 0.1301 - val_u2net_output_sup3_activation_dice_coef: 0.0474 - val_u2net_output_sup3_activation_accuracy: 0.9629 - val_u2net_output_sup3_activation_mse: 0.1700 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1812 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1861 - val_u2net_output_final_activation_dice_coef: 0.0426 - val_u2net_output_final_activation_accuracy: 0.9649 - val_u2net_output_final_activation_mse: 0.2210\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.7025 - u2net_output_sup0_activation_loss: 0.0301 - u2net_output_sup1_activation_loss: 0.0356 - u2net_output_sup2_activation_loss: 0.3890 - u2net_output_sup3_activation_loss: 0.5109 - u2net_output_sup4_activation_loss: 0.5464 - u2net_output_sup5_activation_loss: 0.5609 - u2net_output_final_activation_loss: 0.6296 - u2net_output_sup0_activation_dice_coef: 0.5652 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4909 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0090 - u2net_output_sup2_activation_dice_coef: 0.0629 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1268 - u2net_output_sup3_activation_dice_coef: 0.0437 - u2net_output_sup3_activation_accuracy: 0.9631 - u2net_output_sup3_activation_mse: 0.1680 - u2net_output_sup4_activation_dice_coef: 0.0401 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1793 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9762 - u2net_output_sup5_activation_mse: 0.1842 - u2net_output_final_activation_dice_coef: 0.0383 - u2net_output_final_activation_accuracy: 0.9666 - u2net_output_final_activation_mse: 0.2177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.7025 - u2net_output_sup0_activation_loss: 0.0301 - u2net_output_sup1_activation_loss: 0.0356 - u2net_output_sup2_activation_loss: 0.3890 - u2net_output_sup3_activation_loss: 0.5109 - u2net_output_sup4_activation_loss: 0.5464 - u2net_output_sup5_activation_loss: 0.5609 - u2net_output_final_activation_loss: 0.6296 - u2net_output_sup0_activation_dice_coef: 0.5652 - u2net_output_sup0_activation_accuracy: 0.9860 - u2net_output_sup0_activation_mse: 0.0080 - u2net_output_sup1_activation_dice_coef: 0.4909 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0090 - u2net_output_sup2_activation_dice_coef: 0.0629 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1268 - u2net_output_sup3_activation_dice_coef: 0.0437 - u2net_output_sup3_activation_accuracy: 0.9631 - u2net_output_sup3_activation_mse: 0.1680 - u2net_output_sup4_activation_dice_coef: 0.0401 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1793 - u2net_output_sup5_activation_dice_coef: 0.0390 - u2net_output_sup5_activation_accuracy: 0.9762 - u2net_output_sup5_activation_mse: 0.1842 - u2net_output_final_activation_dice_coef: 0.0383 - u2net_output_final_activation_accuracy: 0.9666 - u2net_output_final_activation_mse: 0.2177 - val_loss: 2.7087 - val_u2net_output_sup0_activation_loss: 0.0362 - val_u2net_output_sup1_activation_loss: 0.0441 - val_u2net_output_sup2_activation_loss: 0.3883 - val_u2net_output_sup3_activation_loss: 0.5098 - val_u2net_output_sup4_activation_loss: 0.5455 - val_u2net_output_sup5_activation_loss: 0.5597 - val_u2net_output_final_activation_loss: 0.6250 - val_u2net_output_sup0_activation_dice_coef: 0.5091 - val_u2net_output_sup0_activation_accuracy: 0.9861 - val_u2net_output_sup0_activation_mse: 0.0104 - val_u2net_output_sup1_activation_dice_coef: 0.4190 - val_u2net_output_sup1_activation_accuracy: 0.9847 - val_u2net_output_sup1_activation_mse: 0.0119 - val_u2net_output_sup2_activation_dice_coef: 0.0657 - val_u2net_output_sup2_activation_accuracy: 0.9206 - val_u2net_output_sup2_activation_mse: 0.1270 - val_u2net_output_sup3_activation_dice_coef: 0.0472 - val_u2net_output_sup3_activation_accuracy: 0.9628 - val_u2net_output_sup3_activation_mse: 0.1680 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1794 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1842 - val_u2net_output_final_activation_dice_coef: 0.0425 - val_u2net_output_final_activation_accuracy: 0.9732 - val_u2net_output_final_activation_mse: 0.2161\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6768 - u2net_output_sup0_activation_loss: 0.0313 - u2net_output_sup1_activation_loss: 0.0368 - u2net_output_sup2_activation_loss: 0.3827 - u2net_output_sup3_activation_loss: 0.5063 - u2net_output_sup4_activation_loss: 0.5429 - u2net_output_sup5_activation_loss: 0.5572 - u2net_output_final_activation_loss: 0.6196 - u2net_output_sup0_activation_dice_coef: 0.5644 - u2net_output_sup0_activation_accuracy: 0.9858 - u2net_output_sup0_activation_mse: 0.0082 - u2net_output_sup1_activation_dice_coef: 0.4885 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0652 - u2net_output_sup2_activation_accuracy: 0.9202 - u2net_output_sup2_activation_mse: 0.1247 - u2net_output_sup3_activation_dice_coef: 0.0450 - u2net_output_sup3_activation_accuracy: 0.9626 - u2net_output_sup3_activation_mse: 0.1659 - u2net_output_sup4_activation_dice_coef: 0.0412 - u2net_output_sup4_activation_accuracy: 0.9768 - u2net_output_sup4_activation_mse: 0.1776 - u2net_output_sup5_activation_dice_coef: 0.0401 - u2net_output_sup5_activation_accuracy: 0.9757 - u2net_output_sup5_activation_mse: 0.1824 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.9733 - u2net_output_final_activation_mse: 0.2128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.6768 - u2net_output_sup0_activation_loss: 0.0313 - u2net_output_sup1_activation_loss: 0.0368 - u2net_output_sup2_activation_loss: 0.3827 - u2net_output_sup3_activation_loss: 0.5063 - u2net_output_sup4_activation_loss: 0.5429 - u2net_output_sup5_activation_loss: 0.5572 - u2net_output_final_activation_loss: 0.6196 - u2net_output_sup0_activation_dice_coef: 0.5644 - u2net_output_sup0_activation_accuracy: 0.9858 - u2net_output_sup0_activation_mse: 0.0082 - u2net_output_sup1_activation_dice_coef: 0.4885 - u2net_output_sup1_activation_accuracy: 0.9850 - u2net_output_sup1_activation_mse: 0.0092 - u2net_output_sup2_activation_dice_coef: 0.0652 - u2net_output_sup2_activation_accuracy: 0.9202 - u2net_output_sup2_activation_mse: 0.1247 - u2net_output_sup3_activation_dice_coef: 0.0450 - u2net_output_sup3_activation_accuracy: 0.9626 - u2net_output_sup3_activation_mse: 0.1659 - u2net_output_sup4_activation_dice_coef: 0.0412 - u2net_output_sup4_activation_accuracy: 0.9768 - u2net_output_sup4_activation_mse: 0.1776 - u2net_output_sup5_activation_dice_coef: 0.0401 - u2net_output_sup5_activation_accuracy: 0.9757 - u2net_output_sup5_activation_mse: 0.1824 - u2net_output_final_activation_dice_coef: 0.0394 - u2net_output_final_activation_accuracy: 0.9733 - u2net_output_final_activation_mse: 0.2128 - val_loss: 2.6821 - val_u2net_output_sup0_activation_loss: 0.0360 - val_u2net_output_sup1_activation_loss: 0.0439 - val_u2net_output_sup2_activation_loss: 0.3826 - val_u2net_output_sup3_activation_loss: 0.5061 - val_u2net_output_sup4_activation_loss: 0.5426 - val_u2net_output_sup5_activation_loss: 0.5560 - val_u2net_output_final_activation_loss: 0.6149 - val_u2net_output_sup0_activation_dice_coef: 0.5268 - val_u2net_output_sup0_activation_accuracy: 0.9857 - val_u2net_output_sup0_activation_mse: 0.0104 - val_u2net_output_sup1_activation_dice_coef: 0.4413 - val_u2net_output_sup1_activation_accuracy: 0.9848 - val_u2net_output_sup1_activation_mse: 0.0120 - val_u2net_output_sup2_activation_dice_coef: 0.0718 - val_u2net_output_sup2_activation_accuracy: 0.9205 - val_u2net_output_sup2_activation_mse: 0.1250 - val_u2net_output_sup3_activation_dice_coef: 0.0491 - val_u2net_output_sup3_activation_accuracy: 0.9637 - val_u2net_output_sup3_activation_mse: 0.1662 - val_u2net_output_sup4_activation_dice_coef: 0.0442 - val_u2net_output_sup4_activation_accuracy: 0.9768 - val_u2net_output_sup4_activation_mse: 0.1779 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1824 - val_u2net_output_final_activation_dice_coef: 0.0423 - val_u2net_output_final_activation_accuracy: 0.9740 - val_u2net_output_final_activation_mse: 0.2111\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6425 - u2net_output_sup0_activation_loss: 0.0298 - u2net_output_sup1_activation_loss: 0.0349 - u2net_output_sup2_activation_loss: 0.3750 - u2net_output_sup3_activation_loss: 0.5009 - u2net_output_sup4_activation_loss: 0.5390 - u2net_output_sup5_activation_loss: 0.5532 - u2net_output_final_activation_loss: 0.6097 - u2net_output_sup0_activation_dice_coef: 0.5683 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0079 - u2net_output_sup1_activation_dice_coef: 0.4959 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0633 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1223 - u2net_output_sup3_activation_dice_coef: 0.0431 - u2net_output_sup3_activation_accuracy: 0.9634 - u2net_output_sup3_activation_mse: 0.1636 - u2net_output_sup4_activation_dice_coef: 0.0393 - u2net_output_sup4_activation_accuracy: 0.9775 - u2net_output_sup4_activation_mse: 0.1757 - u2net_output_sup5_activation_dice_coef: 0.0381 - u2net_output_sup5_activation_accuracy: 0.9764 - u2net_output_sup5_activation_mse: 0.1804 - u2net_output_final_activation_dice_coef: 0.0375 - u2net_output_final_activation_accuracy: 0.9742 - u2net_output_final_activation_mse: 0.2079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.6425 - u2net_output_sup0_activation_loss: 0.0298 - u2net_output_sup1_activation_loss: 0.0349 - u2net_output_sup2_activation_loss: 0.3750 - u2net_output_sup3_activation_loss: 0.5009 - u2net_output_sup4_activation_loss: 0.5390 - u2net_output_sup5_activation_loss: 0.5532 - u2net_output_final_activation_loss: 0.6097 - u2net_output_sup0_activation_dice_coef: 0.5683 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0079 - u2net_output_sup1_activation_dice_coef: 0.4959 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0089 - u2net_output_sup2_activation_dice_coef: 0.0633 - u2net_output_sup2_activation_accuracy: 0.9207 - u2net_output_sup2_activation_mse: 0.1223 - u2net_output_sup3_activation_dice_coef: 0.0431 - u2net_output_sup3_activation_accuracy: 0.9634 - u2net_output_sup3_activation_mse: 0.1636 - u2net_output_sup4_activation_dice_coef: 0.0393 - u2net_output_sup4_activation_accuracy: 0.9775 - u2net_output_sup4_activation_mse: 0.1757 - u2net_output_sup5_activation_dice_coef: 0.0381 - u2net_output_sup5_activation_accuracy: 0.9764 - u2net_output_sup5_activation_mse: 0.1804 - u2net_output_final_activation_dice_coef: 0.0375 - u2net_output_final_activation_accuracy: 0.9742 - u2net_output_final_activation_mse: 0.2079 - val_loss: 2.6563 - val_u2net_output_sup0_activation_loss: 0.0385 - val_u2net_output_sup1_activation_loss: 0.0465 - val_u2net_output_sup2_activation_loss: 0.3752 - val_u2net_output_sup3_activation_loss: 0.5002 - val_u2net_output_sup4_activation_loss: 0.5384 - val_u2net_output_sup5_activation_loss: 0.5521 - val_u2net_output_final_activation_loss: 0.6052 - val_u2net_output_sup0_activation_dice_coef: 0.4895 - val_u2net_output_sup0_activation_accuracy: 0.9854 - val_u2net_output_sup0_activation_mse: 0.0110 - val_u2net_output_sup1_activation_dice_coef: 0.4296 - val_u2net_output_sup1_activation_accuracy: 0.9842 - val_u2net_output_sup1_activation_mse: 0.0124 - val_u2net_output_sup2_activation_dice_coef: 0.0692 - val_u2net_output_sup2_activation_accuracy: 0.9208 - val_u2net_output_sup2_activation_mse: 0.1228 - val_u2net_output_sup3_activation_dice_coef: 0.0480 - val_u2net_output_sup3_activation_accuracy: 0.9642 - val_u2net_output_sup3_activation_mse: 0.1637 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1759 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1806 - val_u2net_output_final_activation_dice_coef: 0.0421 - val_u2net_output_final_activation_accuracy: 0.9746 - val_u2net_output_final_activation_mse: 0.2063\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.6129 - u2net_output_sup0_activation_loss: 0.0292 - u2net_output_sup1_activation_loss: 0.0339 - u2net_output_sup2_activation_loss: 0.3680 - u2net_output_sup3_activation_loss: 0.4962 - u2net_output_sup4_activation_loss: 0.5356 - u2net_output_sup5_activation_loss: 0.5497 - u2net_output_final_activation_loss: 0.6003 - u2net_output_sup0_activation_dice_coef: 0.5965 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0078 - u2net_output_sup1_activation_dice_coef: 0.5311 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0708 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1200 - u2net_output_sup3_activation_dice_coef: 0.0467 - u2net_output_sup3_activation_accuracy: 0.9633 - u2net_output_sup3_activation_mse: 0.1615 - u2net_output_sup4_activation_dice_coef: 0.0421 - u2net_output_sup4_activation_accuracy: 0.9765 - u2net_output_sup4_activation_mse: 0.1740 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9753 - u2net_output_sup5_activation_mse: 0.1787 - u2net_output_final_activation_dice_coef: 0.0402 - u2net_output_final_activation_accuracy: 0.9752 - u2net_output_final_activation_mse: 0.2032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.6129 - u2net_output_sup0_activation_loss: 0.0292 - u2net_output_sup1_activation_loss: 0.0339 - u2net_output_sup2_activation_loss: 0.3680 - u2net_output_sup3_activation_loss: 0.4962 - u2net_output_sup4_activation_loss: 0.5356 - u2net_output_sup5_activation_loss: 0.5497 - u2net_output_final_activation_loss: 0.6003 - u2net_output_sup0_activation_dice_coef: 0.5965 - u2net_output_sup0_activation_accuracy: 0.9861 - u2net_output_sup0_activation_mse: 0.0078 - u2net_output_sup1_activation_dice_coef: 0.5311 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0708 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1200 - u2net_output_sup3_activation_dice_coef: 0.0467 - u2net_output_sup3_activation_accuracy: 0.9633 - u2net_output_sup3_activation_mse: 0.1615 - u2net_output_sup4_activation_dice_coef: 0.0421 - u2net_output_sup4_activation_accuracy: 0.9765 - u2net_output_sup4_activation_mse: 0.1740 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9753 - u2net_output_sup5_activation_mse: 0.1787 - u2net_output_final_activation_dice_coef: 0.0402 - u2net_output_final_activation_accuracy: 0.9752 - u2net_output_final_activation_mse: 0.2032 - val_loss: 2.6217 - val_u2net_output_sup0_activation_loss: 0.0364 - val_u2net_output_sup1_activation_loss: 0.0439 - val_u2net_output_sup2_activation_loss: 0.3678 - val_u2net_output_sup3_activation_loss: 0.4949 - val_u2net_output_sup4_activation_loss: 0.5346 - val_u2net_output_sup5_activation_loss: 0.5484 - val_u2net_output_final_activation_loss: 0.5957 - val_u2net_output_sup0_activation_dice_coef: 0.5294 - val_u2net_output_sup0_activation_accuracy: 0.9860 - val_u2net_output_sup0_activation_mse: 0.0104 - val_u2net_output_sup1_activation_dice_coef: 0.4500 - val_u2net_output_sup1_activation_accuracy: 0.9849 - val_u2net_output_sup1_activation_mse: 0.0118 - val_u2net_output_sup2_activation_dice_coef: 0.0681 - val_u2net_output_sup2_activation_accuracy: 0.9207 - val_u2net_output_sup2_activation_mse: 0.1204 - val_u2net_output_sup3_activation_dice_coef: 0.0474 - val_u2net_output_sup3_activation_accuracy: 0.9652 - val_u2net_output_sup3_activation_mse: 0.1616 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1742 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1788 - val_u2net_output_final_activation_dice_coef: 0.0421 - val_u2net_output_final_activation_accuracy: 0.9762 - val_u2net_output_final_activation_mse: 0.2016\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5804 - u2net_output_sup0_activation_loss: 0.0277 - u2net_output_sup1_activation_loss: 0.0325 - u2net_output_sup2_activation_loss: 0.3608 - u2net_output_sup3_activation_loss: 0.4909 - u2net_output_sup4_activation_loss: 0.5318 - u2net_output_sup5_activation_loss: 0.5457 - u2net_output_final_activation_loss: 0.5908 - u2net_output_sup0_activation_dice_coef: 0.6131 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5409 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0705 - u2net_output_sup2_activation_accuracy: 0.9209 - u2net_output_sup2_activation_mse: 0.1176 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9714 - u2net_output_sup3_activation_mse: 0.1592 - u2net_output_sup4_activation_dice_coef: 0.0415 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1722 - u2net_output_sup5_activation_dice_coef: 0.0402 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1768 - u2net_output_final_activation_dice_coef: 0.0396 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.5804 - u2net_output_sup0_activation_loss: 0.0277 - u2net_output_sup1_activation_loss: 0.0325 - u2net_output_sup2_activation_loss: 0.3608 - u2net_output_sup3_activation_loss: 0.4909 - u2net_output_sup4_activation_loss: 0.5318 - u2net_output_sup5_activation_loss: 0.5457 - u2net_output_final_activation_loss: 0.5908 - u2net_output_sup0_activation_dice_coef: 0.6131 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5409 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0705 - u2net_output_sup2_activation_accuracy: 0.9209 - u2net_output_sup2_activation_mse: 0.1176 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9714 - u2net_output_sup3_activation_mse: 0.1592 - u2net_output_sup4_activation_dice_coef: 0.0415 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1722 - u2net_output_sup5_activation_dice_coef: 0.0402 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1768 - u2net_output_final_activation_dice_coef: 0.0396 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1985 - val_loss: 2.5908 - val_u2net_output_sup0_activation_loss: 0.0351 - val_u2net_output_sup1_activation_loss: 0.0417 - val_u2net_output_sup2_activation_loss: 0.3610 - val_u2net_output_sup3_activation_loss: 0.4905 - val_u2net_output_sup4_activation_loss: 0.5313 - val_u2net_output_sup5_activation_loss: 0.5446 - val_u2net_output_final_activation_loss: 0.5866 - val_u2net_output_sup0_activation_dice_coef: 0.5398 - val_u2net_output_sup0_activation_accuracy: 0.9861 - val_u2net_output_sup0_activation_mse: 0.0102 - val_u2net_output_sup1_activation_dice_coef: 0.4582 - val_u2net_output_sup1_activation_accuracy: 0.9849 - val_u2net_output_sup1_activation_mse: 0.0116 - val_u2net_output_sup2_activation_dice_coef: 0.0735 - val_u2net_output_sup2_activation_accuracy: 0.9210 - val_u2net_output_sup2_activation_mse: 0.1180 - val_u2net_output_sup3_activation_dice_coef: 0.0502 - val_u2net_output_sup3_activation_accuracy: 0.9774 - val_u2net_output_sup3_activation_mse: 0.1595 - val_u2net_output_sup4_activation_dice_coef: 0.0444 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1726 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9760 - val_u2net_output_sup5_activation_mse: 0.1770 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.9773 - val_u2net_output_final_activation_mse: 0.1971\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5493 - u2net_output_sup0_activation_loss: 0.0274 - u2net_output_sup1_activation_loss: 0.0318 - u2net_output_sup2_activation_loss: 0.3536 - u2net_output_sup3_activation_loss: 0.4855 - u2net_output_sup4_activation_loss: 0.5279 - u2net_output_sup5_activation_loss: 0.5417 - u2net_output_final_activation_loss: 0.5814 - u2net_output_sup0_activation_dice_coef: 0.5926 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5245 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0081 - u2net_output_sup2_activation_dice_coef: 0.0676 - u2net_output_sup2_activation_accuracy: 0.9214 - u2net_output_sup2_activation_mse: 0.1152 - u2net_output_sup3_activation_dice_coef: 0.0439 - u2net_output_sup3_activation_accuracy: 0.9785 - u2net_output_sup3_activation_mse: 0.1568 - u2net_output_sup4_activation_dice_coef: 0.0392 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1704 - u2net_output_sup5_activation_dice_coef: 0.0380 - u2net_output_sup5_activation_accuracy: 0.9767 - u2net_output_sup5_activation_mse: 0.1749 - u2net_output_final_activation_dice_coef: 0.0374 - u2net_output_final_activation_accuracy: 0.9779 - u2net_output_final_activation_mse: 0.1939"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.5493 - u2net_output_sup0_activation_loss: 0.0274 - u2net_output_sup1_activation_loss: 0.0318 - u2net_output_sup2_activation_loss: 0.3536 - u2net_output_sup3_activation_loss: 0.4855 - u2net_output_sup4_activation_loss: 0.5279 - u2net_output_sup5_activation_loss: 0.5417 - u2net_output_final_activation_loss: 0.5814 - u2net_output_sup0_activation_dice_coef: 0.5926 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5245 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0081 - u2net_output_sup2_activation_dice_coef: 0.0676 - u2net_output_sup2_activation_accuracy: 0.9214 - u2net_output_sup2_activation_mse: 0.1152 - u2net_output_sup3_activation_dice_coef: 0.0439 - u2net_output_sup3_activation_accuracy: 0.9785 - u2net_output_sup3_activation_mse: 0.1568 - u2net_output_sup4_activation_dice_coef: 0.0392 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1704 - u2net_output_sup5_activation_dice_coef: 0.0380 - u2net_output_sup5_activation_accuracy: 0.9767 - u2net_output_sup5_activation_mse: 0.1749 - u2net_output_final_activation_dice_coef: 0.0374 - u2net_output_final_activation_accuracy: 0.9779 - u2net_output_final_activation_mse: 0.1939 - val_loss: 2.5587 - val_u2net_output_sup0_activation_loss: 0.0334 - val_u2net_output_sup1_activation_loss: 0.0380 - val_u2net_output_sup2_activation_loss: 0.3542 - val_u2net_output_sup3_activation_loss: 0.4868 - val_u2net_output_sup4_activation_loss: 0.5280 - val_u2net_output_sup5_activation_loss: 0.5410 - val_u2net_output_final_activation_loss: 0.5775 - val_u2net_output_sup0_activation_dice_coef: 0.5463 - val_u2net_output_sup0_activation_accuracy: 0.9865 - val_u2net_output_sup0_activation_mse: 0.0098 - val_u2net_output_sup1_activation_dice_coef: 0.4815 - val_u2net_output_sup1_activation_accuracy: 0.9859 - val_u2net_output_sup1_activation_mse: 0.0107 - val_u2net_output_sup2_activation_dice_coef: 0.0690 - val_u2net_output_sup2_activation_accuracy: 0.9207 - val_u2net_output_sup2_activation_mse: 0.1160 - val_u2net_output_sup3_activation_dice_coef: 0.0463 - val_u2net_output_sup3_activation_accuracy: 0.9774 - val_u2net_output_sup3_activation_mse: 0.1572 - val_u2net_output_sup4_activation_dice_coef: 0.0434 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1707 - val_u2net_output_sup5_activation_dice_coef: 0.0426 - val_u2net_output_sup5_activation_accuracy: 0.9759 - val_u2net_output_sup5_activation_mse: 0.1752 - val_u2net_output_final_activation_dice_coef: 0.0419 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1926\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5249 - u2net_output_sup0_activation_loss: 0.0281 - u2net_output_sup1_activation_loss: 0.0323 - u2net_output_sup2_activation_loss: 0.3478 - u2net_output_sup3_activation_loss: 0.4811 - u2net_output_sup4_activation_loss: 0.5247 - u2net_output_sup5_activation_loss: 0.5383 - u2net_output_final_activation_loss: 0.5727 - u2net_output_sup0_activation_dice_coef: 0.6059 - u2net_output_sup0_activation_accuracy: 0.9868 - u2net_output_sup0_activation_mse: 0.0074 - u2net_output_sup1_activation_dice_coef: 0.5402 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0719 - u2net_output_sup2_activation_accuracy: 0.9209 - u2net_output_sup2_activation_mse: 0.1132 - u2net_output_sup3_activation_dice_coef: 0.0460 - u2net_output_sup3_activation_accuracy: 0.9776 - u2net_output_sup3_activation_mse: 0.1547 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9769 - u2net_output_sup4_activation_mse: 0.1688 - u2net_output_sup5_activation_dice_coef: 0.0397 - u2net_output_sup5_activation_accuracy: 0.9758 - u2net_output_sup5_activation_mse: 0.1733 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9769 - u2net_output_final_activation_mse: 0.1896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.5249 - u2net_output_sup0_activation_loss: 0.0281 - u2net_output_sup1_activation_loss: 0.0323 - u2net_output_sup2_activation_loss: 0.3478 - u2net_output_sup3_activation_loss: 0.4811 - u2net_output_sup4_activation_loss: 0.5247 - u2net_output_sup5_activation_loss: 0.5383 - u2net_output_final_activation_loss: 0.5727 - u2net_output_sup0_activation_dice_coef: 0.6059 - u2net_output_sup0_activation_accuracy: 0.9868 - u2net_output_sup0_activation_mse: 0.0074 - u2net_output_sup1_activation_dice_coef: 0.5402 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0719 - u2net_output_sup2_activation_accuracy: 0.9209 - u2net_output_sup2_activation_mse: 0.1132 - u2net_output_sup3_activation_dice_coef: 0.0460 - u2net_output_sup3_activation_accuracy: 0.9776 - u2net_output_sup3_activation_mse: 0.1547 - u2net_output_sup4_activation_dice_coef: 0.0410 - u2net_output_sup4_activation_accuracy: 0.9769 - u2net_output_sup4_activation_mse: 0.1688 - u2net_output_sup5_activation_dice_coef: 0.0397 - u2net_output_sup5_activation_accuracy: 0.9758 - u2net_output_sup5_activation_mse: 0.1733 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9769 - u2net_output_final_activation_mse: 0.1896 - val_loss: 2.5812 - val_u2net_output_sup0_activation_loss: 0.0512 - val_u2net_output_sup1_activation_loss: 0.0617 - val_u2net_output_sup2_activation_loss: 0.3549 - val_u2net_output_sup3_activation_loss: 0.4833 - val_u2net_output_sup4_activation_loss: 0.5241 - val_u2net_output_sup5_activation_loss: 0.5373 - val_u2net_output_final_activation_loss: 0.5688 - val_u2net_output_sup0_activation_dice_coef: 0.4013 - val_u2net_output_sup0_activation_accuracy: 0.9828 - val_u2net_output_sup0_activation_mse: 0.0136 - val_u2net_output_sup1_activation_dice_coef: 0.3441 - val_u2net_output_sup1_activation_accuracy: 0.9812 - val_u2net_output_sup1_activation_mse: 0.0149 - val_u2net_output_sup2_activation_dice_coef: 0.0560 - val_u2net_output_sup2_activation_accuracy: 0.9187 - val_u2net_output_sup2_activation_mse: 0.1158 - val_u2net_output_sup3_activation_dice_coef: 0.0453 - val_u2net_output_sup3_activation_accuracy: 0.9772 - val_u2net_output_sup3_activation_mse: 0.1551 - val_u2net_output_sup4_activation_dice_coef: 0.0434 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1690 - val_u2net_output_sup5_activation_dice_coef: 0.0425 - val_u2net_output_sup5_activation_accuracy: 0.9760 - val_u2net_output_sup5_activation_mse: 0.1734 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1883\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5027 - u2net_output_sup0_activation_loss: 0.0293 - u2net_output_sup1_activation_loss: 0.0341 - u2net_output_sup2_activation_loss: 0.3424 - u2net_output_sup3_activation_loss: 0.4767 - u2net_output_sup4_activation_loss: 0.5214 - u2net_output_sup5_activation_loss: 0.5348 - u2net_output_final_activation_loss: 0.5640 - u2net_output_sup0_activation_dice_coef: 0.6039 - u2net_output_sup0_activation_accuracy: 0.9863 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5356 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0736 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1113 - u2net_output_sup3_activation_dice_coef: 0.0474 - u2net_output_sup3_activation_accuracy: 0.9771 - u2net_output_sup3_activation_mse: 0.1525 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9763 - u2net_output_sup4_activation_mse: 0.1672 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1715 - u2net_output_final_activation_dice_coef: 0.0404 - u2net_output_final_activation_accuracy: 0.9762 - u2net_output_final_activation_mse: 0.1853"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.5027 - u2net_output_sup0_activation_loss: 0.0293 - u2net_output_sup1_activation_loss: 0.0341 - u2net_output_sup2_activation_loss: 0.3424 - u2net_output_sup3_activation_loss: 0.4767 - u2net_output_sup4_activation_loss: 0.5214 - u2net_output_sup5_activation_loss: 0.5348 - u2net_output_final_activation_loss: 0.5640 - u2net_output_sup0_activation_dice_coef: 0.6039 - u2net_output_sup0_activation_accuracy: 0.9863 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5356 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0736 - u2net_output_sup2_activation_accuracy: 0.9204 - u2net_output_sup2_activation_mse: 0.1113 - u2net_output_sup3_activation_dice_coef: 0.0474 - u2net_output_sup3_activation_accuracy: 0.9771 - u2net_output_sup3_activation_mse: 0.1525 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9763 - u2net_output_sup4_activation_mse: 0.1672 - u2net_output_sup5_activation_dice_coef: 0.0409 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1715 - u2net_output_final_activation_dice_coef: 0.0404 - u2net_output_final_activation_accuracy: 0.9762 - u2net_output_final_activation_mse: 0.1853 - val_loss: 2.5274 - val_u2net_output_sup0_activation_loss: 0.0436 - val_u2net_output_sup1_activation_loss: 0.0502 - val_u2net_output_sup2_activation_loss: 0.3443 - val_u2net_output_sup3_activation_loss: 0.4752 - val_u2net_output_sup4_activation_loss: 0.5204 - val_u2net_output_sup5_activation_loss: 0.5335 - val_u2net_output_final_activation_loss: 0.5602 - val_u2net_output_sup0_activation_dice_coef: 0.5305 - val_u2net_output_sup0_activation_accuracy: 0.9852 - val_u2net_output_sup0_activation_mse: 0.0116 - val_u2net_output_sup1_activation_dice_coef: 0.4768 - val_u2net_output_sup1_activation_accuracy: 0.9843 - val_u2net_output_sup1_activation_mse: 0.0125 - val_u2net_output_sup2_activation_dice_coef: 0.0737 - val_u2net_output_sup2_activation_accuracy: 0.9211 - val_u2net_output_sup2_activation_mse: 0.1125 - val_u2net_output_sup3_activation_dice_coef: 0.0502 - val_u2net_output_sup3_activation_accuracy: 0.9777 - val_u2net_output_sup3_activation_mse: 0.1526 - val_u2net_output_sup4_activation_dice_coef: 0.0441 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1673 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1716 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.9769 - val_u2net_output_final_activation_mse: 0.1841\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4759 - u2net_output_sup0_activation_loss: 0.0293 - u2net_output_sup1_activation_loss: 0.0337 - u2net_output_sup2_activation_loss: 0.3362 - u2net_output_sup3_activation_loss: 0.4720 - u2net_output_sup4_activation_loss: 0.5180 - u2net_output_sup5_activation_loss: 0.5312 - u2net_output_final_activation_loss: 0.5555 - u2net_output_sup0_activation_dice_coef: 0.6039 - u2net_output_sup0_activation_accuracy: 0.9862 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5366 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0759 - u2net_output_sup2_activation_accuracy: 0.9205 - u2net_output_sup2_activation_mse: 0.1090 - u2net_output_sup3_activation_dice_coef: 0.0485 - u2net_output_sup3_activation_accuracy: 0.9769 - u2net_output_sup3_activation_mse: 0.1505 - u2net_output_sup4_activation_dice_coef: 0.0429 - u2net_output_sup4_activation_accuracy: 0.9762 - u2net_output_sup4_activation_mse: 0.1655 - u2net_output_sup5_activation_dice_coef: 0.0416 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.1698 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.9760 - u2net_output_final_activation_mse: 0.1811"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.4759 - u2net_output_sup0_activation_loss: 0.0293 - u2net_output_sup1_activation_loss: 0.0337 - u2net_output_sup2_activation_loss: 0.3362 - u2net_output_sup3_activation_loss: 0.4720 - u2net_output_sup4_activation_loss: 0.5180 - u2net_output_sup5_activation_loss: 0.5312 - u2net_output_final_activation_loss: 0.5555 - u2net_output_sup0_activation_dice_coef: 0.6039 - u2net_output_sup0_activation_accuracy: 0.9862 - u2net_output_sup0_activation_mse: 0.0077 - u2net_output_sup1_activation_dice_coef: 0.5366 - u2net_output_sup1_activation_accuracy: 0.9853 - u2net_output_sup1_activation_mse: 0.0087 - u2net_output_sup2_activation_dice_coef: 0.0759 - u2net_output_sup2_activation_accuracy: 0.9205 - u2net_output_sup2_activation_mse: 0.1090 - u2net_output_sup3_activation_dice_coef: 0.0485 - u2net_output_sup3_activation_accuracy: 0.9769 - u2net_output_sup3_activation_mse: 0.1505 - u2net_output_sup4_activation_dice_coef: 0.0429 - u2net_output_sup4_activation_accuracy: 0.9762 - u2net_output_sup4_activation_mse: 0.1655 - u2net_output_sup5_activation_dice_coef: 0.0416 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.1698 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.9760 - u2net_output_final_activation_mse: 0.1811 - val_loss: 2.4873 - val_u2net_output_sup0_activation_loss: 0.0388 - val_u2net_output_sup1_activation_loss: 0.0413 - val_u2net_output_sup2_activation_loss: 0.3366 - val_u2net_output_sup3_activation_loss: 0.4722 - val_u2net_output_sup4_activation_loss: 0.5168 - val_u2net_output_sup5_activation_loss: 0.5300 - val_u2net_output_final_activation_loss: 0.5517 - val_u2net_output_sup0_activation_dice_coef: 0.5280 - val_u2net_output_sup0_activation_accuracy: 0.9864 - val_u2net_output_sup0_activation_mse: 0.0105 - val_u2net_output_sup1_activation_dice_coef: 0.4780 - val_u2net_output_sup1_activation_accuracy: 0.9855 - val_u2net_output_sup1_activation_mse: 0.0112 - val_u2net_output_sup2_activation_dice_coef: 0.0696 - val_u2net_output_sup2_activation_accuracy: 0.9207 - val_u2net_output_sup2_activation_mse: 0.1097 - val_u2net_output_sup3_activation_dice_coef: 0.0473 - val_u2net_output_sup3_activation_accuracy: 0.9776 - val_u2net_output_sup3_activation_mse: 0.1508 - val_u2net_output_sup4_activation_dice_coef: 0.0437 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1656 - val_u2net_output_sup5_activation_dice_coef: 0.0426 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1699 - val_u2net_output_final_activation_dice_coef: 0.0419 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1799\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4458 - u2net_output_sup0_activation_loss: 0.0282 - u2net_output_sup1_activation_loss: 0.0323 - u2net_output_sup2_activation_loss: 0.3293 - u2net_output_sup3_activation_loss: 0.4675 - u2net_output_sup4_activation_loss: 0.5142 - u2net_output_sup5_activation_loss: 0.5273 - u2net_output_final_activation_loss: 0.5470 - u2net_output_sup0_activation_dice_coef: 0.6078 - u2net_output_sup0_activation_accuracy: 0.9867 - u2net_output_sup0_activation_mse: 0.0075 - u2net_output_sup1_activation_dice_coef: 0.5403 - u2net_output_sup1_activation_accuracy: 0.9858 - u2net_output_sup1_activation_mse: 0.0084 - u2net_output_sup2_activation_dice_coef: 0.0740 - u2net_output_sup2_activation_accuracy: 0.9212 - u2net_output_sup2_activation_mse: 0.1066 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9777 - u2net_output_sup3_activation_mse: 0.1486 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1637 - u2net_output_sup5_activation_dice_coef: 0.0394 - u2net_output_sup5_activation_accuracy: 0.9768 - u2net_output_sup5_activation_mse: 0.1679 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.9767 - u2net_output_final_activation_mse: 0.1770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.4458 - u2net_output_sup0_activation_loss: 0.0282 - u2net_output_sup1_activation_loss: 0.0323 - u2net_output_sup2_activation_loss: 0.3293 - u2net_output_sup3_activation_loss: 0.4675 - u2net_output_sup4_activation_loss: 0.5142 - u2net_output_sup5_activation_loss: 0.5273 - u2net_output_final_activation_loss: 0.5470 - u2net_output_sup0_activation_dice_coef: 0.6078 - u2net_output_sup0_activation_accuracy: 0.9867 - u2net_output_sup0_activation_mse: 0.0075 - u2net_output_sup1_activation_dice_coef: 0.5403 - u2net_output_sup1_activation_accuracy: 0.9858 - u2net_output_sup1_activation_mse: 0.0084 - u2net_output_sup2_activation_dice_coef: 0.0740 - u2net_output_sup2_activation_accuracy: 0.9212 - u2net_output_sup2_activation_mse: 0.1066 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9777 - u2net_output_sup3_activation_mse: 0.1486 - u2net_output_sup4_activation_dice_coef: 0.0407 - u2net_output_sup4_activation_accuracy: 0.9770 - u2net_output_sup4_activation_mse: 0.1637 - u2net_output_sup5_activation_dice_coef: 0.0394 - u2net_output_sup5_activation_accuracy: 0.9768 - u2net_output_sup5_activation_mse: 0.1679 - u2net_output_final_activation_dice_coef: 0.0391 - u2net_output_final_activation_accuracy: 0.9767 - u2net_output_final_activation_mse: 0.1770 - val_loss: 2.4538 - val_u2net_output_sup0_activation_loss: 0.0344 - val_u2net_output_sup1_activation_loss: 0.0394 - val_u2net_output_sup2_activation_loss: 0.3291 - val_u2net_output_sup3_activation_loss: 0.4673 - val_u2net_output_sup4_activation_loss: 0.5136 - val_u2net_output_sup5_activation_loss: 0.5263 - val_u2net_output_final_activation_loss: 0.5436 - val_u2net_output_sup0_activation_dice_coef: 0.5175 - val_u2net_output_sup0_activation_accuracy: 0.9868 - val_u2net_output_sup0_activation_mse: 0.0099 - val_u2net_output_sup1_activation_dice_coef: 0.4585 - val_u2net_output_sup1_activation_accuracy: 0.9858 - val_u2net_output_sup1_activation_mse: 0.0109 - val_u2net_output_sup2_activation_dice_coef: 0.0774 - val_u2net_output_sup2_activation_accuracy: 0.9221 - val_u2net_output_sup2_activation_mse: 0.1065 - val_u2net_output_sup3_activation_dice_coef: 0.0487 - val_u2net_output_sup3_activation_accuracy: 0.9777 - val_u2net_output_sup3_activation_mse: 0.1492 - val_u2net_output_sup4_activation_dice_coef: 0.0439 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1640 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1681 - val_u2net_output_final_activation_dice_coef: 0.0424 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1760\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4125 - u2net_output_sup0_activation_loss: 0.0256 - u2net_output_sup1_activation_loss: 0.0293 - u2net_output_sup2_activation_loss: 0.3222 - u2net_output_sup3_activation_loss: 0.4631 - u2net_output_sup4_activation_loss: 0.5103 - u2net_output_sup5_activation_loss: 0.5234 - u2net_output_final_activation_loss: 0.5387 - u2net_output_sup0_activation_dice_coef: 0.6197 - u2net_output_sup0_activation_accuracy: 0.9876 - u2net_output_sup0_activation_mse: 0.0068 - u2net_output_sup1_activation_dice_coef: 0.5546 - u2net_output_sup1_activation_accuracy: 0.9868 - u2net_output_sup1_activation_mse: 0.0076 - u2net_output_sup2_activation_dice_coef: 0.0744 - u2net_output_sup2_activation_accuracy: 0.9221 - u2net_output_sup2_activation_mse: 0.1042 - u2net_output_sup3_activation_dice_coef: 0.0456 - u2net_output_sup3_activation_accuracy: 0.9786 - u2net_output_sup3_activation_mse: 0.1468 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1619 - u2net_output_sup5_activation_dice_coef: 0.0387 - u2net_output_sup5_activation_accuracy: 0.9776 - u2net_output_sup5_activation_mse: 0.1661 - u2net_output_final_activation_dice_coef: 0.0384 - u2net_output_final_activation_accuracy: 0.9775 - u2net_output_final_activation_mse: 0.1730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.4125 - u2net_output_sup0_activation_loss: 0.0256 - u2net_output_sup1_activation_loss: 0.0293 - u2net_output_sup2_activation_loss: 0.3222 - u2net_output_sup3_activation_loss: 0.4631 - u2net_output_sup4_activation_loss: 0.5103 - u2net_output_sup5_activation_loss: 0.5234 - u2net_output_final_activation_loss: 0.5387 - u2net_output_sup0_activation_dice_coef: 0.6197 - u2net_output_sup0_activation_accuracy: 0.9876 - u2net_output_sup0_activation_mse: 0.0068 - u2net_output_sup1_activation_dice_coef: 0.5546 - u2net_output_sup1_activation_accuracy: 0.9868 - u2net_output_sup1_activation_mse: 0.0076 - u2net_output_sup2_activation_dice_coef: 0.0744 - u2net_output_sup2_activation_accuracy: 0.9221 - u2net_output_sup2_activation_mse: 0.1042 - u2net_output_sup3_activation_dice_coef: 0.0456 - u2net_output_sup3_activation_accuracy: 0.9786 - u2net_output_sup3_activation_mse: 0.1468 - u2net_output_sup4_activation_dice_coef: 0.0400 - u2net_output_sup4_activation_accuracy: 0.9778 - u2net_output_sup4_activation_mse: 0.1619 - u2net_output_sup5_activation_dice_coef: 0.0387 - u2net_output_sup5_activation_accuracy: 0.9776 - u2net_output_sup5_activation_mse: 0.1661 - u2net_output_final_activation_dice_coef: 0.0384 - u2net_output_final_activation_accuracy: 0.9775 - u2net_output_final_activation_mse: 0.1730 - val_loss: 2.4438 - val_u2net_output_sup0_activation_loss: 0.0417 - val_u2net_output_sup1_activation_loss: 0.0457 - val_u2net_output_sup2_activation_loss: 0.3245 - val_u2net_output_sup3_activation_loss: 0.4634 - val_u2net_output_sup4_activation_loss: 0.5099 - val_u2net_output_sup5_activation_loss: 0.5227 - val_u2net_output_final_activation_loss: 0.5359 - val_u2net_output_sup0_activation_dice_coef: 0.5154 - val_u2net_output_sup0_activation_accuracy: 0.9856 - val_u2net_output_sup0_activation_mse: 0.0111 - val_u2net_output_sup1_activation_dice_coef: 0.4731 - val_u2net_output_sup1_activation_accuracy: 0.9852 - val_u2net_output_sup1_activation_mse: 0.0116 - val_u2net_output_sup2_activation_dice_coef: 0.0754 - val_u2net_output_sup2_activation_accuracy: 0.9217 - val_u2net_output_sup2_activation_mse: 0.1050 - val_u2net_output_sup3_activation_dice_coef: 0.0492 - val_u2net_output_sup3_activation_accuracy: 0.9778 - val_u2net_output_sup3_activation_mse: 0.1475 - val_u2net_output_sup4_activation_dice_coef: 0.0440 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1623 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1664 - val_u2net_output_final_activation_dice_coef: 0.0423 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1723\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3902 - u2net_output_sup0_activation_loss: 0.0261 - u2net_output_sup1_activation_loss: 0.0298 - u2net_output_sup2_activation_loss: 0.3163 - u2net_output_sup3_activation_loss: 0.4599 - u2net_output_sup4_activation_loss: 0.5071 - u2net_output_sup5_activation_loss: 0.5200 - u2net_output_final_activation_loss: 0.5311 - u2net_output_sup0_activation_dice_coef: 0.6308 - u2net_output_sup0_activation_accuracy: 0.9874 - u2net_output_sup0_activation_mse: 0.0069 - u2net_output_sup1_activation_dice_coef: 0.5676 - u2net_output_sup1_activation_accuracy: 0.9866 - u2net_output_sup1_activation_mse: 0.0077 - u2net_output_sup2_activation_dice_coef: 0.0767 - u2net_output_sup2_activation_accuracy: 0.9218 - u2net_output_sup2_activation_mse: 0.1020 - u2net_output_sup3_activation_dice_coef: 0.0464 - u2net_output_sup3_activation_accuracy: 0.9779 - u2net_output_sup3_activation_mse: 0.1454 - u2net_output_sup4_activation_dice_coef: 0.0404 - u2net_output_sup4_activation_accuracy: 0.9771 - u2net_output_sup4_activation_mse: 0.1604 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9768 - u2net_output_sup5_activation_mse: 0.1645 - u2net_output_final_activation_dice_coef: 0.0389 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.3902 - u2net_output_sup0_activation_loss: 0.0261 - u2net_output_sup1_activation_loss: 0.0298 - u2net_output_sup2_activation_loss: 0.3163 - u2net_output_sup3_activation_loss: 0.4599 - u2net_output_sup4_activation_loss: 0.5071 - u2net_output_sup5_activation_loss: 0.5200 - u2net_output_final_activation_loss: 0.5311 - u2net_output_sup0_activation_dice_coef: 0.6308 - u2net_output_sup0_activation_accuracy: 0.9874 - u2net_output_sup0_activation_mse: 0.0069 - u2net_output_sup1_activation_dice_coef: 0.5676 - u2net_output_sup1_activation_accuracy: 0.9866 - u2net_output_sup1_activation_mse: 0.0077 - u2net_output_sup2_activation_dice_coef: 0.0767 - u2net_output_sup2_activation_accuracy: 0.9218 - u2net_output_sup2_activation_mse: 0.1020 - u2net_output_sup3_activation_dice_coef: 0.0464 - u2net_output_sup3_activation_accuracy: 0.9779 - u2net_output_sup3_activation_mse: 0.1454 - u2net_output_sup4_activation_dice_coef: 0.0404 - u2net_output_sup4_activation_accuracy: 0.9771 - u2net_output_sup4_activation_mse: 0.1604 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9768 - u2net_output_sup5_activation_mse: 0.1645 - u2net_output_final_activation_dice_coef: 0.0389 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1693 - val_loss: 2.4150 - val_u2net_output_sup0_activation_loss: 0.0348 - val_u2net_output_sup1_activation_loss: 0.0404 - val_u2net_output_sup2_activation_loss: 0.3202 - val_u2net_output_sup3_activation_loss: 0.4641 - val_u2net_output_sup4_activation_loss: 0.5077 - val_u2net_output_sup5_activation_loss: 0.5194 - val_u2net_output_final_activation_loss: 0.5283 - val_u2net_output_sup0_activation_dice_coef: 0.5713 - val_u2net_output_sup0_activation_accuracy: 0.9868 - val_u2net_output_sup0_activation_mse: 0.0098 - val_u2net_output_sup1_activation_dice_coef: 0.4916 - val_u2net_output_sup1_activation_accuracy: 0.9853 - val_u2net_output_sup1_activation_mse: 0.0112 - val_u2net_output_sup2_activation_dice_coef: 0.0841 - val_u2net_output_sup2_activation_accuracy: 0.9232 - val_u2net_output_sup2_activation_mse: 0.1034 - val_u2net_output_sup3_activation_dice_coef: 0.0511 - val_u2net_output_sup3_activation_accuracy: 0.9764 - val_u2net_output_sup3_activation_mse: 0.1474 - val_u2net_output_sup4_activation_dice_coef: 0.0444 - val_u2net_output_sup4_activation_accuracy: 0.9766 - val_u2net_output_sup4_activation_mse: 0.1611 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9767 - val_u2net_output_sup5_activation_mse: 0.1648 - val_u2net_output_final_activation_dice_coef: 0.0425 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1686\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3731 - u2net_output_sup0_activation_loss: 0.0283 - u2net_output_sup1_activation_loss: 0.0322 - u2net_output_sup2_activation_loss: 0.3117 - u2net_output_sup3_activation_loss: 0.4573 - u2net_output_sup4_activation_loss: 0.5038 - u2net_output_sup5_activation_loss: 0.5165 - u2net_output_final_activation_loss: 0.5234 - u2net_output_sup0_activation_dice_coef: 0.6136 - u2net_output_sup0_activation_accuracy: 0.9867 - u2net_output_sup0_activation_mse: 0.0075 - u2net_output_sup1_activation_dice_coef: 0.5516 - u2net_output_sup1_activation_accuracy: 0.9858 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0781 - u2net_output_sup2_activation_accuracy: 0.9220 - u2net_output_sup2_activation_mse: 0.1001 - u2net_output_sup3_activation_dice_coef: 0.0474 - u2net_output_sup3_activation_accuracy: 0.9778 - u2net_output_sup3_activation_mse: 0.1440 - u2net_output_sup4_activation_dice_coef: 0.0416 - u2net_output_sup4_activation_accuracy: 0.9771 - u2net_output_sup4_activation_mse: 0.1587 - u2net_output_sup5_activation_dice_coef: 0.0403 - u2net_output_sup5_activation_accuracy: 0.9769 - u2net_output_sup5_activation_mse: 0.1628 - u2net_output_final_activation_dice_coef: 0.0401 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.3731 - u2net_output_sup0_activation_loss: 0.0283 - u2net_output_sup1_activation_loss: 0.0322 - u2net_output_sup2_activation_loss: 0.3117 - u2net_output_sup3_activation_loss: 0.4573 - u2net_output_sup4_activation_loss: 0.5038 - u2net_output_sup5_activation_loss: 0.5165 - u2net_output_final_activation_loss: 0.5234 - u2net_output_sup0_activation_dice_coef: 0.6136 - u2net_output_sup0_activation_accuracy: 0.9867 - u2net_output_sup0_activation_mse: 0.0075 - u2net_output_sup1_activation_dice_coef: 0.5516 - u2net_output_sup1_activation_accuracy: 0.9858 - u2net_output_sup1_activation_mse: 0.0083 - u2net_output_sup2_activation_dice_coef: 0.0781 - u2net_output_sup2_activation_accuracy: 0.9220 - u2net_output_sup2_activation_mse: 0.1001 - u2net_output_sup3_activation_dice_coef: 0.0474 - u2net_output_sup3_activation_accuracy: 0.9778 - u2net_output_sup3_activation_mse: 0.1440 - u2net_output_sup4_activation_dice_coef: 0.0416 - u2net_output_sup4_activation_accuracy: 0.9771 - u2net_output_sup4_activation_mse: 0.1587 - u2net_output_sup5_activation_dice_coef: 0.0403 - u2net_output_sup5_activation_accuracy: 0.9769 - u2net_output_sup5_activation_mse: 0.1628 - u2net_output_final_activation_dice_coef: 0.0401 - u2net_output_final_activation_accuracy: 0.9768 - u2net_output_final_activation_mse: 0.1656 - val_loss: 2.7821 - val_u2net_output_sup0_activation_loss: 0.2475 - val_u2net_output_sup1_activation_loss: 0.2133 - val_u2net_output_sup2_activation_loss: 0.3195 - val_u2net_output_sup3_activation_loss: 0.4626 - val_u2net_output_sup4_activation_loss: 0.5050 - val_u2net_output_sup5_activation_loss: 0.5161 - val_u2net_output_final_activation_loss: 0.5180 - val_u2net_output_sup0_activation_dice_coef: 0.2618 - val_u2net_output_sup0_activation_accuracy: 0.8954 - val_u2net_output_sup0_activation_mse: 0.0756 - val_u2net_output_sup1_activation_dice_coef: 0.2417 - val_u2net_output_sup1_activation_accuracy: 0.9081 - val_u2net_output_sup1_activation_mse: 0.0658 - val_u2net_output_sup2_activation_dice_coef: 0.0815 - val_u2net_output_sup2_activation_accuracy: 0.9252 - val_u2net_output_sup2_activation_mse: 0.1020 - val_u2net_output_sup3_activation_dice_coef: 0.0474 - val_u2net_output_sup3_activation_accuracy: 0.9772 - val_u2net_output_sup3_activation_mse: 0.1456 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9768 - val_u2net_output_sup4_activation_mse: 0.1594 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9767 - val_u2net_output_sup5_activation_mse: 0.1631 - val_u2net_output_final_activation_dice_coef: 0.0419 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1637\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3478 - u2net_output_sup0_activation_loss: 0.0276 - u2net_output_sup1_activation_loss: 0.0319 - u2net_output_sup2_activation_loss: 0.3054 - u2net_output_sup3_activation_loss: 0.4540 - u2net_output_sup4_activation_loss: 0.5003 - u2net_output_sup5_activation_loss: 0.5128 - u2net_output_final_activation_loss: 0.5158 - u2net_output_sup0_activation_dice_coef: 0.5943 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5274 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0082 - u2net_output_sup2_activation_dice_coef: 0.0789 - u2net_output_sup2_activation_accuracy: 0.9232 - u2net_output_sup2_activation_mse: 0.0976 - u2net_output_sup3_activation_dice_coef: 0.0468 - u2net_output_sup3_activation_accuracy: 0.9781 - u2net_output_sup3_activation_mse: 0.1426 - u2net_output_sup4_activation_dice_coef: 0.0411 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1571 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9771 - u2net_output_sup5_activation_mse: 0.1610 - u2net_output_final_activation_dice_coef: 0.0398 - u2net_output_final_activation_accuracy: 0.9771 - u2net_output_final_activation_mse: 0.1620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.3478 - u2net_output_sup0_activation_loss: 0.0276 - u2net_output_sup1_activation_loss: 0.0319 - u2net_output_sup2_activation_loss: 0.3054 - u2net_output_sup3_activation_loss: 0.4540 - u2net_output_sup4_activation_loss: 0.5003 - u2net_output_sup5_activation_loss: 0.5128 - u2net_output_final_activation_loss: 0.5158 - u2net_output_sup0_activation_dice_coef: 0.5943 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0073 - u2net_output_sup1_activation_dice_coef: 0.5274 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0082 - u2net_output_sup2_activation_dice_coef: 0.0789 - u2net_output_sup2_activation_accuracy: 0.9232 - u2net_output_sup2_activation_mse: 0.0976 - u2net_output_sup3_activation_dice_coef: 0.0468 - u2net_output_sup3_activation_accuracy: 0.9781 - u2net_output_sup3_activation_mse: 0.1426 - u2net_output_sup4_activation_dice_coef: 0.0411 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1571 - u2net_output_sup5_activation_dice_coef: 0.0399 - u2net_output_sup5_activation_accuracy: 0.9771 - u2net_output_sup5_activation_mse: 0.1610 - u2net_output_final_activation_dice_coef: 0.0398 - u2net_output_final_activation_accuracy: 0.9771 - u2net_output_final_activation_mse: 0.1620 - val_loss: 2.3743 - val_u2net_output_sup0_activation_loss: 0.0350 - val_u2net_output_sup1_activation_loss: 0.0407 - val_u2net_output_sup2_activation_loss: 0.3104 - val_u2net_output_sup3_activation_loss: 0.4605 - val_u2net_output_sup4_activation_loss: 0.5014 - val_u2net_output_sup5_activation_loss: 0.5124 - val_u2net_output_final_activation_loss: 0.5139 - val_u2net_output_sup0_activation_dice_coef: 0.5385 - val_u2net_output_sup0_activation_accuracy: 0.9860 - val_u2net_output_sup0_activation_mse: 0.0102 - val_u2net_output_sup1_activation_dice_coef: 0.4892 - val_u2net_output_sup1_activation_accuracy: 0.9847 - val_u2net_output_sup1_activation_mse: 0.0115 - val_u2net_output_sup2_activation_dice_coef: 0.0910 - val_u2net_output_sup2_activation_accuracy: 0.9272 - val_u2net_output_sup2_activation_mse: 0.0993 - val_u2net_output_sup3_activation_dice_coef: 0.0521 - val_u2net_output_sup3_activation_accuracy: 0.9755 - val_u2net_output_sup3_activation_mse: 0.1453 - val_u2net_output_sup4_activation_dice_coef: 0.0445 - val_u2net_output_sup4_activation_accuracy: 0.9764 - val_u2net_output_sup4_activation_mse: 0.1580 - val_u2net_output_sup5_activation_dice_coef: 0.0428 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1614 - val_u2net_output_final_activation_dice_coef: 0.0425 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1617\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3308 - u2net_output_sup0_activation_loss: 0.0295 - u2net_output_sup1_activation_loss: 0.0329 - u2net_output_sup2_activation_loss: 0.3005 - u2net_output_sup3_activation_loss: 0.4515 - u2net_output_sup4_activation_loss: 0.4975 - u2net_output_sup5_activation_loss: 0.5099 - u2net_output_final_activation_loss: 0.5091 - u2net_output_sup0_activation_dice_coef: 0.6097 - u2net_output_sup0_activation_accuracy: 0.9859 - u2net_output_sup0_activation_mse: 0.0079 - u2net_output_sup1_activation_dice_coef: 0.5517 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0086 - u2net_output_sup2_activation_dice_coef: 0.0827 - u2net_output_sup2_activation_accuracy: 0.9243 - u2net_output_sup2_activation_mse: 0.0957 - u2net_output_sup3_activation_dice_coef: 0.0486 - u2net_output_sup3_activation_accuracy: 0.9767 - u2net_output_sup3_activation_mse: 0.1414 - u2net_output_sup4_activation_dice_coef: 0.0425 - u2net_output_sup4_activation_accuracy: 0.9759 - u2net_output_sup4_activation_mse: 0.1557 - u2net_output_sup5_activation_dice_coef: 0.0412 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1596 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.9756 - u2net_output_final_activation_mse: 0.1587"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.3308 - u2net_output_sup0_activation_loss: 0.0295 - u2net_output_sup1_activation_loss: 0.0329 - u2net_output_sup2_activation_loss: 0.3005 - u2net_output_sup3_activation_loss: 0.4515 - u2net_output_sup4_activation_loss: 0.4975 - u2net_output_sup5_activation_loss: 0.5099 - u2net_output_final_activation_loss: 0.5091 - u2net_output_sup0_activation_dice_coef: 0.6097 - u2net_output_sup0_activation_accuracy: 0.9859 - u2net_output_sup0_activation_mse: 0.0079 - u2net_output_sup1_activation_dice_coef: 0.5517 - u2net_output_sup1_activation_accuracy: 0.9852 - u2net_output_sup1_activation_mse: 0.0086 - u2net_output_sup2_activation_dice_coef: 0.0827 - u2net_output_sup2_activation_accuracy: 0.9243 - u2net_output_sup2_activation_mse: 0.0957 - u2net_output_sup3_activation_dice_coef: 0.0486 - u2net_output_sup3_activation_accuracy: 0.9767 - u2net_output_sup3_activation_mse: 0.1414 - u2net_output_sup4_activation_dice_coef: 0.0425 - u2net_output_sup4_activation_accuracy: 0.9759 - u2net_output_sup4_activation_mse: 0.1557 - u2net_output_sup5_activation_dice_coef: 0.0412 - u2net_output_sup5_activation_accuracy: 0.9756 - u2net_output_sup5_activation_mse: 0.1596 - u2net_output_final_activation_dice_coef: 0.0411 - u2net_output_final_activation_accuracy: 0.9756 - u2net_output_final_activation_mse: 0.1587 - val_loss: 2.3418 - val_u2net_output_sup0_activation_loss: 0.0383 - val_u2net_output_sup1_activation_loss: 0.0414 - val_u2net_output_sup2_activation_loss: 0.3006 - val_u2net_output_sup3_activation_loss: 0.4504 - val_u2net_output_sup4_activation_loss: 0.4962 - val_u2net_output_sup5_activation_loss: 0.5086 - val_u2net_output_final_activation_loss: 0.5061 - val_u2net_output_sup0_activation_dice_coef: 0.5250 - val_u2net_output_sup0_activation_accuracy: 0.9863 - val_u2net_output_sup0_activation_mse: 0.0104 - val_u2net_output_sup1_activation_dice_coef: 0.4647 - val_u2net_output_sup1_activation_accuracy: 0.9848 - val_u2net_output_sup1_activation_mse: 0.0114 - val_u2net_output_sup2_activation_dice_coef: 0.0742 - val_u2net_output_sup2_activation_accuracy: 0.9265 - val_u2net_output_sup2_activation_mse: 0.0964 - val_u2net_output_sup3_activation_dice_coef: 0.0491 - val_u2net_output_sup3_activation_accuracy: 0.9779 - val_u2net_output_sup3_activation_mse: 0.1417 - val_u2net_output_sup4_activation_dice_coef: 0.0438 - val_u2net_output_sup4_activation_accuracy: 0.9771 - val_u2net_output_sup4_activation_mse: 0.1558 - val_u2net_output_sup5_activation_dice_coef: 0.0426 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1597 - val_u2net_output_final_activation_dice_coef: 0.0429 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1580\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3009 - u2net_output_sup0_activation_loss: 0.0271 - u2net_output_sup1_activation_loss: 0.0305 - u2net_output_sup2_activation_loss: 0.2936 - u2net_output_sup3_activation_loss: 0.4480 - u2net_output_sup4_activation_loss: 0.4938 - u2net_output_sup5_activation_loss: 0.5062 - u2net_output_final_activation_loss: 0.5018 - u2net_output_sup0_activation_dice_coef: 0.6253 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0072 - u2net_output_sup1_activation_dice_coef: 0.5666 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0846 - u2net_output_sup2_activation_accuracy: 0.9404 - u2net_output_sup2_activation_mse: 0.0931 - u2net_output_sup3_activation_dice_coef: 0.0486 - u2net_output_sup3_activation_accuracy: 0.9774 - u2net_output_sup3_activation_mse: 0.1398 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9765 - u2net_output_sup4_activation_mse: 0.1540 - u2net_output_sup5_activation_dice_coef: 0.0408 - u2net_output_sup5_activation_accuracy: 0.9763 - u2net_output_sup5_activation_mse: 0.1579 - u2net_output_final_activation_dice_coef: 0.0409 - u2net_output_final_activation_accuracy: 0.9762 - u2net_output_final_activation_mse: 0.1552"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.3009 - u2net_output_sup0_activation_loss: 0.0271 - u2net_output_sup1_activation_loss: 0.0305 - u2net_output_sup2_activation_loss: 0.2936 - u2net_output_sup3_activation_loss: 0.4480 - u2net_output_sup4_activation_loss: 0.4938 - u2net_output_sup5_activation_loss: 0.5062 - u2net_output_final_activation_loss: 0.5018 - u2net_output_sup0_activation_dice_coef: 0.6253 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0072 - u2net_output_sup1_activation_dice_coef: 0.5666 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0846 - u2net_output_sup2_activation_accuracy: 0.9404 - u2net_output_sup2_activation_mse: 0.0931 - u2net_output_sup3_activation_dice_coef: 0.0486 - u2net_output_sup3_activation_accuracy: 0.9774 - u2net_output_sup3_activation_mse: 0.1398 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9765 - u2net_output_sup4_activation_mse: 0.1540 - u2net_output_sup5_activation_dice_coef: 0.0408 - u2net_output_sup5_activation_accuracy: 0.9763 - u2net_output_sup5_activation_mse: 0.1579 - u2net_output_final_activation_dice_coef: 0.0409 - u2net_output_final_activation_accuracy: 0.9762 - u2net_output_final_activation_mse: 0.1552 - val_loss: 2.3234 - val_u2net_output_sup0_activation_loss: 0.0378 - val_u2net_output_sup1_activation_loss: 0.0425 - val_u2net_output_sup2_activation_loss: 0.2959 - val_u2net_output_sup3_activation_loss: 0.4493 - val_u2net_output_sup4_activation_loss: 0.4933 - val_u2net_output_sup5_activation_loss: 0.5053 - val_u2net_output_final_activation_loss: 0.4993 - val_u2net_output_sup0_activation_dice_coef: 0.5297 - val_u2net_output_sup0_activation_accuracy: 0.9856 - val_u2net_output_sup0_activation_mse: 0.0108 - val_u2net_output_sup1_activation_dice_coef: 0.4796 - val_u2net_output_sup1_activation_accuracy: 0.9848 - val_u2net_output_sup1_activation_mse: 0.0117 - val_u2net_output_sup2_activation_dice_coef: 0.0859 - val_u2net_output_sup2_activation_accuracy: 0.9793 - val_u2net_output_sup2_activation_mse: 0.0938 - val_u2net_output_sup3_activation_dice_coef: 0.0503 - val_u2net_output_sup3_activation_accuracy: 0.9778 - val_u2net_output_sup3_activation_mse: 0.1407 - val_u2net_output_sup4_activation_dice_coef: 0.0440 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1543 - val_u2net_output_sup5_activation_dice_coef: 0.0427 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1581 - val_u2net_output_final_activation_dice_coef: 0.0427 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1547\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2771 - u2net_output_sup0_activation_loss: 0.0268 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2881 - u2net_output_sup3_activation_loss: 0.4448 - u2net_output_sup4_activation_loss: 0.4902 - u2net_output_sup5_activation_loss: 0.5024 - u2net_output_final_activation_loss: 0.4945 - u2net_output_sup0_activation_dice_coef: 0.6072 - u2net_output_sup0_activation_accuracy: 0.9873 - u2net_output_sup0_activation_mse: 0.0071 - u2net_output_sup1_activation_dice_coef: 0.5491 - u2net_output_sup1_activation_accuracy: 0.9864 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0802 - u2net_output_sup2_activation_accuracy: 0.9813 - u2net_output_sup2_activation_mse: 0.0907 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9781 - u2net_output_sup3_activation_mse: 0.1384 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1523 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9771 - u2net_output_sup5_activation_mse: 0.1561 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9771 - u2net_output_final_activation_mse: 0.1518"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.2771 - u2net_output_sup0_activation_loss: 0.0268 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2881 - u2net_output_sup3_activation_loss: 0.4448 - u2net_output_sup4_activation_loss: 0.4902 - u2net_output_sup5_activation_loss: 0.5024 - u2net_output_final_activation_loss: 0.4945 - u2net_output_sup0_activation_dice_coef: 0.6072 - u2net_output_sup0_activation_accuracy: 0.9873 - u2net_output_sup0_activation_mse: 0.0071 - u2net_output_sup1_activation_dice_coef: 0.5491 - u2net_output_sup1_activation_accuracy: 0.9864 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0802 - u2net_output_sup2_activation_accuracy: 0.9813 - u2net_output_sup2_activation_mse: 0.0907 - u2net_output_sup3_activation_dice_coef: 0.0462 - u2net_output_sup3_activation_accuracy: 0.9781 - u2net_output_sup3_activation_mse: 0.1384 - u2net_output_sup4_activation_dice_coef: 0.0403 - u2net_output_sup4_activation_accuracy: 0.9773 - u2net_output_sup4_activation_mse: 0.1523 - u2net_output_sup5_activation_dice_coef: 0.0391 - u2net_output_sup5_activation_accuracy: 0.9771 - u2net_output_sup5_activation_mse: 0.1561 - u2net_output_final_activation_dice_coef: 0.0392 - u2net_output_final_activation_accuracy: 0.9771 - u2net_output_final_activation_mse: 0.1518 - val_loss: 2.3651 - val_u2net_output_sup0_activation_loss: 0.0642 - val_u2net_output_sup1_activation_loss: 0.0590 - val_u2net_output_sup2_activation_loss: 0.3083 - val_u2net_output_sup3_activation_loss: 0.4480 - val_u2net_output_sup4_activation_loss: 0.4911 - val_u2net_output_sup5_activation_loss: 0.5022 - val_u2net_output_final_activation_loss: 0.4923 - val_u2net_output_sup0_activation_dice_coef: 0.3336 - val_u2net_output_sup0_activation_accuracy: 0.9809 - val_u2net_output_sup0_activation_mse: 0.0154 - val_u2net_output_sup1_activation_dice_coef: 0.3014 - val_u2net_output_sup1_activation_accuracy: 0.9803 - val_u2net_output_sup1_activation_mse: 0.0155 - val_u2net_output_sup2_activation_dice_coef: 0.0526 - val_u2net_output_sup2_activation_accuracy: 0.9774 - val_u2net_output_sup2_activation_mse: 0.0950 - val_u2net_output_sup3_activation_dice_coef: 0.0473 - val_u2net_output_sup3_activation_accuracy: 0.9775 - val_u2net_output_sup3_activation_mse: 0.1394 - val_u2net_output_sup4_activation_dice_coef: 0.0430 - val_u2net_output_sup4_activation_accuracy: 0.9769 - val_u2net_output_sup4_activation_mse: 0.1529 - val_u2net_output_sup5_activation_dice_coef: 0.0424 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1565 - val_u2net_output_final_activation_dice_coef: 0.0425 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1514\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2565 - u2net_output_sup0_activation_loss: 0.0269 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2822 - u2net_output_sup3_activation_loss: 0.4423 - u2net_output_sup4_activation_loss: 0.4873 - u2net_output_sup5_activation_loss: 0.4995 - u2net_output_final_activation_loss: 0.4881 - u2net_output_sup0_activation_dice_coef: 0.6356 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0071 - u2net_output_sup1_activation_dice_coef: 0.5779 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0878 - u2net_output_sup2_activation_accuracy: 0.9808 - u2net_output_sup2_activation_mse: 0.0883 - u2net_output_sup3_activation_dice_coef: 0.0491 - u2net_output_sup3_activation_accuracy: 0.9770 - u2net_output_sup3_activation_mse: 0.1371 - u2net_output_sup4_activation_dice_coef: 0.0426 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1509 - u2net_output_sup5_activation_dice_coef: 0.0412 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1547 - u2net_output_final_activation_dice_coef: 0.0415 - u2net_output_final_activation_accuracy: 0.9758 - u2net_output_final_activation_mse: 0.1487"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 107s 1s/step - loss: 2.2565 - u2net_output_sup0_activation_loss: 0.0269 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2822 - u2net_output_sup3_activation_loss: 0.4423 - u2net_output_sup4_activation_loss: 0.4873 - u2net_output_sup5_activation_loss: 0.4995 - u2net_output_final_activation_loss: 0.4881 - u2net_output_sup0_activation_dice_coef: 0.6356 - u2net_output_sup0_activation_accuracy: 0.9870 - u2net_output_sup0_activation_mse: 0.0071 - u2net_output_sup1_activation_dice_coef: 0.5779 - u2net_output_sup1_activation_accuracy: 0.9862 - u2net_output_sup1_activation_mse: 0.0079 - u2net_output_sup2_activation_dice_coef: 0.0878 - u2net_output_sup2_activation_accuracy: 0.9808 - u2net_output_sup2_activation_mse: 0.0883 - u2net_output_sup3_activation_dice_coef: 0.0491 - u2net_output_sup3_activation_accuracy: 0.9770 - u2net_output_sup3_activation_mse: 0.1371 - u2net_output_sup4_activation_dice_coef: 0.0426 - u2net_output_sup4_activation_accuracy: 0.9761 - u2net_output_sup4_activation_mse: 0.1509 - u2net_output_sup5_activation_dice_coef: 0.0412 - u2net_output_sup5_activation_accuracy: 0.9759 - u2net_output_sup5_activation_mse: 0.1547 - u2net_output_final_activation_dice_coef: 0.0415 - u2net_output_final_activation_accuracy: 0.9758 - u2net_output_final_activation_mse: 0.1487 - val_loss: 2.2691 - val_u2net_output_sup0_activation_loss: 0.0350 - val_u2net_output_sup1_activation_loss: 0.0386 - val_u2net_output_sup2_activation_loss: 0.2834 - val_u2net_output_sup3_activation_loss: 0.4418 - val_u2net_output_sup4_activation_loss: 0.4864 - val_u2net_output_sup5_activation_loss: 0.4984 - val_u2net_output_final_activation_loss: 0.4855 - val_u2net_output_sup0_activation_dice_coef: 0.5488 - val_u2net_output_sup0_activation_accuracy: 0.9864 - val_u2net_output_sup0_activation_mse: 0.0101 - val_u2net_output_sup1_activation_dice_coef: 0.5003 - val_u2net_output_sup1_activation_accuracy: 0.9858 - val_u2net_output_sup1_activation_mse: 0.0108 - val_u2net_output_sup2_activation_dice_coef: 0.0895 - val_u2net_output_sup2_activation_accuracy: 0.9810 - val_u2net_output_sup2_activation_mse: 0.0889 - val_u2net_output_sup3_activation_dice_coef: 0.0506 - val_u2net_output_sup3_activation_accuracy: 0.9779 - val_u2net_output_sup3_activation_mse: 0.1376 - val_u2net_output_sup4_activation_dice_coef: 0.0440 - val_u2net_output_sup4_activation_accuracy: 0.9771 - val_u2net_output_sup4_activation_mse: 0.1511 - val_u2net_output_sup5_activation_dice_coef: 0.0426 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1549 - val_u2net_output_final_activation_dice_coef: 0.0429 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1482\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2254 - u2net_output_sup0_activation_loss: 0.0257 - u2net_output_sup1_activation_loss: 0.0282 - u2net_output_sup2_activation_loss: 0.2747 - u2net_output_sup3_activation_loss: 0.4381 - u2net_output_sup4_activation_loss: 0.4830 - u2net_output_sup5_activation_loss: 0.4952 - u2net_output_final_activation_loss: 0.4805 - u2net_output_sup0_activation_dice_coef: 0.6291 - u2net_output_sup0_activation_accuracy: 0.9877 - u2net_output_sup0_activation_mse: 0.0068 - u2net_output_sup1_activation_dice_coef: 0.5771 - u2net_output_sup1_activation_accuracy: 0.9871 - u2net_output_sup1_activation_mse: 0.0074 - u2net_output_sup2_activation_dice_coef: 0.0836 - u2net_output_sup2_activation_accuracy: 0.9824 - u2net_output_sup2_activation_mse: 0.0852 - u2net_output_sup3_activation_dice_coef: 0.0455 - u2net_output_sup3_activation_accuracy: 0.9791 - u2net_output_sup3_activation_mse: 0.1353 - u2net_output_sup4_activation_dice_coef: 0.0394 - u2net_output_sup4_activation_accuracy: 0.9783 - u2net_output_sup4_activation_mse: 0.1489 - u2net_output_sup5_activation_dice_coef: 0.0381 - u2net_output_sup5_activation_accuracy: 0.9781 - u2net_output_sup5_activation_mse: 0.1527 - u2net_output_final_activation_dice_coef: 0.0384 - u2net_output_final_activation_accuracy: 0.9780 - u2net_output_final_activation_mse: 0.1452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.2254 - u2net_output_sup0_activation_loss: 0.0257 - u2net_output_sup1_activation_loss: 0.0282 - u2net_output_sup2_activation_loss: 0.2747 - u2net_output_sup3_activation_loss: 0.4381 - u2net_output_sup4_activation_loss: 0.4830 - u2net_output_sup5_activation_loss: 0.4952 - u2net_output_final_activation_loss: 0.4805 - u2net_output_sup0_activation_dice_coef: 0.6291 - u2net_output_sup0_activation_accuracy: 0.9877 - u2net_output_sup0_activation_mse: 0.0068 - u2net_output_sup1_activation_dice_coef: 0.5771 - u2net_output_sup1_activation_accuracy: 0.9871 - u2net_output_sup1_activation_mse: 0.0074 - u2net_output_sup2_activation_dice_coef: 0.0836 - u2net_output_sup2_activation_accuracy: 0.9824 - u2net_output_sup2_activation_mse: 0.0852 - u2net_output_sup3_activation_dice_coef: 0.0455 - u2net_output_sup3_activation_accuracy: 0.9791 - u2net_output_sup3_activation_mse: 0.1353 - u2net_output_sup4_activation_dice_coef: 0.0394 - u2net_output_sup4_activation_accuracy: 0.9783 - u2net_output_sup4_activation_mse: 0.1489 - u2net_output_sup5_activation_dice_coef: 0.0381 - u2net_output_sup5_activation_accuracy: 0.9781 - u2net_output_sup5_activation_mse: 0.1527 - u2net_output_final_activation_dice_coef: 0.0384 - u2net_output_final_activation_accuracy: 0.9780 - u2net_output_final_activation_mse: 0.1452 - val_loss: 2.2482 - val_u2net_output_sup0_activation_loss: 0.0343 - val_u2net_output_sup1_activation_loss: 0.0395 - val_u2net_output_sup2_activation_loss: 0.2773 - val_u2net_output_sup3_activation_loss: 0.4397 - val_u2net_output_sup4_activation_loss: 0.4834 - val_u2net_output_sup5_activation_loss: 0.4951 - val_u2net_output_final_activation_loss: 0.4788 - val_u2net_output_sup0_activation_dice_coef: 0.5486 - val_u2net_output_sup0_activation_accuracy: 0.9869 - val_u2net_output_sup0_activation_mse: 0.0098 - val_u2net_output_sup1_activation_dice_coef: 0.4880 - val_u2net_output_sup1_activation_accuracy: 0.9856 - val_u2net_output_sup1_activation_mse: 0.0110 - val_u2net_output_sup2_activation_dice_coef: 0.0786 - val_u2net_output_sup2_activation_accuracy: 0.9809 - val_u2net_output_sup2_activation_mse: 0.0863 - val_u2net_output_sup3_activation_dice_coef: 0.0478 - val_u2net_output_sup3_activation_accuracy: 0.9777 - val_u2net_output_sup3_activation_mse: 0.1364 - val_u2net_output_sup4_activation_dice_coef: 0.0435 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1496 - val_u2net_output_sup5_activation_dice_coef: 0.0425 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1533 - val_u2net_output_final_activation_dice_coef: 0.0429 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1451\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2119 - u2net_output_sup0_activation_loss: 0.0272 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2698 - u2net_output_sup3_activation_loss: 0.4364 - u2net_output_sup4_activation_loss: 0.4808 - u2net_output_sup5_activation_loss: 0.4928 - u2net_output_final_activation_loss: 0.4748 - u2net_output_sup0_activation_dice_coef: 0.6158 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0072 - u2net_output_sup1_activation_dice_coef: 0.5620 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0080 - u2net_output_sup2_activation_dice_coef: 0.0901 - u2net_output_sup2_activation_accuracy: 0.9808 - u2net_output_sup2_activation_mse: 0.0829 - u2net_output_sup3_activation_dice_coef: 0.0487 - u2net_output_sup3_activation_accuracy: 0.9771 - u2net_output_sup3_activation_mse: 0.1344 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9762 - u2net_output_sup4_activation_mse: 0.1478 - u2net_output_sup5_activation_dice_coef: 0.0408 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.1515 - u2net_output_final_activation_dice_coef: 0.0413 - u2net_output_final_activation_accuracy: 0.9759 - u2net_output_final_activation_mse: 0.1425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_dice_coef available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 106s 1s/step - loss: 2.2119 - u2net_output_sup0_activation_loss: 0.0272 - u2net_output_sup1_activation_loss: 0.0302 - u2net_output_sup2_activation_loss: 0.2698 - u2net_output_sup3_activation_loss: 0.4364 - u2net_output_sup4_activation_loss: 0.4808 - u2net_output_sup5_activation_loss: 0.4928 - u2net_output_final_activation_loss: 0.4748 - u2net_output_sup0_activation_dice_coef: 0.6158 - u2net_output_sup0_activation_accuracy: 0.9869 - u2net_output_sup0_activation_mse: 0.0072 - u2net_output_sup1_activation_dice_coef: 0.5620 - u2net_output_sup1_activation_accuracy: 0.9860 - u2net_output_sup1_activation_mse: 0.0080 - u2net_output_sup2_activation_dice_coef: 0.0901 - u2net_output_sup2_activation_accuracy: 0.9808 - u2net_output_sup2_activation_mse: 0.0829 - u2net_output_sup3_activation_dice_coef: 0.0487 - u2net_output_sup3_activation_accuracy: 0.9771 - u2net_output_sup3_activation_mse: 0.1344 - u2net_output_sup4_activation_dice_coef: 0.0422 - u2net_output_sup4_activation_accuracy: 0.9762 - u2net_output_sup4_activation_mse: 0.1478 - u2net_output_sup5_activation_dice_coef: 0.0408 - u2net_output_sup5_activation_accuracy: 0.9760 - u2net_output_sup5_activation_mse: 0.1515 - u2net_output_final_activation_dice_coef: 0.0413 - u2net_output_final_activation_accuracy: 0.9759 - u2net_output_final_activation_mse: 0.1425 - val_loss: 2.2229 - val_u2net_output_sup0_activation_loss: 0.0345 - val_u2net_output_sup1_activation_loss: 0.0381 - val_u2net_output_sup2_activation_loss: 0.2694 - val_u2net_output_sup3_activation_loss: 0.4363 - val_u2net_output_sup4_activation_loss: 0.4802 - val_u2net_output_sup5_activation_loss: 0.4919 - val_u2net_output_final_activation_loss: 0.4724 - val_u2net_output_sup0_activation_dice_coef: 0.5488 - val_u2net_output_sup0_activation_accuracy: 0.9870 - val_u2net_output_sup0_activation_mse: 0.0097 - val_u2net_output_sup1_activation_dice_coef: 0.4976 - val_u2net_output_sup1_activation_accuracy: 0.9861 - val_u2net_output_sup1_activation_mse: 0.0105 - val_u2net_output_sup2_activation_dice_coef: 0.0833 - val_u2net_output_sup2_activation_accuracy: 0.9812 - val_u2net_output_sup2_activation_mse: 0.0831 - val_u2net_output_sup3_activation_dice_coef: 0.0489 - val_u2net_output_sup3_activation_accuracy: 0.9778 - val_u2net_output_sup3_activation_mse: 0.1349 - val_u2net_output_sup4_activation_dice_coef: 0.0436 - val_u2net_output_sup4_activation_accuracy: 0.9770 - val_u2net_output_sup4_activation_mse: 0.1481 - val_u2net_output_sup5_activation_dice_coef: 0.0425 - val_u2net_output_sup5_activation_accuracy: 0.9768 - val_u2net_output_sup5_activation_mse: 0.1517 - val_u2net_output_final_activation_dice_coef: 0.0430 - val_u2net_output_final_activation_accuracy: 0.9768 - val_u2net_output_final_activation_mse: 0.1421\n",
            "Total time to train: 5398.457995891571\n"
          ]
        }
      ],
      "source": [
        "# Train ResUNet with generator\n",
        "# def u2net(n_labels, filter_num_down, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "u2net_tall = u2net(2, [32, 64, 128, 256], input_size=(tileSize, tileSize, 3))\n",
        "# u2net_tall = load_model('Output/u2net_tall/u2net_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/u2net_tall\", \"u2net_tall\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True)]\n",
        "\n",
        "\n",
        "train_rgb_tall = TrainGenerator(4, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "u2net_tall = train(u2net_tall, callbacks, train_rgb_tall, validation_df, \"u2net_tall\", epochs=50, steps_per_epoch=100)\n",
        "# Total 70 epochs total"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYI5BUfYvhhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrMvEtwPpUVd"
      },
      "source": [
        "### **Swin U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Swin UNet with generator\n",
        "# swin_unet_tall = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "swin_unet_tall = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "# swin_unet_tall.load_weights('Output/swin_unet_tall/swin_unet_tall.hdf5')\n",
        "\n",
        "# r2_unet = load_model('Output/r2_unet_tall/r2_unet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/swin_unet_tall\", \"swin_unet_tall\"+\".hdf5\"),\n",
        "                             monitor='val_loss',verbose=1, save_weights_only=True, save_best_only=True)]\n",
        "\n",
        "\n",
        "train_rgb_tall = TrainGenerator(1, images_rgb, tall_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTest], [n.reshape(1,tileSize,tileSize,1) for n in yTestTall]))\n",
        "\n",
        "# Trained for 60 epochs total\n",
        "swin_unet_tall = train(swin_unet_tall, callbacks, train_rgb_tall, validation_df, \"swin_unet_tall\", epochs=40, steps_per_epoch=100)"
      ],
      "metadata": {
        "id": "0KgN3Mfn7-JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fND8lJisl2XL"
      },
      "outputs": [],
      "source": [
        "print(swin_unet_tall)\n",
        "swin_unet_tall.save_weights('Output/swin_unet_tall')\n",
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_batch = next(train_rgb_tall)\n",
        "input_data, labels = sample_batch\n",
        "\n",
        "print(\"Input data shape:\", input_data.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN1a3BEZ6JGj",
        "outputId": "4d83ce43-d207-4a6d-ffa4-85611f3bdfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: (1, 512, 512, 3)\n",
            "Labels shape: (1, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InHicdICHRpI"
      },
      "source": [
        "## **Training on short plants**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAAmkWbPHbGV"
      },
      "source": [
        "\n",
        "### **UNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daFnj_erHd2e"
      },
      "outputs": [],
      "source": [
        "uNet_short = UNet(input_size=(tileSize,tileSize,3))\n",
        "unet_short = load_model('Output/unet_short/unet_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ EarlyStopping(patience=200, monitor=\"val_dice_coef\"),\n",
        "                 ModelCheckpoint(os.path.join(\"Output/unet_short\", \"unet_short.hdf5\"),\n",
        "                 monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max') ]\n",
        "\n",
        "train_rgb_short = TrainGenerator(8, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "uNet_short = train(unet_short, callbacks, train_rgb_short, validation_df, \"unet_short\", epochs=40, steps_per_epoch=100)\n",
        "# Total 120 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afXSl7YrIlGD"
      },
      "source": [
        "### **Attention UNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgqXvSWmIt9u"
      },
      "outputs": [],
      "source": [
        "uNetAM_short = UNetAM(input_size=(tileSize,tileSize,3), batch_size=1)\n",
        "model_amu_short = load_model('Output/unetAM_short/unetAM_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ EarlyStopping(patience=200, monitor=\"val_dice_coef\"),\n",
        "                 ModelCheckpoint(os.path.join(\"Output/unetAM_short\", \"unetAM_short\"+\".hdf5\"),\n",
        "                 monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max') ]\n",
        "\n",
        "train_rgb_short = TrainGenerator(1, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "uNetAM_ahort = train(model_amu_short, callbacks, train_rgb_short, validation_df, \"unetAM_short\", batch_size=1, epochs=500, steps_per_epoch=100)\n",
        "\n",
        "# Total epochs 1000 (500+500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbLTQG0pIlu8"
      },
      "source": [
        "### **ResNet50SegNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8huG_YziJN3Z"
      },
      "outputs": [],
      "source": [
        "# resNet_ = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "res50 = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "# res50.load_weights('Output/resNet_short/resNet_short.hdf5')\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resNet_short\", \"resNet_short.hdf5\"), monitor='val_dice_coef', save_weights_only=True, mode='max', verbose=1, save_best_only=True)]\n",
        "# callbacks = []\n",
        "train_rgb_short = TrainGenerator(4, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "resNet_short = train(res50, callbacks, train_rgb_short, validation_df, \"resNet_short\", epochs=20, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWECfnNdJjqk"
      },
      "source": [
        "### **FCN32-VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty1gTQCZJoAq"
      },
      "outputs": [],
      "source": [
        "# Train FCN32 with generator\n",
        "fcn32_short = fcn_32(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "# fcn_short = load_model('Output/fcn32_short/fcn32_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/fcn32_short\", \"fcn32_short\"+\".hdf5\"),\n",
        "                             monitor='val_loss',verbose=1, save_best_only=True)]\n",
        "train_rgb_short = TrainGenerator(8, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "fcn32_short = train(fcn32_short, callbacks, train_rgb_short, validation_df, \"fcn32_short\", epochs=60, steps_per_epoch=100)\n",
        "\n",
        "# Total 80 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPmfN9SSKBbD"
      },
      "source": [
        "### **ResUNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMSEI5S2KERl"
      },
      "outputs": [],
      "source": [
        "# Train ResUNet with generator\n",
        "resUNet_short = res_unet(tileSize, [32, 64, 128, 256], 3, 3, 1)\n",
        "# resUNet_short = load_model('Output/resUNet_short/resUNet_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resUNet_short\", \"resUNet_short\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_short = TrainGenerator(4, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "resUNet_short = train(resUNet_short, callbacks, train_rgb_short, validation_df, \"resUNet_short\", epochs=50, steps_per_epoch=100)\n",
        "# Total 70"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUdhW6ujKT8m"
      },
      "source": [
        "### **Attention ResUNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiPd87maKTSw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_array_ops import const\n",
        "# Train Res Attention UNet with generator\n",
        "resaunet_short_ = att_res_unet(tileSize, [32, 64, 128, 256], 3, 3, 1, lr = 0.0005)\n",
        "# aresUNet = load_model('Output/resaunet_short/resaunet_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/resaunet_short\", \"resaunet_short\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "\n",
        "train_rgb_short = TrainGenerator(4, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "resaunet_short = train(resaunet_short_, callbacks, train_rgb_short, validation_df, \"resaunet_short\", epochs=60, steps_per_epoch=100)\n",
        "\n",
        "\n",
        "\n",
        "# JUST THE PROBABILITY!!!!! MULTI SCALE PATCH SIZE\n",
        "# UNTIL 26th for all result including innovation\n",
        "\n",
        "# trained more unets on 512, 256 when constrained\n",
        "# metrics between 512 and 256 for unet^2?\n",
        "\n",
        "# Stitch together for U^2 256\n",
        "# Load in swin\n",
        "# Stitch for swin\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GFg0Pq2QQdG"
      },
      "source": [
        "### **UNet++**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5brEqELzQ4Vk"
      },
      "outputs": [],
      "source": [
        "# Train ResUNet with generator\n",
        "uNetplus_short = unet_plus([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3))\n",
        "# resUNet = load_model('Output/resUNet_tall/resUNet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/unet_plus_short\", \"unet_plus_short\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_short = TrainGenerator(8, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "uNetplus_short = train(uNetplus_short, callbacks, train_rgb_short, validation_df, \"unet_plus_short\", epochs=20, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArcD9FpmQVZv"
      },
      "source": [
        "### **R2 U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbpkqWn9Rd3A"
      },
      "outputs": [],
      "source": [
        "# Train ResUNet with generator\n",
        "r2_unet_short = r2_unet([64, 128, 256, 512], 1, input_size=(tileSize,tileSize,3))\n",
        "r2_unet = load_model('Output/r2_unet_short_256/r2_unet_short_256.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/r2_unet_short_256\", \"r2_unet_short_256\"+\".hdf5\"),\n",
        "                             monitor='val_dice_coef',verbose=1, save_best_only=True, mode='max')]\n",
        "train_rgb_short = TrainGenerator(1, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "# Trained for 60 epochs total\n",
        "r2_unet_short = train(r2_unet_short, callbacks, train_rgb_short, validation_df, \"r2_unet_short_256\", epochs=100, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owFzqlX7QjTQ"
      },
      "source": [
        "### **U^2 Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6K0qFG6SwQL"
      },
      "outputs": [],
      "source": [
        "# Train ResUNet with generator\n",
        "# def u2net(n_labels, filter_num_down, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, num_out=1, out_layer = 'Sigmoid', lossfunc = 'binary_crossentropy'):\n",
        "\n",
        "u2net_short = u2net(2, [32, 64, 128, 256], input_size=(tileSize, tileSize, 3))\n",
        "# resUNet = load_model('Output/resUNet_tall/resUNet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/u2net_short\", \"u2net_short\"+\".hdf5\"),\n",
        "                             monitor='val_loss',verbose=1, save_best_only=True)]\n",
        "\n",
        "\n",
        "train_rgb_short = TrainGenerator(4, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "u2net_short = train(u2net_short, callbacks, train_rgb_short, validation_df, \"u2net_short\", epochs=50, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erChjVtnUvkX"
      },
      "source": [
        "### **Swin U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zHDNncGUwav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a0e06dc-450a-408a-f3a7-805d7660031c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0345f971d273>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Trained for 60 epochs total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mswin_unet_short\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswin_unet_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rgb_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"swin_unet_short\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-324a31e325bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, callbacks, inGen, valGen, modelName, batch_size, epochs, steps_per_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     history = model.fit(inGen, epochs=epochs, steps_per_epoch=steps_per_epoch,\n\u001b[0m\u001b[1;32m     12\u001b[0m                       validation_data=valGen, batch_size=batch_size, callbacks=[callbacks])\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrainTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_unet_collection/transformer_layers.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mpatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mpatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filefw5xobzz.py\", line 15, in tf__call\n        patches = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(patches), (ag__.ld(batch_size), ag__.ld(patch_num) * ag__.ld(patch_num), ag__.ld(patch_dim))), None, fscope)\n\n    TypeError: Exception encountered when calling layer 'patch_extract_5' (type patch_extract).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.10/dist-packages/keras_unet_collection/transformer_layers.py\", line 55, in call  *\n            patches = tf.reshape(patches, (batch_size, patch_num*patch_num, patch_dim))\n    \n        TypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'\n    \n    \n    Call arguments received by layer 'patch_extract_5' (type patch_extract):\n      • images=tf.Tensor(shape=(None, None, None, None), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Train Swin UNet with generator\n",
        "# swin_unet_tall = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "swin_unet_short = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "# swin_unet_tall.load_weights('Output/swin_unet_tall/swin_unet_tall.hdf5')\n",
        "\n",
        "# r2_unet = load_model('Output/r2_unet_tall/r2_unet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "callbacks = [ModelCheckpoint(os.path.join(\"Output/swin_unet_short\", \"swin_unet_short\"+\".hdf5\"),\n",
        "                             monitor='val_loss',verbose=1, save_weights_only=True, save_best_only=True)]\n",
        "\n",
        "\n",
        "train_rgb_short = TrainGenerator(1, images_rgb_short, short_masks, data_gen_args, save_to_dir=None)\n",
        "validation_df = tf.data.Dataset.from_tensor_slices(([n[:,:,0:3].reshape(1,tileSize,tileSize,3) for n in xTestShort], [n.reshape(1,tileSize,tileSize,1) for n in yTestShort]))\n",
        "\n",
        "# Trained for 60 epochs total\n",
        "swin_unet_short = train(swin_unet_short, callbacks, train_rgb_short, validation_df, \"swin_unet_short\", epochs=60, steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIsW5rk6--7W"
      },
      "source": [
        "# **Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPm_Kc4bJQIG"
      },
      "source": [
        "## **Load tall plants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwvwK2Yykukb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from keras_unet_collection.losses import dice\n",
        "\n",
        "# model_unet = load_model('drive/MyDrive/paramo_ml/paramo-unet-tall.hdf5')\n",
        "model_unet_tall = load_model('Output/unet_tall/unet_tall.hdf5', custom_objects={'dice_coef': dice_coef}) # Some reason this is broken\n",
        "model_amu_tall = load_model('Output/unetAM_tall/unetAM_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "res50 = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "res50.load_weights('Output/resNet_tall/resNet.hdf5')\n",
        "fcn_tall = load_model('Output/fcn32_tall_old/fcn32_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "resUNet = load_model('Output/resUNet_tall/resUNet_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "unet_plus = load_model('Output/unet_plus_tall/unet_plus_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "r2_unet_256 = load_model('Output/r2_unet_tall_256/r2_unet_tall_256.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "aresUNet = load_model('Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "#model_unet_short = load_model('Output/unet_short.hdf5')\n",
        "# model_unet_tall = load_model('paramo-unet-tall.hdf5')\n",
        "\n",
        "u2net_tall = load_model('Output/u2net_tall/u2net_tall.hdf5', custom_objects={'dice': dice})\n",
        "swin_tall = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "swin_tall.load_weights('Output/swin_unet_tall/swin_unet_tall.hdf5')\n",
        "# print(model_unet_tall.summary(), model_amu_tall.summary(), res50.summary(), fcn_tall.summary(), resUNet.summary())\n",
        "\n",
        "# aresUNet_96 = load_model('Output/resaunet_tall_96x96/resaunet_tall_96x96.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "# aresUNet_128= load_mcustom_objects={\"Patches\": Patches, \"PatchEncoder\":PatchEncoder}odel('Output/resaunet_tall_128x128/resaunet_tall_128x128.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "# aresUNet_256 = load_model('Output/resaunet_tall_256x256/resaunet_tall_256x256.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "# aresUNet_512 = load_model('Output/resaunet_tall_512x512/resaunet_tall_512x512.hdf5', custom_objects={'dice_coef': dice_coef})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNk7RDAzttBH"
      },
      "source": [
        "### **Finding individual tiles for visual comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tmJhh8GzTVO"
      },
      "outputs": [],
      "source": [
        "all_ims = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', 512, offset=(5000,13192), channels=3)\n",
        "all_ims = [n/255 for n in all_ims]\n",
        "\n",
        "all_msks = load_and_split_image('labels/paramo_label_final/tall_mask_new.tif', 512, offset=(5000,13192), channels=1)\n",
        "all_msks = [n/255 for n in all_msks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2nRTvTvtyVQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def show_im(models, names, im, truth):\n",
        "  fig, unet_axs = plt.subplots(2, 5, figsize=(24,12))\n",
        "  i1=0\n",
        "  for i,model in enumerate(models):\n",
        "    try:\n",
        "      unet_axs[i1%2][i%5].imshow(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)))\n",
        "    except:\n",
        "      #For weird u2 net stuff\n",
        "      unet_axs[i1%2][i%5].imshow(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3))[0].reshape(tileSize, tileSize)))\n",
        "\n",
        "    unet_axs[i1%2][i%5].set_title(names[i], size=20)\n",
        "    unet_axs[i1%2][i%5].set_aspect('equal')\n",
        "    if i==4:\n",
        "      i1+=1\n",
        "\n",
        "\n",
        "  unet_axs[1][4].imshow(truth.reshape(tileSize, tileSize))\n",
        "  unet_axs[1][4].set_aspect('equal')\n",
        "  unet_axs[1][4].set_title(\"Ground Truth\", size=20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "show_im([model_unet_tall, model_amu_tall, res50, fcn_tall, resUNet, aresUNet, unet_plus, u2net_tall, swin_tall],\n",
        "        [\"U-Net\", \"Attention U-Net\", \"ResNet50SegNet\", \"FCN32-VGG\", \"Res U-Net\", \"Attention Res U-Net\", \"U-Net++\", \"U^2 Net\", \"Swin U-Net\"], all_ims[2], all_msks[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxN0EnehJUQ6"
      },
      "source": [
        "## **Load short plants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuIQVcoGWkGu"
      },
      "outputs": [],
      "source": [
        "tileSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPHSGfJXJXf7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# model_unet = load_model('drive/MyDrive/paramo_ml/paramo-unet-short.hdf5')\n",
        "model_unet_short = load_model('Output/unet_short/unet_short.hdf5', custom_objects={'dice_coef': dice_coef}) # Some reason this is broken\n",
        "model_amu_short = load_model('Output/unetAM_short/unetAM_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "res50_short = ResNet50SegNet(input_size=(tileSize,tileSize,3), lr=0.0001)\n",
        "res50_short.load_weights('Output/resNet_short/resNet_short.hdf5')\n",
        "fcn_short = load_model('Output/fcn32_short/fcn32_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "resUNet_short = load_model('Output/resUNet_short/resUNet_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "aresUNet_short = load_model('Output/resaunet_short/resaunet_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "unet_plus_short = load_model('Output/unet_plus_short/unet_plus_short.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "r2_unet_256_short = load_model('Output/r2_unet_short_256/r2_unet_short_256.hdf5', custom_objects={'dice_coef': dice_coef})\n",
        "u2net_short = load_model('Output/u2net_short/u2net_short.hdf5', custom_objects={'dice': dice})\n",
        "swin_short = swin_unet(n_labels=1, filter_num_begin=4, input_size=(tileSize, tileSize, 3))\n",
        "swin_short.load_weights('Output/swin_unet_short/swin_unet_short.hdf5')\n",
        "\n",
        "#model_unet_short = load_model('Output/unet_short.hdf5')\n",
        "#model_unet_short = load_model('paramo-unet-short.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYfUFe0Y6Vy7"
      },
      "source": [
        "### **Finding individual tiles for visual comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yic38Cb37VCR"
      },
      "outputs": [],
      "source": [
        "all_ims = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', 512, offset=(5000,13192), channels=3)\n",
        "all_ims = [n/255 for n in all_ims]\n",
        "\n",
        "all_msks = load_and_split_image('labels/paramo_label_final/short_mask_new.tif', 512, offset=(5000,13192), channels=1)\n",
        "all_msks = [n/255 for n in all_msks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "332C5BKJ7aZS"
      },
      "outputs": [],
      "source": [
        "def show_im(models, names, im, truth):\n",
        "  fig, unet_axs = plt.subplots(2, 5, figsize=(24,12))\n",
        "  i1=0\n",
        "  for i,model in enumerate(models):\n",
        "    try:\n",
        "      unet_axs[i1%2][i%5].imshow(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)))\n",
        "    except:\n",
        "      #For weird u2 net stuff\n",
        "      unet_axs[i1%2][i%5].imshow(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3))[0].reshape(tileSize, tileSize)))\n",
        "\n",
        "    unet_axs[i1%2][i%5].set_title(names[i], size=20)\n",
        "    unet_axs[i1%2][i%5].set_aspect('equal')\n",
        "    if i==4:\n",
        "      i1+=1\n",
        "\n",
        "\n",
        "  unet_axs[1][4].imshow(truth.reshape(tileSize, tileSize))\n",
        "  unet_axs[1][4].set_aspect('equal')\n",
        "  unet_axs[1][4].set_title(\"Ground Truth\", size=20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "show_im([model_unet_short, model_amu_short, res50_short, fcn_short, resUNet_short, aresUNet_short, unet_plus_short, r2_unet_256_short, u2net_short, swin_short],\n",
        "        [\"U-Net\", \"Attention U-Net\", \"ResNet50SegNet\", \"FCN32-VGG\", \"Res U-Net\", \"Attention Res U-Net\", \"U-Net++\", \"R2 U-Net\", \"U^2 Net\", \"Swin U-Net\"], all_ims[45], all_msks[45])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LIj067f7PSY"
      },
      "source": [
        "## **Overlaying image tiles**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cZqGgrg7NYx"
      },
      "outputs": [],
      "source": [
        "fig, unet_axs = plt.subplots(1, 3, figsize=(24,12))\n",
        "index = 10\n",
        "\n",
        "unet_axs[0].imshow(xTest[index][:,:,0:3])\n",
        "\n",
        "#unet_axs[0,1].imshow(np.round(model_unet2.predict(X_test[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.5)\n",
        "unet_axs[1].imshow(yTestTall[index].reshape(512,512), cmap='gray')\n",
        "\n",
        "unet_axs[2].imshow(xTest[index][:,:,0:3])\n",
        "unet_axs[2].imshow(np.round(model_unet_tall.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.6)\n",
        "\n",
        "unet_axs[0].axis('off')\n",
        "unet_axs[1].axis('off')\n",
        "unet_axs[2].axis('off')\n",
        "\n",
        "unet_axs[0].set_aspect('equal')\n",
        "unet_axs[1].set_aspect('equal')\n",
        "unet_axs[2].set_aspect('equal')\n",
        "\n",
        "unet_axs[0].set_title('Image', size=20)\n",
        "unet_axs[1].set_title('Ground Truth', size=20)\n",
        "unet_axs[2].set_title('U-Net', size=20)\n",
        "\n",
        "fig, attunet_axs = plt.subplots(1, 3, figsize=(24,12)) #\n",
        "\n",
        "attunet_axs[0].imshow(xTest[index][:,:,0:3])\n",
        "attunet_axs[1].imshow(xTest[index][:,:,0:3])\n",
        "attunet_axs[2].imshow(xTest[index][:,:,0:3])\n",
        "\n",
        "#attunet_axs[0,1].imshow(np.round(model_unet2.predict(X_test[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.5)\n",
        "\n",
        "attunet_axs[0].imshow(np.round(model_amu_tall.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.5)\n",
        "attunet_axs[1].imshow(np.round(resUNet.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.5)\n",
        "attunet_axs[2].imshow(np.round(aresUNet.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.5)\n",
        "\n",
        "attunet_axs[0].axis('off')\n",
        "attunet_axs[1].axis('off')\n",
        "attunet_axs[2].axis('off')\n",
        "\n",
        "attunet_axs[0].set_aspect('equal')\n",
        "attunet_axs[1].set_aspect('equal')\n",
        "attunet_axs[2].set_aspect('equal')\n",
        "\n",
        "attunet_axs[0].set_title('Attention U-Net', size=20)\n",
        "attunet_axs[1].set_title('Residual U-Net', size=20)\n",
        "attunet_axs[2].set_title('Residual Attention U-Net', size=20)\n",
        "\n",
        "fig, res50plt = plt.subplots(1, 3, figsize=(18,8))\n",
        "\n",
        "res50plt[0].imshow(xTest[index][:,:,0:3])\n",
        "res50plt[1].imshow(xTest[index][:,:,0:3])\n",
        "\n",
        "res50plt[0].imshow(np.round(res50.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.6)\n",
        "res50plt[1].imshow(np.round(fcn_tall.predict(xTest[index][:,:,0:3].reshape(1,512,512,3)).reshape(512,512)), alpha=0.6)\n",
        "\n",
        "res50plt[0].axis('off')\n",
        "res50plt[1].axis('off')\n",
        "res50plt[2].axis('off')\n",
        "\n",
        "res50plt[0].set_aspect('equal')\n",
        "res50plt[1].set_aspect('equal')\n",
        "res50plt[2].set_aspect('equal')\n",
        "\n",
        "res50plt[0].set_title('ResNet50 SegNet', size=20)\n",
        "res50plt[1].set_title('FCN32-VGG16', size=20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# i=0\n",
        "# for im in yTestTall:\n",
        "#     if True in im:\n",
        "#         print(i)\n",
        "#     i+=1\n",
        "\n",
        "\n",
        "# out = model_unet_tall.predict(xTest[2][:,:,0:3].reshape(1,512,512,3))\n",
        "# plt.imshow(out.reshape(512,512))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpGU0A5bqkbS"
      },
      "source": [
        "## **Building matrix of metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIl_zUX1u7Rr"
      },
      "source": [
        "### **Metrics**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-Ji3HsBuUL7"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Format tall and short mask reproduction correctly\n",
        "#\n",
        "def mask_gen(mask): # Rounds masks according to highest value pixel\n",
        "  mask_out = np.zeros((512,512))\n",
        "  for i in range(mask.shape[0]):\n",
        "    for j in range(mask.shape[1]):\n",
        "      mask_out[i,j] = np.argmax(mask[i,j,:])\n",
        "\n",
        "  # Re-order the features if needed (to make visualisation colours more legible)\n",
        "  '''\n",
        "  for i in range(mask.shape[0]):\n",
        "    for j in range(mask.shape[1]):\n",
        "      if mask_out[i,j] == 0:\n",
        "        mask_out[i,j] = 1\n",
        "      elif mask_out[i,j] == 1:\n",
        "        mask_out[i,j] = 2\n",
        "      else:\n",
        "        mask_out[i,j] = 0\n",
        "  '''\n",
        "  return mask_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9etU70RUC17H"
      },
      "outputs": [],
      "source": [
        "# pscore = maskacc\n",
        "# pmaskscore = paramo acc\n",
        "\n",
        "# pscore = recall\n",
        "# pmaskscore = precision\n",
        "\n",
        "# DEPRICATED\n",
        "\n",
        "def get_accuracy(model, xIn, maskIn):\n",
        "    score = []\n",
        "    pscore = []\n",
        "    pmaskscore = []\n",
        "\n",
        "\n",
        "\n",
        "    for i, im in enumerate(xIn):\n",
        "        matches = 0\n",
        "        total = 0\n",
        "\n",
        "        pmatches = 0\n",
        "        ptotal = 0\n",
        "\n",
        "        pmaskmatches = 0\n",
        "        pmasktotal = 0\n",
        "        reconstruction = model.predict(xIn[i].reshape(1,tileSize,tileSize,3))\n",
        "\n",
        "        if type(reconstruction) is list:\n",
        "            reconstruction = reconstruction[0]\n",
        "\n",
        "        all_images_tester = np.round(reconstruction.flatten())\n",
        "        all_masks_tester = maskIn[i].flatten()\n",
        "\n",
        "        # Cycle through prediction image\n",
        "        for ii, val in enumerate(all_images_tester):\n",
        "            if (all_masks_tester[ii] == val):\n",
        "                #print(\"Pixel\", ii, \" matches! \")\n",
        "                matches+=1\n",
        "            total+=1\n",
        "\n",
        "\n",
        "\n",
        "            if 1 == all_masks_tester[ii]:\n",
        "                if 1 == val:\n",
        "                    pmatches+=1\n",
        "                ptotal+=1\n",
        "\n",
        "            if 1 == val:\n",
        "                if 1 == all_masks_tester[ii]:\n",
        "                    pmaskmatches+=1\n",
        "                pmasktotal+=1\n",
        "\n",
        "        score.append(matches/total)\n",
        "\n",
        "        if ptotal == 0 : pscore.append(0)\n",
        "        else : pscore.append(pmatches/ptotal)\n",
        "\n",
        "        if pmasktotal == 0 : pmaskscore.append(0)\n",
        "        else : pmaskscore.append(pmaskmatches/pmasktotal)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return score, pscore, pmaskscore\n",
        "\n",
        "# inimages = full_img[5000:13192, 5000:13192, :]\n",
        "# all_ims = []\n",
        "# for i in range(inimages.shape[0] // tileSize):\n",
        "#   for j in range(inimages.shape[1] // tileSize):\n",
        "#     all_ims.append(inimages[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,3))\n",
        "\n",
        "# inmasks = full_mask[5000:13192, 5000:13192, :]\n",
        "# all_msks = []\n",
        "# for i in range(inmasks.shape[0] // tileSize):\n",
        "#   for j in range(inmasks.shape[1] // tileSize):\n",
        "#     all_msks.append(inmasks[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,1))\n",
        "\n",
        "# print(inimages.shape)\n",
        "\n",
        "# all_ims = [n/255.0 for n in all_ims]\n",
        "\n",
        "# score, pscore, pmaskscore = get_accuracy(model_unet_tall, all_ims, all_msks)\n",
        "\n",
        "# print(\"calculated accuracy (by pixel)      \", np.mean(score))\n",
        "# print(\"calculated accuracy (by paramo)     \", np.mean(pscore))\n",
        "# print(\"calculated accuracy (by mask paramo)\", np.mean(pmaskscore))\n",
        "\n",
        "# plt.imshow(yTestTall[1].reshape(tileSize,tileSize))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djZ1o8iZT912"
      },
      "outputs": [],
      "source": [
        "# Returns IOU mean\n",
        "def iou(xIn, yIn, model):\n",
        "  sum=0\n",
        "  count=0\n",
        "  for x in range(len(xIn)):\n",
        "\n",
        "    yPred = model.predict(xIn[x].reshape(1,tileSize, tileSize, 3))\n",
        "\n",
        "    if type(yPred) is list:\n",
        "        yPred = yPred[0]\n",
        "\n",
        "    yPredThreshhold = np.round(yPred)\n",
        "    intersection = np.logical_and(yIn[x], yPredThreshhold)\n",
        "    union = np.logical_or(yIn[x], yPredThreshhold)\n",
        "\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "    sum += iou_score\n",
        "\n",
        "    count+=1\n",
        "\n",
        "  return sum/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwm9KKt0BuGe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def f1_score_eval_basic(precision, recall):\n",
        "\n",
        "    prec = np.mean(precision)\n",
        "    rec = np.mean(recall)\n",
        "\n",
        "    if prec + rec == 0:\n",
        "        return 0\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def f1_score_curr(xIn, yIn, model):\n",
        "  # Precision = TP / TP + FP\n",
        "  # Recall = TP / TP + FN\n",
        "\n",
        "  prec = []\n",
        "  rec = []\n",
        "\n",
        "  for i,im in enumerate(xIn):\n",
        "      reconstruction = model.predict(im.reshape(1,tileSize,tileSize,3))\n",
        "\n",
        "      if type(reconstruction) is list:\n",
        "            reconstruction = reconstruction[0]\n",
        "\n",
        "      reconstruction = np.round(reconstruction.flatten())\n",
        "      maskim = yIn[i].flatten()\n",
        "\n",
        "      TP=0\n",
        "      FP=0\n",
        "      FN=0\n",
        "\n",
        "      for ii, pixel in enumerate(reconstruction):\n",
        "        if pixel == maskim[ii] and pixel == 1: # True positive\n",
        "          TP+=1\n",
        "        if pixel != maskim[ii] and pixel == 0: # Pixel is 0, mask is 1 => False negative\n",
        "          FN+=1\n",
        "        if pixel != maskim[ii] and pixel == 1: # Pixel is 1, mask is 0 => False positive\n",
        "          FP+=1\n",
        "\n",
        "      if (TP+FP) != 0 : prec.append(TP/(TP+FP))\n",
        "      else : prec.append(0)\n",
        "\n",
        "      if (TP+FN) != 0 : rec.append(TP/(TP+FN))\n",
        "      else : rec.append(0)\n",
        "\n",
        "\n",
        "  return prec, rec, f1_score_eval_basic(prec, rec)\n",
        "\n",
        "def f1_score_avg(xIn, yIn, model):\n",
        "  sum=0\n",
        "  count=0\n",
        "  for x in range(len(xIn)):\n",
        "\n",
        "    yPred = model.predict(xIn[x].reshape(1,tileSize, tileSize, 3))\n",
        "\n",
        "    if type(yPred) is list:\n",
        "        yPred = yPred[0]\n",
        "\n",
        "    yPredThreshhold = np.round(yPred)\n",
        "    yPredThreshhold = yPredThreshhold.reshape(tileSize,tileSize).astype(np.uint8)\n",
        "\n",
        "    print(yIn[x].shape, yPredThreshhold.shape)\n",
        "\n",
        "    sum += dice_coef(yIn[x].reshape(tileSize, tileSize), yPredThreshhold)\n",
        "\n",
        "    count+=1\n",
        "\n",
        "  return sum/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y801hAAfDIk3"
      },
      "outputs": [],
      "source": [
        "def build_score_matrices(model, xIn, yIn):\n",
        "    # score, mask_accuracy, paramo_accuracy = get_accuracy(model, xIn, yIn)\n",
        "    prec, rec, f1score = f1_score_curr(xIn, yIn, model)\n",
        "\n",
        "    return [ iou(xIn, yIn, model),\n",
        "             np.mean(prec),\n",
        "             np.mean(rec),\n",
        "             f1score]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpUXec5pcFCT"
      },
      "outputs": [],
      "source": [
        "def build_model_matrices(models, model_names, xIn, yIn):\n",
        "    metrics = []\n",
        "    for i,model in enumerate(models):\n",
        "        print(\"on\",model)\n",
        "        metrics.append([i, build_score_matrices(model, xIn, yIn)])\n",
        "\n",
        "    metrics_im_only = {'classifier': [n for n in model_names],\n",
        "                       'iou': [metrics[n][1][0] for n in range(len(model_names))],\n",
        "                       'precision': [metrics[n][1][1] for n in range(len(model_names))],\n",
        "                       'recall': [metrics[n][1][2] for n in range(len(model_names))],\n",
        "                       'f1 score': [metrics[n][1][3] for n in range(len(model_names))]}\n",
        "\n",
        "    return metrics_im_only\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9BWIqlECYcf"
      },
      "source": [
        "### **Metric investigation 🧐**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDA3TOIs-O3-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "metrics_im_only = build_model_matrices([r2_unet_256], [\"R2 U-Net\"], xTest, yTestTall)\n",
        "\n",
        "\n",
        "# U ++ HERE TOO!@!@!@!\n",
        "\n",
        "metrics_im_only = pd.DataFrame(metrics_im_only)\n",
        "metrics_im_only.to_csv('Output/metrics_im_only_256x256.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eXryDIZHBex"
      },
      "outputs": [],
      "source": [
        "fcn_tall = load_model('Output/fcn32_tall_256x256/fcn32_tall.hdf5', custom_objects={'dice_coef': dice_coef})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146-Wm3pHKlI"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(r2_unet_256.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxkZRk9UPM5O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "totalx = xTrain[0] + xTest\n",
        "\n",
        "totaly = yTrainTall[0] + yTestTall\n",
        "\n",
        "\n",
        "metrics_im_only = build_model_matrices([model_unet_tall, model_amu_tall, res50, fcn_tall, resUNet, aresUNet, unet_plus, r2_unet_256, u2net_tall, swin_tall],\n",
        "                                       [\"U-Net\", \"Attention U-Net\", \"ResNet50SegNet\", \"FCN32-VGG\", \"Res U-Net\", \"Attention Res U-Net\", \"U-Net++\", \"R2 U-Net\", \"U^2 Net\", \"Swin U-Net\"],\n",
        "                                       tall_images, masks2)\n",
        "# metrics_im_only = build_model_matrices([model_unet_tall, model_amu_tall, fcn_tall], [\"U-Net\", \"Attention U-Net\", \"FCN32\"], xTest, yTestTall)\n",
        "\n",
        "print(metrics_im_only)\n",
        "metrics_im_only = pd.DataFrame(metrics_im_only)\n",
        "metrics_im_only.to_csv('Output/metrics_im_only_512x512_all.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o19rDSE_reR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "metrics_im_only = build_model_matrices([model_unet_short, model_amu_short, res50_short, fcn_short, resUNet_short, aresUNet_short, unet_plus_short, r2_unet_256_short, u2net_short, swin_short],\n",
        "                                       [\"U-Net\", \"Attention U-Net\", \"ResNet50SegNet\", \"FCN32-VGG\", \"Res U-Net\", \"Attention Res U-Net\", \"U-Net++\", \"R2 U-Net\", \"U^2 Net\", \"Swin U-Net\"],\n",
        "                                       xTestShort, yTestShort)\n",
        "# metrics_im_only = build_model_matrices([model_unet_tall, model_amu_tall, fcn_tall], [\"U-Net\", \"Attention U-Net\", \"FCN32\"], xTest, yTestTall)\n",
        "\n",
        "print(metrics_im_only)\n",
        "metrics_im_only = pd.DataFrame(metrics_im_only)\n",
        "metrics_im_only.to_csv('Output/metrics_im_only_512x512_short_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KOUbySnPlLP"
      },
      "outputs": [],
      "source": [
        "metrics_unet_plus = build_model_matrices([unet_plus], [\"U-Net++\"], xTest, yTestTall)\n",
        "\n",
        "print(metrics_unet_plus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtPaCWLwXpyX"
      },
      "outputs": [],
      "source": [
        "resaumetrics = pd.DataFrame(metrics_96 + metrics_128 + metrics_256 + metrics_512)\n",
        "metrics_im_only.to_csv('Output/res_au_metrics.csv')\n",
        "\n",
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzpjuEU7Js5Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# metrics_im_only_short = build_model_matrices([model_unet_short, model_amu_short, res50_short, fcn_short, resUNet_short, aresUNet_short],\n",
        "                                    #    [\"U-Net\", \"Attention U-Net\", \"ResNet50SegNet\", \"FCN32-VGG\", \"Res U-Net\", \"Attention Res U-Net\"],\n",
        "                                    #    xTest, yTestTall)\n",
        "metrics_im_only_short = build_model_matrices([model_unet_short, aresUNet_short], [\"U-Net\", \"Att - Res UNet\"], xTestShort, yTestShort)\n",
        "\n",
        "print(metrics_im_only)\n",
        "metrics_im_only = pd.DataFrame(metrics_im_only_short)\n",
        "metrics_im_only.to_csv('Output/metrics_im_only_short.csv')\n",
        "\n",
        "\n",
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9DR1VL3BeiM"
      },
      "outputs": [],
      "source": [
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23KBxyMoHwA"
      },
      "source": [
        "## **Predicting full mask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI9hIk9OnqkY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Metrics for single-class evaluation (using only tall or only short plants)\n",
        "def stitch(model, image, dims=(8192, 8192), maskSize=(512,512), output='result.tif', rounded=True):\n",
        "    scores = []\n",
        "    if type(image) != list:\n",
        "        reconstruction = model.predict(image, batch_size=1).reshape(maskSize[0], maskSize[1])\n",
        "        if rounded == True : reconstruction = np.round(reconstruction)\n",
        "\n",
        "        return reconstruction\n",
        "\n",
        "\n",
        "    else: # If a list of images input, find accuracy for each\n",
        "        for i in range(len(image)):\n",
        "            reconstruction = model.predict(image[i].reshape(1, maskSize[0], maskSize[1], 3)).reshape(maskSize[0], maskSize[1])\n",
        "            if rounded == True : reconstruction = np.round(reconstruction)\n",
        "\n",
        "            scores.append(reconstruction)\n",
        "\n",
        "    # full_height, full_width = 12300, 12300 #25x25 tiles\n",
        "\n",
        "    img2 = Image.new(\"L\", (dims[0], dims[1]))\n",
        "\n",
        "    tester = 0\n",
        "\n",
        "    tileH = math.floor(dims[0]/maskSize[0])\n",
        "    tileW = math.floor(dims[1]/maskSize[1])\n",
        "\n",
        "    row=0\n",
        "    for i,img in enumerate(scores):\n",
        "        col = i%tileH\n",
        "\n",
        "        newimg = img.T.reshape(maskSize[0],maskSize[1])\n",
        "\n",
        "        toPaste = Image.fromarray(255.0*newimg)\n",
        "\n",
        "\n",
        "        if i == 125:\n",
        "            test = img\n",
        "            test2 = newimg\n",
        "            test3 = toPaste\n",
        "            print(img.shape)\n",
        "\n",
        "\n",
        "        img2.paste(toPaste, (maskSize[0]*row, maskSize[1]*col))\n",
        "        if col == tileW-1:\n",
        "            row+=1\n",
        "\n",
        "\n",
        "    img2.save(os.path.join(\"Output\",output,output+\".tif\"))\n",
        "    # img2.save(\"result.tif\")\n",
        "\n",
        "    # Create subplot of toPaste stuff here!!!\n",
        "\n",
        "\n",
        "    return os.path.join(\"Output\",output,output+\".tif\"), img2, test, test2, test3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0K152JSy-Ax"
      },
      "outputs": [],
      "source": [
        "def save_coords(mask_img_path, output, col_off=5000, row_off=5000, width=8192, height=8192):\n",
        "    # Opening file\n",
        "    with rasterio.open('images/drone_paramo/DUI-01-1_ortho.tif') as src:\n",
        "\n",
        "        # Getting window\n",
        "        window = Window(col_off=col_off, row_off=row_off, width=width, height=height)\n",
        "\n",
        "        # Copying metadata\n",
        "        kwargs = src.meta.copy()\n",
        "        print(kwargs)\n",
        "\n",
        "        kwargs.update({\n",
        "            'height': window.height,\n",
        "            'width' : window.width,\n",
        "            'transform': rasterio.windows.transform(window, src.transform)})\n",
        "\n",
        "        new_window = src.read(window=window)\n",
        "\n",
        "        print(kwargs)\n",
        "\n",
        "        with rasterio.open(\"slicewithcoords.tif\", 'w', **kwargs) as dest:\n",
        "            dest.write(new_window)\n",
        "\n",
        "    with rasterio.open('slicewithcoords.tif') as src:\n",
        "        kwargs = src.meta.copy()\n",
        "\n",
        "\n",
        "        kwargs.update({\n",
        "            'count': 1})\n",
        "\n",
        "        print(kwargs)\n",
        "        with rasterio.open(os.path.join(\"Output\",output,output+\"_coords.tif\"), 'w', **kwargs) as dest:\n",
        "            dest.write(rxr.open_rasterio(mask_img_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1sBjGofobxt"
      },
      "source": [
        "## **Stitching, predicting and finding coordinates**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vRSWrhaRarr"
      },
      "source": [
        "### **Tall plants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNIJQ-5joaoF"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "tileSize = 512\n",
        "\n",
        "\n",
        "# full_height, full_width = 13056, 13056 # 16x16 tiles FOR 512x512 TILES and 32x32 FOR 256x256 TILES!!!\n",
        "full_height, full_width = 8192, 8192\n",
        "# #full_height, full_width = 12300, 12300 #25x25 tiles\n",
        "# # full_mask = full_mask_og[5000:13192, 5000:13192, :] # This is a region which contains tall and short plants\n",
        "\n",
        "full_height_96, full_width_96 = 8256, 8256 # FOR 96x96 TILES!!!\n",
        "# 5000, 8192\n",
        "\n",
        "\n",
        "# inmasks = full_mask[5000:13192, 5000:13192, :]\n",
        "# all_msks = []\n",
        "# for i in range(inmasks.shape[0] // tileSize):\n",
        "#   for j in range(inmasks.shape[1] // tileSize):\n",
        "#     all_msks.append(inmasks[tileSize*(i):tileSize*(i+1), tileSize*(j):tileSize*(j+1), :].reshape(tileSize,tileSize,1))\n",
        "\n",
        "all_ims = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', 512, offset=(5000,13192), channels=3)\n",
        "\n",
        "all_ims = [n/255 for n in all_ims]\n",
        "\n",
        "print(len(all_ims))\n",
        "\n",
        "# all_ims_256 = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', 256, offset=(5000,13192), channels=3)\n",
        "\n",
        "# all_ims_256  = [n/255 for n in all_ims_256]\n",
        "## UNET\n",
        "# unet_img_path = stitch(model_amu_tall, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_tall\")\n",
        "# save_coords(unet_img_path, \"unet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# aunet_img_path = stitch(model_amu_tall, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unetAM_tall\")\n",
        "# save_coords(aunet_img_path, \"unetAM_tall\", 5000, 5000, 8192, 8192)\n",
        "# # def save_coords(mask_img_path, name, col_off=5000, row_off=5000, width=8192, height=8192):\n",
        "\n",
        "# res50_img_path = stitch(res50, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resNet_tall\")\n",
        "# save_coords(res50_img_path, \"resNet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# fcn_tall_path = stitch(res50, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"fcn32_tall\")\n",
        "# save_coords(fcn_tall_path, \"fcn32_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# resunet_path = stitch(resUNet, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resUNet_tall\")\n",
        "# save_coords(resunet_path, \"resUNet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# aresunet_path = stitch(aresUNet, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resaunet_tall\")\n",
        "# save_coords(aresunet_path, \"resaunet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# resaunet_path_96 = stitch(aresUNet_96, all_ims, dims=(full_width_96, full_height_96), maskSize=(tileSize, tileSize), output=\"resaunet_tall_96x96\", rounded=False)\n",
        "# save_coords(resaunet_path_96[0], \"resaunet_tall_96x96\", 5000, 5000, 8256, 8256)\n",
        "\n",
        "# resaunet_path_128 = stitch(aresUNet_128, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resaunet_tall_128x128\", rounded=False)\n",
        "# save_coords(resaunet_path_128[0], \"resaunet_tall_128x128\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# resaunet_path_256 = stitch(aresUNet_256, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resaunet_tall_256x256\", rounded=False)\n",
        "# save_coords(resaunet_path_256[0], \"resaunet_tall_256x256\", 0, 0, 13056, 13056)\n",
        "\n",
        "# u2net_path = stitch(u2net_tall, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"u2net_tall\", rounded=True)\n",
        "# save_coords(u2net_path[0], \"u2net_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# unet_plus_path = stitch(unet_plus, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_plus_tall\", rounded=True)\n",
        "# save_coords(unet_plus_path[0], \"unet_plus_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# tileSize = 256\n",
        "# r2_256_path = stitch(r2_unet_256, all_ims_256, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_plus_tall\", rounded=True)\n",
        "# save_coords(r2_256_path[0], \"r2_unet_tall_256\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "swin_path = stitch(swin_tall, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"swin_unet_tall\", rounded=True)\n",
        "save_coords(swin_path[0], \"swin_unet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# u2net_path = stitch(swin_tall, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"swin_unet_tall\", rounded=True)\n",
        "# save_coords(u2net_path[0], \"swin_unet_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# resaunet_path_512 = stitch(unet_plus, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_plus_tall\", rounded=True)\n",
        "# save_coords(resaunet_path_512[0], \"unet_plus_tall\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# Saving to drive\n",
        "save_to_drive()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFwdONeNRdIc"
      },
      "source": [
        "### **Short plants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox-bJG1ERizM"
      },
      "outputs": [],
      "source": [
        "\n",
        "full_height, full_width = 8192, 8192 # 16x16 tiles\n",
        "# #full_height, full_width = 12300, 12300 #25x25 tiles\n",
        "# # full_mask = full_mask_og[5000:13192, 5000:13192, :] # This is a region which contains short and short plants\n",
        "\n",
        "# #full_height, full_width = 8256, 8256 # FOR 96x96 TILES!!!\n",
        "\n",
        "all_ims = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', 512, offset=(5000,13192), channels=3)\n",
        "\n",
        "all_ims = [n/255 for n in all_ims]\n",
        "\n",
        "print(len(all_ims))\n",
        "# print(len(all_msks), len(all_ims))\n",
        "\n",
        "\n",
        "\n",
        "# for i, im in enumerate(all_msks):\n",
        "#     if 1 in im:\n",
        "#         print(i)\n",
        "\n",
        "\n",
        "## UNET\n",
        "# unet_img_path = stitch(model_unet_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_short\")\n",
        "# save_coords(unet_img_path[0], \"unet_short\", 5000, 5000, 8192, 8192)\n",
        "# plt.imshow(unet_img_path[1])\n",
        "\n",
        "# aunet_img_path = stitch(model_amu_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unetAM_short\")\n",
        "# save_coords(aunet_img_path[0], \"unetAM_short\", 5000, 5000, 8192, 8192)\n",
        "# # def save_coords(mask_img_path, name, col_off=5000, row_off=5000, width=8192, height=8192):\n",
        "\n",
        "# res50_img_path = stitch(res50_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resNet_short\")\n",
        "# save_coords(res50_img_path[0], \"resNet_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# fcn_short_path = stitch(fcn_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"fcn32_short\")\n",
        "# save_coords(fcn_short_path[0], \"fcn32_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# resunet_path = stitch(resUNet_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resUNet_short\")\n",
        "# save_coords(resunet_path[0], \"resUNet_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# aresunet_path = stitch(aresUNet_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"resaunet_short\")\n",
        "# save_coords(aresunet_path[0], \"resaunet_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# unet_plus_short_path = stitch(unet_plus_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"unet_plus_short\")\n",
        "# save_coords(unet_plus_short_path[0], \"unet_plus_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "# u2net_short_path = stitch(u2net_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"u2net_short\")\n",
        "# save_coords(u2net_short_path[0], \"u2net_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "swin_short_path = stitch(swin_short, all_ims, dims=(full_width, full_height), maskSize=(tileSize, tileSize), output=\"swin_unet_short\")\n",
        "save_coords(swin_short_path[0], \"swin_unet_short\", 5000, 5000, 8192, 8192)\n",
        "\n",
        "\n",
        "# Saving to drive\n",
        "save_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fbpeR_y7cwB"
      },
      "outputs": [],
      "source": [
        "full_height, full_width = 8192, 8192 #25x25 tiles\n",
        "\n",
        "img2 = Image.new(\"L\", (full_width, full_height))\n",
        "\n",
        "tester = 0\n",
        "\n",
        "plt.imshow(all_masks[0].reshape(512,512))\n",
        "\n",
        "row=0\n",
        "for i,img in enumerate(all_masks):\n",
        "    col = i%16\n",
        "\n",
        "    newimg = img.reshape(512,512)\n",
        "\n",
        "    toPaste = Image.fromarray(255.0*newimg.astype(np.uint8))\n",
        "\n",
        "\n",
        "    # print(col, row)\n",
        "\n",
        "    img2.paste(toPaste, (512*col, 512*row))\n",
        "    if col == 15:\n",
        "        row+=1\n",
        "\n",
        "img2.save(\"result.tif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eccqa32uMmYz"
      },
      "outputs": [],
      "source": [
        "# Saving to drive\n",
        "save_to_drive();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qet7tDX5V3d1"
      },
      "outputs": [],
      "source": [
        "#save_comparison(uNet_img)\n",
        "# save_comparison(auNet_img, \"attentionUNet\")\n",
        "# save_comparison(res50_img, \"residual\")\n",
        "# save_comparison(fcn_img, \"fcn\")\n",
        "# save_comparison(resuNet_img, \"resunet\")\n",
        "# save_comparison(resauNet_img, \"resaunet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzebUJmG2YkZ"
      },
      "outputs": [],
      "source": [
        "num=10\n",
        "fig, axs = plt.subplots(num, 3, gridspec_kw=dict(hspace=0), figsize=(50,25))\n",
        "\n",
        "\n",
        "for i,im in enumerate(xTest):\n",
        "  if i >= num : break\n",
        "  axs[i][0].set_title('Image', size=20)\n",
        "  axs[i][1].set_title('U-Net', size=20)\n",
        "  axs[i][2].set_title('Ground Truth', size=20)\n",
        "\n",
        "  axs[i][0].set_aspect('equal')\n",
        "  axs[i][1].set_aspect('equal')\n",
        "  axs[i][2].set_aspect('equal')\n",
        "\n",
        "  axs[i][0].axis('off')\n",
        "  axs[i][1].axis('off')\n",
        "  axs[i][2].axis('off')\n",
        "\n",
        "  axs[i][0].imshow(xTest[i][:,:,0:3])\n",
        "  axs[i][1].imshow(xTest[i][:,:,0:3])\n",
        "  axs[i][2].imshow(yTestTall[i].reshape(tileSize,tileSize))\n",
        "\n",
        "  pred = aresUNet.predict(xTest[i][:,:,0:3].reshape(1,tileSize,tileSize,3)).reshape(tileSize,tileSize)\n",
        "\n",
        "#   print(len(pred))\n",
        "\n",
        "  for ii,n in enumerate(pred):\n",
        "      if np.average(n) != 0:\n",
        "          n[ii] = 1\n",
        "      else:\n",
        "          n[ii] = 0\n",
        "\n",
        "\n",
        "  axs[i][1].imshow(np.round(pred), alpha=0.6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bocU-yUi4eas"
      },
      "source": [
        "### **Stitching together unrounded**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4uXgq5qMMBx"
      },
      "outputs": [],
      "source": [
        "res = aresUNet_512.predict(all_ims[9].reshape(1,tileSize,tileSize,3)).reshape(tileSize,tileSize)\n",
        "plt.imshow(res*255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVMGsXSmpbEb"
      },
      "source": [
        "## **Tile highlighting**\n",
        "\n",
        "*   Takes true map && predicted map\n",
        "*   Scale up to (tileSize, tileSize, 3)\n",
        "*   Highlights false positives as red   255, 0, 0\n",
        "*   Highlights false negatives as blue  0, 0, 255\n",
        "*   Returns tile image with highlights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hglyJvmZq8A1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def highlight(pred, true, pos=1.0):\n",
        "  # Expand dims\n",
        "  # Call highlight false\n",
        "  # Call highlight pos\n",
        "  # Do O(n) max\n",
        "  # Return value\n",
        "\n",
        "  # Doesn't modify existing but creates a new image which it'll overlay on figure\n",
        "  hlight = np.zeros((tileSize*tileSize, 3), float)\n",
        "\n",
        "  # hlight = hlight.flatten().reshape(512*512,3)\n",
        "\n",
        "  predPix = pred.reshape(tileSize*tileSize, 1)\n",
        "  truePix = true.reshape(tileSize*tileSize, 1)\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for i,pix in enumerate(predPix):\n",
        "    # print(pix, truePix[i])\n",
        "    # False\n",
        "    if 1 in pix and 0 in truePix[i]:\n",
        "        # print(\"hi\", i, math.floor(i/512)+i%512)\n",
        "        hlight[(i)] = [0.99, 0.2, 0.2]\n",
        "        count+=1\n",
        "    if 0 in pix and 1 in truePix[i]:\n",
        "        # print(\"h3i\", i, math.floor(i/512)+i%512)\n",
        "        hlight[(i)] = [0.2, 0.2, 0.99]\n",
        "        count+=1\n",
        "\n",
        "    if 1 in pix and 1 in truePix[i]:\n",
        "        # print(\"hi1\", i, math.floor(i/512)+i%512)\n",
        "        hlight[(i)] = pos\n",
        "        count+=1\n",
        "\n",
        "\n",
        "\n",
        "  plt.imshow(hlight.reshape(tileSize, tileSize, 3))\n",
        "\n",
        "\n",
        "  return hlight.reshape(tileSize, tileSize, 3)\n",
        "\n",
        "  # for i, pixel in enumerate(pred):\n",
        "  #   if 1 in pixel:\n",
        "  #     print(i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6foljJy1dfVF"
      },
      "outputs": [],
      "source": [
        "all_ims = load_and_split_image('images/drone_paramo/DUI-01-1_ortho.tif', tileSize, offset=(5000,13192), channels=3)\n",
        "all_ims = [n/255 for n in all_ims]\n",
        "\n",
        "all_msks = load_and_split_image('labels/paramo_label_final/tall_mask_new.tif', tileSize, offset=(5000,13192), channels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eMHu8w4WXs-"
      },
      "outputs": [],
      "source": [
        "# print(all_ims[0][0])\n",
        "\n",
        "# test = highlight(np.round(model_unet_tall.predict(all_ims[2].reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)), all_msks[2])\n",
        "\n",
        "\n",
        "def show_im(models, names, im, truth):\n",
        "  col = 3\n",
        "  row = 4\n",
        "\n",
        "  results = []\n",
        "  results.append(im)\n",
        "  results.append(truth)\n",
        "  names.insert(0, \"Image\")\n",
        "  names.insert(1, \"Ground Reference\")\n",
        "\n",
        "  fig, unet_axs = plt.subplots(col, row, figsize=(34,34))\n",
        "  fig.subplots_adjust(wspace=0.1, hspace=-0.40)\n",
        "#   unet_axs[0][0].imshow(truth.reshape(tileSize, tileSize))\n",
        "#   unet_axs[0][0].imshow(im.reshape(tileSize, tileSize, 3), alpha=0.5)\n",
        "#   unet_axs[0][0].set_aspect('equal')\n",
        "#   unet_axs[0][0].set_title(\"Ground Truth\", size=20)\n",
        "\n",
        "\n",
        "  for model in models:\n",
        "    try:\n",
        "      res = highlight(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)), truth)\n",
        "      results.append(np.asarray(res))\n",
        "    except:\n",
        "      #For weird u2 net stuff\n",
        "      res = highlight(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3))[0].reshape(tileSize, tileSize)), truth)\n",
        "      results.append(np.asarray(res))\n",
        "\n",
        "\n",
        "  iii=0\n",
        "  for i in range(col):\n",
        "      for ii in range(row):\n",
        "          if i==0 and ii==1:\n",
        "            unet_axs[i][ii].imshow(results[iii].reshape(tileSize, tileSize), cmap='gray')\n",
        "          elif i==0 and ii==0:\n",
        "            unet_axs[i][ii].imshow(results[iii].reshape(tileSize, tileSize, 3))\n",
        "          else:\n",
        "            unet_axs[i][ii].imshow(results[iii].reshape(tileSize, tileSize, 3))\n",
        "            unet_axs[i][ii].imshow(im.reshape(tileSize, tileSize, 3), alpha=0.5)\n",
        "\n",
        "\n",
        "          unet_axs[i][ii].set_title(names[iii], fontsize = 40.0)\n",
        "          unet_axs[i][ii].axis('off')\n",
        "\n",
        "          iii+=1\n",
        "    #   if iii == 11 : break\n",
        "\n",
        "\n",
        "\n",
        "# def show_im(models, names, im, truth):\n",
        "#   i1=0\n",
        "#   for i,model in enumerate(models):\n",
        "#     try:\n",
        "#       plt.imshow(highlight(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)), truth))\n",
        "#     except:\n",
        "#       #For weird u2 net stuff\n",
        "#       plt.imshow(highlight(np.round(model.predict(im.reshape(1, tileSize, tileSize, 3))[0].reshape(tileSize, tileSize)), truth))\n",
        "\n",
        "#     plt.title(names[i], size=20)\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "#     if i==4:\n",
        "#       i1+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ri94BcWlJo"
      },
      "outputs": [],
      "source": [
        "index = 10\n",
        "\n",
        "show_im([fcn_tall, u2net_tall, swin_tall, res50, r2_unet_256, resUNet, model_amu_tall, unet_plus, aresUNet, model_unet_tall],\n",
        "        [\"FCN32-VGG\", \"U^2 Net\", \"Swin U-Net\", \"ResNet50SegNet\", \"R2 U-Net\", \"Res U-Net\", \"Attention U-Net\", \"U-Net++\", \"Attention Res U-Net\", \"U-Net\"], all_ims[index], all_msks[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Idt2UzArT4Pz"
      },
      "outputs": [],
      "source": [
        "print(range(4))\n",
        "\n",
        "for i in range(4):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdTqtvcKNqNE"
      },
      "outputs": [],
      "source": [
        "fig, unet_axs = plt.subplots(1, 1, figsize=(8,4))\n",
        "unet_axs.set_title(\"Ground Reference\", size=30)\n",
        "unet_axs.set_aspect('equal')\n",
        "unet_axs.axis('off')\n",
        "\n",
        "unet_axs.imshow(all_msks[index].reshape(tileSize, tileSize))\n",
        "unet_axs.imshow(all_ims[index].reshape(tileSize, tileSize, 3), alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtSKdL3NWzF3"
      },
      "outputs": [],
      "source": [
        "all_msks = load_and_split_image('labels/paramo_label_final/short_mask_new.tif', 512, offset=(5000,13192), channels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezw1WihtuW7Y"
      },
      "outputs": [],
      "source": [
        "index = 87\n",
        "plt.imshow(all_ims[index])\n",
        "plt.show()\n",
        "plt.imshow(all_msks[index].reshape(tileSize, tileSize))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvNzilwFWspZ"
      },
      "outputs": [],
      "source": [
        "index = 87\n",
        "\n",
        "show_im([fcn_short, swin_short, u2net_short, model_unet_short, r2_unet_256_short, unet_plus_short, res50_short, resUNet_short, model_amu_short, aresUNet_short],\n",
        "        [\"FCN32-VGG\", \"Swin U-Net\", \"U^2 Net\", \"U-Net\", \"R2 U-Net\", \"U-Net++\", \"ResNet50SegNet\", \"Res U-Net\", \"Attention U-Net\", \"Attention Res U-Net\"], all_ims[index], all_msks[index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CMMIfDsoTXc"
      },
      "outputs": [],
      "source": [
        "fig, unet_axs = plt.subplots(1, 1, figsize=(8,4))\n",
        "unet_axs.set_title(\"Ground Truth\", size=20)\n",
        "unet_axs.set_aspect('equal')\n",
        "unet_axs.axis('off')\n",
        "\n",
        "unet_axs.imshow(all_msks[index].reshape(tileSize, tileSize))\n",
        "unet_axs.imshow(all_ims[index].reshape(tileSize, tileSize, 3), alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq5U7nejcz5K"
      },
      "outputs": [],
      "source": [
        "for i,im in enumerate(all_msks):\n",
        "    if 1 in im:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7m9hR3d89QL",
        "outputId": "30721511-5648-49ec-9717-f75190552fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vNdL3ivE4jo"
      },
      "outputs": [],
      "source": [
        "plt.imshow(all_msks[2].reshape(tileSize, tileSize))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ32H8GqWBAB"
      },
      "source": [
        "## **Mis-classification examples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2AkeyhiWNST"
      },
      "source": [
        "### **Tall plants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MiUESgkV9xn"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# CHANGE COLOUR OF TALL PLANTS\n",
        "# CHANGE COLOUR OF SHORT PLANTS\n",
        "\n",
        "# THEN COMBINE\n",
        "\n",
        "selection = [ 82, 82, 55 ]\n",
        "models = [ model_unet_tall, aresUNet_short ]\n",
        "tall = load_and_split_image('labels/paramo_label_final/tall_mask_new.tif', tileSize, offset=(5000,13192), channels=1)\n",
        "short = load_and_split_image('labels/paramo_label_final/short_mask_new.tif', tileSize, offset=(5000,13192), channels=1)\n",
        "masks = [tall, short]\n",
        "\n",
        "# all_ims[index], all_msks[index]\n",
        "col = 3\n",
        "row = 2\n",
        "fig, tall_axs = plt.subplots(row, col, figsize=(32,32))\n",
        "fig.subplots_adjust(wspace=0.1, hspace=-0.50)\n",
        "# fig.subplots_adjust(wspace=0.01, hspace=0.01, bottom=0.01)\n",
        "# fig.tight_layout()\n",
        "\n",
        "# for index,i in enumerate(selection):\n",
        "#     tall_axs[index].imshow(highlight(np.round(u2net_tall.predict(xTest[i].reshape(1, tileSize, tileSize, 3))[0].reshape(tileSize, tileSize)), yTestTall[i]))\n",
        "#     tall_axs[index].imshow(xTest[i].reshape(tileSize, tileSize, 3), alpha=0.5)\n",
        "#     tall_axs[index].axis('off')\n",
        "\n",
        "tall_axs[0][0].set_title(\"Images\", size=30)\n",
        "tall_axs[0][1].set_title(\"Prediction\", size=30)\n",
        "tall_axs[0][2].set_title(\"Evaluation\", size=30)\n",
        "\n",
        "tall_axs[0][0].set_ylabel(\"Best tall\", fontsize=30)\n",
        "tall_axs[1][0].set_ylabel(\"Best short\", fontsize=30)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(row):\n",
        "    print(i)\n",
        "    tall_axs[i][0].imshow(all_ims[selection[i]])\n",
        "\n",
        "for i in range(row):\n",
        "    tall_axs[i][0].set_yticklabels([])\n",
        "    tall_axs[i][1].set_yticklabels([])\n",
        "    tall_axs[i][2].set_yticklabels([])\n",
        "\n",
        "    tall_axs[i][0].set_xticks([])\n",
        "    tall_axs[i][1].set_xticks([])\n",
        "    tall_axs[i][2].set_xticks([])\n",
        "\n",
        "    tall_axs[i][0].set_xticklabels([])\n",
        "    tall_axs[i][1].set_xticklabels([])\n",
        "    tall_axs[i][2].set_xticklabels([])\n",
        "\n",
        "    tall_axs[i][0].set_yticks([])\n",
        "    tall_axs[i][1].set_yticks([])\n",
        "    tall_axs[i][2].set_yticks([])\n",
        "\n",
        "    # if i >= len(models):\n",
        "\n",
        "    #     pred1 = np.round(models[0].predict(all_ims[selection[len(selection)-1]].reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize))\n",
        "    #     pred2 = np.round(models[1].predict(all_ims[selection[len(selection)-1]].reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize))\n",
        "\n",
        "    #     image1 = pred1.flatten()\n",
        "    #     image2 = pred2.flatten()\n",
        "\n",
        "    #     image3 = np.zeros((512*512, 3), float)\n",
        "\n",
        "    #     for ii, pix in enumerate(image1):\n",
        "    #         if pix == 1 or image2[ii] == 1:\n",
        "    #             image3[ii] = [((0)%2*0.8), 0.7, (0%2*0.8)]\n",
        "    #         if image2[ii] == 1:\n",
        "    #             image3[ii] = [((1)%2*0.8), 0.7, (1%2*0.8)]\n",
        "\n",
        "\n",
        "    #     # Combining highlights\n",
        "    #     image1pt = highlight(pred1, masks[0][len(selection)-1]).reshape(512*512, 3)\n",
        "    #     image2pt = highlight(pred2, masks[1][len(selection)-1]).reshape(512*512, 3)\n",
        "\n",
        "    #     image3pt = np.zeros((512*512, 3), float)\n",
        "\n",
        "    #     for ii, pix in enumerate(image1pt):\n",
        "    #         if 1 in pix or 1 in image2pt[ii]:\n",
        "    #             image3pt[ii] = [1, 1, 1]\n",
        "    #             continue\n",
        "    #         if 0 not in pix:\n",
        "    #             image3pt[ii] = [((0)%2*0.8), 0.7, (0%2*0.8)]\n",
        "    #         if 0 not in image2pt[ii]:\n",
        "    #             image3pt[ii] = [((1)%2*0.8), 0.7, (1%2*0.8)]\n",
        "\n",
        "\n",
        "    #     tall_axs[2][1].imshow(image3.reshape(tileSize, tileSize, 3))\n",
        "    #     tall_axs[2][2].imshow(image3pt.reshape(tileSize, tileSize, 3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # else:\n",
        "    pred = np.round(models[i].predict(all_ims[selection[i]].reshape(1, tileSize, tileSize, 3))).reshape(tileSize, tileSize, 1)\n",
        "    new = np.zeros((tileSize*tileSize, 3), float)\n",
        "\n",
        "    for ii, pix in enumerate(pred.flatten()):\n",
        "        if 1 == pix:\n",
        "            new[ii] = [1, 1, 1]\n",
        "\n",
        "    tall_axs[i][1].imshow(new.reshape(tileSize, tileSize, 3))\n",
        "    tall_axs[i][2].imshow(highlight(np.round(models[i].predict(all_ims[selection[i]].reshape(1, tileSize, tileSize, 3))), masks[i%2][selection[i]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ELg-IRpDHgp"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.round(models[1].predict(xTest[selection[len(selection)-1]].reshape(1, tileSize, tileSize, 3)).reshape(tileSize, tileSize)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf7nIlA09Mhv"
      },
      "outputs": [],
      "source": [
        "plt.imshow(xTest[12])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "84pQFCMkwyEi",
        "9bMTSXO5xTTb",
        "MCBtnut5Ftjn",
        "IKKP20ENHZ2S",
        "hmaqrSN05VgT",
        "SzrN0bSOH9Y4",
        "8OuWrCJvtv70",
        "yy5OcOL8048_",
        "r17kF2p111Hl",
        "ss57ZlJYp4dz",
        "mgd0GLWyKta3",
        "F-o5c_auKvyF",
        "4gGjJcklKztE",
        "gAAmkWbPHbGV",
        "afXSl7YrIlGD",
        "CbLTQG0pIlu8",
        "CWECfnNdJjqk",
        "fPmfN9SSKBbD",
        "rUdhW6ujKT8m",
        "1GFg0Pq2QQdG",
        "ArcD9FpmQVZv",
        "owFzqlX7QjTQ",
        "erChjVtnUvkX",
        "oIsW5rk6--7W",
        "uPm_Kc4bJQIG",
        "YNk7RDAzttBH",
        "mxN0EnehJUQ6",
        "eYfUFe0Y6Vy7",
        "7LIj067f7PSY",
        "vpGU0A5bqkbS",
        "KIl_zUX1u7Rr",
        "t9BWIqlECYcf",
        "I23KBxyMoHwA",
        "7vRSWrhaRarr",
        "PFwdONeNRdIc",
        "bocU-yUi4eas"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}